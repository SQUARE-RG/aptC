Description: <short summary of the patch>
 TODO: Put a short summary on the line above and replace this paragraph
 with a longer explanation of this change. Complete the meta-information
 with other relevant fields (see below for details). To make it easier, the
 information below has been extracted from the changelog. Adjust it or drop
 it.
 .
 aptc (1.0-1) UNRELEASED; urgency=medium
 .
   * Initial release (Closes: #nnnn)  <nnnn is the bug number of your ITP>
Author: unknown <txz@unknown>

---
The information above should follow the Patch Tagging Guidelines, please
checkout http://dep.debian.net/deps/dep3/ to learn about the format. Here
are templates for supplementary fields that you might want to add:

Origin: <vendor|upstream|other>, <url of original patch>
Bug: <url in upstream bugtracker>
Bug-Debian: https://bugs.debian.org/<bugnumber>
Bug-Ubuntu: https://launchpad.net/bugs/<bugnumber>
Forwarded: <no|not-needed|url proving that it has been forwarded>
Reviewed-By: <name and email of someone who approved the patch>
Last-Update: 2024-08-08

--- aptc-1.0.orig/README.md
+++ aptc-1.0/README.md
@@ -8,7 +8,7 @@ docker run --name aptc -v <项目位置>
 进入docker后，在docker内执行:
 ```
 /usr/bin/apt update
-/usr/bin/apt -y install python3 python3-pip python3-loguru python3-pycurl python3-certifi python3-wget python3-lz4 python3-magic python3-packaging python3-rarfile python3-numpy
+/usr/bin/apt -y install python3 python3-pip python3-loguru python3-pycurl python3-certifi python3-wget python3-lz4 python3-magic python3-packaging python3-rarfile python3-numpy python3-license-expression
 pip3 install spdx-tools
 pip3 install cyclonedx-bom
 pip3 install cyclonedx-python-lib
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/__init__.py
@@ -0,0 +1,207 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype.**
+
+For :pep:`8` compliance, this namespace exposes a subset of the metadata
+constants published by the :mod:`beartype.meta` submodule. These metadata
+constants are commonly inspected (and thus expected) by external automation.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Consider significantly expanding the above module docstring, assuming
+#Sphinx presents this module in its generated frontmatter.
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: Explicitly list *ALL* public attributes imported below in the
+# "__all__" list global declared below to avoid linter complaints.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To avoid race conditions during setuptools-based installation, this
+# module may import *ONLY* from modules guaranteed to exist at the start of
+# installation. This includes all standard Python and package submodules but
+# *NOT* third-party dependencies, which if currently uninstalled will only be
+# installed at some later time in the installation. Likewise, to avoid circular
+# import dependencies, the top-level of this module should avoid importing
+# package submodules where feasible.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+# ....................{ IMPORTS ~ meta                     }....................
+# For PEP 8 compliance, versions constants expected by external automation are
+# imported under their PEP 8-mandated names.
+from beartype.meta import VERSION as __version__
+from beartype.meta import VERSION_PARTS as __version_info__
+
+# ....................{ IMPORTS ~ non-meta                 }....................
+from sys import modules as _modules
+
+# If this submodule is being imported at install time from our top-level
+# "setup.py" script, avoid implicitly importing from *ANY* "beartype" submodule
+# other than the "beartype.meta" submodule. By sheer force of will,
+# "beartype.meta" is the *ONLY* "beartype" submodule guaranteed to be safely
+# importable at install time. All other "beartype" submodules should be assumed
+# to be unsafe due to potentially importing one or more optional runtime
+# dependencies yet to be installed (e.g., "typing_extensions").
+#
+# See "setup.py" for gruesome details you do *NOT* want to know about.
+if 'beartype.__is_installing__' not in _modules:
+    # Publicize the private @beartype._decor.beartype decorator as
+    # @beartype.beartype, preserving all implementation details as private.
+    from beartype._decor.decormain import (
+        beartype as beartype)
+
+    # Publicize all top-level configuration attributes required to configure the
+    # @beartype.beartype decorator.
+    from beartype._conf.confcls import (
+        BeartypeConf as BeartypeConf)
+    from beartype._conf.confenum import (
+        BeartypeStrategy as BeartypeStrategy,
+        BeartypeViolationVerbosity as BeartypeViolationVerbosity,
+    )
+    from beartype._conf.confoverrides import (
+        BeartypeHintOverrides as BeartypeHintOverrides)
+# Else, this submodule is *NOT* being imported at install time.
+
+# Delete the temporarily imported "sys.modules" global for ultimate safety.
+del _modules
+
+# ....................{ GLOBALS                           }....................
+# Document all global variables imported into this namespace above.
+
+__version__ = __version__
+'''
+Human-readable package version as a ``.``-delimited string.
+
+For PEP 8 compliance, this specifier has the canonical name ``__version__``
+rather than that of a typical global (e.g., ``VERSION_STR``).
+'''
+
+
+__version_info__ = __version_info__
+'''
+Machine-readable package version as a tuple of integers.
+
+For PEP 8 compliance, this specifier has the canonical name
+``__version_info__`` rather than that of a typical global (e.g.,
+``VERSION_PARTS``).
+'''
+
+
+__all__ = [
+    'BeartypeConf',
+    'BeartypeHintOverrides',
+    'BeartypeStrategy',
+    'BeartypeViolationVerbosity',
+    'beartype',
+    '__version__',
+    '__version_info__',
+]
+'''
+Special list global of the unqualified names of all public package attributes
+explicitly exported by and thus safely importable from this package.
+
+Caveats
+-------
+**This global is defined only for conformance with static type checkers,** a
+necessary prerequisite for :pep:`561`-compliance. This global is *not* intended
+to enable star imports of the form ``from beartype import *`` (now largely
+considered a harmful anti-pattern by the Python community), although it
+technically does the latter as well.
+
+This global would ideally instead reference *only* a single package attribute
+guaranteed *not* to exist (e.g., ``'STAR_IMPORTS_CONSIDERED_HARMFUL'``),
+effectively disabling star imports. Since doing so induces spurious static
+type-checking failures, we reluctantly embrace the standard approach. For
+example, :mod:`mypy` emits an error resembling:
+
+    error: Module 'beartype' does not explicitly export attribute 'beartype';
+    implicit reexport disabled.
+'''
+
+# ....................{ DEPRECATIONS                       }....................
+def __getattr__(attr_deprecated_name: str) -> object:
+    '''
+    Dynamically retrieve a deprecated attribute with the passed unqualified
+    name from this submodule and emit a non-fatal deprecation warning on each
+    such retrieval if this submodule defines this attribute *or* raise an
+    exception otherwise.
+
+    The Python interpreter implicitly calls this :pep:`562`-compliant module
+    dunder function under Python >= 3.7 *after* failing to directly retrieve an
+    explicit attribute with this name from this submodule. Since this dunder
+    function is only called in the event of an error, neither space nor time
+    efficiency are a concern here.
+
+    Parameters
+    ----------
+    attr_deprecated_name : str
+        Unqualified name of the deprecated attribute to be retrieved.
+
+    Returns
+    ----------
+    object
+        Value of this deprecated attribute.
+
+    Warns
+    ----------
+    DeprecationWarning
+        If this attribute is deprecated.
+
+    Raises
+    ----------
+    AttributeError
+        If this attribute is unrecognized and thus erroneous.
+    '''
+
+    # Isolate imports to avoid polluting the module namespace.
+    from beartype._util.module.utilmoddeprecate import deprecate_module_attr
+
+    # Package scope (i.e., dictionary mapping from the names to values of all
+    # non-deprecated attributes defined by this package).
+    attr_nondeprecated_name_to_value = globals()
+
+    # If this deprecated attribute is the deprecated "beartype.abby" submodule,
+    # forcibly import the non-deprecated "beartype.door" submodule aliased to
+    # "beartype.abby" into this package scope. For efficiency, this package does
+    # *NOT* unconditionally import and expose the "beartype.door" submodule
+    # above. That submodule does *NOT* exist in the globals() dictionary
+    # defaulted to above and *MUST* now be forcibly injected there.
+    if attr_deprecated_name == 'abby':
+        from beartype import door
+        attr_nondeprecated_name_to_value = {'door': door}
+        attr_nondeprecated_name_to_value.update(globals())
+    #FIXME: To support attribute-based deferred importation ala "lazy loading"
+    #of heavyweight subpackages like "beartype.door" and "beartype.vale", it
+    #looks like we'll need to manually add support here for that: e.g.,
+    #    elif attr_deprecated_name in {'cave', 'claw', 'door', 'vale',}:
+    #        #FIXME: Dynamically import this attribute here... somehow. Certainly, if
+    #        #such functionality does *NOT* exist, add it to the existing
+    #        #"utilmodimport" submodule: e.g.,
+    #        attr_value = import_module_attr(f'beartype.{attr_deprecated_name}')
+    #        attr_nondeprecated_name_to_value = {attr_deprecated_name: attr_value}
+    #FIXME: Rename "attr_deprecated_name" to merely "attr_name", please.
+    #FIXME: Revise docstring accordingly, please.
+    #FIXME: Exhaustively test this, please. Because we'll never manage to keep
+    #this in sync, we *ABSOLUTELY* should author a unit test that:
+    #* Decides the set of all public subpackages of "beartype".
+    #* Validates that each subpackage in this set is accessible as a
+    #  "beartype.{subpackage_name}" attribute.
+
+    # Else, this deprecated attribute is any other attribute.
+
+    # Return the value of this deprecated attribute and emit a warning.
+    return deprecate_module_attr(
+        attr_deprecated_name=attr_deprecated_name,
+        attr_deprecated_name_to_nondeprecated_name={
+            'abby': 'door',
+        },
+        attr_nondeprecated_name_to_value=attr_nondeprecated_name_to_value,
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_cave/_caveabc.py
@@ -0,0 +1,146 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+:mod:`beartype.cave`-specific **abstract base classes (ABCs).**
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Refactor this private submodule into a new public "beartype.caver"
+#submodule, so-named as it enables users to externally create new ad-hoc
+#protocols implementing structural subtyping resembling those predefined by
+#"beartype.cave". To do so:
+#
+#* In the "beartype.caver" submodule:
+#  * Define a new make_type_structural() function with signature resembling:
+#    def make_type_structural(name: str, method_names: Iterable) -> type:
+#  * Implement this function to dynamically create a new type with the passed
+#    classname defining:
+#    * Abstract methods with the passed method names.
+#    * A __subclasshook__() dunder method checking the passed class for
+#      concrete methods with these names.
+#    To do so, note that abstract methods *CANNOT* be dynamically
+#    monkey-patched in after class creation but *MUST* instead be statically
+#    defined at class creation time (due to metaclass shenanigans).
+#    Fortunately, doing so is trivial; simply use the three-argument form of
+#    the type() constructor, as demonstrated by this StackOverflow answer:
+#    https://stackoverflow.com/a/14219244/2809027
+#  * *WAIT!* There's no need to call the type() constructor directly. Instead,
+#    define a new make_type() function in this new submodule copied from the
+#    betse.util.type.classes.define_class() function (but renamed, obviously).
+#* Replace the current manual definition of "_BoolType" below with an in-place
+#  call to that method from the "beartype.cave" submodule: e.g.,
+#    BoolType = _make_type_structural(
+#        name='BoolType', method_names=('__bool__',))
+#
+#Dis goin' be good.
+#FIXME: Actually, don't do any of the above. That would simply be reinventing
+#the wheel, as the "typing.Protocol" superclass already exists and is more than
+#up to the task. In fact, once we drop support for Python < 3.7, we should:
+#* Redefine the "_BoolType" class declared below should in terms of the
+#  "typing.Protocol" superclass.
+#* Shift the "_BoolType" class directly into the "beartype.cave" submodule.
+#* Refactor away this entire submodule.
+
+# ....................{ IMPORTS                            }....................
+from abc import ABCMeta, abstractmethod
+
+# ....................{ FUNCTIONS                          }....................
+def _check_methods(C: type, *methods: str):
+    '''
+    Private utility function called by abstract base classes (ABCs) implementing
+    structural subtyping by detecting whether the passed class or some
+    superclass of that class defines all of the methods with the passed method
+    names.
+
+    For safety, this function has been duplicated as is from its eponymous
+    counterpart in the private stdlib :mod:`_colletions_abc` module.
+
+    Parameters
+    ----------
+    C : type
+        Class to be validated as defining these methods.
+    methods : Tuple[str, ...]
+        Tuple of the names of all methods to validate this class as defining.
+
+    Returns
+    ----------
+    Either:
+
+        * ``True`` if this class defines all of these methods.
+        * ``NotImplemented`` if this class fails to define one or more of these
+          methods.
+    '''
+
+    mro = C.__mro__
+    for method in methods:
+        for B in mro:  # pyright: ignore[reportGeneralTypeIssues]
+            if method in B.__dict__:
+                if B.__dict__[method] is None:
+                    return NotImplemented
+                break
+        else:
+            return NotImplemented
+
+    return True
+
+# ....................{ SUPERCLASSES                       }....................
+class BoolType(object, metaclass=ABCMeta):
+    '''
+    Type of all **booleans** (i.e., objects defining the ``__bool__()`` dunder
+    method; objects reducible in boolean contexts like ``if`` conditionals to
+    either ``True`` or ``False``).
+
+    This type matches:
+
+    * **Builtin booleans** (i.e., instances of the standard :class:`bool` class
+      implemented in low-level C).
+    * **NumPy booleans** (i.e., instances of the :class:`numpy.bool_` class
+      implemented in low-level C and Fortran) if :mod:`numpy` is importable.
+
+    Usage
+    ----------
+    Non-standard boolean types like NumPy booleans are typically *not*
+    interoperable with the standard standard :class:`bool` type. In particular,
+    it is typically *not* the case, for any variable ``my_bool`` of
+    non-standard boolean type and truthy value, that either ``my_bool is True``
+    or ``my_bool == True`` yield the desired results. Rather, such variables
+    should *always* be coerced into the standard :class:`bool` type before
+    being compared -- either:
+
+    * Implicitly (e.g., ``if my_bool: pass``).
+    * Explicitly (e.g., ``if bool(my_bool): pass``).
+
+    Caveats
+    ----------
+    **There exists no abstract base class governing booleans in Python.**
+    Although various Python Enhancement Proposals (PEPs) were authored on the
+    subject, all were rejected as of this writing. Instead, this type trivially
+    implements an ad-hoc abstract base class (ABC) detecting objects satisfying
+    the boolean protocol via structural subtyping. Although no actual
+    real-world classes subclass this :mod:`beartype`-specific ABC, the
+    detection implemented by this ABC suffices to match *all* boolean types.
+
+    See Also
+    ----------
+    :class:`beartype.cave.ContainerType`
+        Further details on structural subtyping.
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    # This abstract base class (ABC) has been implemented ala standard
+    # container ABCs in the private stdlib "_collections_abc" module (e.g., the
+    # trivial "_collections_abc.Sized" type).
+    __slots__ = ()
+
+    @abstractmethod
+    def __bool__(self):
+        return False
+
+    @classmethod
+    def __subclasshook__(cls, C):
+        if cls is BoolType:
+            return _check_methods(C, '__bool__')
+        return NotImplemented
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_cave/_cavefast.py
@@ -0,0 +1,1558 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype fast cave** (i.e., private subset of the public :mod:`beartype.cave`
+subpackage profiled to be efficiently importable at :mod:`beartype` startup and
+thus safely importable throughout the internal :mod:`beartype` codebase).
+
+The public :mod:`beartype.cave` subpackage has been profiled to *not* be
+efficiently importable at :mod:`beartype` startup and thus *not* safely
+importable throughout the internal :mod:`beartype` codebase. Why? Because
+:mod:`beartype.cave` currently imports from expensive third-party packages on
+importation (e.g., :mod:`numpy`) despite :mod:`beartype` itself *never*
+requiring those imports. Until resolved, that subpackage is considered tainted.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Add types for all remaining useful "collections.abc" interfaces,
+#including:
+#* "Reversible".
+#* "AsyncIterable".
+#* "AsyncIterator".
+#* "AsyncGenerator".
+#
+#There certainly exist other "collections.abc" interfaces as well, but it's
+#unclear whether they have any practical real-world utility during type
+#checking. These include:
+#* "ByteString". (wut)
+#* Dictionary-specific views (e.g., "MappingView", "ItemsView").
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+import functools as _functools
+import numbers as _numbers
+import re as _re
+import types as _types
+import typing as _typing
+from beartype.roar import BeartypeCallUnavailableTypeException
+from beartype._cave._caveabc import BoolType
+from beartype._util.py.utilpyversion import (
+    IS_PYTHON_AT_LEAST_3_12,
+    IS_PYTHON_AT_LEAST_3_10,
+    IS_PYTHON_AT_LEAST_3_9,
+)
+from collections import deque as _deque
+from collections.abc import (
+    Collection as _Collection,
+    Container as _Container,
+    Generator as _Generator,
+    Hashable as _Hashable,
+    Iterable as _Iterable,
+    Iterator as _Iterator,
+    Mapping as _Mapping,
+    MutableMapping as _MutableMapping,
+    Sequence as _Sequence,
+    MutableSequence as _MutableSequence,
+    Set as _Set,
+    Sized as _Sized,
+)
+from enum import (
+    Enum as _Enum,
+    EnumMeta as _EnumMeta,
+)
+from io import IOBase as _IOBase
+from typing import (
+    TYPE_CHECKING,
+    Any,
+    Tuple as _TupleTyping,
+)
+
+# Note that:
+#
+# * "BuiltinMethodType" is intentionally *NOT* imported, as that type is
+#   exactly synonymous with "BuiltinFunctionType", implying C-based methods are
+#   indistinguishable from C-based functions. To prevent C-based functions from
+#   being misidentified as C-based methods, all C-based functions and methods
+#   are ambiguously identified as C-based callables.
+# * "LambdaType" is intentionally *NOT* imported, as that type is exactly
+#   synonymous with "FunctionType", implying lambdas are indistinguishable from
+#   pure-Python functions. To prevent pure-Python functions from being
+#   misidentified as lambdas, all lambdas are currently misidentified as
+#   pure-Python functions.
+#
+# These are the lesser of multiple evils.
+from types import (
+    AsyncGeneratorType as _AsyncGeneratorType,
+    BuiltinFunctionType as _BuiltinFunctionType,
+    CellType as _CellType,
+    CoroutineType as _CoroutineType,
+    FrameType as _FrameType,
+    FunctionType as _FunctionType,
+    GeneratorType as _GeneratorType,
+    GetSetDescriptorType as _GetSetDescriptorType,
+    MemberDescriptorType as _MemberDescriptorType,
+    MethodType as _MethodType,
+    ModuleType as _ModuleType,
+    TracebackType as _TracebackType,
+)
+
+# ....................{ IMPORTS ~ conditional              }....................
+#FIXME: Preserve for when we inevitably require similar logic in the future.
+
+# # Attempt to import types unavailable under Python 3.5, all of which should
+# # be passed through the intermediary _get_type_or_unavailable() helper
+# # function first before being assigned to module globals below. The
+# # docstrings for such globals should contain a sentence resembling:
+# #     **This type is unavailable under Python 3.5,** where it defaults to
+# #     :class:`UnavailableType` for safety.
+# try:
+#     _Collection = type(list[str])
+# # If this is Python 3.5, define placeholder globals of the same name.
+# except ImportError:
+#     _Collection = None
+
+# ....................{ CLASSES                            }....................
+class UnavailableType(object):
+    '''
+    **Unavailable type** (i.e., type *not* available under the active Python
+    interpreter, typically due to insufficient Python version or non-installed
+    third-party dependencies).
+    '''
+
+    def __instancecheck__(self, obj) -> None:
+        raise BeartypeCallUnavailableTypeException(
+            f'{self} not passable as the second parameter to isinstance().')
+
+    def __subclasscheck__(self, cls) -> None:
+        raise BeartypeCallUnavailableTypeException(
+            f'{self} not passable as the second parameter to issubclass().')
+
+
+# This is private, as it's unclear whether anyone requires access to this yet.
+class _UnavailableTypesTuple(tuple):
+    '''
+    Type of any **tuple of unavailable types** (i.e., types *not* available
+    under the active Python interpreter, typically due to insufficient Python
+    version or non-installed third-party dependencies).
+    '''
+
+    pass
+
+# ....................{ TYPES ~ core                       }....................
+AnyType = object
+'''
+Type of all objects regardless of type.
+'''
+
+
+ClassType = type
+'''
+Type of all types.
+'''
+
+
+FileType = _IOBase
+'''
+Abstract base class of all **file-like objects** (i.e., objects implementing
+the standard ``read()``, ``write()``, and ``close()`` methods).
+'''
+
+
+ModuleType = _ModuleType
+'''
+Type of all **C- and Python-based modules** (i.e., importable files implemented
+either as C extensions or in pure Python).
+'''
+
+# ....................{ TYPES ~ core : singleton           }....................
+EllipsisType: type = type(Ellipsis)
+'''
+Type of the :data:`Ellipsis` singleton.
+'''
+
+
+NoneType: type = type(None)
+'''
+Type of the :data:`None` singleton.
+
+Curiously, although the type of the :data:`None` object is a class object whose
+``__name__`` attribute is ``NoneType``, there exists no globally accessible
+class by that name. To circumvents this obvious oversight, this global globally
+exposes this class.
+
+This class is principally useful for annotating both:
+
+* Callable parameters accepting :data:`None` as a valid value.
+* Callables returning :data:`None` as a valid value.
+
+Note that, for obscure and uninteresting reasons, the standard :mod:`types`
+module defined the same type with the same name under Python 2.x but *not* 3.x.
+Depressingly, this type must now be manually redefined everywhere.
+'''
+
+
+# Define this type as either...
+NotImplementedType: type = (
+    # If the active Python interpreter targets at least Python >= 3.10 and thus
+    # exposes this type in the standard "types" module, this type;
+    _types.NotImplementedType  # type: ignore[assignment,attr-defined]
+    if IS_PYTHON_AT_LEAST_3_10 else
+    # Else, this type manually introspected from this builtin singleton.
+    type(NotImplemented)  # type: ignore[misc]
+)
+'''
+Type of the :data:`NotImplemented` singleton.
+'''
+
+# ....................{ TYPES ~ call                       }....................
+CallableCodeObjectType: Any = type((lambda: None).__code__)
+'''
+Type of all **code objects** (i.e., C-based objects underlying all pure-Python
+callables to which those callables are compiled for efficiency).
+'''
+
+
+# Alias this type to this standard type.
+#
+# Note that this is explicitly required for "nuitka" support, which supports
+# this standard type but *NOT* the non-standard approach used to deduce this
+# type under Python 3.7 leveraged below.
+ClosureVarCellType = _CellType
+'''
+Type of all **pure-Python closure cell variables.**
+'''
+
+# ....................{ TYPES ~ call : exception           }....................
+ExceptionTracebackType = _TracebackType
+'''
+Type of all **traceback objects** (i.e., C-based objects comprising the full
+stack traces associated with raised exceptions).
+'''
+
+
+CallableFrameType = _FrameType
+'''
+Type of all **call stack frame objects** (i.e., C-based objects
+encapsulating each call to each callable on the current call stack).
+'''
+
+# ....................{ TYPES ~ call : function            }....................
+FunctionType = _FunctionType
+'''
+Type of all **pure-Python functions** (i.e., functions implemented in Python
+*not* associated with an owning class or instance of a class).
+
+Caveats
+-------
+**This type ambiguously matches many callables not commonly associated with
+standard functions,** including:
+
+* **Lambda functions.** Of course, distinguishing between conventional named
+  functions and unnamed lambda functions would usually be seen as overly
+  specific. So, this ambiguity is *not* necessarily a bad thing.
+* **Unbound instance methods** (i.e., instance methods accessed on their
+  declaring classes rather than bound instances).
+* **Static methods** (i.e., methods decorated with the builtin
+  :func:`staticmethod` decorator, regardless of whether those methods are
+  accessed on their declaring classes or associated instances).
+
+**This type matches no callables whatsoever under some non-CPython
+interpreters,** including:
+
+* PyPy, which unconditionally compiles *all* pure-Python functions into C-based
+  functions. Ergo, under PyPy, *all* functions are guaranteed to be of the type
+  :class:`FunctionOrMethodCType` regardless of whether those functions were
+  initially defined in Python or C.
+
+See Also
+--------
+:class:`.MethodBoundInstanceOrClassType`
+    Type of all pure-Python bound instance and class methods.
+'''
+
+
+FunctionOrMethodCType = _BuiltinFunctionType
+'''
+Type of all **C-based callables** (i.e., functions and methods implemented with
+low-level C rather than high-level Python, typically either in third-party C
+extensions, official stdlib C extensions, or the active Python interpreter
+itself).
+'''
+
+# ....................{ TYPES ~ call : method : bound      }....................
+MethodBoundInstanceOrClassType = _MethodType
+'''
+Type of all **pure-Python bound instance and class methods** (i.e., methods
+implemented in pure Python, bound to either instances of classes or classes
+*and* implicitly passed those instances or classes as their first parameters).
+
+Caveats
+-------
+There exists *no* corresponding :class:`MethodUnboundInstanceType` type, as
+unbound pure-Python instance methods are ambiguously implemented as functions of
+type :class:`.FunctionType` indistinguishable from conventional functions.
+Indeed, `official documentation <PyInstanceMethod_Type documentation_>`__ for
+the ``PyInstanceMethod_Type`` C type explicitly admits that:
+
+    This instance of PyTypeObject represents the Python instance method type.
+    It is not exposed to Python programs.
+
+.. _PyInstanceMethod_Type documentation:
+   https://docs.python.org/3/c-api/method.html#c.PyInstanceMethod_Type
+'''
+
+
+#FIXME: Directly alias this to "_types.MethodWrapperType" now, please.
+# Although Python >= 3.7 now exposes an explicit method wrapper type via the
+# standard "types.MethodWrapperType" object, this is of no benefit to older
+# versions of Python. Ergo, the type of an arbitrary method wrapper guaranteed
+# to *ALWAYS* exist is obtained instead.
+MethodBoundInstanceDunderCType: Any = type(''.__add__)
+'''
+Type of all **C-based bound method wrappers** (i.e., callable objects
+implemented in low-level C, associated with special methods of builtin types
+when accessed as instance rather than class attributes).
+
+See Also
+--------
+:class:`MethodUnboundInstanceDunderCType`
+    Type of all C-based unbound dunder method wrapper descriptors.
+'''
+
+# ....................{ TYPES ~ call : method : unbound    }....................
+# Although Python >= 3.7 now exposes an explicit method wrapper type via the
+# standard "types.ClassMethodDescriptorType" object, this is of no benefit to
+# older versions of Python. Ergo, the type of an arbitrary method descriptor
+# guaranteed to *ALWAYS* exist is obtained instead.
+MethodUnboundClassCType: Any = type(dict.__dict__['fromkeys'])
+'''
+Type of all **C-based unbound class method descriptors** (i.e., callable objects
+implemented in low-level C, associated with class methods of builtin types when
+accessed with the low-level :attr:`object.__dict__` dictionary rather than as
+class or instance attributes).
+
+Despite being unbound, class method descriptors remain callable (e.g., by
+explicitly passing the intended ``cls`` objects as their first parameters).
+'''
+
+
+# Although Python >= 3.7 now exposes an explicit method wrapper type via the
+# standard "types.WrapperDescriptorType" object, this is of no benefit to older
+# versions of Python. Ergo, the type of an arbitrary method descriptor
+# guaranteed to *ALWAYS* exist is obtained instead.
+MethodUnboundInstanceDunderCType: Any = type(str.__add__)
+'''
+Type of all **C-based unbound dunder method wrapper descriptors** (i.e.,
+callable objects implemented in low-level C, associated with dunder methods of
+builtin types when accessed as class rather than instance attributes).
+
+Despite being unbound, method descriptor wrappers remain callable (e.g., by
+explicitly passing the intended ``self`` objects as their first parameters).
+
+See Also
+--------
+:class:`MethodBoundInstanceDunderCType`
+    Type of all C-based unbound dunder method wrappers.
+:class:`MethodUnboundInstanceNondunderCType`
+    Type of all C-based unbound non-dunder method descriptors.
+'''
+
+
+# Although Python >= 3.7 now exposes an explicit method wrapper type via the
+# standard "types.MethodDescriptorType" object, this is of no benefit to older
+# versions of Python. Ergo, the type of an arbitrary method descriptor
+# guaranteed to *ALWAYS* exist is obtained instead.
+MethodUnboundInstanceNondunderCType: Any = type(str.upper)
+'''
+Type of all **C-based unbound non-dunder method descriptors** (i.e., callable
+objects implemented in low-level C, associated with non-dunder methods of
+builtin types when accessed as class rather than instance attributes).
+
+Despite being unbound, method descriptors remain callable (e.g., by explicitly
+passing the intended ``self`` objects as their first parameters).
+
+See Also
+--------
+:class:`MethodUnboundInstanceDunderCType`
+    Type of all C-based unbound dunder method wrapper descriptors.
+'''
+
+
+MethodUnboundPropertyNontrivialCExtensionType = _GetSetDescriptorType
+'''
+Type of all **C extension-specific unbound non-trivial property method
+descriptors** (i.e., uncallable objects implemented in low-level C extensions,
+associated with **non-trivial property methods** (i.e., wrapping underlying
+attributes that are *not* trivially convertible to C types) of C extensions when
+accessed with the low-level :attr:`object.__dict__` dictionary rather than as
+class or instance attributes).
+'''
+
+
+MethodUnboundPropertyTrivialCExtensionType = _MemberDescriptorType
+'''
+Type of all **C extension-specific unbound trivial property method descriptors**
+(i.e., uncallable objects implemented in low-level C extensions, associated with
+**trivial property methods** (i.e., wrapping underlying attributes that are
+trivially convertible to C types) of C extensions when accessed with the
+low-level :attr:`object.__dict__` dictionary rather than as class or instance
+attributes).
+'''
+
+# ....................{ TYPES ~ call : method : decorator  }....................
+MethodDecoratorClassType = classmethod
+'''
+Type of all **C-based unbound class method descriptors** (i.e., non-callable
+instances of the builtin :class:`classmethod` decorator class implemented in
+low-level C, associated with class methods implemented in pure Python, and
+accessed with the low-level :attr:`object.__dict__` dictionary rather than as
+class or instance attributes).
+
+Caveats
+-------
+Class method objects are *only* directly accessible via the low-level
+:attr:`object.__dict__` dictionary. When accessed as class or instance
+attributes, class methods reduce to instances of the standard
+:class:`MethodBoundInstanceOrClassType` type.
+
+Class method objects are *not* callable, as their implementations fail to
+define the ``__call__`` dunder method.
+'''
+
+
+MethodDecoratorPropertyType = property
+'''
+Type of all **C-based unbound property method descriptors** (i.e., non-callable
+instances of the builtin :class:`property` decorator class implemented in
+low-level C, associated with property getter and setter methods implemented in
+pure Python, and accessed as class rather than instance attributes).
+
+Caveats
+-------
+Property objects are directly accessible both as class attributes *and* via the
+low-level :attr:`object.__dict__` dictionary. Property objects are *not*
+accessible as instance attributes, for hopefully obvious reasons.
+
+Property objects are *not* callable, as their implementations fail to define
+the ``__call__`` dunder method.
+'''
+
+
+MethodDecoratorStaticType = staticmethod
+'''
+Type of all **C-based unbound static method descriptors** (i.e., non-callable
+instances of the builtin :class:`classmethod` decorator class implemented in
+low-level C, associated with static methods implemented in pure Python, and
+accessed with the low-level :attr:`object.__dict__` dictionary rather than as
+class or instance attributes).
+
+Caveats
+-------
+Static method objects are *only* directly accessible via the low-level
+:attr:`object.__dict__` dictionary. When accessed as class or instance
+attributes, static methods reduce to instances of the standard
+:class:`FunctionType` type.
+
+Static method objects are *not* callable, as their implementations fail to
+define the ``__call__`` dunder method.
+'''
+
+# ....................{ TYPES ~ call : return : async      }....................
+AsyncGeneratorCType = _AsyncGeneratorType
+'''
+C-based type returned by all **asynchronous pure-Python generators** (i.e.,
+callables implemented in pure Python containing one or more ``yield``
+statements whose declaration is preceded by the ``async`` keyword).
+
+Caveats
+-------
+**This is not the type of asynchronous generator callables** but rather the
+type implicitly created and *returned* by these callables. Since these
+callables are simply callables subject to syntactic sugar, the type of these
+callables is simply :data:`CallableTypes`.
+'''
+
+
+AsyncCoroutineCType = _CoroutineType
+'''
+C-based type returned by all **asynchronous coroutines** (i.e., callables
+implemented in pure Python *not* containing one or more ``yield`` statements
+whose declaration is preceded by the ``async`` keyword).
+
+Caveats
+-------
+**This is not the type of asynchronous coroutine callables** but rather the
+type implicitly created and *returned* by these callables. Since these
+callables are simply callables subject to syntactic sugar, the type of these
+callables is simply :data:`CallableTypes`.
+'''
+
+# ....................{ TYPES ~ call : return : generator  }....................
+GeneratorType = _Generator
+'''
+Type of all **C- and Python-based generator objects** (i.e., iterators
+implementing the :class:`collections.abc.Generator` protocol), including:
+
+* Pure-Python subclasses of the :class:`collections.abc.Generator` superclass.
+* C-based generators returned by pure-Python callables containing one or more
+  ``yield`` statements.
+* C-based generator comprehensions created by pure-Python syntax delimited by
+  ``(`` and ``)``.
+
+Caveats
+-------
+**This is not the type of generator callables** but rather the type implicitly
+created and *returned* by these callables. Since these callables are simply
+callables subject to syntactic sugar, the type of these callables is simply
+:data:`CallableTypes`.
+
+See Also
+--------
+:class:`GeneratorCType`
+    Subtype of all C-based generators.
+'''
+
+
+GeneratorCType = _GeneratorType
+'''
+C-based type returned by all **pure-Python generators** (i.e., callables
+implemented in pure Python containing one or more ``yield`` statements,
+implicitly converted at runtime to return a C-based iterator of this type) as
+well as the C-based type of all **pure-Python generator comprehensions** (i.e.,
+``(``- and ``)``-delimited syntactic sugar implemented in pure Python, also
+implicitly converted at runtime to return a C-based iterator of this type).
+
+Caveats
+-------
+**This is not the type of generator callables** but rather the type implicitly
+created and *returned* by these callables. Since these callables are simply
+callables subject to syntactic sugar, the type of these callables is simply
+:data:`CallableTypes`.
+
+This special-purpose type is a subtype of the more general-purpose
+:class:`GeneratorType`. Whereas the latter applies to *all* generators
+implementing the :class:`collections.abc.Iterator` protocol, the former only
+applies to generators implicitly created by Python itself.
+'''
+
+# ....................{ TYPES ~ call : module : functools  }....................
+CallableFunctoolsPartialType = _functools.partial
+'''
+Pure-Python type of all **partial callables** (i.e., possibly C-based callable
+wrapped by the pure-Python callable :class:`functools.partial` type).
+
+Caveats
+-------
+This type does *not* distinguish between whether the original callable wrapped
+by :class:`functools.partial` is C-based or pure Python -- only that some
+callable of indeterminate origin is in fact wrapped.
+'''
+
+
+@_functools.lru_cache
+def _lru_cache_func(n: int) -> int:
+    '''
+    Arbitrary :func:`functools.lru_cache`-memoized function defined solely to
+    inspect various dunder attributes common to all such functions.
+    '''
+
+    return n + 1
+
+
+# If this submodule is currently being statically type-checked by a pure static
+# type-checker, ignore false positives complaining that this type is not a type.
+if TYPE_CHECKING:
+    class CallableFunctoolsLruCacheType(object): pass
+# Else, this submodule is *NOT* currently being statically type-checked by a
+# pure static type-checker. In this case, define this type properly. *sigh*
+else:
+    CallableFunctoolsLruCacheType = type(_lru_cache_func)
+    '''
+    C-based type of all low-level private objects created and returned by the
+    :func:`functools.lru_cache` decorator (e.g.,
+    :class:`functools._lru_cache_wrapper`).
+
+    This type enables functionality elsewhere to reliably detect when a callable
+    has been decorated by that decorator.
+    '''
+# print(f'LRU_CACHE_TYPE: {LRU_CACHE_TYPE}')
+
+
+# Delete temporary private callables defined above as a negligible safety (and
+# possible space complexity) measure.
+del _lru_cache_func
+
+# ....................{ TYPES ~ class                      }....................
+# If this submodule is currently being statically type-checked by a pure static
+# type-checker, ignore false positives complaining that this type is not a type.
+if TYPE_CHECKING:
+    class ClassDictType(object): pass
+# Else, this submodule is *NOT* currently being statically type-checked by a
+# pure static type-checker. In this case, define this type properly. *sigh*
+else:
+    ClassDictType = type(type.__dict__)
+    '''
+    Type of all **pure-Python class dictionaries** (i.e., immutable mappings
+    officially referred to as "mapping proxies," whose keys are strictly
+    constrained for both efficiency and correctness to be Python identifier
+    strings).
+    '''
+
+# ....................{ TYPES ~ data                       }....................
+ContainerType = _Container
+'''
+Type of all **containers** (i.e., concrete instances of the abstract
+:class:`collections.abc.Container` base class as well as arbitrary objects
+whose classes implement all abstract methods declared by that base class
+regardless of whether those classes actually subclass that base class).
+
+Caveats
+-------
+This type ambiguously matches both:
+
+* **Explicit container subtypes** (i.e., concrete subclasses of the
+  :class:`collections.abc.Container` abstract base class (ABC)).
+* **Structural container subtypes** (i.e., arbitrary classes implementing the
+  abstract ``__contains__`` method declared by that ABC *without* subclassing
+  that ABC), as formalized by :pep:`544`. Notably, since the **NumPy array
+  type** (i.e., :class:`numpy.ndarray`) defines that method, this type magically
+  matches the NumPy array type as well.
+
+Of course, distinguishing between explicit and structural subtypes would
+usually be seen as overly specific. So, this ambiguity is *not* necessarily a
+BadThing™.
+
+What is a BadThing™ is that container ABCs violate the "explicit is better than
+implicit" maxim of :pep:`20` by intentionally deceiving you for your own
+benefit, which you of course appreciate. Thanks to arcane dunder magics buried
+in the :class:`abc.ABCMeta` metaclass, the :func:`isinstance` and
+:func:`issubclass` builtin functions (which the :func:`beartype.beartype`
+decorator internally defers to) ambiguously mistype structural container
+subtypes as explicit container subtypes:
+
+.. code-block:: pycon
+
+   >>> from collections.abc import Container
+   >>> class FakeContainer(object):
+   ...     def __contains__(self, obj): return True
+   >>> FakeContainer.__mro__
+   ... (FakeContainer, object)
+   >>> issubclass(FakeContainer, Container)
+   True
+   >>> isinstance(FakeContainer(), Container)
+   True
+'''
+
+
+IterableType = _Iterable
+'''
+Type of all **iterables** (i.e., both concrete and structural instances of the
+abstract :class:`collections.abc.Iterable` base class).
+
+Iterables are containers that may be indirectly iterated over by calling the
+:func:`iter` builtin, which internally calls the ``__iter__()`` dunder methods
+implemented by these containers, which return **iterators** (i.e., instances of
+the :class:`IteratorType` type), which directly support iteration.
+
+This type also matches **NumPy arrays** (i.e., instances of the concrete
+:class:`numpy.ndarray` class) via structural subtyping.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+:class:`IteratorType`
+    Further details on iteration.
+'''
+
+
+IteratorType = _Iterator
+'''
+Type of all **iterators** (i.e., both concrete and structural instances of
+the abstract :class:`collections.abc.Iterator` base class; objects iterating
+over associated data streams, which are typically containers).
+
+Iterators implement at least two dunder methods:
+
+* ``__next__()``, iteratively returning successive items from associated data
+  streams (e.g., container objects) until throwing standard
+  :data:`StopIteration` exceptions on reaching the ends of those streams.
+* ``__iter__()``, returning themselves. Since iterables (i.e., instances of the
+  :class:`IterableType` type) are *only* required to implement the
+  ``__iter__()`` dunder method, all iterators are by definition iterables as
+  well.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+:class:`IterableType`
+    Further details on iteration.
+'''
+
+
+SizedType = _Sized
+'''
+Type of all **sized containers** (i.e., both concrete and structural instances
+of the abstract :class:`collections.abc.Sized` base class; containers defining
+the ``__len__()`` dunder method internally called by the :func:`len` builtin).
+
+This type also matches **NumPy arrays** (i.e., instances of the concrete
+:class:`numpy.ndarray` class) via structural subtyping.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+'''
+
+
+CollectionType = _Collection
+'''
+Type of all **collections** (i.e., both concrete and structural instances of
+the abstract :class:`collections.abc.Collection` base class; sized iterable
+containers defining the ``__contains__()``, ``__iter__()``, and ``__len__()``
+dunder methods).
+
+This type also matches **NumPy arrays** (i.e., instances of the concrete
+:class:`numpy.ndarray` class) via structural subtyping.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+'''
+
+
+QueueType = _deque
+'''
+Type of all **double-ended queues** (i.e., instances of the concrete
+:class:`collections.deque` class, the only queue type defined by the Python
+stdlib).
+
+Caveats
+-------
+The :mod:`collections.abc` subpackage currently provides no corresponding
+abstract interface to formalize queue types. Double-ended queues are it, sadly.
+'''
+
+
+SetType = _Set
+'''
+Type of all **set-like containers** (i.e., both concrete and structural
+instances of the abstract :class:`collections.abc.Set` base class; containers
+guaranteeing uniqueness across all contained items).
+
+This type matches both the standard :class:`set` and :class:`frozenset` types
+*and* the types of the :class:`dict`-specific views returned by the
+:meth:`dict.items` and :meth:`dict.keys` (but *not* :meth:`dict.values`)
+methods.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+'''
+
+# ....................{ TYPES ~ data : mapping             }....................
+HashableType = _Hashable
+'''
+Type of all **hashable objects** (i.e., both concrete and structural instances
+of the abstract :class:`collections.abc.Hashable` base class; objects
+implementing the ``__hash__()`` dunder method required for all dictionary keys
+and set items).
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+'''
+
+
+MappingType = _Mapping
+'''
+Type of all **mutable** and **immutable mappings** (i.e., both concrete and
+structural instances of the abstract :class:`collections.abc.Mapping` base
+class; dictionary-like containers containing key-value pairs mapping from
+hashable keys to corresponding values).
+
+Caveats
+-------
+**This type does not guarantee mutability** (i.e., the capacity to modify
+instances of this type after instantiation). This type ambiguously matches both
+mutable mapping types (e.g., :class:`dict`) and immutable mapping types (e.g.,
+:class:`ClassDictType`). Where mutability is required, prefer the non-ambiguous
+:class:`MappingMutableType` type instead.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+'''
+
+
+MappingMutableType = _MutableMapping
+'''
+Type of all **mutable mappings** (i.e., both concrete and structural instances
+of the abstract :class:`collections.abc.MutableMapping` base class;
+dictionary-like containers permitting modification of contained key-value
+pairs).
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+:class:`MappingType`
+    Type of all mutable and immutable mappings.
+'''
+
+# ....................{ TYPES ~ data : sequence            }....................
+SequenceType = _Sequence
+'''
+Type of all **mutable** and **immutable sequences** (i.e., both concrete and
+structural instances of the abstract :class:`collections.abc.Sequence` base
+class; reversible collections whose items are efficiently accessible but *not*
+necessarily modifiable with 0-based integer-indexed lookup).
+
+Caveats
+-------
+**This type does not guarantee mutability** (i.e., the capacity to modify
+instances of this type after instantiation). This type ambiguously matches both
+mutable sequence types (e.g., :class:`list`) and immutable sequence types
+(e.g., :class:`tuple`). Where mutability is required, prefer the non-ambiguous
+:class:`SequenceMutableType` type instead.
+
+**This type matches the string type (i.e., :class:`str`),** which satisfies the
+:class:`collections.abc.Sequence` API but *not* the
+:class:`collections.abc.MutableSequence` API. Where **non-string sequences**
+(i.e., sequences that are anything but strings) are required, prefer the
+non-ambiguous :class:`SequenceMutableType` type instead.
+
+**This type does not match NumPy arrays (i.e., instances of the concrete
+:class:`numpy.ndarray` class),** which satisfy most but *not* all of the
+:class:`collections.abc.Sequence` API. Specifically, NumPy arrays fail to
+define:
+
+* The ``__reversible__`` dunder method.
+* The ``count`` public method.
+* The ``index`` public method.
+
+Most callables accepting sequences *never* invoke these edge-case methods and
+should thus be typed to accept NumPy arrays as well. To do so, prefer either:
+
+* The :class:`beartype.cave.SequenceOrNumpyArrayTypes` tuple of types matching
+  both sequences and NumPy arrays.
+* The :class:`beartype.cave.SequenceMutableOrNumpyArrayTypes` tuple of types
+  matching both mutable sequences and NumPy arrays.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+'''
+
+
+SequenceMutableType = _MutableSequence
+'''
+Type of all **mutable sequences** (i.e., both concrete and structural instances
+of the abstract :class:`collections.abc.Sequence` base class; reversible
+collections whose items are both efficiently accessible *and* modifiable with
+0-based integer-indexed lookup).
+
+Caveats
+-------
+**This type does not match NumPy arrays (i.e., instances of the concrete
+:class:`numpy.ndarray` class),** which satisfy most but *not* all of the
+:class:`collections.abc.MutableSequence` API. Specifically, NumPy arrays fail
+to define:
+
+* The ``__reversible__`` dunder method.
+* The ``append`` public method.
+* The ``count`` public method.
+* The ``extend`` public method.
+* The ``index`` public method.
+* The ``insert`` public method.
+* The ``pop`` public method.
+* The ``remove`` public method.
+* The ``reverse`` public method.
+
+Most callables accepting mutable sequences *never* invoke these edge-case
+methods and should thus be typed to accept NumPy arrays as well. To do so,
+prefer the :class:`beartype.cave.SequenceMutableOrNumpyArrayTypes` tuple of
+types matching both mutable sequences and NumPy arrays.
+
+See Also
+--------
+:class:`ContainerType`
+    Further details on structural subtyping.
+:class:`SequenceType`
+    Further details on sequences.
+'''
+
+# ....................{ TYPES ~ enum                       }....................
+# Enumeration types are sufficiently obscure to warrant formalization here.
+
+EnumType = _EnumMeta
+'''
+Type of all **enumeration types** (i.e., metaclass of all classes containing
+all enumeration members comprising those enumerations).
+
+Motivation
+----------
+This type is commonly used to validate callable parameters as enumerations. In
+recognition of its popularity, this type is intentionally named ``EnumType``
+rather than ``EnumMetaType``. While the latter *would* technically be less
+ambiguous, the former has the advantage of inviting correctness throughout
+downstream codebases -- a less abundant resource.
+
+Why? Because *all* enumeration types are instances of this type rather than the
+:class:`Enum` class despite being superficially defined as instances of the
+:class:`Enum` class. Thanks to metaclass abuse, enumeration types do *not*
+adhere to standard Pythonic semantics. Notably, the following non-standard
+invariants hold across *all* enumerations:
+
+.. code-block:: pycon
+
+   >>> from enum import Enum
+   >>> GyreType = Enum(
+   ...     'GyreType', ('THE', 'FALCON', 'CANNOT', 'HEAR', 'THE', 'FALCONER'))
+   >>> from beartype import cave
+   >>> isinstance(GyreType, Enum)
+   False
+   >>> isinstance(GyreType, cave.EnumType)
+   True
+   >>> isinstance(GyreType, cave.ClassType)
+   True
+   >>> isinstance(GyreType.FALCON, cave.EnumType)
+   False
+   >>> isinstance(GyreType.FALCON, cave.EnumMemberType)
+   True
+   >>> isinstance(GyreType.FALCON, cave.ClassType)
+   False
+
+Yes, this is insane. Yes, this is Python.
+'''
+
+
+EnumMemberType = _Enum
+'''
+Type of all **enumeration members** (i.e., abstract base class of all
+alternative choices defined as enumeration fields).
+
+Caveats
+-------
+When type checking callable parameters, this class should *only* be referenced
+where the callable permissively accepts any enumeration member type rather than
+a specific enumeration member type. In the latter case, that type is simply
+that enumeration's type and should be directly referenced as such: e.g.,
+
+.. code-block:: pycon
+
+   >>> from enum import Enum
+   >>> from beartype import beartype
+   >>> EndymionType = Enum('EndymionType', ('BEAUTY', 'JOY',))
+   >>> @beartype
+   ... def our_feet_were_soft_in_flowers(superlative: EndymionType) -> str:
+   ...     return str(superlative).lower()
+'''
+
+# ....................{ TYPES ~ hint : pep : 585           }....................
+# Define this type as either...
+HintGenericSubscriptedType: type = (
+    # If the active Python interpreter targets at least Python >= 3.9 and thus
+    # supports PEP 585, this type;
+    type(list[str])  # type: ignore[misc]
+    if IS_PYTHON_AT_LEAST_3_9 else
+    # Else, a placeholder type.
+    UnavailableType
+)
+'''
+C-based type of all subscripted generics if the active Python interpreter
+targets Python >= 3.9 *or* :class:`.UnavailableType` otherwise.
+
+This type is a version-agnostic generalization of the standard
+:class:`types.GenericAlias` type available only under Python >= 3.9. Subscripted
+generics include:
+
+* :pep:`585`-compliant **builtin type hints** (i.e., C-based type hints
+  instantiated by subscripting either a concrete builtin container class like
+  :class:`list` or :class:`tuple` *or* an abstract base class (ABC) declared by
+  the :mod:`collections.abc` submodule like :class:`collections.abc.Iterable`
+  or :class:`collections.abc.Sequence`).
+* :pep:`484`-compliant **subscripted generics** (i.e., user-defined classes
+  subclassing one or more :pep:`484`-compliant type hints subsequently
+  subscripted by one or more PEP-compliant type hints).
+* :pep:`585`-compliant **subscripted generics** (i.e., user-defined classes
+  subclassing one or more :pep:`585`-compliant type hints subsequently
+  subscripted by one or more PEP-compliant type hints).
+
+Caveats
+----------
+**This low-level type ambiguously matches semantically unrelated PEP-compliant
+type hints,** rendering this type all but useless for most practical purposes.
+To distinguish between the various semantic types of hints ambiguously matched
+by this type, higher-level PEP-specific functions *must* be called instead.
+These include:
+
+* :func:`beartype._util.hint.pep.proposal.pep484.utilpep484.is_hint_pep484_generic`,
+  detecting :pep:`484`-compliant generic type hints.
+* :func:`beartype._util.hint.pep.proposal.utilpep585.is_hint_pep585_builtin_subscripted`,
+  detecting :pep:`585`-compliant builtin type hints.
+* :func:`beartype._util.hint.pep.proposal.utilpep585.is_hint_pep585_generic`,
+  detecting :pep:`585`-compliant generic type hints.
+'''
+
+# ....................{ TYPES ~ hint : pep : 604           }....................
+# If this submodule is currently being statically type-checked by a pure static
+# type-checker, ignore false positives complaining that this type is not a type.
+if TYPE_CHECKING:
+    class HintPep604Type(object): pass
+# Else, this submodule is *NOT* currently being statically type-checked by a
+# pure static type-checker. In this case, define this type properly. *sigh*
+else:
+    # Define this type as either...
+    HintPep604Type = (
+        # If the active Python interpreter targets at least Python >= 3.10 and
+        # thus supports PEP 604, this type;
+        _types.UnionType
+        if IS_PYTHON_AT_LEAST_3_10 else
+        # Else, a placeholder type.
+        UnavailableType
+    )
+    '''
+    C-based type of all :pep:`604`-compliant **new unions** (i.e., objects
+    created by expressions of the form ``{type1} | {type2} | ... | {typeN}``) if
+    the active Python interpreter targets Python >= 3.10 *or*
+    :class:`.UnavailableType` otherwise.
+
+    This type is a version-agnostic generalization of the standard
+    :class:`types.UnionType` type available only under Python >= 3.10.
+    '''
+
+
+HintPep604Types: _TupleTyping[type, ...] = (type, HintGenericSubscriptedType)
+'''
+Tuple of all :pep:`604`-compliant **new union item types** (i.e., types of all
+objects permissible as the items of new unions), including:
+
+* The C-based type of all types (e.g., the type of the first item in the new
+  union ``list | None``).
+* The C-based type of all subscripted generics (e.g., the type of the first item
+  in the new union ``list[dict[str, int]] | None``).
+'''
+
+# ....................{ TYPES ~ hint : pep : 695           }....................
+# If this submodule is currently being statically type-checked by a pure static
+# type-checker, ignore false positives complaining that this type is not a type.
+# Notably, mypy inexplicably refuses to accept this by emitting "errors"
+# resembling the following wherever this type is accessed:
+#     beartype/_util/hint/pep/proposal/utilpep695.py:120: error: Variable
+#         "beartype._cave._cavefast.HintPep695Type" is not valid as a type
+#         [valid-type]
+#     beartype/_util/hint/pep/proposal/utilpep695.py:120: note: See
+#         https://mypy.readthedocs.io/en/stable/common_issues.html#variables-vs-type-aliases
+if TYPE_CHECKING:
+    class HintPep695Type(object): pass
+# Else, this submodule is *NOT* currently being statically type-checked by a
+# pure static type-checker. In this case, define this type properly. *sigh*
+else:
+    # Define this type as either...
+    HintPep695Type = (
+        # If the active Python interpreter targets at least Python >= 3.12 and
+        # thus supports PEP 695, this type;
+        _typing.TypeAliasType
+        if IS_PYTHON_AT_LEAST_3_12 else
+        # Else, a placeholder type.
+        UnavailableType
+    )
+    '''
+    C-based type of all :pep:`695`-compliant **type aliases** (i.e., objects
+    created by statements of the form ``type {alias_name} = {alias_value}``) if
+    the active Python interpreter targets Python >= 3.12 *or*
+    :class:`.UnavailableType` otherwise.
+
+    This type is a version-agnostic generalization of the standard
+    :class:`typing.TypeAliasType` type available only under Python >= 3.12.
+    '''
+
+# ....................{ TYPES ~ scalar                     }....................
+StrType = str    # Well, isn't that special.
+'''
+Type of all **unencoded Unicode strings** (i.e., instances of the builtin
+:class:`str` class; sequences of abstract Unicode codepoints that have yet to
+be encoded into physical encoded bytes in encoded byte strings).
+
+This type matches:
+
+* **Builtin Unicode strings** (i.e., :class:`str` instances).
+* **NumPy Unicode strings** (i.e., :class:`numpy.str_` instances) if
+  :mod:`numpy` is importable. Whereas most NumPy scalar types do *not* subclass
+  builtin scalar types, the :class:`numpy.str_` class *does* subclass the
+  builtin :class:`str` type. NumPy Unicode strings are thus usable wherever
+  builtin Unicode strings are usable.
+
+Caveats
+----------
+This type does *not* match **encoded byte strings** (i.e., sequences of
+physical encoded bytes, including the builtin :class:`bytestring` type), which
+require foreknowledge of the encoding previously used to encode those bytes.
+Unencoded Unicode strings require no such foreknowledge and are thus
+incompatible with encoded byte strings at the API level.
+
+This type only matches **builtin Unicode strings** (i.e., :class:`str`
+instances) and instances of subtypes of that type (e.g., :class:`numpy.str_`,
+the NumPy Unicode string type). Whereas the comparable :class:`BoolType`
+matches arbitrary objects satisfying the boolean protocol (i.e., ``__bool__()``
+dunder method) via structural subtyping, this type does *not* match arbitrary
+objects satisfying the string protocol via structural subtyping -- because
+there is no string protocol. While Python's data model does define a
+``__str__()`` dunder method called to implicitly convert arbitrary objects into
+strings, that method is called infrequently. As exhibited by the infamously
+rejected :pep:`3140` proposal, the :meth:`list.__str__` implementation
+stringifies list items by erroneously calling the unrelated ``__repr__()``
+method rather than the expected ``__str__()`` method on those items. Moreover,
+``__str__()`` fails to cover common string operations such as string
+concatenation and repetition. Covering those operations would require a new
+abstract base class (ABC) matching arbitrary objects satisfying the
+:class:`Sequence` protocol as well as ``__str__()`` via structural subtyping;
+while trivial, that ABC would then ambiguously match all builtin sequence types
+(e.g., :class:`list`, :class:`tuple`) as string types, which they clearly are
+not. In short, matching only :class:`str` is the *only* unambiguous means of
+matching Unicode string types.
+'''
+
+# ....................{ TYPES ~ scalar : number            }....................
+NumberType = _numbers.Number
+'''
+Type of all **numbers** (i.e., concrete instances of the abstract
+:class:`numbers.Number` base class).
+
+This type effectively matches *all* numbers regardless of implementation,
+including:
+
+* **Integers** (i.e., real numbers expressible without fractional components),
+  including:
+  * **Builtin integers** (i.e., :class:`int` instances).
+  * **NumPy integers** (e.g., :class:`numpy.int_` instances), whose types are
+    all implicitly registered at :mod:`numpy` importation time as satisfying
+    the :class:`numbers.Integral` protocol.
+  * **SymPy integers** (e.g., :class:`sympy.core.numbers.Integer` instances),
+    whose type is implicitly registered at :mod:`sympy` importation time as
+    satisfying the class:`numbers.Integral` protocol.
+* **Rational numbers** (i.e., real numbers expressible as the ratio of two
+  integers), including:
+  * **Builtin floating-point numbers** (i.e., :class:`float` instances).
+  * **NumPy floating-point numbers** (e.g., :class:`numpy.single` instances),
+    all of which are implicitly registered at :mod:`numpy` importation time as
+    :class:`numbers.Rational` subclasses.
+  * **Stdlib fractions** (i.e., :class:`fractions.Fraction` instances).
+  * **SymPy floating-point numbers** (e.g., :class:`sympy.core.numbers.Float`
+    instances), whose type implicitly registered at :mod:`sympy` importation
+    time as satisfying the class:`numbers.Real` protocol.
+  * **SymPy rational numbers** (e.g., :class:`sympy.core.numbers.Rational`
+    instances), whose type implicitly registered at :mod:`sympy` importation
+    time as satisfying the class:`numbers.Rational` protocol.
+* **Irrational numbers** (i.e., real numbers *not* expressible as the ratio of
+  two integers), including:
+  * **SymPy irrational numbers** (i.e., SymPy-specific symbolic objects whose
+    ``is_irrational`` assumption evaluates to ``True``).
+
+Caveats
+----------
+This type does *not* match:
+
+* **Stdlib decimals** (i.e., :class:`decimal.Decimal` instances), which support
+  both unrounded decimal (i.e., fixed-point arithmetic) and rounded
+  floating-point arithmetic. Despite being strictly rational, the
+  :class:`decimal.Decimal` class only subclasses the coarse-grained abstract
+  :class:`numbers.Number` base superclass rather than the fine-grained abstract
+  :class:`numbers.Rational` base subclass. So it goes.
+* **SymPy complex numbers,** which are "non-atomic" (i.e., defined as the
+  combination of two separate real and imaginary components rather than as one
+  unified complex number containing these components) and thus incommensurable
+  with all of the above "atomic" types.
+'''
+
+
+NumberRealType = IntOrFloatType = _numbers.Real
+'''
+Type of all **real numbers** (i.e., concrete instances of the abstract
+:class:`numbers.Real` base class; numbers expressible as linear values on the
+real number line).
+
+This type matches all numbers matched by :class:`NumberType` *except* complex
+numbers with non-zero imaginary components, which (as the name implies) are
+non-real.
+
+Equivalently, this type matches all integers (e.g., :class:`int`,
+:class:`numpy.int_`), floating-point numbers (e.g., :class:`float`,
+:class:`numpy.single`), rational numbers (e.g., :class:`fractions.Fraction`,
+:class:`sympy.core.numbers.Rational`), and irrational numbers. However,
+rational and irrational numbers are rarely used in comparison to integers and
+floating-point numbers. This type thus reduces to matching all integer and
+floating-point types in practice and is thus also accessible under the alias
+:class:`IntOrFloatType` -- a less accurate but more readable name than
+:class:`NumberRealType`.
+
+See Also
+----------
+:class:`NumberType`
+    Further details.
+'''
+
+
+IntType = _numbers.Integral
+'''
+Type of all **integers** (i.e., concrete instances of the abstract
+:class:`numbers.Integral` base class; real numbers expressible without
+fractional components).
+
+This type matches all numbers matched by the :class:`NumberType` *except*
+complex numbers with non-zero imaginary components, rational numbers with
+denominators not equal to one, and irrational numbers.
+
+Equivalently, this type matches all integers (e.g., :class:`int`,
+:class:`numpy.int_`).
+
+See Also
+----------
+:class:`NumberType`
+    Further details.
+'''
+
+# ....................{ TYPES ~ stdlib : re                }....................
+# Regular expression types are also sufficiently obscure to warrant
+# formalization here.
+
+# Yes, this is the only reliable means of obtaining the type of compiled
+# regular expressions. For unknown reasons presumably concerning the archaic
+# nature of Python's regular expression support, this type is *NOT* publicly
+# exposed. While the private "re._pattern_type" attribute does technically
+# provide this type, it does so in a private and hence non-portable manner.
+RegexCompiledType: type = _re.Pattern
+'''
+Type of all **compiled regular expressions** (i.e., objects created and
+returned by the stdlib :func:`re.compile` function).
+'''
+
+
+# Yes, this type is required for type validation at module scope elsewhere.
+# Yes, this is the most time-efficient means of obtaining this type. No, this
+# type is *NOT* directly importable. Although this type's classname is
+# published to be "_sre.SRE_Match", the "_sre" C extension provides no such
+# type for pure-Python importation. So it goes.
+RegexMatchType: type = _re.Match
+'''
+Type of all **regular expression match objects** (i.e., objects returned by the
+:func:`re.match` function).
+'''
+
+# ....................{ TUPLES ~ unavailable               }....................
+# Unavailable types are defined *BEFORE* any subsequent types, as the latter
+# commonly leverage the former.
+
+UnavailableTypes = _UnavailableTypesTuple()
+'''
+**Tuple of unavailable types** (i.e., types *not* available under the active
+Python interpreter, typically due to insufficient Python version or
+non-installed third-party dependencies).
+
+Caveats
+----------
+**This tuple should always be used in lieu of the empty tuple.** Although
+technically equivalent to the empty tuple, the :func:`beartype.beartype`
+decorator explicitly distinguishes between this tuple and the empty tuple.
+Specifically, for any callable parameter or return type annotated with:
+
+* This tuple, :func:`beartype.beartype` emits a non-fatal warning ignorable
+  with a simple :mod:`warnings` filter.
+* The empty tuple, :func:`beartype.beartype` raises a fatal exception.
+'''
+
+# ....................{ TUPLES ~ py                        }....................
+ModuleOrStrTypes = (ModuleType, StrType)
+'''
+Tuple of both the module *and* string type.
+'''
+
+
+#FIXME: This is probably incorrect under Python >= 3.9, where isinstance() also
+#accepts "|"-delimited unions of types (e.g., float | int | str). What are
+#those types, exactly?
+TestableTypes = (ClassType, tuple)
+'''
+Tuple of all **testable types** (i.e., types suitable for use as the second
+parameter passed to the :func:`isinstance` and :func:`issubclass` builtins).
+'''
+
+# ....................{ TUPLES ~ call                      }....................
+FunctionTypes = (FunctionType, FunctionOrMethodCType,)
+'''
+Tuple of all **function types** (i.e., types whose instances are either
+built-in or user-defined functions).
+
+Caveats
+----------
+**This tuple may yield false positives when used to validate types.** Since
+Python fails to distinguish between C-based functions and methods, this tuple
+is the set of all function types as well as the ambiguous type of all C-based
+functions and methods.
+'''
+
+# ....................{ TUPLES ~ call : method             }....................
+MethodBoundTypes = (
+    MethodBoundInstanceOrClassType, MethodBoundInstanceDunderCType)
+'''
+Tuple of all **bound method types** (i.e., types whose instances are callable
+objects bound to either instances or classes).
+'''
+
+
+MethodUnboundTypes = (
+    MethodUnboundClassCType,
+    MethodUnboundInstanceDunderCType,
+    MethodUnboundInstanceNondunderCType,
+)
+'''
+Tuple of all **unbound method types** (i.e., types whose instances are callable
+objects bound to neither instances nor classes).
+
+Unbound decorator objects (e.g., non-callable instances of the builtin
+:class:`classmethod`, :class:`property`, or :class:`staticmethod` decorator
+classes) are *not* callable and thus intentionally excluded.
+'''
+
+
+MethodDecoratorBuiltinTypes = (
+    MethodDecoratorClassType,
+    MethodDecoratorPropertyType,
+    MethodDecoratorStaticType,
+)
+'''
+Tuple of all **C-based unbound method decorator types** (i.e., builtin decorator
+types implemented in low-level C whose instances are typically uncallable,
+associated with callable methods implemented in pure Python).
+'''
+
+
+MethodDescriptorNondataTypes = (
+    MethodDecoratorClassType,
+    MethodDecoratorStaticType,
+    MethodBoundInstanceOrClassType,
+)
+'''
+Tuple of all **builtin method non-data descriptor types** (i.e., C-based
+descriptors builtin to Python defining only the ``__get__()`` dunder method,
+encapsulating read-only access to some kind of method).
+'''
+
+
+MethodDescriptorTypes = (
+    # @classmethod, @staticmethod, and @property descriptor types.
+    MethodDecoratorBuiltinTypes + (
+        # Method descriptor type.
+        MethodBoundInstanceOrClassType,
+    )
+)
+'''
+Tuple of all **builtin method descriptor types** (i.e., C-based descriptors
+builtin to Python, encapsulating various operations on various kinds of methods
+whose instances are typically uncallable).
+
+This tuple matches the types of all:
+
+* **Class method descriptors** (i.e., methods decorated by the builtin
+  :class:`classmethod` decorator).
+* **Instance method descriptors** (i.e., methods *not* decorated by a builtin
+  method decorator).
+* **Property method descriptors** (i.e., methods decorated by the builtin
+  :class:`property` decorator).
+* **Static method descriptors** (i.e., methods decorated by the builtin
+  :class:`staticmethod` decorator).
+'''
+
+
+MethodTypes = (FunctionOrMethodCType,) + MethodBoundTypes + MethodUnboundTypes
+'''
+Tuple of all **method types** (i.e., types whose instances are callable objects
+associated with methods implemented in either low-level C or pure Python).
+
+Unbound decorator objects (e.g., non-callable instances of the builtin
+:class:`classmethod`, :class:`property`, or :class:`staticmethod` decorator
+classes) are *not* callable and thus intentionally excluded.
+
+Caveats
+----------
+**This tuple may yield false positives when used to validate types.** Since
+Python fails to distinguish between C-based functions and methods, this tuple
+is the set of all pure-Python bound and unbound method types as well as the
+ambiguous type of all C-based bound methods and non-method functions.
+'''
+
+# ....................{ TUPLES ~ call : callable           }....................
+# For DRY, this tuple is defined as the set union of all function and method
+# types defined above converted back to a tuple.
+#
+# While this tuple could also be defined as the simple concatenation of the
+# "FunctionTypes" and "MethodTypes" tuples, doing so would duplicate all types
+# ambiguously residing in both tuples (i.e., "FunctionOrMethodCType"). Doing so
+# would induce inefficiencies during type checking. That would be bad.
+CallableTypes = tuple(set(FunctionTypes) | set(MethodTypes))
+'''
+Tuple of all **callable types** (i.e., types whose instances are callable
+objects implemented in either low-level C or high-level Python, including both
+built-in and user-defined functions, lambdas, methods, and method descriptors).
+'''
+
+
+CallableCTypes = (
+    FunctionOrMethodCType,
+    MethodBoundInstanceDunderCType,
+    MethodUnboundInstanceDunderCType,
+    MethodUnboundInstanceNondunderCType,
+    MethodUnboundClassCType,
+)
+'''
+Tuple of all **C-based callable types** (i.e., types whose instances are
+callable objects implemented in low-level C rather than high-level Python).
+'''
+
+
+CallablePyTypes = (
+    FunctionType,
+    MethodBoundInstanceOrClassType,
+)
+'''
+Tuple of all **pure-Python callable types** (i.e., types whose instances are
+callable objects implemented in high-level Python rather than low-level C).
+
+**This tuple is empty under PyPy,** which unconditionally compiles *all*
+pure-Python callables into C-based callables.
+'''
+
+
+CallableOrClassTypes = CallableTypes + (ClassType,)
+'''
+Tuple of all callable types as well as the type of all types.
+'''
+
+
+CallableOrStrTypes = CallableTypes + (StrType,)
+'''
+Tuple of all callable types as well as the string type.
+'''
+
+
+#FIXME: Define a new "CallableClassType" by copying the "BoolType" approach
+#except for the __call__() dunder method instead.
+#FIXME: Replace "ClassType" below by "CallableClassType".
+#FIXME: Add the "CallableClassType" type to the "CallableTypes" tuple as well.
+DecoratorTypes = CallableTypes + (ClassType,)
+'''
+Tuple of all **decorator types** (i.e., both callable classes *and* the type of
+those classes).
+
+Caveats
+----------
+**This tuple may yield false positives when used to validate types.** Since
+classes themselves may be callable (i.e., by defining the special ``__call__``
+method), this tuple is the set of all standard callable types as well as that
+of classes. In particular, this tuple describes all types permissible for use
+as decorators. Since most classes are *not* callable, however, this tuple may
+yield false positives when passed classes.
+'''
+
+# ....................{ TUPLES ~ call : return             }....................
+AsyncCTypes = (AsyncGeneratorCType, AsyncCoroutineCType)
+'''
+Tuple of all C-based types returned by all **asynchronous callables** (i.e.,
+callables implemented in pure Python whose declaration is preceded by the
+``async`` keyword).
+'''
+
+# ....................{ TUPLES ~ scalar                    }....................
+BoolOrNumberTypes = (BoolType, NumberType,)
+'''
+Tuple of all **boolean** and **number types** (i.e., classes whose instances
+are either numbers or types trivially convertible into numbers).
+
+This tuple matches booleans, integers, rational numbers, irrational numbers,
+real numbers, and complex numbers.
+
+Booleans are trivially convertible into integers. While details differ by
+implementation, common implementations in lower-level languages (e.g., C, C++,
+Perl) typically implicitly convert:
+
+* ``False`` to ``0`` and vice versa.
+* ``True`` to ``1`` and vice versa.
+'''
+
+# ....................{ TUPLES ~ post-init : container     }....................
+# Tuples of types assuming the above initialization to have been performed.
+
+MappingOrSequenceTypes = (MappingType, SequenceType)
+'''
+Tuple of all container base classes conforming to (but *not* necessarily
+subclassing) the canonical :class:`collections.abc.Mapping` *or*
+:class:`collections.abc.Sequence` APIs.
+'''
+
+
+ModuleOrSequenceTypes = (ModuleType, SequenceType)
+'''
+Tuple of the module type *and* all container base classes conforming to (but
+*not* necessarily subclassing) the canonical :class:`collections.abc.Sequence`
+API.
+'''
+
+
+NumberOrIterableTypes = (NumberType, IterableType,)
+'''
+Tuple of all numeric types *and* all container base classes conforming to (but
+*not* necessarily subclassing) the canonical :class:`collections.abc.Iterable`
+API.
+'''
+
+
+NumberOrSequenceTypes = (NumberType, SequenceType,)
+'''
+Tuple of all numeric types *and* all container base classes conforming to (but
+*not* necessarily subclassing) the canonical :class:`collections.abc.Sequence`
+API.
+'''
+
+# ....................{ TUPLES ~ post-init : scalar        }....................
+ScalarTypes = BoolOrNumberTypes + (StrType,)
+'''
+Tuple of all **scalar types** (i.e., classes whose instances are atomic scalar
+primitives).
+
+This tuple matches all:
+
+* **Boolean types** (i.e., types satisfying the :class:`BoolType` protocol).
+* **Numeric types** (i.e., types satisfying the :class:`NumberType` protocol).
+* **Textual types** (i.e., types contained in the :class:`StrTypes` tuple).
+'''
+
+# ....................{ TUPLES ~ stdlib                    }....................
+RegexTypes = (RegexCompiledType, StrType)
+'''
+Tuple of all **regular expression-like types** (i.e., types either defining
+regular expressions or losslessly convertible to such types).
+
+This tuple matches:
+
+* The **compiled regular expression type** (i.e., type of all objects created
+  and returned by the stdlib :func:`re.compile` function).
+* All **textual types** (i.e., types contained in the :class:`StrTypes`
+  tuple).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_cave/_cavemap.py
@@ -0,0 +1,232 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype cave-specific abstract base classes (ABCs).**
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: As with the parallel "beartype._cave.abc" submodule, refactor the
+#contents of this private submodule into the newly proposed public
+#"beartype.caver" submodule. To do so:
+#
+#* In the "beartype.caver" submodule:
+#  * Define a new make_type() function copied from the
+#    betse.util.type.classes.define_class() function (but renamed, obviously).
+#  * Define a new make_type_defaultdict() function copied from the
+#    betse.util.type.iterable.mapping.mapcls.DefaultDict() function, but with
+#    signature resembling:
+#    def make_type_defaultdict(
+#        name: str,
+#        missing_key_maker: CallableTypes,
+#        items: (Iterable, type(None)),
+#    ) -> type:
+#    Internally, this function should call make_type() to do so.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeCaveNoneTypeOrKeyException,
+    BeartypeCaveNoneTypeOrMutabilityException,
+)
+from beartype.typing import (
+    Any,
+    Tuple,
+    Union,
+)
+from beartype._util.hint.nonpep.utilnonpeptest import die_unless_hint_nonpep
+
+# ....................{ CONSTANTS                          }....................
+_NoneType: type = type(None)
+'''
+Type of the :data:`None` singleton, duplicated from the :mod:`beartype.cave`
+submodule to prevent cyclic import dependencies.
+'''
+
+
+_NoneTypes: Tuple[type, ...] = (_NoneType,)
+'''
+Tuple of only the type of the :data:`None` singleton.
+'''
+
+# ....................{ HINTS                              }....................
+_TypeTuple = Tuple[Union[type, str], ...]
+'''
+PEP-compliant type hint matching a **type tuple** (i.e., tuple containing only
+types and forward references to deferred types specified as the fully-qualified
+names of those types).
+'''
+
+# ....................{ CLASSES                            }....................
+class _NoneTypeOrType(dict):
+    '''
+    :class:`NoneType` **tuple factory type** (i.e., :class:`dict` subclass,
+    instances of which are dictionaries mapping from arbitrary types or tuples
+    of types to the same types or tuples of types concatenated with the type of
+    the :data:`None` singleton).
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    def __missing__(self, hint: Union[type, str, _TypeTuple]) -> _TypeTuple:
+        '''
+        Dunder method explicitly called by the superclass
+        :meth:`dict.__getitem__` method implicitly called on getting the passed
+        missing key with ``[``- and ``]``-delimited syntax.
+
+        Specifically, this method:
+
+        * If a single type or string is passed:
+
+          #. Creates a new 2-tuple containing only that object and the type of
+             the :data:`None` singleton.
+          #. Maps the passed type to that 2-tuple.
+          #. Returns that 2-tuple.
+
+        * Else if a tuple of one or more types and/or strings is passed:
+
+          #. Creates a new tuple appending the type of the :data:`None`
+             singleton to the passed tuple.
+          #. Maps the passed type to the new tuple.
+          #. Returns the new tuple.
+
+        * Else, raises an exception.
+
+        Parameters
+        ----------
+        hint : Union[type, str, _TypeTuple]
+            Type, string, or tuple of one or more types and/or strings *not*
+            currently cached by this factory.
+
+        Returns
+        -------
+        _TypeTuple
+            Tuple of types appending the type of the :data:`None` singleton to
+            the passed type, string, or tuple of types and/or strings.
+
+        Raises
+        ------
+        BeartypeCaveNoneTypeOrKeyException
+            If this key is neither:
+
+            * A **string** (i.e., forward reference specified as either a
+              fully-qualified or unqualified classname).
+            * A **type** (i.e., class).
+            * A **non-empty tuple** (i.e., semantic union of types) containing
+              only strings and types.
+        '''
+
+        # If this missing key is *NOT* a PEP-noncompliant type hint, raise an
+        # exception.
+        die_unless_hint_nonpep(
+            hint=hint,
+            exception_prefix='"NoneTypeOr" key',
+            exception_cls=BeartypeCaveNoneTypeOrKeyException,
+        )
+
+        # Tuple of types to be cached and returned by this call.
+        hint_or_none: _TypeTuple = None  # type: ignore[assignment]
+
+        # If this key is a type...
+        if isinstance(hint, type):
+            # If this type is "NoneType", reuse the existing "_NoneTypes" tuple
+            # containing only this type.
+            if hint is _NoneType:
+                hint_or_none = _NoneTypes
+            # Else, this type is *NOT* "NoneType". In this case, instantiate a
+            # new tuple of types concatenating this type with "NoneType".
+            else:
+                hint_or_none = (hint, _NoneType)
+        # Else if this key is a non-empty tuple...
+        elif isinstance(hint, tuple):
+            # If "NoneType" is already in this tuple, reuse this tuple as is.
+            if _NoneType in hint:
+                hint_or_none = hint
+            # Else, "NoneType" is *NOT* already in this tuple. In this case,
+            # instantiate a new tuple of types concatenating this tuple with
+            # "NoneType".
+            else:
+                hint_or_none = hint + _NoneTypes
+        # Else, this key is invalid. Thanks to the above call to the
+        # die_unless_hint_nonpep() function, this should *NEVER* occur.
+        # Nonetheless, raise a human-readable exception for sanity.
+        else:
+            raise BeartypeCaveNoneTypeOrKeyException(
+                f'"NoneTypeOr" key {repr(hint)} unsupported.')
+
+        # Cache this tuple under this key.
+        self[hint] = hint_or_none
+
+        # Return this tuple.
+        return hint_or_none
+
+# ....................{ SINGLETONS                         }....................
+NoneTypeOr: Any = _NoneTypeOrType()
+'''
+**:class:``NoneType`` tuple factory** (i.e., dictionary mapping from arbitrary
+types or tuples of types to the same types or tuples of types concatenated with
+the type of the :data:`None` singleton).
+
+This factory efficiently generates and caches tuples of types containing
+:class:`NoneType` from arbitrary user-specified types and tuples of types. To
+do so, simply index this factory with any desired type *or* tuple of types; the
+corresponding value will then be another tuple containing :class:`NoneType`
+and that type *or* those types.
+
+Motivation
+----------
+This factory is commonly used to type-hint **optional callable parameters**
+(i.e., parameters defaulting to :data:`None` when *not* explicitly passed by the
+caller). Although such parameters may also be type-hinted with a tuple manually
+containing :class:`NoneType`, doing so inefficiently recreates these tuples
+for each optional callable parameter across the entire codebase.
+
+This factory avoids such inefficient recreation. Instead, when indexed with any
+arbitrary key:
+
+* If that key has already been successfully accessed on this factory, this
+  factory returns the existing value (i.e., tuple containing :class:`NoneType`
+  and that key if that key is a type *or* the items of that key if that key is a
+  tuple) previously mapped and cached to that key.
+* Else, if that key is:
+
+  * A type, this factory:
+
+    #. Creates a new tuple containing that type and :class:`NoneType`.
+    #. Associates that key with that tuple.
+    #. Returns that tuple.
+
+  * A tuple of types, this factory:
+
+    #. Creates a new tuple containing these types and :class:`NoneType`.
+    #. Associates that key with that tuple.
+    #. Returns that tuple.
+
+  * Any other object, raises a human-readable
+    :class:`beartype.roar.BeartypeCaveNoneTypeOrKeyException` exception.
+
+This factory is analogous to the :pep:`484`_-compliant :class:`typing.Optional`
+type despite otherwise *not* complying with :pep:`484`_.
+
+Examples
+--------
+.. code-block:: pycon
+
+   # Function accepting an optional parameter with neither
+   # "beartype.cave" nor "typing".
+   >>> def to_autumn(season_of_mists: (str, type(None)) = None) -> str
+   ...     return season_of_mists if season_of_mists is not None else (
+   ...         'While barred clouds bloom the soft-dying day,')
+
+   # Function accepting an optional parameter with "beartype.cave".
+   >>> from beartype.cave import NoneTypeOr
+   >>> def to_autumn(season_of_mists: NoneTypeOr[str] = None) -> str
+   ...     return season_of_mists if season_of_mists is not None else (
+   ...         'Then in a wailful choir the small gnats mourn')
+
+   # Function accepting an optional parameter with "typing".
+   >>> from typing import Optional
+   >>> def to_autumn(season_of_mists: Optional[str] = None) -> str
+   ...     return season_of_mists if season_of_mists is not None else (
+   ...         'Or sinking as the light wind lives or dies;')
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/_checksnip.py
@@ -0,0 +1,185 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **type-checking function code snippets** (i.e., triple-quoted
+pure-Python string constants formatted and concatenated together to dynamically
+generate the implementations of functions type-checking arbitrary objects
+against arbitrary PEP-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkmagic import (
+    ARG_NAME_CONF,
+    ARG_NAME_CLS_STACK,
+    ARG_NAME_FUNC,
+    ARG_NAME_EXCEPTION_PREFIX,
+    ARG_NAME_GET_VIOLATION,
+    ARG_NAME_HINT,
+    ARG_NAME_WARN,
+    VAR_NAME_PITH_ROOT,
+    VAR_NAME_RANDOM_INT,
+    VAR_NAME_VIOLATION,
+)
+
+# ....................{ CODE ~ signature                   }....................
+CODE_CHECKER_SIGNATURE = f'''{{code_signature_prefix}}def {{func_name}}(
+    {VAR_NAME_PITH_ROOT},
+{{code_signature_args}}
+):'''
+'''
+Code snippet declaring the signature of all type-checking tester functions
+created by the :func:`beartype._check.checkmagic.make_func_tester` factory.
+
+Note that:
+
+* This signature intentionally:
+
+  * Avoids annotating its parameters or return by type hints. Doing so would be:
+
+    * Pointless, as the type-checking functions dynamically created and returned
+      by factory functions defined by the "beartype._check.checkmake" submodule
+      are only privately called by the public beartype.door.is_bearable() and
+      beartype.door.die_if_unbearable() runtime type-checkers.
+    * Harmful, as doing so would prevent this common signature from being
+      generically reused as the signature for both raisers and testers.
+
+  * Names the single public parameter accepted by this tester function
+    ``{VAR_NAME_PITH_ROOT}``. Doing so trivially ensures that the memoized
+    type-checking boolean expression generated by the
+    :func:`beartype._check.code.codemake.make_check_expr` code factory
+    implicitly type-checks the passed object *without* further modification
+    (e.g., global search-and-replacement), ensuring that memoized expression may
+    be efficiently reused as is *without* subsequent unmemoization. Clever, huh?
+
+* ``code_signature_prefix`` is usually either:
+
+  * For synchronous callables, the empty string.
+  * For asynchronous callables (e.g., asynchronous generators, coroutines), the
+    space-suffixed keyword ``"async "``.
+'''
+
+# ....................{ CODE ~ check                       }....................
+CODE_TESTER_CHECK_PREFIX = '''
+    # Return true only if the passed object satisfies this type hint.
+    return '''
+'''
+Code snippet prefixing the type-check of an arbitrary object passed to a
+type-checking tester function against an arbitrary type hint passed to the same
+function.
+'''
+
+# ....................{ CODE ~ check                       }....................
+CODE_RAISER_HINT_OBJECT_CHECK_PREFIX = '''
+
+    # Type-check this object against this type hint.
+    if not '''
+'''
+Code snippet prefixing the type-check of an arbitrary object passed to a
+type-checking raiser function against an arbitrary type hint passed to the same
+function.
+'''
+
+
+CODE_RAISER_FUNC_PITH_CHECK_PREFIX = '''
+        # Type-check this parameter or return against this type hint.
+        if not '''
+'''
+Code snippet prefixing the type-check of a parameter or return of a decorated
+callable against the type hint annotating that parameter or return.
+'''
+
+# ....................{ CODE ~ violation : get             }....................
+CODE_GET_HINT_OBJECT_VIOLATION = f''':
+            {VAR_NAME_VIOLATION} = {ARG_NAME_GET_VIOLATION}(
+                obj={VAR_NAME_PITH_ROOT},
+                hint={ARG_NAME_HINT},
+                conf={ARG_NAME_CONF},
+                exception_prefix={ARG_NAME_EXCEPTION_PREFIX},{{arg_random_int}}
+            )
+'''
+'''
+Code snippet suffixing all code type-checking the **root pith** (i.e., arbitrary
+object) against the root type hint annotating that pith by either raising a
+fatal exception or emitting a non-fatal warning.
+
+This snippet expects to be formatted with these named interpolations:
+
+* ``{arg_random_int}``, whose value is either:
+
+  * If type-checking for the current type hint requires a pseudo-random integer,
+    :data:`.CODE_HINT_ROOT_SUFFIX_RANDOM_INT`.
+  * Else, the empty substring.
+'''
+
+
+CODE_GET_FUNC_PITH_VIOLATION = f''':
+            {VAR_NAME_VIOLATION} = {ARG_NAME_GET_VIOLATION}(
+                func={ARG_NAME_FUNC},
+                conf={ARG_NAME_CONF},
+                pith_name={{pith_name}},
+                pith_value={VAR_NAME_PITH_ROOT},{{arg_cls_stack}}{{arg_random_int}}
+            )
+'''
+'''
+Code snippet suffixing all code type-checking the **root pith** (i.e., value of
+the current parameter or return value) against the root type hint annotating
+that pith by either raising a fatal exception or emitting a non-fatal warning.
+
+This snippet expects to be formatted with these named interpolations:
+
+* ``{arg_cls_stack}``, whose value is either:
+
+  * If type-checking for the current type hint requires the type stack,
+    :data:`.CODE_HINT_ROOT_SUFFIX_CLS_STACK`.
+  * Else, the empty substring.
+
+* ``{arg_random_int}``, whose value is either:
+
+  * If type-checking for the current type hint requires a pseudo-random integer,
+    :data:`.CODE_HINT_ROOT_SUFFIX_RANDOM_INT`.
+  * Else, the empty substring.
+'''
+
+
+CODE_GET_VIOLATION_CLS_STACK = f'''
+                cls_stack={ARG_NAME_CLS_STACK},'''
+'''
+Code snippet passing the value of the **type stack** (i.e., either a tuple of
+the one or more :func:`beartype.beartype`-decorated classes lexically containing
+the class variable or method annotated by a type hint type-checked by the larger
+code snippet embedding this snippet *or* :data:`None`) required by the current
+call to the exception-handling function call embedded in the
+:data:`.CODE_HINT_ROOT_SUFFIX` snippet.
+'''
+
+
+CODE_GET_VIOLATION_RANDOM_INT = f'''
+                random_int={VAR_NAME_RANDOM_INT},'''
+'''
+Code snippet passing the value of the random integer previously
+generated for the current call to the exception-handling function call embedded
+in the :data:`.CODE_HINT_ROOT_SUFFIX` snippet.
+'''
+
+# ....................{ CODE ~ violation                   }....................
+CODE_RAISE_VIOLATION = f'''
+            raise {VAR_NAME_VIOLATION}'''
+'''
+Code snippet raising the type-checking violation previously generated by the
+:data:`.CODE_HINT_ROOT_SUFFIX` or
+:data:`.PEP484_CODE_CHECK_NORETURN` code snippets as a fatal exception.
+'''
+
+
+CODE_WARN_VIOLATION = f'''
+            {ARG_NAME_WARN}(str({VAR_NAME_VIOLATION}), type({VAR_NAME_VIOLATION}))'''
+'''
+Code snippet emitting the type-checking violation previously generated by the
+:data:`.CODE_HINT_ROOT_SUFFIX` or
+:data:`.PEP484_CODE_CHECK_NORETURN` code snippets as a non-fatal warning.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/checkcache.py
@@ -0,0 +1,50 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **type-checking cache utilities** (i.e., low-level callables
+manipulating global dictionaries distributed throughout the
+:mod:`beartype._check` subpackage).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.code.codescope import _tuple_union_to_tuple_union
+from beartype._check.convert.convcoerce import _hint_repr_to_hint
+from beartype._check.forward.reference.fwdrefmake import (
+    _forwardref_args_to_forwardref)
+from beartype._check.forward.reference.fwdrefmeta import (
+    _forwardref_to_referee)
+
+# ....................{ CLEARERS                           }....................
+def clear_checker_caches() -> None:
+    '''
+    Clear (i.e., empty) *all* internal caches specifically leveraged by the
+    :mod:`beartype._check` subpackage, enabling callers to reset this subpackage
+    to its initial state.
+
+    Notably, this function clears:
+
+    * The **forward reference proxy cache** (i.e., private
+      :data:`beartype._check.forward.reference.fwdrefmake._forwardref_args_to_forwardref`
+      dictionary).
+    * The **forward reference referee cache** (i.e., private
+      :data:`beartype._check.forward.reference.fwdrefmeta._forwardref_to_referee`
+      dictionary).
+    * The **tuple union cache** (i.e., private
+      :data:`beartype._check.code.codescope._tuple_union_to_tuple_union`
+      dictionary).
+    * The **type hint coercion cache** (i.e., private
+      :data:`beartype._check.convert.convcoerce._hint_repr_to_hint`
+      dictionary).
+    '''
+    # print('Clearing all \"beartype._check\" caches...')
+
+    # Clear all relevant caches used throughout this subpackage.
+    _forwardref_to_referee.clear()
+    _forwardref_args_to_forwardref.clear()
+    _hint_repr_to_hint.clear()
+    _tuple_union_to_tuple_union.clear()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/checkcall.py
@@ -0,0 +1,679 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype dataclass** (i.e., class aggregating *all* metadata for the callable
+currently being decorated by the :func:`beartype.beartype` decorator).**
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorWrappeeException
+from beartype.typing import (
+    Callable,
+    Dict,
+    FrozenSet,
+    Optional,
+)
+from beartype._cave._cavefast import CallableCodeObjectType
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._check.forward.fwdscope import BeartypeForwardScope
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    TypeStack,
+)
+from beartype._util.cache.pool.utilcachepoolobjecttyped import (
+    acquire_object_typed)
+from beartype._util.func.utilfunccodeobj import get_func_codeobj
+from beartype._util.func.utilfuncget import get_func_annotations
+from beartype._util.func.utilfunctest import (
+    is_func_coro,
+    is_func_nested,
+)
+from beartype._util.func.utilfuncwrap import unwrap_func_all_isomorphic
+
+# ....................{ CLASSES                            }....................
+class BeartypeCall(object):
+    '''
+    **Beartype call metadata** (i.e., object encapsulating *all* metadata for
+    the user-defined callable currently being decorated by the
+    :func:`beartype.beartype` decorator).
+
+    Design
+    ------
+    This the *only* object instantiated by that decorator for that callable,
+    substantially reducing both space and time costs. That decorator then
+    passes this object to most lower-level functions, which then:
+
+    #. Access read-only instance variables of this object as input.
+    #. Modify writable instance variables of this object as output. In
+       particular, these lower-level functions typically accumulate pure-Python
+       code comprising the generated wrapper function type-checking the
+       decorated callable by setting various instance variables of this object.
+
+    Caveats
+    -------
+    **This object cannot be used to communicate state between low-level
+    memoized callables** (e.g.,
+    :func:`beartype._check.code.codemake.make_func_pith_code`) **and
+    higher-level callables** (e.g.,
+    :func:`beartype._decor.wrap.wrapmain.generate_code`). Instead, memoized
+    callables *must* return that state as additional return values up the call
+    stack to those higher-level callables. By definition, memoized callables
+    are *not* recalled on subsequent calls passed the same parameters. Since
+    only the first call to those callables passed those parameters would set
+    the appropriate state on this object intended to be communicated to
+    higher-level callables, *all* subsequent calls would subtly fail with
+    difficult-to-diagnose issues. See also `<issue #5_>`__, which exhibited
+    this very complaint.
+
+    .. _issue #5:
+       https://github.com/beartype/beartype/issues/5
+
+    Attributes
+    ----------
+    cls_stack : TypeStack
+        **Type stack** (i.e., either tuple of zero or more arbitrary types *or*
+        :data:`None`). See also the parameter of the same name accepted by the
+        :func:`beartype._decor.decorcore.beartype_object` function for details.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all flags, options, settings, and other metadata configuring the
+        current decoration of the decorated callable).
+    func_arg_name_to_hint : dict[str, object]
+        Dictionary mapping from the name of each annotated parameter accepted
+        by the decorated callable to the type hint annotating that parameter.
+    func_arg_name_to_hint_get : Callable[[str, object], object]
+        :meth:`dict.get` method bound to the :attr:`func_arg_name_to_hint`
+        dictionary, localized as a negligible microoptimization. Blame Guido.
+    func_wrappee : Optional[Callable]
+        Possibly wrapped **decorated callable** (i.e., high-level callable
+        currently being decorated by the :func:`beartype.beartype` decorator)
+        if the :meth:`reinit` method has been called *or* ``None`` otherwise.
+        Note the lower-level :attr:`func_wrappee_wrappee` callable should
+        *usually* be accessed instead; although higher-level, this callable may
+        only be a wrapper function and hence yield inaccurate or even erroneous
+        metadata (especially the code object) for the callable being wrapped.
+    func_wrappee_codeobj : CallableCodeObjectType
+        Possibly wrapped **decorated callable wrappee code object** (i.e.,
+        code object underlying the high-level :attr:`func_wrappee` callable
+        currently being decorated by the :func:`beartype.beartype` decorator).
+        For efficiency, this code object should *always* be accessed in lieu of
+        inefficiently calling the comparatively slower
+        :func:`beartype._util.func.utilfunccodeobj.get_func_codeobj` getter.
+    func_wrappee_is_nested : bool
+        Either:
+
+        * If this wrappee callable is **nested** (i.e., declared in the body of
+          another pure-Python callable or class), :data:`True`.
+        * If this wrappee callable is **global** (i.e., declared at module scope
+          in its submodule), :data:`False`.
+    func_wrappee_scope_forward : Optional[BeartypeForwardScope]
+        Either:
+
+        * If this wrappee callable is annotated by at least one **stringified
+          type hint** (i.e., declared as a :pep:`484`- or :pep:`563`-compliant
+          forward reference referring to an actual type hint that has yet to be
+          declared in the local and global scopes declaring this callable) that
+          :mod:`beartype` has already resolved to its referent, this wrappee
+          callable's **forward scope** (i.e., dictionary mapping from the name
+          to value of each locally and globally accessible attribute in the
+          local and global scope of this wrappee callable as well as deferring
+          the resolution of each currently undeclared attribute in that scope by
+          replacing that attribute with a forward reference proxy resolved only
+          when that attribute is passed as the second parameter to an
+          :func:`isinstance`-based runtime type-check).
+        * Else, :data:`None`.
+
+        Note that:
+
+        * The reconstruction of this scope is computationally expensive and thus
+          deferred until needed to resolve the first stringified type hint
+          annotating this wrappee callable.
+        * All callables have local scopes *except* global functions, whose local
+          scopes are by definition the empty dictionary.
+    func_wrappee_scope_nested_names : Optional[frozenset[str]]
+        Either:
+
+        * If this wrappee callable is annotated by at least one stringified type
+          hint that :mod:`beartype` has already resolved to its referent,
+          either:
+
+          * If this wrappee callable is **nested** (i.e., declared in the body
+            of another pure-Python callable or class), the non-empty frozen set
+            of the unqualified names of all parent callables lexically
+            containing this nested wrappee callable (including this nested
+            wrappee callable itself).
+          * Else, this wrappee callable is declared at global scope in its
+            submodule. In this case, the empty frozen set.
+
+        * Else, :data:`None`.
+    func_wrappee_wrappee : Optional[Callable]
+        Possibly unwrapped **decorated callable wrappee** (i.e., low-level
+        callable wrapped by the high-level :attr:`func_wrappee` callable
+        currently being decorated by the :func:`beartype.beartype` decorator)
+        if the :meth:`reinit` method has been called *or* ``None`` otherwise.
+        If the higher-level :attr:`func_wrappee` callable does *not* actually
+        wrap another callable, this callable is identical to that callable.
+    func_wrappee_wrappee_codeobj : CallableCodeObjectType
+        Possibly unwrapped **decorated callable wrappee code object** (i.e.,
+        code object underlying the low-level :attr:`func_wrappee_wrappee`
+        callable wrapped by the high-level :attr:`func_wrappee` callable
+        currently being decorated by the :func:`beartype.beartype` decorator).
+        For efficiency, this code object should *always* be accessed in lieu of
+        inefficiently calling the comparatively slower
+        :func:`beartype._util.func.utilfunccodeobj.get_func_codeobj` getter.
+    func_wrapper_code_call_prefix : Optional[str]
+        Code snippet prefixing all calls to the decorated callable in the body
+        of the wrapper function wrapping that callable with type checking if
+        the :meth:`reinit` method has been called *or* ``None`` otherwise. If
+        non-``None``, this string is guaranteed to be either:
+
+        * If the decorated callable is synchronous (i.e., neither a coroutine
+          nor asynchronous generator), the empty string.
+        * If the decorated callable is asynchronous (i.e., either a coroutine
+          nor asynchronous generator), the ``"await "`` keyword.
+    func_wrapper_code_signature_prefix : Optional[str]
+        Code snippet prefixing the signature declaring the wrapper function
+        wrapping the decorated callable with type checking. Specifically, this
+        string is guaranteed to be either:
+
+        * If the decorated callable is synchronous (i.e., neither a coroutine
+          nor asynchronous generator), the empty string.
+        * If the decorated callable is asynchronous (i.e., either a coroutine
+          or asynchronous generator), the ``"async "`` keyword.
+    func_wrapper_scope : LexicalScope
+        **Local scope** (i.e., dictionary mapping from the name to value of
+        each attribute referenced in the signature) of this wrapper function.
+    func_wrapper_name : Optional[str]
+        Machine-readable name of the wrapper function to be generated and
+        returned by this decorator.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently
+    # called @beartype decorations. Slotting has been shown to reduce read and
+    # write costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        'cls_stack',
+        'conf',
+        'func_arg_name_to_hint',
+        'func_arg_name_to_hint_get',
+        'func_wrappee',
+        'func_wrappee_codeobj',
+        'func_wrappee_is_nested',
+        'func_wrappee_scope_forward',
+        'func_wrappee_scope_nested_names',
+        'func_wrappee_wrappee',
+        'func_wrappee_wrappee_codeobj',
+        'func_wrapper_code_call_prefix',
+        'func_wrapper_code_signature_prefix',
+        'func_wrapper_scope',
+        'func_wrapper_name',
+    )
+
+    # Coerce instances of this class to be unhashable, preventing spurious
+    # issues when accidentally passing these instances to memoized callables by
+    # implicitly raising a "TypeError" exception on the first call to those
+    # callables. There exists no tangible benefit to permitting these instances
+    # to be hashed (and thus also cached), since these instances are:
+    # * Specific to the decorated callable and thus *NOT* safely cacheable
+    #   across functions applying to different decorated callables.
+    # * Already cached via the acquire_object_typed() function called by the
+    #   "beartype._decor.decormain" submodule.
+    #
+    # See also:
+    #     https://docs.python.org/3/reference/datamodel.html#object.__hash__
+    __hash__ = None  # type: ignore[assignment]
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self) -> None:
+        '''
+        Initialize this metadata by nullifying all instance variables.
+
+        Caveats
+        -------
+        **This class is not intended to be explicitly instantiated.** Instead,
+        callers are expected to (in order):
+
+        #. Acquire cached instances of this class via the
+           :mod:`beartype._util.cache.pool.utilcachepoolobjecttyped` submodule.
+        #. Call the :meth:`reinit` method on these instances to properly
+           initialize these instances.
+        '''
+
+        # Nullify instance variables for safety.
+        self.cls_stack: TypeStack = None
+        self.conf: BeartypeConf = None  # type: ignore[assignment]
+        self.func_arg_name_to_hint: Dict[str, object] = None  # type: ignore[assignment]
+        self.func_arg_name_to_hint_get: Callable[[str, object], object] = None  # type: ignore[assignment]
+        self.func_wrappee: Callable = None  # type: ignore[assignment]
+        self.func_wrappee_codeobj: CallableCodeObjectType = None  # type: ignore[assignment]
+        self.func_wrappee_is_nested: bool = None  # type: ignore[assignment]
+        self.func_wrappee_scope_forward: Optional[BeartypeForwardScope] = None
+        self.func_wrappee_scope_nested_names: Optional[FrozenSet[str]] = None
+        self.func_wrappee_wrappee: Callable = None  # type: ignore[assignment]
+        self.func_wrappee_wrappee_codeobj: CallableCodeObjectType = None  # type: ignore[assignment]
+        self.func_wrapper_code_call_prefix: str = None  # type: ignore[assignment]
+        self.func_wrapper_code_signature_prefix: str = None  # type: ignore[assignment]
+        self.func_wrapper_scope: LexicalScope = {}
+        self.func_wrapper_name: str = None  # type: ignore[assignment]
+
+
+    def reinit(
+        self,
+
+        # Mandatory parameters.
+        func: Callable,
+        conf: BeartypeConf,
+
+        # Optional parameters.
+        cls_stack: TypeStack = None,
+    ) -> None:
+        '''
+        Reinitialize this metadata from the passed callable, typically after
+        acquisition of a previously cached instance of this class from the
+        :mod:`beartype._util.cache.pool.utilcachepoolobject` submodule.
+
+        If :pep:`563` is conditionally active for this callable, this function
+        additionally resolves all postponed annotations on this callable to
+        their referents (i.e., the intended annotations to which those
+        postponed annotations refer).
+
+        Parameters
+        ----------
+        func : Callable
+            Callable currently being decorated by :func:`beartype.beartype`.
+        conf : BeartypeConf
+            Beartype configuration configuring :func:`beartype.beartype`
+            specific to this callable.
+        cls_stack : TypeStack
+            **Type stack** (i.e., either tuple of zero or more arbitrary types
+            *or* :data:`None`). See also the parameter of the same name accepted
+            by the :func:`beartype._decor.decorcore.beartype_object` function.
+
+        Raises
+        ------
+        BeartypePep563Exception
+            If evaluating a postponed annotation on this callable raises an
+            exception (e.g., due to that annotation referring to local state no
+            longer accessible from this deferred evaluation).
+        BeartypeDecorWrappeeException
+            If either:
+
+            * This callable is uncallable.
+            * This callable is neither a pure-Python function *nor* method;
+              equivalently, if this callable is either C-based *or* a class or
+              object defining the ``__call__()`` dunder method.
+            * This configuration is *not* actually a configuration.
+            * ``cls_owner`` is neither a class *nor* ``None``.
+        '''
+
+        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+        # CAUTION: Note this method intentionally avoids creating and passing an
+        # "exception_prefix" substring to callables called below. Why? Because
+        # exhaustive profiling has shown that creating that substring consumes a
+        # non-trivial slice of decoration time. In other words, efficiency.
+        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        # If this callable is uncallable, raise an exception.
+        if not callable(func):
+            raise BeartypeDecorWrappeeException(f'{repr(func)} uncallable.')
+        # Else, this callable is callable.
+        #
+        # If this configuration is *NOT* a configuration, raise an exception.
+        elif not isinstance(conf, BeartypeConf):
+            raise BeartypeDecorWrappeeException(
+                f'"conf" {repr(conf)} not beartype configuration.')
+        # Else, this configuration is a configuration.
+        #
+        # If this class stack is neither a tuple *NOR* "None", raise an
+        # exception.
+        elif not isinstance(cls_stack, _TypeStackOrNone):
+            raise BeartypeDecorWrappeeException(
+                f'"cls_stack" {repr(cls_stack)} neither tuple nor "None".')
+        # Else, this class stack is either a tuple *OR* "None".
+
+        # If this class stack is *NOT* "None", this class stack is a tuple. In
+        # this case, for each item of this class stack tuple...
+        if cls_stack:
+            for cls_stack_item in cls_stack:
+                # If this item is *NOT* a type, raise an exception.
+                if not isinstance(cls_stack_item, type):
+                    raise BeartypeDecorWrappeeException(
+                        f'"cls_stack" item {repr(cls_stack_item)} not type.')
+        # Else, this class stack is "None".
+
+        # Classify all passed parameters.
+        self.cls_stack = cls_stack
+        self.conf = conf
+
+        # Wrappee callable currently being decorated.
+        self.func_wrappee = func
+
+        # Possibly unwrapped callable unwrapped from this wrappee callable.
+        self.func_wrappee_wrappee = unwrap_func_all_isomorphic(func)
+        # self.func_wrappee_wrappee = unwrap_func_all(func)
+        # print(f'func_wrappee: {self.func_wrappee}')
+        # print(f'func_wrappee_wrappee: {self.func_wrappee_wrappee}')
+
+        # True only if this wrappee callable is nested. As a minor efficiency
+        # gain, we can avoid the slightly expensive call to is_func_nested() by
+        # noting that:
+        # * If the class stack is non-empty, then this wrappee callable is
+        #   necessarily nested in one or more classes.
+        # * Else, defer to the is_func_nested() tester.
+        self.func_wrappee_is_nested = bool(cls_stack) or is_func_nested(func)
+
+        # Defer the resolution of both global and local scopes for this wrappee
+        # callable until needed to subsequently resolve stringified type hints.
+        self.func_wrappee_scope_forward = None
+        self.func_wrappee_scope_nested_names = None
+
+        # Possibly wrapped callable code object.
+        self.func_wrappee_codeobj = get_func_codeobj(
+            func=func,
+            exception_cls=BeartypeDecorWrappeeException,
+        )
+
+        # Possibly unwrapped callable code object.
+        self.func_wrappee_wrappee_codeobj = get_func_codeobj(
+            func=self.func_wrappee_wrappee,
+            exception_cls=BeartypeDecorWrappeeException,
+        )
+
+        # Efficiently reduce this local scope back to the dictionary of all
+        # parameters unconditionally required by *ALL* wrapper functions.
+        self.func_wrapper_scope.clear()
+
+        # Machine-readable name of the wrapper function to be generated.
+        self.func_wrapper_name = func.__name__
+
+        #FIXME: Globally replace all references to "__annotations__" throughout
+        #the "beartype._decor" subpackage with references to this instead.
+        #Since doing so is a negligible optimization, this is fine... for now.
+        #FIXME: *WOOPS.* Due to PEP 649, we absolutely need to get out ahead of
+        #this before Python 3.13 and catastrophe strike. Notably:
+        #* Define a new "beartype._data.hint.datahinttyping.Hintable" type hint
+        #  resembling:
+        #      from beartype._cave._cavefast import (
+        #          FunctionType,
+        #          MethodBoundInstanceOrClassType,
+        #      )
+        #
+        #      Hintable = Union[
+        #          FunctionType,                    # <-- pure-Python function
+        #          MethodBoundInstanceOrClassType,  # <-- pure-Python method
+        #          ModuleType,  # <-- C-based *OR* pure-Python module
+        #          type,        # <-- C-based *OR* pure-Python class
+        #      ]
+        #      '''
+        #      PEP-compliant type hint matching any **hintable** (i.e., ideally
+        #      pure-Python object defining the ``__annotations__`` dunder
+        #      attribute as well as the ``__annotate__`` dunder callable if the
+        #      active Python interpreter targets Python >= 3.13).
+        #      '''
+        #* Define a new "beartype._data.cls.datacls.HintableTypes" tuple union
+        #  resembling:
+        #      from beartype._cave._cavefast import (
+        #          FunctionType,
+        #          MethodBoundInstanceOrClassType,
+        #      )
+        #
+        #      HintableTypes = (
+        #          FunctionType,                    # <-- pure-Python function
+        #          MethodBoundInstanceOrClassType,  # <-- pure-Python method
+        #          ModuleType,  # <-- C-based *OR* pure-Python module
+        #          type,        # <-- C-based *OR* pure-Python class
+        #      )
+        #* Rename "HintAnnotations" to "HintableAnnotations" in that same
+        #  submodule.
+        #* Define a new "beartype._util.hintable" subpackage.
+        #* Define a new "beartype._util.hintable.utilhintableget" submodule.
+        #* Define a new get_hintable_hint_name_to_hint() getter in that
+        #  submodule whose signature resembles:
+        #      from beartype._data.hint.datahinttyping import (
+        #          Hintable,
+        #          HintableAnnotations,
+        #      )
+        #
+        #      def get_hintable_hint_name_to_hint(hintable: Hintable) -> (
+        #          HintableAnnotations):
+        #* Define a new "BeartypePep649Exception" exception type, please.
+        #* Implement this getter conditionally depending on the active Python
+        #  interpreter as follows:
+        #      from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_13
+        #
+        #      # If the active Python interpreter targets Python >= 3.13, defer
+        #      # to the PEP 649-compliant __annotate__() dunder callable rather
+        #      # than the PEP 484-compliant __annotations__() dunder attribute.
+        #      # Why? Because the latter simply reduces to calling
+        #      # "self.__annotate__(inspect.VALUE)", which raises a "NameError"
+        #      # exception if the passed hintable is annotated by one or more
+        #      # unquoted forward references. Unacceptable!
+        #      #
+        #      # Note that this getter is memoized *ONLY* under Python >= 3.13.
+        #      # Why? Because __annotate__() *ONLY* memoizes the annotations
+        #      # dictionary it creates and returns when passed "inspect.VALUE".
+        #      # When passed *ANY* other "format" value, __annotate__() avoids
+        #      # avoids caching its return value. Creating this return value is
+        #      # algorithmically non-trivial and computationally expensive. So,
+        #      # we are effectively required to memoize this return value here.
+        #      if IS_PYTHON_AT_LEAST_3_13:
+        #          # Defer version-specific imports.
+        #          from inspect import FORWARDREF
+        #          from beartype.roar import BeartypePep649Exception
+        #          from beartype._data.cls.datacls import HintableTypes
+        #
+        #          @callable_cached
+        #          def get_hintable_hint_name_to_hint(hintable: Hintable) -> (
+        #              HintableAnnotations):
+        #
+        #              if not isinstance(hintable, HintableTypes):
+        #                  raise BeartypePep649(
+        #                      f'Object {repr(hintable)} not hintable '
+        #                      f'(i.e., defines no PEP 649 __annotate__() '
+        #                      f'data descriptor).'
+        #                  )
+        #              # Note that this will probably become a shockingly common
+        #              # occurrence. PEP 649 openly encourages users to destroy
+        #              # the "__annotate__" dunder method by setting that method
+        #              # to "None": e.g.,
+        #              #     Failing that, it’s best to overwrite the object’s
+        #              #     __annotate__ method with None to prevent
+        #              #     inspect.get_annotations from generating stale
+        #              #     results for SOURCE and FORWARDREF formats.
+        #              elif hintable.__annotate__ is None:
+        #                  raise BeartypePep649(
+        #                      f'Object {repr(hintable)} annotations destroyed '
+        #                      f'(i.e., PEP 649 __annotate__() data descriptor '
+        #                      f'externally set to "None").'
+        #                  )
+        #
+        #              # Return the annotations dictionary for this hintable,
+        #              # implicitly replacing all unquoted forward references to
+        #              # undefined attributes in type hints described by this
+        #              # dictionary with "typing.ForwardRef" proxies.
+        #              return hintable.__annotate__(FORWARDREF)
+        #      else:
+        #          def get_hintable_hint_name_to_hint(hintable: Hintable) -> (
+        #              HintableAnnotations):
+        #              return hintable.__annotations__
+        #* Grep the codebase for all references to "__annotations__". All such
+        #  references *MUST* immediately be refactored as calls to
+        #  get_hintable_hint_name_to_hint().
+        #FIXME: *SUPERB.* However, note that even the following might not
+        #suffice for Python >= 3.13. Why? Because, to quote PEP 649:
+        #    Initially, inspect.get_annotations will call the object’s
+        #    __annotate__ method requesting the desired format. If that raises
+        #    NotImplementedError, inspect.get_annotations will construct a “fake
+        #    globals” environment, then call the object’s __annotate__ method.
+        #    inspect.get_annotations produces FORWARDREF format by creating a
+        #    new empty “fake globals” dict, pre-populating it with the current
+        #    contents of the __annotate__ method’s globals dict, binding the
+        #    “fake globals” dict to the object’s __annotate__ method, calling
+        #    that requesting VALUE format, and returning the result.
+        #
+        #...heh. So, our get_hintable_hint_name_to_hint() implementation needs
+        #to either:
+        #* Just defer to inspect.get_annotations(). I'm *NOT* particularly keen
+        #  on that. That implementation is likely to be suboptimal and, more
+        #  importantly, outside our control. Moreover, there's really *NO* need
+        #  to defer to somebody else's implementation. Why? Because we basically
+        #  already implemented the entirety of inspect.get_annotations() without
+        #  knowing it as our "beartype._check.forward" subpackage. Ergo...
+        #* Derive mild inspiration from inspect.get_annotations(), but otherwise
+        #  substitute stock CPython stuff like "typing.ForwardRef" with
+        #  equivalent functionality from our own "beartype._check.forward"
+        #  subpackage.
+        #
+        #Control is pivotal here. We can iterate on underlying issues
+        #significantly faster than CPython. We can also optimize and
+        #microoptimize this as we see fit to generate even better yields.
+        #
+        #Note, however, that PEP 649-compliant stringizers are pretty
+        #phenomenal. It's unlikely that @beartype could or even should implement
+        #a better internal alternative. Ideally, our
+        #"beartype._check.forward.reference" API could be mildly refactored to
+        #internally support PEP 649-compliant stringizers under Python >= 3.13.
+        #Is that even feasible? Who knows. But... it's certainly desirable.
+        #FIXME: Actually... let's just defer to inspect.get_annotations(). Look.
+        #I know. I know. It's a shame. We threw a veritable ton of volunteer
+        #hours at "beartype._check.forward". But inspect.get_annotations() is
+        #strictly better than anything we've done or could reasonably do.
+        #Seriously. That train is moving on. Honestly, reproducing
+        #inspect.get_annotations() in @beartype is probably *NOT* feasible.
+        #inspect.get_annotations() does all sorts of intense and crazy stuff:
+        #    The “fake globals” environment will also have to create a fake
+        #    “closure”, a tuple of ForwardRef objects pre-created with the names
+        #    of the free variables referenced by the __annotate__ method.
+        #
+        #There's just no way we're dynamically constructing fake closures. So,
+        #inspect.get_annotations() is it -- at least, initially. I mean, if
+        #significant issues end up arising from our usage of
+        #inspect.get_annotations()... well, that's fine. At that point, we'd
+        #obviously begin deriving our alternative heavily inspired by
+        #inspect.get_annotations(). Until then, we genuinely do need to assume
+        #that CPython devs know what they are talking about. Call that getter.
+
+        # Annotations dictionary *AFTER* resolving all postponed hints.
+        #
+        # Note that the functools.update_wrapper() function underlying the
+        # @functools.wrap decorator underlying all sane decorators propagates
+        # this dictionary from lower-level wrappees to higher-level wrappers by
+        # default. We intentionally classify the annotations dictionary of this
+        # higher-level wrapper, which *SHOULD* be the superset of that of this
+        # lower-level wrappee (and thus more reflective of reality).
+        self.func_arg_name_to_hint = get_func_annotations(func)
+
+        # dict.get() method bound to this dictionary.
+        self.func_arg_name_to_hint_get = self.func_arg_name_to_hint.get
+
+        # If this callable is an asynchronous coroutine callable (i.e.,
+        # callable declared with "async def" rather than merely "def" keywords
+        # containing *NO* "yield" expressions)...
+        #
+        # Note that:
+        # * The code object of the higher-level wrapper rather than lower-level
+        #   wrappee is passed. Why? Because @beartype directly decorates *ONLY*
+        #   the former, whose asynchronicity has *NO* relation to that of the
+        #   latter. Notably, it is both feasible and (relatively) commonplace
+        #   for third-party decorators to enable:
+        #   * Synchronous callables to be called asynchronously by wrapping
+        #     synchronous callables with asynchronous closures.
+        #   * Asynchronous callables to be called synchronously by wrapping
+        #     asynchronous callables with synchronous closures. Indeed, our
+        #     top-level "conftest.py" pytest plugin does exactly this --
+        #     enabling asynchronous tests to be safely called by pytest's
+        #     currently synchronous framework.
+        # * The higher-level is_func_async() tester is intentionally *NOT*
+        #   called here, as doing so would also implicitly prefix all calls to
+        #   asynchronous generator callables (i.e., callables also declared
+        #   with the "async def" rather than merely "def" keywords but
+        #   containing one or more "yield" expressions) with the "await"
+        #   keyword. Whereas asynchronous coroutine objects implicitly returned
+        #   by all asynchronous coroutine callables return a single awaitable
+        #   value, asynchronous generator objects implicitly returned by all
+        #   asynchronous generator callables *NEVER* return any awaitable
+        #   value; they instead yield one or more values to external "async
+        #   for" loops.
+        if is_func_coro(self.func_wrappee_codeobj):
+            # Code snippet prefixing all calls to this callable.
+            self.func_wrapper_code_call_prefix = 'await '
+
+            # Code snippet prefixing the declaration of the wrapper function
+            # wrapping this callable with type-checking.
+            self.func_wrapper_code_signature_prefix = 'async '
+        # Else, this callable is synchronous (i.e., callable declared with
+        # "def" rather than "async def"). In this case, reduce these code
+        # snippets to the empty string.
+        else:
+            self.func_wrapper_code_call_prefix = ''
+            self.func_wrapper_code_signature_prefix = ''
+
+# ....................{ FACTORIES                          }....................
+#FIXME: Unit test us up, please.
+def make_beartype_call(
+    # Mandatory parameters.
+    func: Callable,
+    conf: BeartypeConf,
+
+    # Variadic keyword parameters.
+    **kwargs
+) -> BeartypeCall:
+    '''
+    **Beartype call metadata** (i.e., object encapsulating *all* metadata for
+    the passed user-defined callable, typically currently being decorated by the
+    :func:`beartype.beartype` decorator).
+
+    Caveats
+    -------
+    **This higher-level factory function should always be called in lieu of
+    instantiating the** :class:`.BeartypeCall` **class directly.** Why?
+    Brute-force efficiency. This factory efficiently reuses previously
+    instantiated :class:`.BeartypeCall` objects rather than inefficiently
+    instantiating new :class:`.BeartypeCall` objects.
+
+    **The caller must pass the metadata returned by this factory back to the**
+    :func:`beartype._util.cache.pool.utilcachepoolobjecttyped.release_object_typed`
+    **function.** If accidentally omitted, this metadata will simply be
+    garbage-collected rather than available for efficient reuse by this factory.
+    Although hardly a worst-case outcome, omitting that explicit call largely
+    defeats the purpose of calling this factory in the first place.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be described.
+    conf : BeartypeConf
+        Beartype configuration configuring :func:`beartype.beartype` uniquely
+        specific to this callable.
+
+    All remaining keyword parameters are passed as is to the
+    :meth:`.BeartypeCall.reinit` method.
+
+    Returns
+    -------
+    BeartypeCall
+        Beartype call metadata describing this callable.
+
+    '''
+
+    # Previously cached callable metadata reinitialized from that callable.
+    bear_call = acquire_object_typed(BeartypeCall)
+    bear_call.reinit(func, conf, **kwargs)
+
+    # Return this metadata.
+    return bear_call
+
+# ....................{ GLOBALS ~ private                  }....................
+_TypeStackOrNone = NoneTypeOr[tuple]
+'''
+2-tuple ``(type, type(None)``, globally cached for negligible space and time
+efficiency gains on validating passed parameters below.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/checkmagic.py
@@ -0,0 +1,179 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype decorator **type-checking function code magic** (i.e., global string
+constants embedded in the implementations of functions type-checking arbitrary
+objects against arbitrary PEP-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ NAMES                              }....................
+NAME_PREFIX = '__beartype_'
+'''
+Substring prefixing the names of all *other* global string constants declared by
+this submodule.
+'''
+
+# ....................{ NAMES ~ func                       }....................
+FUNC_CHECKER_NAME_PREFIX = f'{NAME_PREFIX}checker_'
+'''
+Substring prefixing the unqualified basenames of all type-checking raiser and
+tester functions created by the
+:func:`beartype._check.checkmake._make_func_checker` factory function.
+'''
+
+# ....................{ NAMES ~ parameter                  }....................
+# To avoid colliding with the names of arbitrary caller-defined parameters, the
+# beartype-specific parameter names *MUST* be prefixed by "__beartype_".
+
+ARG_NAME_CONF = f'{NAME_PREFIX}conf'
+'''
+Name of the **private beartype configuration parameter** (i.e.,
+:mod:`beartype`-specific parameter whose default value is the
+:class:`beartype.BeartypeConf` instance configuring each wrapper function
+generated by the :func:`beartype.beartype` decorator).
+'''
+
+
+ARG_NAME_CLS_STACK = f'{NAME_PREFIX}cls_stack'
+'''
+Name of the **private decorated type stack parameter** (i.e.,
+:mod:`beartype`-specific parameter whose default value is the type stack
+conditionally passed to wrappers generated by the :func:`beartype.beartype`
+decorator whose type-checking logic requires one or more of the classes
+lexically containing the decorated methods wrapped by these wrappers).
+'''
+
+
+ARG_NAME_EXCEPTION_PREFIX = f'{NAME_PREFIX}exception_prefix'
+'''
+Name of the **private exception prefix parameter** (i.e.,
+:mod:`beartype`-specific parameter whose default value is the human-readable
+label prefixing the representation of the currently type-checked object in
+exception messages raised when this object violates its type hint, conditionally
+passed to wrappers generated by the :func:`beartype.door.die_if_unbearable`
+type-checker injected for :pep:`526`-compliant annotated variable assignments by
+:mod:`beartype.claw`-published import hooks).
+'''
+
+
+ARG_NAME_FUNC = f'{NAME_PREFIX}func'
+'''
+Name of the **private decorated callable parameter** (i.e.,
+:mod:`beartype`-specific parameter whose default value is the decorated
+callable passed to each wrapper function generated by the
+:func:`beartype.beartype` decorator).
+'''
+
+
+ARG_NAME_GETRANDBITS = f'{NAME_PREFIX}getrandbits'
+'''
+Name of the **private getrandbits parameter** (i.e., :mod:`beartype`-specific
+parameter whose default value is the highly performant C-based
+:func:`random.getrandbits` function conditionally passed to wrappers generated
+by the :func:`beartype.beartype` decorator whose type-checking logic requires
+one or more random integers).
+'''
+
+
+ARG_NAME_GET_VIOLATION = f'{NAME_PREFIX}get_violation'
+'''
+Name of the **private exception raising parameter** (i.e.,
+:mod:`beartype`-specific parameter whose default value is the
+:func:`beartype._check.error.errorget.get_func_pith_violation`
+function raising human-readable exceptions on call-time type-checking failures
+passed to each wrapper function generated by the :func:`beartype.beartype`
+decorator).
+'''
+
+
+ARG_NAME_HINT = f'{NAME_PREFIX}hint'
+'''
+Name of the **private type hint parameter** (i.e., :mod:`beartype`-specific
+parameter whose default value is the user-defined type hint unconditionally
+passed to the current wrapper function generated by the
+:func:`beartype.door.die_if_unbearable` type-checker receiving that hint).
+'''
+
+
+#FIXME: Excise us up, pleas. This should no longer be required.
+ARG_NAME_TYPISTRY = f'{NAME_PREFIX}typistry'
+'''
+Name of the **private beartypistry parameter** (i.e., :mod:`beartype`-specific
+parameter whose default value is the beartypistry singleton conditionally
+passed to every wrapper function generated by the :func:`beartype.beartype`
+decorator requiring one or more types or tuples of types cached by this
+singleton).
+'''
+
+
+ARG_NAME_WARN = f'{NAME_PREFIX}warn'
+'''
+Name of the **standard warn function** (i.e., :mod:`beartype`-specific
+parameter whose default value is the :func:`warnings.warn` function
+conditionally passed to every wrapper function generated by the
+:func:`beartype.beartype` decorator configured by either the
+:attr:`beartype.BeartypeConf.violation_param_type` or
+:attr:`beartype.BeartypeConf.violation_return_type` options to emit
+non-fatal warnings rather than raise fatal exceptions).
+'''
+
+# ....................{ NAMES ~ var                        }....................
+VAR_NAME_ARGS_LEN = f'{NAME_PREFIX}args_len'
+'''
+Name of the local variable providing the **positional argument count** (i.e.,
+number of positional arguments passed to the current call).
+'''
+
+
+VAR_NAME_RANDOM_INT = f'{NAME_PREFIX}random_int'
+'''
+Name of the local variable providing a **pseudo-random integer** (i.e.,
+unsigned 32-bit integer pseudo-randomly generated for subsequent use in
+type-checking randomly indexed container items by the current call).
+'''
+
+
+VAR_NAME_VIOLATION = f'{NAME_PREFIX}violation'
+'''
+Name of the local variable providing the **violation exception** (i.e.,
+exception describing a type-checking violation to be either raised as a fatal
+exception or emitted as a non-fatal warning by the current call as configured by
+the :attr:`beartype.BeartypeConf.violation_param_type` and
+:attr:`beartype.BeartypeConf.violation_return_type` options).
+'''
+
+# ....................{ NAMES ~ var : pith                 }....................
+VAR_NAME_PITH_PREFIX = f'{NAME_PREFIX}pith_'
+'''
+Substring prefixing all local variables providing a **pith** (i.e., either the
+current parameter or return value *or* item contained in the current parameter
+or return value type-checked by the current call).
+'''
+
+
+VAR_NAME_PITH_ROOT = f'{VAR_NAME_PITH_PREFIX}0'
+'''
+Name of the local variable providing the **root pith** (i.e., value of the
+current parameter or return value being type-checked by the current call).
+'''
+
+# ....................{ CODE ~ pith                        }....................
+CODE_PITH_ROOT_NAME_PLACEHOLDER = '?|PITH_ROOT_NAME`^'
+'''
+Placeholder source substring to be globally replaced by the **root pith name**
+(i.e., name of the current parameter if called by the
+:func:`pep_code_check_param` function *or* ``return`` if called by the
+:func:`pep_code_check_return` function) in the parameter- and return-agnostic
+code generated by the memoized
+:func:`beartype._check.checkmake.make_code_raiser_func_pith_check` function.
+
+See Also
+--------
+:attr:`beartype._data.error.dataerrmagic.EXCEPTION_PLACEHOLDER`
+    Related commentary.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/checkmake.py
@@ -0,0 +1,895 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype type-checking function code factories** (i.e., low-level
+callables dynamically generating pure-Python code snippets type-checking
+arbitrary objects passed to arbitrary callables against PEP-compliant type hints
+passed to those same callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Callable,
+    Optional,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._check.checkmagic import (
+    ARG_NAME_CONF,
+    ARG_NAME_EXCEPTION_PREFIX,
+    ARG_NAME_GETRANDBITS,
+    ARG_NAME_GET_VIOLATION,
+    ARG_NAME_HINT,
+    ARG_NAME_WARN,
+    CODE_PITH_ROOT_NAME_PLACEHOLDER,
+    FUNC_CHECKER_NAME_PREFIX,
+)
+from beartype._check.convert.convsanify import sanify_hint_root_statement
+from beartype._check.code.codemake import make_check_expr
+from beartype._check.error.errorget import (
+    get_func_pith_violation,
+    get_hint_object_violation,
+)
+from beartype._check.util.checkutilmake import make_func_signature
+from beartype._check._checksnip import (
+    CODE_CHECKER_SIGNATURE,
+    CODE_RAISER_FUNC_PITH_CHECK_PREFIX,
+    CODE_RAISER_HINT_OBJECT_CHECK_PREFIX,
+    CODE_TESTER_CHECK_PREFIX,
+    CODE_GET_FUNC_PITH_VIOLATION,
+    CODE_GET_HINT_OBJECT_VIOLATION,
+    CODE_GET_VIOLATION_CLS_STACK,
+    CODE_GET_VIOLATION_RANDOM_INT,
+    CODE_RAISE_VIOLATION,
+    CODE_WARN_VIOLATION,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._conf.conftest import die_unless_conf
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN_REPR
+from beartype._data.hint.datahinttyping import (
+    CallableRaiser,
+    CallableRaiserOrTester,
+    CallableTester,
+    CodeGenerated,
+    LexicalScope,
+    TypeStack,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.error.utilerrraise import reraise_exception_placeholder
+from beartype._util.error.utilerrwarn import reissue_warnings_placeholder
+from beartype._util.func.utilfuncmake import make_func
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585ref import (
+    get_hint_pep484585_ref_names_relative_to)
+from beartype._util.hint.utilhinttest import is_hint_ignorable
+from itertools import count
+from warnings import (
+    catch_warnings,
+    warn,
+)
+
+# ....................{ FACTORIES ~ func                   }....................
+@callable_cached
+def make_func_raiser(
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: All calls to this memoized factory pass parameters *POSITIONALLY*
+    # rather than by keyword. Care should be taken when refactoring parameters,
+    # particularly with respect to parameter position.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    hint: object,
+    conf: BeartypeConf,
+    exception_prefix: str,
+) -> CallableRaiser:
+    '''
+    **Type-checking raiser function factory** (i.e., low-level callable
+    dynamically generating a pure-Python raiser function testing whether an
+    arbitrary object passed to that raiser satisfies the type hint passed to
+    this factory and either raising an exception or emitting a warning when that
+    object violates that hint).
+
+    This factory is memoized for efficiency.
+
+    Caveats
+    -------
+    **This factory intentionally accepts no** ``exception_cls`` **parameter.**
+    Instead, simply set the :attr:`.BeartypeConf.violation_door_type` option of
+    the passed ``conf`` parameter accordingly.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be type-checked.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    CallableRaiser
+        Type-checking raiser function generated by this factory for this hint.
+
+    See Also
+    --------
+    :func:`._make_func_checker`
+        Further details.
+    '''
+
+    # Defer to this lower-level factory function for ultimate lols.
+    return _make_func_checker(  # type: ignore[return-value]
+        hint=hint,
+        conf=conf,
+        make_code_check=make_code_raiser_hint_object_check,
+        exception_prefix=exception_prefix,
+    )
+
+
+@callable_cached
+def make_func_tester(
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: All calls to this memoized factory pass parameters *POSITIONALLY*
+    # rather than by keyword. Care should be taken when refactoring parameters,
+    # particularly with respect to parameter position.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+    exception_prefix: str = 'is_bearable() ',
+) -> CallableTester:
+    '''
+    **Type-checking tester function factory** (i.e., low-level callable
+    dynamically generating a pure-Python tester function testing whether an
+    arbitrary object passed to that tester satisfies the type hint passed to
+    this factory and returning that result as its boolean return).
+
+    This factory is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be type-checked.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object). Defaults
+        to ``BeartypeConf()``, the default :math:`O(1)` configuration.
+
+    Returns
+    -------
+    CallableTester
+        Type-checking tester function generated by this factory for this hint.
+
+    See Also
+    --------
+    :func:`._make_func_checker`
+        Further details.
+    '''
+
+    # Defer to this lower-level factory function for great convenience.
+    return _make_func_checker(  # type: ignore[return-value]
+        hint=hint,
+        conf=conf,
+        make_code_check=make_code_tester_check,
+        exception_prefix=exception_prefix,
+    )
+
+# ....................{ FACTORIES ~ code                   }....................
+#FIXME: Unit test us up, please.
+@callable_cached
+def make_code_tester_check(
+    hint: object,
+    conf: BeartypeConf,
+    exception_prefix : str,
+) -> CodeGenerated:
+    '''
+    Pure-Python code snippet of a type-checking tester function type-checking an
+    arbitrary object against the passed type hint under the passed beartype
+    configuration by returning whether that object satisfies this hint or not.
+
+    This factory is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be type-checked.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    CodeGenerated
+        Tuple containing the Python code snippet dynamically generated by this
+        code factory and metadata describing that code. See the
+        :attr:`beartype._data.hint.datahinttyping.CodeGenerated` type hint.
+
+    See Also
+    --------
+    :func:`.make_check_expr`
+        Further details.
+    '''
+
+    # Python code snippet comprising a single boolean expression type-checking
+    # an arbitrary object against this hint.
+    (
+        code_expr,
+        func_scope,
+        hint_refs_type_basename,
+    ) = make_check_expr(hint, conf)
+
+    # Code snippet type-checking the root pith against the root hint.
+    func_code = f'{CODE_TESTER_CHECK_PREFIX}{code_expr}'
+
+    # Return all metadata required by higher-level callers.
+    return (
+        func_code,
+        func_scope,
+        hint_refs_type_basename,
+    )
+
+# ....................{ FACTORIES ~ code : raiser          }....................
+#FIXME: Unit test us up, please.
+@callable_cached
+def make_code_raiser_func_pith_check(
+    hint: object,
+    conf: BeartypeConf,
+    cls_stack: Optional[TypeStack],
+    is_param: Optional[bool],
+) -> CodeGenerated:
+    '''
+    Pure-Python code snippet of a type-checking raiser function type-checking a
+    parameter or return of a decorated callable against the passed type hint
+    under the passed beartype configuration by either raising a fatal exception
+    *or* emitting a non-fatal warning when that parameter or return violates
+    this hint.
+
+    This factory is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be type-checked.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    cls_stack : Optional[TypeStack]
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+    is_param : Optional[bool]
+        **Tri-state pith boolean.** Although it would be simpler for this
+        factory to accept a pith name, doing so would also effectively unmemoize
+        this factory as well as all higher-level factories calling this factory.
+        If the code snippet generated and returned by this factory is
+        type-checking a previously localized:
+
+        * Parameter of a decorated callable, :data:`True`.
+        * Return of a decorated callable, :data:`False`.
+        * Arbitrary object passed to the :func:`beartype.door.die_if_unbearable`
+          type-checker, :data:`None`.
+
+        Defaults to :data:`None`.
+
+    Returns
+    -------
+    CodeGenerated
+        Tuple containing the Python code snippet dynamically generated by this
+        code factory and metadata describing that code. See the
+        :attr:`beartype._data.hint.datahinttyping.CodeGenerated` type hint.
+
+    See Also
+    --------
+    :func:`.make_check_expr`
+        Further details.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the make_code_hint_object_check() factory.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Python code snippet comprising a single boolean expression type-checking
+    # an arbitrary object against this hint.
+    (
+        code_expr,
+        func_scope,
+        hint_refs_type_basename,
+    ) = make_check_expr(hint, conf, cls_stack)
+
+    # Code snippet passing the value of the random integer previously generated
+    # for the current call to the exception-handling function call embedded in
+    # the "CODE_HINT_ROOT_SUFFIX" snippet, defaulting to *NOT* passing this.
+    arg_random_int = (
+        CODE_GET_VIOLATION_RANDOM_INT
+        if ARG_NAME_GETRANDBITS in func_scope else
+        ''
+    )
+
+    # Code snippet passing the current class stack if needed to type-check this
+    # type hint, defaulting to *NOT* passing this.
+    arg_cls_stack = CODE_GET_VIOLATION_CLS_STACK if cls_stack else ''
+
+    # Pass hidden parameters to this raiser function exposing the
+    # get_func_pith_violation() getter called by the
+    # "CODE_GET_FUNC_PITH_VIOLATION" snippet.
+    func_scope[ARG_NAME_GET_VIOLATION] = get_func_pith_violation
+
+    # Code snippet generating a human-readable violation exception or warning
+    # when the root pith violates the root type hint.
+    code_get_violation = CODE_GET_FUNC_PITH_VIOLATION.format(
+        arg_cls_stack=arg_cls_stack,
+        arg_random_int=arg_random_int,
+        pith_name=CODE_PITH_ROOT_NAME_PLACEHOLDER,
+    )
+
+    # Code snippet handling the previously generated violation by either raising
+    # that violation as a fatal exception or emitting that violation as a
+    # non-fatal warning.
+    code_handle_violation = _make_code_raiser_violation(
+        conf=conf, func_scope=func_scope, is_param=is_param)
+
+    # Code snippet type-checking the root pith against the root hint.
+    func_code = (
+        f'{CODE_RAISER_FUNC_PITH_CHECK_PREFIX}'
+        f'{code_expr}'
+        f'{code_get_violation}'
+        f'{code_handle_violation}'
+    )
+
+    # Return all metadata required by higher-level callers.
+    return (
+        func_code,
+        func_scope,
+        hint_refs_type_basename,
+    )
+
+
+@callable_cached
+def make_code_raiser_func_pep484_noreturn_check(
+    conf: BeartypeConf) -> CodeGenerated:
+    '''
+    Pure-Python code snippet of a type-checking raiser function type-checking a
+    return of a decorated callable against the :obj:`typing.NoReturn` type hint
+    annotating that return under the passed beartype configuration by either
+    raising a fatal exception *or* emitting a non-fatal warning when that
+    callable violates this hint by itself failing to raise an exception.
+
+    This factory is memoized for efficiency.
+
+    Parameters
+    ----------
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+
+    Returns
+    -------
+    CodeGenerated
+        Tuple containing the Python code snippet dynamically generated by this
+        code factory and metadata describing that code. See the
+        :attr:`beartype._data.hint.datahinttyping.CodeGenerated` type hint.
+    '''
+
+    # Lexical scope to be returned, initialized to the empty dictionary.
+    func_scope = {}
+
+    # Pass hidden parameters to this raiser function exposing the
+    # get_func_pith_violation() getter called by the
+    # "CODE_GET_FUNC_PITH_VIOLATION" snippet.
+    func_scope[ARG_NAME_GET_VIOLATION] = get_func_pith_violation
+
+    # Code snippet generating a human-readable violation exception or warning
+    # when the root pith violates the root type hint.
+    code_get_violation = CODE_GET_FUNC_PITH_VIOLATION.format(
+        arg_cls_stack='',
+        arg_random_int='',
+        pith_name=ARG_NAME_RETURN_REPR,
+    )
+
+    # Code snippet handling the previously generated violation by either raising
+    # that violation as a fatal exception or emitting that violation as a
+    # non-fatal warning.
+    code_handle_violation = _make_code_raiser_violation(
+        conf=conf, func_scope=func_scope, is_param=False)
+
+    # Code snippet type-checking the root pith against the root hint.
+    func_code = f'{code_get_violation}{code_handle_violation}'
+
+    # Return all metadata required by higher-level callers.
+    return (
+        func_code,
+        func_scope,
+        (),  # Irrelevant "hint_refs_type_basename" tuple item. Chug it!
+    )
+
+
+#FIXME: Unit test us up, please.
+@callable_cached
+def make_code_raiser_hint_object_check(
+    hint: object,
+    conf: BeartypeConf,
+    exception_prefix: str,
+) -> CodeGenerated:
+    '''
+    Pure-Python code snippet of a type-checking raiser function type-checking an
+    arbitrary object against the passed type hint under the passed beartype
+    configuration by either raising a fatal exception *or* emitting a non-fatal
+    warning when that object violates this hint.
+
+    This factory is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be type-checked.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    CodeGenerated
+        Tuple containing the Python code snippet dynamically generated by this
+        code factory and metadata describing that code. See the
+        :attr:`beartype._data.hint.datahinttyping.CodeGenerated` type hint.
+
+    See Also
+    --------
+    :func:`.make_check_expr`
+        Further details.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the make_code_raiser_func_pith_check() factory.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Python code snippet comprising a single boolean expression type-checking
+    # an arbitrary object against this hint.
+    (
+        code_expr,
+        func_scope,
+        hint_refs_type_basename,
+    ) = make_check_expr(hint, conf)
+
+    # Code snippet passing the value of the random integer previously generated
+    # for the current call to the exception-handling function call embedded in
+    # the "CODE_HINT_ROOT_SUFFIX" snippet, defaulting to *NOT* passing this.
+    arg_random_int = (
+        CODE_GET_VIOLATION_RANDOM_INT
+        if ARG_NAME_GETRANDBITS in func_scope else
+        ''
+    )
+
+    # Pass hidden parameters to this raiser function exposing:
+    # * The passed exception prefix accessed by this snippet.
+    # * The get_hint_object_violation() getter called by the
+    #   "CODE_GET_HINT_OBJECT_VIOLATION" snippet.
+    # * The passed type hint accessed by this snippet.
+    func_scope[ARG_NAME_EXCEPTION_PREFIX] = exception_prefix
+    func_scope[ARG_NAME_GET_VIOLATION] = get_hint_object_violation
+    func_scope[ARG_NAME_HINT] = hint
+
+    # Code snippet generating a human-readable violation exception or warning
+    # when the root pith violates the root type hint.
+    code_get_violation = CODE_GET_HINT_OBJECT_VIOLATION.format(
+        arg_random_int=arg_random_int)
+
+    # Code snippet handling the previously generated violation by either raising
+    # that violation as a fatal exception or emitting that violation as a
+    # non-fatal warning.
+    code_handle_violation = _make_code_raiser_violation(
+        conf=conf, func_scope=func_scope, is_param=None)
+
+    # Code snippet type-checking the root pith against the root hint.
+    func_code = (
+        f'{CODE_RAISER_HINT_OBJECT_CHECK_PREFIX}'
+        f'{code_expr}'
+        f'{code_get_violation}'
+        f'{code_handle_violation}'
+    )
+
+    # Return all metadata required by higher-level callers.
+    return (
+        func_code,
+        func_scope,
+        hint_refs_type_basename,
+    )
+
+# ....................{ PRIVATE ~ globals                  }....................
+_func_checker_name_counter = count(start=0, step=1)
+'''
+**Type-checking function name uniquifier** (i.e., iterator yielding the next
+integer incrementation starting at 0, leveraged by the
+:func:`._make_func_checker` factory to uniquify the names of the type-checking
+functions dynamically generated by that factory).
+'''
+
+# ....................{ PRIVATE ~ testers                  }....................
+def _func_checker_ignorable(obj: object) -> bool:
+    '''
+    **Ignorable type-checking tester function singleton** (i.e., function
+    unconditionally returning :data:`True`, semantically equivalent to a tester
+    testing whether an arbitrary object passed to this tester satisfies an
+    ignorable type hint).
+
+    The :func:`make_func_tester` factory efficiently returns this singleton when
+    passed an ignorable type hint rather than inefficiently regenerating a
+    unique ignorable type-checking tester function for that hint.
+    '''
+
+    return True
+
+# ....................{ PRIVATE ~ factories : func         }....................
+#FIXME: Unit test us up, please.
+def _make_func_checker(
+    # Mandatory parameters.
+    hint: object,
+    conf: BeartypeConf,
+    make_code_check: Callable[..., CodeGenerated],
+
+    # Optional parameters.
+    exception_prefix: str = 'die_if_unbearable() or is_bearable() ',
+) -> CallableRaiserOrTester:
+    '''
+    **Type-checking function factory** (i.e., low-level callable dynamically
+    generating a pure-Python tester function testing whether an arbitrary object
+    passed to that tester satisfies the type hint passed to this factory and
+    either returning that result as its boolean return *or* raising a fatal
+    exception or emitting a non-fatal warning if that result is :data:`False`).
+
+    This factory is intentionally *not* memoized (e.g., by the
+    ``@callable_cached`` decorator), as this factory is only called by
+    higher-level memoized factories.
+
+    Caveats
+    -------
+    **This factory intentionally accepts no** ``exception_cls`` **parameter.**
+    Doing so would only ambiguously obscure context-sensitive exceptions raised
+    by lower-level utility functions called by this higher-level factory.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be type-checked.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    make_code_check : Callable[..., CodeGenerated]
+        **Type-checking code factory** (i.e., function dynamically generating a
+        code snippet of a function type-checking an arbitrary object against the
+        passed type hint under the passed beartype configuration).
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to a reasonably sensible string.
+
+    Returns
+    -------
+    CallableTester
+        Type-checking tester function generated by this factory for this hint.
+
+    Raises
+    ------
+    All exceptions raised by the lower-level :func:`.make_check_expr` factory.
+    Additionally, this factory also raises:
+
+    BeartypeConfException
+        If this configuration is *not* a :class:`.BeartypeConf` instance.
+    BeartypeDecorHintForwardRefException
+        If this hint contains one or more relative forward references, which
+        this factory explicitly prohibits to improve both the efficiency and
+        portability of calls by users to the resulting type-checker.
+    _BeartypeUtilCallableException
+        If this function erroneously generates a syntactically invalid
+        type-checking function. That should *never* happen, but let's admit that
+        you're still reading this for a reason.
+
+    Warns
+    -----
+    All warnings emitted by the lower-level :func:`.make_check_expr` factory.
+    '''
+    assert callable(make_code_check), f'{repr(make_code_check)} uncallable.'
+
+    # Attempt to...
+    try:
+        # With a context manager "catching" *ALL* non-fatal warnings emitted
+        # during this logic for subsequent "playback" below...
+        with catch_warnings(record=True) as warnings_issued:
+            # ....................{ VALIDATION             }....................
+            # If "conf" is *NOT* a configuration, raise an exception.
+            die_unless_conf(conf)
+            # Else, "conf" is a configuration.
+
+            # Either:
+            # * If this hint is PEP-noncompliant, the PEP-compliant type hint
+            #   converted from this PEP-noncompliant type hint.
+            # * If this hint is PEP-compliant and supported, this hint as is.
+            # * Else, raise an exception (i.e., if this hint is neither
+            #   PEP-noncompliant nor a supported PEP-compliant hint).
+            #
+            # Do this first *BEFORE* passing this hint to any further callables.
+            hint = sanify_hint_root_statement(
+                hint=hint, conf=conf, exception_prefix=EXCEPTION_PLACEHOLDER)
+
+            # If this hint is ignorable, all objects satisfy this hint. In this
+            # case, return a trivial function unconditionally returning true.
+            if is_hint_ignorable(hint):
+                return _func_checker_ignorable
+            # Else, this hint is unignorable.
+
+            # ....................{ CODE                   }....................
+            # Python code snippet comprising a single boolean expression
+            # type-checking an arbitrary object against this hint.
+            (
+                code_check,
+                func_scope,
+                hint_refs_type_basename,
+            ) = make_code_check(hint, conf, exception_prefix)
+
+            #FIXME: Actually, nothing below is particularly significant. Users
+            #now basically require this. So, let's find a way to do this. The
+            #only genuinely significant blocker here from @beartype's
+            #perspective is *MEMOIZATION.* Currently, the parent factories
+            #(e.g., make_func_raiser()) transitively calling this factory are
+            #memoized by @callable_cached. Clearly, memoization breaks down in
+            #the face of relative forward references... *OR DOES IT!?* We now
+            #need to probably:
+            #* Figure out a way of replacing all relative forward references
+            #  with corresponding "ForwardRefRelativeProxy" objects.
+            #* This is a fundamentally new type of thing we currently do *NOT*
+            #  have. The idea here is that these objects should dynamically
+            #  introspect up the call stack for the first stack frame residing
+            #  in a non-"beartype" module, which these objects then resolve each
+            #  relative forward reference against.
+            #* Consider refactoring our "codemake" algorthm to unconditionally
+            #  do this for *ALL* relative forward references. Doing so would
+            #  (probably) be a lot faster than the current global string
+            #  replacement approach... maybe. Okay, maybe not. But maybe.
+            #
+            #Sounds fun! Sounds like a lot of non-trivial work, too. But that's
+            #where all the fun resides, doesn't it? *DOESN'T IT!?*
+            #FIXME: *WAIT.* That doesn't quite work. The issue, of course, that
+            #the scope in which a callable is called may no longer have access
+            #to the scope in which a callable was defined, which is where the
+            #class referred to by relative forward references actually lives.
+            #So, we absolutely should *NOT* "Consider refactoring our..." No.
+            #Don't do that. That said, the above idea *SHOULD* still behave
+            #itself for if_bearable() and die_if_unbearable(), because these
+            #statement-level type-checkers actually do run in the same scopes
+            #that their type hints are defined in. Huh. Pretty nifty, eh? This
+            #then suggests that:
+            #* We'll need to generalize our "codemake" function to accept a new
+            #  optional "is_refs_relative_proxy: bool = False" parameter. When:
+            #  * "True", code generation replaces all relative forward
+            #    references with corresponding "ForwardRefRelativeProxy" objects
+            #    as detailed above.
+            #  * "False", code generation simply returns relative forward
+            #    references as it currently does.
+
+            # If this hint contains one or more relative forward references,
+            # this hint is non-portable across lexical scopes. In this case,
+            # raise an exception. Why? Because this hint is relative to and thus
+            # valid only with respect to the caller's current lexical scope.
+            # However, there is *NO* guarantee that the type-checking function
+            # created and returned by this factory resides in the same lexical
+            # scope.
+            #
+            # Suppose that type-checking function does, however. Even in that
+            # best case, *ALL* calls to that tester would still be non-portable.
+            # Why? Because those calls would now tacitly assume the original
+            # lexical scope that they were called in. Those calls are now
+            # lexically-dependent and thus could *NOT* be trivially
+            # copy-and-pasted into different lexical scopes (e.g., submodules,
+            # classes, or callables); doing so would raise exceptions at call
+            # time, due to being unable to resolve those references. Preventing
+            # users from doing something that will blow up in their test suites
+            # commits after the fact is not simply a good thing; it's really the
+            # only sane thing left.
+            #
+            # Suppose that we didn't particularly care about end user sanity,
+            # however. Even in that worst case, resolving these references would
+            # still be non-trivial, non-portable, and (perhaps most importantly)
+            # incredibly slow. Why? Because doing so would require iteratively
+            # introspecting the call stack for the first callable *NOT* residing
+            # in the "beartype" codebase. These references would then be
+            # resolved against the global and local lexical scope of that
+            # callable. While technically feasible, doing so would render
+            # higher-level "beartype" functions calling this lower-level factory
+            # (e.g., our increasingly popular public beartype.door.is_bearable()
+            # and die_if_unbearable() type-checkers) sufficiently slow as to be
+            # pragmatically infeasible.
+            if hint_refs_type_basename:
+                # Defer to a low-level getter to raise a reasonable exception.
+                get_hint_pep484585_ref_names_relative_to(
+                    # First relative forward reference in this type hint,
+                    # arbitrarily chosen for convenience.
+                    hint=hint_refs_type_basename[0],
+                    exception_prefix=(
+                        f'{EXCEPTION_PLACEHOLDER}type hint {repr(hint)} '),
+                )
+            # Else, this hint contains *NO* relative forward references.
+
+            # Unqualified basename of this type-checking function, uniquified by
+            # suffixing an arbitrary integer unique to this function.
+            func_checker_name = (
+                f'{FUNC_CHECKER_NAME_PREFIX}{next(_func_checker_name_counter)}')
+
+            # Python code snippet declaring the signature of the type-checking
+            # function function to be defined and returned by this factory.
+            code_signature = make_func_signature(
+                func_name=func_checker_name,
+                func_scope=func_scope,
+                code_signature_format=CODE_CHECKER_SIGNATURE,
+                conf=conf,
+            )
+
+            # Python code snippet defining this type-checking function in full.
+            func_checker_code = f'{code_signature}{code_check}'
+
+            # ....................{ FUNCTION               }....................
+            # Type-checking tester function to be returned.
+            func_tester = make_func(
+                func_name=func_checker_name,
+                func_code=func_checker_code,
+                func_locals=func_scope,
+                func_label='die_if_unbearable() or is_bearable() type-checker',
+                is_debug=conf.is_debug,
+            )
+        # If one or more warnings were issued, reissue these warnings with each
+        # placeholder substring (i.e., "EXCEPTION_PLACEHOLDER" instance)
+        # replaced by a human-readable description of this callable and
+        # annotated return.
+        if warnings_issued:
+            reissue_warnings_placeholder(
+                warnings=warnings_issued, target_str=exception_prefix)
+        # Else, *NO* warnings were issued.
+    # If doing so raises *ANY* exception, reraise this exception with each
+    # placeholder substring (i.e., "EXCEPTION_PLACEHOLDER" instance) replaced by
+    # an explanatory prefix.
+    except Exception as exception:
+        reraise_exception_placeholder(
+            exception=exception, target_str=exception_prefix)
+
+    # Return this tester function.
+    return func_tester  # type: ignore[return-value]
+
+# ....................{ PRIVATE ~ factories : code         }....................
+def _make_code_raiser_violation(
+    # Mandatory parameters.
+    conf: BeartypeConf,
+    func_scope: LexicalScope,
+
+    # Optional parameters.
+    is_param: Optional[bool] = None,
+) -> str:
+    '''
+    Pure-Python code snippet of a **type-checking raiser function** (i.e.,
+    dynamically generated by the :func:`.make_raiser_func` factory) either
+    raising a fatal exception or emitting a non-fatal warning when an arbitrary
+    object violates an arbitrary type hint under the passed beartype
+    configuration in the body of that raiser.
+
+    This factory is intentionally *not* memoized (e.g., by the
+    ``@callable_cached`` decorator), as this factory is only called by
+    higher-level memoized factories.
+
+    Parameters
+    ----------
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    func_scope : LexicalScope
+        **Lexical scope** (i.e., dictionary mapping from the relative
+        unqualified name to value of each locally or globally scoped attribute
+        accessible to a callable or class).
+    is_param : Optional[bool]
+        **Tri-state pith boolean.** Although it would be simpler for this
+        factory to accept a pith name, doing so would also effectively unmemoize
+        this factory as well as all higher-level factories calling this factory.
+        If the code snippet generated and returned by this factory is
+        type-checking a previously localized:
+
+        * Parameter of a decorated callable, :data:`True`.
+        * Return of a decorated callable, :data:`False`.
+        * Arbitrary object passed to the :func:`beartype.door.die_if_uncallable`
+          type-checker, :data:`None`.
+
+        Defaults to :data:`None`.
+
+    Returns
+    -------
+    CodeGenerated
+        Tuple containing the Python code snippet dynamically generated by this
+        code factory and metadata describing that code. See the
+        :attr:`beartype._data.hint.datahinttyping.CodeGenerated` type hint for
+        details.
+
+    Raises
+    ------
+    All exceptions raised by the lower-level :func:`make_check_expr` factory.
+
+    Warns
+    -----
+    All warnings emitted by the lower-level :func:`make_check_expr` factory.
+
+    See Also
+    --------
+    :func:`.make_check_expr`
+        Further details.
+    '''
+    assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+    assert isinstance(func_scope, dict), (
+        f'{repr(func_scope)} not dictionary.')
+    assert isinstance(is_param, NoneTypeOr[bool]), (
+        f'{repr(is_param)} neither boolean nor "None".')
+
+    # Pass a hidden parameter to this raiser function exposing the passed
+    # beartype configuration accessed by this snippet.
+    func_scope[ARG_NAME_CONF] = conf
+
+    # Code snippet handling the previously generated violation by either raising
+    # that violation as a fatal exception or emitting that violation as a
+    # non-fatal warning, contextually initialized below.
+    code_violation = ''  # type: ignore[assignment]
+
+    # If this code snippet produces this violation by emitting a non-fatal
+    # warning (rather than raising an exception), detected as either...
+    if (
+        # If this object is neither a parameter nor return of a decorated
+        # callable, this object was directly passed to either the
+        # beartype.door.is_bearable() or beartype.door.die_if_unbearable()
+        # functions. In either case, set this boolean to this previously
+        # computed DOOR-specific boolean.
+        conf._is_violation_door_warn if is_param is None else
+        # Else, this object is either a parameter or return of a decorated
+        # callable.
+        #
+        # If this object is be a parameter of a decorated callable, set this
+        # boolean to this previously computed parameter-specific boolean.
+        conf._is_violation_param_warn if is_param else
+        # Else, this object is *NOT* a parameter of a decorated callable. In this
+        # case, this object *MUST* be a return of a decorated callable. Set
+        # this boolean to this previously computed return-specific boolean.
+        conf._is_violation_return_warn
+    ):
+        # Emit a non-fatal warning.
+        code_violation = CODE_WARN_VIOLATION
+
+        # Pass the warnings.warn() function required to emit this warning to
+        # this wrapper function as an optional hidden parameter.
+        #
+        # Note that we intentionally do *NOT* pass the higher-level
+        # issue_warning() function. Why? Efficiency, mostly. Recall that
+        # issue_warning() is *ONLY* called to pretend that warnings generated by
+        # callables both defined by and residing in this codebase are actually
+        # generated by external third-party code. Although this wrapper function
+        # is also generated by callables defined by this codebase (including
+        # this callable, of course), this wrapper function does *NOT* reside
+        # inside this codebase but instead effectively resides inside the
+        # external third-party module defining the original function this
+        # wrapper function wraps. Needlessly passing issue_warning() rather than
+        # warn() here would only consume CPU cycles for *NO* tangible gain.
+        func_scope[ARG_NAME_WARN] = warn
+    # Else...
+    else:
+        # Raise a fatal exception.
+        code_violation = CODE_RAISE_VIOLATION
+
+    # Return this code snippet.
+    return code_violation
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/__init__.py
@@ -0,0 +1,1925 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+# ....................{ TODO                               }....................
+#FIXME: [SPEED] There exists a significant optimization that we *ABSOLUTELY*
+#should implement. Currently, the "hints_meta" data structure is represented as
+#a FixedList of size j, each item of which is a k-length tuple. If you briefly
+#consider it, however, that structure could equivalently be represented as a
+#FixedList of size j * k, where we simply store the items previously stored in
+#each k-length tuple directly in that FixedList itself.
+#
+#Iterating forward and backward by single hints over that FixedList is still
+#trivial. Rather than incrementing or decrementing an index by 1, we instead
+#increment or decrement an index by k.
+#
+#The resulting structure is guaranteed to be considerably more space-efficient,
+#due to being both contiguous in memory and requiring only a single object
+#(and thus object dictionary) to maintain. Cue painless forehead slap.
+
+#FIXME: [PEP] Add support for Python 3.10-specific PEPs and thus:
+#* PEP 612-compliance. Since we don't currently support callable annotations,
+#  we probably can't extend that non-existent support to PEP 612. Nonetheless,
+#  we *ABSOLUTELY* should ensure that we do *NOT* raise exceptions when passed
+#  the two new "typing" singletons introduced by this:
+#  * "typing.ParamSpec", documented at:
+#    https://docs.python.org/3.10/library/typing.html#typing.ParamSpec
+#  * "typing.Concatenate", documented at:
+#    https://docs.python.org/3.10/library/typing.html#typing.Concatenate
+#  Ideally, we should simply ignore these singletons for now in a similar
+#  manner to how we currently ignore type variables. After all, these
+#  singletons are actually a new unique category of callable-specific type
+#  variables. See also:
+#  https://www.python.org/dev/peps/pep-0612
+
+#FIXME: [O(n)] Ah-ha! We now know how to implement O(log n) and O(n)
+#type-checking in a scaleable manner that preserves @beartype's strong
+#performance guarantees. How? With a timed deadline cutoff. Specifically:
+#* Define a new "BeartypeConf.check_time_max_multiplier" instance variable,
+#  which we've already conveniently documented.
+#* Note this critical formula in the documentation for that variable (with the
+#  equality flipped so as to express the condition under which @beartype
+#  continues to perform type-checks):
+#      b * check_time_max_multiplier < T
+#
+#  Naturally, real life isn't quite that convenient. We don't actually have
+#  either "b" or "T". We need to dynamically compute them on each check. What we
+#  *DO* have is:
+#  * "B", the total time consumed by all *PRIOR* @beartype type-checks.
+#  * "t", the current time.
+#  * "s", the initial time at which the current round of @beartype type-checks
+#    was started (e.g., for the current call to a @beartype-decorated callable).
+#  * "Z", the initial time at which the active Python interpreter was started.
+#
+#  For convenience, additionally let:
+#  * "K" be "check_time_max_multiplier" for readability.
+#
+#  Note that "t - s" yields the total time consumed by the *CURRENT* round of
+#  @beartype type-checks. Ergo, "B + t - s" yields the total time consumed by
+#  *ALL* @beartype type-checks. Given that, "b" and "T" can both then be
+#  expressed in terms of these known quantities:
+#      b = B + t - s
+#      T =     t - Z
+#
+#  Then the above formula expands to:
+#      (B + t - s) * K < t - Z     (4 total arithmetic operations)
+#
+#  Note that "t" *MUST* be localized as a local instance variable (e.g., as
+#  "time_curr = time()) to avoid erroneous recomputation of that time. Also, "K"
+#  and "Z" are constants. Ideally, we would be able to simplify away some of
+#  this. Superficially, simplification yields *NO* significant joys:
+#      Bk + Kt - Ks - t + Z < 0
+#      Bk + Z + t(K - 1) < Ks      (6 total arithmetic operations)
+#
+#  However, "K - 1" is clearly also a constant. Let "L = K - 1". Then:
+#      KB + Z + Lt < Ks            (5 total arithmetic operations)
+#      KB - Ks + Z + Lt < 0
+#      K(B - s) + Lt < -Z          (5 total arithmetic operations)
+#
+#  Ah-ha! But "-Z" is also a constant. Let "Y = -Z". Then we have:
+#      K(B - s) + Lt < Y           (4 total arithmetic operations)
+#
+#  This is considerably better. Since "t" only appears once, we no longer need
+#  to localize the result of calling the time() function and can instead simply
+#  embed that call directly -- a significant savings in both time and code
+#  complexity.
+#
+#  Can we do better? Possibly. Note that "s ~= t" for most intents and purposes.
+#  In particular, "s - Z ~= t - Z" (with respect to orders of magnitude, which
+#  is all the right side of that equation is attempting to capture, anyway).
+#  We can then resimplify as follows:
+#      (B + t - s) * K < s - Z     (4 total arithmetic operations)
+#      KB + Kt - Ks - s < -Z
+#      KB + Kt - Ks - s < -Z
+#      K(B + t) - s(K + 1) < Y
+#      K(B + t) - Ls < Y           (4 total arithmetic operations)
+#
+#  Amusingly, that fails to help (and in fact reduces accuracy). Gah! The best
+#  we can do from here is to eliminate the need for "Y" from above as follows:
+#      K(B - s) + Lt < -Z          (5 total arithmetic operations)
+#      K(B - s) < -Lt - Z
+#      K(B - s) < -(Lt + Z)
+#      -K(B - s) > Lt + Z
+#      K(s - B) > Lt + Z           (4 total arithmetic operations)
+#      K(s - B) - Lt > Z           (4 total arithmetic operations)
+#
+#  Furthermore, note that:
+#  * "s" is internally localized at the start of the body of each
+#    @beartype-decorated callable.
+#  * "t" is simply a call to the time() function.
+#  * "K" and "L = K - 1" don't actually need to be passed anywhere. They're
+#    *NOT* variables; they're just hard-coded in at code generation time.
+#  * "B and Z", on the other hand, *DO* need to passed to each
+#    @beartype-decorated callable under the O(n) strategy.
+#  * Moreover, "B" *MUST* be updated by each @beartype-decorated callable under
+#    the O(n) strategy.
+#
+#  Ah-ha! With respect to each call to a @beartype-decorated callable under the
+#  O(n) strategy, the quantity "K(s - B)" is actually a constant. Since "Z" is
+#  also a constant, we simply localize these two constants at the start of the
+#  body of each such callable into a new constant "J = K(s - B) - Z". This then
+#  yields:
+#      K(s - B) - Lt > Z           (4 total arithmetic operations)
+#      K(s - B) - Z > Lt
+#      J > Lt
+#      Lt < J                      (1 total arithmetic operation)
+#
+#  And... that's all she wrote, folks. While that condition holds, @beartype
+#  continues performing O(n) type-checks. It should be noted that this
+#  simplified conditional trivially follows from only a few steps of the
+#  original conditional like so:
+#      (B + t - s) * K < t - Z
+#      KB + Kt - Ks < t - Z
+#      Kt - t < Ks - KB - Z
+#      t(K - 1) < K(s - B) - Z
+#* Altogether, the above implies that each @beartype-decorated callable under
+#  the O(n) strategy should be passed a new hidden "__beartype_times" parameter.
+#  This parameter is a 2-list "(process_time_start, beartype_time_total)",
+#  where:
+#  * "process_time_start" is simply "Z".
+#  * "beartype_time_total" is simply "B".
+#
+#  This 2-list is a global list exposed to each @beartype-decorated callable via
+#  this "__beartype_times" parameter. Declare this global list in a separate
+#  submodule -- say, a new "exprtime" submodule -- as follows:
+#      from time import monotonic
+#
+#      CHECK_TIMES = [monotonic(), 0.0]
+#      '''
+#      **Type-checking wall-clock time accumulator** (i.e., list whose items
+#      allow :mod:`beartype`-generated type-checkers under non-constant
+#      strategies like :attr:`beartype.BeartypeStrategy.On` to record how much
+#      time the active Python process has devoted to :mod:`beartype`, enabling
+#      :mod:`beartype` to prematurely halt type-checking when those
+#      type-checkers exceed scheduled deadlines).
+#
+#      Specifically, this global is a 2-list
+#      ``(process_time_start, beartype_time_total)``, where:
+#
+#      * ``process_time_start`` is the initial time at which the active Python
+#        process was started, denominated in fractional seconds.
+#      * ``beartype_time_total`` is the total time consumed by all *prior*
+#        :mod:`beartype`-generated type-checks, denominated in fractional
+#        seconds.
+#      '''
+#* Now, note the naive implementation of an O(n) type-check for a callable
+#  accepting a parameter annotated by the type hint "list[str]":
+#      @beartype(conf=BeartypeConf(strategy=BeartypeStrategy.On))
+#      def muh_callable(muh_param: list[str]) -> None:
+#          ...
+#
+#          if not (
+#              isinstance(muh_param, list) and
+#              all(isinstance(muh_item, str) for muh_item in list)
+#          ):
+#              raise get_func_pith_violation(...)
+#          ...
+#
+#  Trivial. Now, note the non-naive implementation of the same O(n) type-check
+#  respecting the "check_time_max_multiplier" configuration setting:
+#      from beartype._check._expr.exprtime import CHECK_TIMES
+#      from time import monotonic
+#
+#      @beartype(conf=BeartypeConf(strategy=BeartypeStrategy.On))
+#      def muh_callable(
+#          muh_param: list[str],
+#          __beartype_check_times = CHECK_TIMES,
+#          __beartype_get_time_monotonic = monotonic,
+#      ) -> None:
+#          CHECK_TIME_START = __beartype_get_time_monotonic()
+#
+#          # Constant "J" in the inequality "Lt < J" governing @beartype's
+#          # deadline scheduler for non-constant type-checking, denominated in
+#          # fractional seconds.
+#          CHECK_TIME_MAX = (
+#              {check_time_max_multiplier}(
+#                  CHECK_TIME_START - __beartype_check_times[1]
+#              ) - __beartype_check_times[0]
+#          )
+#
+#          ...
+#
+#          if not (
+#              isinstance(muh_param, list) and
+#              # For each item of this iterable...
+#              all(
+#                  (
+#                      # If @beartype has yet to exceed its scheduled deadline
+#                      # for non-constant type-checks *AND*...
+#                      (
+#                          {check_time_max_multiplier - 1} *
+#                          __beartype_get_time_monotonic() < CHECK_TIME_MAX
+#                      ) and
+#                      isinstance(muh_item, str)
+#                  )
+#                  for muh_item in list
+#              )
+#          # *AND* @beartype has still yet to exceed its scheduled deadline for
+#          # non-constant type-checks...
+#          ) and (
+#              {check_time_max_multiplier - 1} *
+#              __beartype_get_time_monotonic() < CHECK_TIME_MAX
+#          ):
+#              raise get_func_pith_violation(...)
+#          # Else, this pith either satisfies this hint *OR* @beartype has
+#          # exceeded its scheduled deadline for non-constant type-checks.
+#
+#          # Update the total time consumed by @beartype type-checks.
+#          __beartype_check_times[1] += (
+#              __beartype_get_time_monotonic() - CHECK_TIME_START)
+#          ...
+#
+#Seriously trivial, everybody. \o/
+
+#FIXME: [DFS] The "LRUDuffleCacheStrong" class designed below assumes that
+#calculating the semantic height of a type hint (e.g., 3 for the complex hint
+#Optional[int, dict[Union[bool, tuple[int, ...], Sequence[set]], list[str]])
+#is largely trivial. It isn't -- at all. Computing that without a context-free
+#recursion-esque algorithm of some sort is literally infeasible. We absolutely
+#*MUST* get that height right, since we'll be exponentiating that height to
+#estimate space consumption of arbitrary objects. Off-by-one errors are
+#unacceptable when the difference between a height of 2 and a height of 3 means
+#tens of thousands in additional estimated space consumption.
+#
+#So. How do we do this, then? *SIMPLE.* Okay, not simple -- but absolutely
+#beneficial for a medley of unrelated pragmatic reasons and thus something we
+#need to pursue anyway regardless of the above concerns.
+#
+#The solution is to make the breadth-first search (BFS) internally performed
+#by the make_func_pith_code() function below more recursion-esque. We will
+#*NOT* be refactoring that function to leverage:
+#
+#* Recursion rather than iteration for all of the obvious reasons.
+#* A stack-like depth-first search (DFS) approach. While implementing a DFS
+#  with iteration can technically be done, doing so imposes non-trivial
+#  technical constraints because you then need to store interim results (which
+#  in a proper recursive function would simply be local variables) as you
+#  iteratively complete each non-leaf node. That's horrifying. So, we'll be
+#  preserving our breadth-first search (BFS) approach. The reason why a BFS is
+#  often avoided in the real world are space concerns: a BFS consumes
+#  significantly more space than a comparable DFS, because:
+#  * The BFS constructs the entire tree before operating on that tree.
+#  * The DFS only constructs a vertical slice of the entire tree before
+#    operating only on that slice.
+#  In our case, however, space consumption of a BFS versus DFS is irrelevant.
+#  Why? Because type hints *CANNOT* be deeply nested without raising recursion
+#  limit errors from deep within the CPython interpreter, as we well know.
+#  Ergo, a BFS will only consume slightly more temporary space than a DFS. This
+#  means a "FixedList" of the same size trivially supports both.
+#
+#First, let's recap what we're currently doing:
+#
+#* In a single "while ...:" loop, we simultaneously construct the BFS tree
+#  (stored in a "FixedList" of tuples) *AND* output results from that tree as
+#  we are dynamically constructing it.
+#
+#The "simultaneously" is the problem there. We're disappointed we didn't
+#realize it sooner, but our attempt to do *EVERYTHING* in a single pass is why
+#we had such extraordinary difficulties correctly situating code generated by
+#child type hints into the code generated for parent type hints. We
+#circumvented the issue by repeatedly performing a global search-and-replace on
+#the code being generated, which is horrifyingly inefficient *AND* error-prone.
+#We should have known then that something was wrong. Sadly, we proceeded.
+#
+#Fortunately, this is the perfect moment to correct our wrongs -- before we
+#proceed any deeper into a harmful path dependency. How? By splitting our
+#current monolithic BFS algorithm into two disparate BFS phases -- each
+#mirroring the behaviour of a recursive algorithm:
+#
+#1. In the first phase, a "while ...:" loop constructs the BFS tree by
+#   beginning at the root hint, iteratively visiting all child hints, and
+#   inserting metadata describing those hints into our "hints_meta" list as we
+#   currently do. That's it. That's all. But that's enough. This construction
+#   then gives us efficient random access over the entire type hinting
+#   landscape, which then permits us to implement the next phase -- which does
+#   the bulk of the work. To do so, we'll add additional metadata to our
+#   current "hint_meta" tuple: e.g.,
+#   * "_HINT_META_INDEX_CHILD_FIRST_INDEX", the 0-based index into the
+#     "hints_meta" FixedList of the first child hint of the current hint if any
+#     *OR* "None" otherwise. Since this is a BFS, that child hint could appear
+#     at any 0-based index following the current hint; finding that child hint
+#     during the second phase thus requires persisting the index of that hint.
+#     Note that the corresponding index of the last child hint of the current
+#     hint need *NOT* be stored, as adding the length of the argument list of
+#     the current hint to the index of the first child hint trivially gives the
+#     index of the last child hint.
+#   * "_HINT_META_INDEX_CODE", the Python code snippet type-checking the
+#     current hint to be generated by the second phase.
+#   * "_HINT_META_INDEX_HEIGHT", the 1-based height of the current hint in this
+#     BFS tree. Leaf nodes have a height of 1. All non-leaf nodes have a height
+#     greater than 1. This height *CANNOT* be defined during the first phase
+#     but *MUST* instead be deferred to the second phase.
+#   * ...probably loads more stuff, but that's fine.
+#2. In the second phase, another "while ...:" loop generates a Python code
+#   snippet type-checking the root hint and all child hints visitable from that
+#   hint in full by beginning *AT THE LAST CHILD HINT ADDED TO THE*
+#   "hints_meta" FixedList, generating code type-checking that hint,
+#   iteratively visiting all hints *IN THE REVERSE DIRECTION BACK UP THE TREE*,
+#   and so on.
+#
+#That's insanely swag. It shames us that we only thought of it now. *sigh*
+#FIXME: Note that this new approach will probably (hopefully only slightly)
+#reduce decoration efficiency. This means that we should revert to optimizing
+#the common case of PEP-noncompliant classes. Currently, we uselessly iterate
+#over these classes with the same BFS below as we do PEP-compliant classes --
+#which is extreme overkill. This will be trivial (albeit irksome) to revert,
+#but it really is fairly crucial. *sigh*
+#FIXME: Now that we actually have an audience (yay!), we *REALLY* need to avoid
+#breaking anything. But implementing the above refactoring would absolutely
+#break everything for an indeterminate period of time. So how do we do this?
+#*SIMPLE*. We leave this submodule as is *UNTIL* our refactoring passes tests.
+#In the meanwhile, we safely isolate our refactoring work to the following new
+#submodules:
+#* "_pephinttree.py", implementing the first phase detailed above.
+#* "_pephintgene.py", implementing the second phase detailed above.
+#
+#To test, we locally change a simple "import" statement in the parent
+#"_pepcode" submodule and then revert that import before committing. Rinse
+#until tests pass, which will presumably take several weeks at least.
+#FIXME: See additional commentary at this front-facing issue:
+#    https://github.com/beartype/beartype/issues/31#issuecomment-799938621
+#FIXME: Actually, *FORGET EVERYTHING ABOVE.* We actually do want to
+#fundamentally refactor this iterative BFS into an iterative DFS. Why? Because
+#we increasingly need to guard against both combinatorial explosion *AND*
+#recursion. That's imperative -- and we basically *CANNOT* do that with the
+#current naive BFS approach. Yes, implementing a DFS is somewhat more work. But
+#it's *NOT* infeasible. It's very feasible. More importantly, it's necessary.
+#Since @beartype should eventually handle recursive type hints, we'll need
+#recursion guards anyway. Specifically:
+#* Guarding against recursion would be trivial if we were actually using a
+#  depth-first algorithm. While delving, you'd just maintain a local set of the
+#  IDs of all type hints previously visited. You'd then avoid delving into
+#  anything if the ID of that thing is already in that set. Likewise, after
+#  delving into that thing, you'd then pop the ID of that thing off that set.
+#* Likewise, handling combinatorial explosion would *ALSO* be trivial if we were
+#  actually using a depth-first algorithm. By "combinatorial explosion," we are
+#  referring to what happens if we try to type-check dataclass and
+#  "typing.NamedTuple" instances that are *NOT* decorated by @beartype.
+#  Type-checking those instances has to happen at @beartype call time, clearly.
+#  There are actually two kinds of combinatorial explosion at play here:
+#  * Combinatorial explosion while type-checking at @beartype call time. This is
+#    avoidable by simply type-checking *EXACTLY ONE* random field of each
+#    "NamedTuple" instance on each call. Simple. "NamedTuple" instances are
+#    literally just tuples, so random access is trivial. (Type-checking random
+#    fields of dataclass instances is less trivial but still feasible; just pass
+#    a list whose values are dataclass field names as a private
+#    @beartype-specific parameter to type-checking @beartype wrapper functions.
+#    That list then effectively maps from 0-based indices to dataclass field
+#    names. We then perform random access on that list to generate random field
+#    names, which can then be accessed with reasonable efficiency.)
+#  * Combinatorial explosion while generating type-checking code at @beartype
+#    decoration time. This is the problem, folks. Why? Because we currently
+#    employ a breadth-first search (BFS), which requires generating the entire
+#    tree of all type hints to be visited. Currently, that's fine, because type
+#    hints are typically compact; exhausting memory is unlikely. But as soon as
+#    we start generating type-checking code for "NamedTuple" instances *NOT*
+#    decorated by @beartype, we have to begin visiting *ALL* type hints
+#    annotating *ALL* fields of those type hints by adding those hints to our
+#    BFS tree. Suddenly, combinatorial explosion becomes a very real thing.
+#
+#The solution is to radically transform our existing BFS search into a DFS
+#search. Again, this is something we would need to do eventually anyway to
+#handle recursive type hints, because how can you guard against recursion in an
+#iterative BFS anyway? And... anyway, DFS is simply the right approach. It's
+#what we should have done all along, clearly. It's also non-trivial, which is
+#why we didn't do it all along.
+#
+#For example, for each type hint visited by a DFS, we'll need to additionally
+#record metadata like:
+#* "_HINT_META_INDEX_ARGS_INDEX_NEXT", the 0-based index into the
+#  "hint.__args__" tuple (listing all child type hints for the currently visited
+#  type hint "hint") of the next child type hint of the associated parent type
+#  hint to be visited. When "_HINT_META_INDEX_ARGS_INDEX_NEXT ==
+#  len(hint.__args__)", the DFS has successfully visited all child type hints of
+#  the currently visited type hint "hint" and should now iteratively recurse up
+#  (rather than down) the DFS stack.
+#* "_HINT_META_INDEX_CODE", the Python code snippet type-checking the currently
+#  visited hint. This code snippet will be gradually filled in as child type
+#  hints of the currently visited type hint are themselves visited. Indeed, this
+#  implies that the currently visited parent type hint *MUST* always be able to
+#  access the "_HINT_META_INDEX_CODE" entry of the most recently visited child
+#  type hint of that parent -- which, in turn, implies that the entire
+#  "hints_meta" FixedList of each child type hint must be temporarily preserved.
+#  Specifically, when recursing up the DFS stack, each parent type hint will:
+#  1. Access the "hints_meta" FixedList of its most recently visited child type
+#     to fill in its own "_HINT_META_INDEX_CODE".
+#  2. Pop that "hints_meta" FixedList of its most recently visited child type
+#     hint off the DFS stack.
+#
+#Some type hints like unions will additionally require hint-specific entries in
+#their "hints_meta" FixedList. The code for a union *CANNOT* be efficiently
+#generated until *ALL* child type hints of that union have been. Although
+#hint-specific entries could be appended to the "hints_meta" FixedList
+#structure, doing so would rapidly increase the memory consumption of all other
+#types of hints for no particularly good reason. Instead, a single new
+#hint-specific entry should be added:
+#* "_HINT_META_INDEX_DATA", an arbitrary object required by this kind of hint.
+#  In the case of unions, this will be an instance of a dataclass resembling:
+#      @dataclass
+#      def _HintMetaDataUnion(object):
+#          HINTS_CHILD_NONPEP = set()
+#          '''
+#          Set of all previously visited PEP-noncompliant child type hints
+#          (e.g., isinstanceable classes) of this parent union type hint.
+#          '''
+#
+#          HINTS_CHILD_PEP = set()
+#          '''
+#          Set of all previously visited PEP-compliant child type hints of this
+#          parent union type hint.
+#          '''
+#
+#   Naturally, "_HintMetaDataUnion" instances should be cached with the standard
+#   acquire_object() and release_object() approach. *shrug*
+#
+#Oh! Wait. Nevermind. We don't actually need "_HINT_META_INDEX_DATA" or
+#"_HintMetaDataUnion". It's true that we would need both if we needed to handle
+#unions strictly with a classical DFS approach -- but there's *NO* pragmatic
+#reason to do so. Instead, we'll just continue handling unions as we currently
+#do: by iterating over child type hints of unions and separating them into
+#PEP-compliant and PEP-noncompliant sets. So, basically a mini-BFS over unions
+#*BEFORE* we then delve into their PEP-compliant child type hints in the
+#standard DFS way. That's fine, because we're *NOT* purists here. Whatever is
+#fastest and simplest (in that order) is what wins.
+#
+#Note that a DFS still needs to expensively interpolate code snippets into
+#format templates. There's *NO* way around that; since dynamic code generation
+#is what we've gotten ourselves into here, string munging is a necessary "good."
+#FIXME: *OKAY.* It's time to contemplate the unthinkable, folks. Note that our
+#existing make_check_expr() code generation function internally calls the
+#_enqueue_hint_child() closure on each child. You should now be thinking: "Why
+#didn't we simply implement this recursively?" Because that is what I am now
+#thinking, people. Specifically, since we're *ALREADY* paying function call
+#costs, there's little reason not to simply go full-blown recursion and
+#implement this accordingly.
+#
+#Note that this is *NOT* to say that we should go FULL-FULL-BLOWN
+#object-oriented via the DOOR API. That would impose substantial slowdown.
+#Instead, rather, we should begin considering a family of low-level
+#sign-specific functions that generate code for each sign category: e.g.,
+#* _make_check_expr_union() for "HintSignUnion" hints.
+#* _make_check_expr_sequence_1_arg() for "HintSignSequence" hints.
+#* And so on.
+#
+#Then define a private dictionary mapping from signs to those functions. Viola!
+#Misery has been substantially reduced.
+#
+#That said, the current approach still offers benefits. Since all state is
+#centralized into a single function, sharing state between different
+#code-generating "subfunctions" is trivial; they're just local variables. This
+#suggests that we should initially:
+#* Attempt to generalize the current single-function approach from BFS to DFS.
+#* If that fails, do *NOT* hesitate to generalize to a multi-function recursive
+#  approach. However we can implement this is how we must implement this.
+
+#FIXME: Note that there exist four possible approaches to random item selection
+#for arbitrary containers depending on container type. Either the actual pith
+#object (in descending order of desirability):
+#* Satisfies "collections.abc.Sequence" (*NOTE: NOT* "typing.Sequence", as we
+#  don't particularly care how the pith is type-hinted for this purpose), in
+#  which case the above approach trivially applies.
+#* Else is *NOT* a one-shot container (e.g., generator and... are there any
+#  other one-shot container types?) and is *NOT* slotted (i.e., has no
+#  "__slots__" attribute), then generalize the mapping-specific
+#  _get_dict_nonempty_random_key() approach delineated below.
+#* Else is *NOT* a one-shot container (e.g., generator and... are there any
+#  other one-shot container types?) but is slotted (i.e., has a "__slots__"
+#  attribute), then the best we can do is the trivial O(1) approach by
+#  calling "{hint_child_pith} := next({hint_curr_pith})" to unconditionally
+#  check the first item of this container. What you goin' do? *shrug* (Note
+#  that we could try getting around this with a global cache of weak references
+#  to iterators mapped on object ID, but... ain't nobody got time or interest
+#  for that. Also, prolly plenty dangerous.)
+#* Else is a one-shot container, in which case *DO ABSOLUTELY NUTHIN'.*
+#FIXME: We should ultimately make this user-configurable (e.g., as a global
+#configuration setting). Some users might simply prefer to *ALWAYS* look up a
+#fixed 0-based index (e.g., "0", "-1"). For the moment, however, the above
+#probably makes the most sense as a reasonably general-purpose default.
+#FIXME: [THIS-IS-BOSS] *AH-HA.* First, note that the above
+#_get_dict_nonempty_random_key() concept, while clever, is largely useless. Why?
+#Because *ALL* builtin C-based reiterables (e.g., dict, set) are slotted. We'd
+#might as well just ignore that and leap straight to a general-purpose answer.
+#
+#Indeed, we've *FINALLY* realized how to genuinely perform iterative access to
+#arbitrary non-sequence containers in an O(1) manner *WITHOUT* introducing
+#memory leaks or requiring asynchronous background shenanigans. The core conceit
+#is quite simple, really. Internally:
+#
+#* @beartype maintains two global dictionaries:
+#  * A global "_REITERABLE_ID_TO_WEAKPROXY" dictionary mapping from the object
+#    ID of each reiterable that has been previously type-checked by @beartype to
+#    at least once to a strong reference to a "weakref.proxy" instance safely
+#    proxying that reiterable.
+#  * A global "_REITERABLE_ID_TO_ITER" dictionary mapping from the object ID of
+#    each reiterable that has been previously type-checked by @beartype to
+#    at least once to a strong reference to an iterator over that
+#    "weakref.proxy" instance safely proxying that reiterable.
+#
+#  This approach substantially reduces the negative harms associated with memory
+#  leaks -- although one worst-case memory leak *DOES* still remain. Notably,
+#  since these proxies are themselves discrete objects, storing strong
+#  references to both these proxies and these iterators could under worst-case
+#  behaviour consume all available space. Ergo, this dictionary will need to be
+#  efficiently maintained as a large (but still limited) LRU cache. Ideally, the
+#  real-world size of this cache should be bound to a maximum of (say) 1MB space
+#  consumption. Since only proxy shim objects and iterators over those objects
+#  are stored (and we expect the size of these proxies and iterators to be quite
+#  small), this cache *SHOULD* be able to support an exceedingly large number of
+#  proxies before becoming full.
+#
+#  Since this dictionary is only leveraged for type-checking, thread
+#  synchronization is irrelevant (although, of course, care should be taken to
+#  ensure that this dictionary remains internally consistent regardless of
+#  thread preemption).
+#* @beartype provides a trivial _get_reiterable_item_next() getter for use in
+#  dynamically generated type-checking code, which will then call that getter
+#  rather than iter() on reiterables to retrieve an effectively random item from
+#  those reiterables. Internally, this getter leverages the above global
+#  dictionaries as follows:
+#      # Note that this getter assumes the passed reiterable to be *NON-EMPTY.*
+#      # It is the caller's responsibility to ensure that (e.g., by explicitly
+#      # calling "len(reiterable)" or "bool(reiterable)" *BEFORE* calling this
+#      # getter). Trivial, but worth noting. For efficiency, this getter
+#      # intentionally does *NOT* explicitly validate that constraint.
+#      def _get_reiterable_item_next(
+#          reiterable: _BeartypeReiterableTypes) -> object:
+#
+#          #FIXME: Curiously, some C-based containers *DO* support weak
+#          #references. Crucially, this includes sets, frozensets, arrays, and
+#          #deques. Dicts, however, do *NOT*. Are dicts the only notable
+#          #exceptions? Not quite. *ANY* user-defined reiterable defining
+#          #"__slots__" that does *NOT* contain the string '__weakref__' also
+#          #does *NOT* support weak references. In short, we can really only
+#          #perform the following for a small subset of type hints: e.g.,
+#          #* "typing.Deque".
+#          #* "typing.FrozenSet".
+#          #* "typing.Set".
+#          #
+#          #Aaaaaaand... we're pretty sure that's it. Three is better than
+#          #nothing, of course. But... that's still not that great. We could try
+#          #to dynamically test for weak-referenceability -- except we're pretty
+#          #sure that that *CANNOT* be done efficiently in the general case.
+#          #We'd need to either:
+#          #* Call dir(), which dynamically creates and returns a new dict.
+#          #  That's right out.
+#          #* Access "__dict__" directly, which is only defined for pure-Python
+#          #  instances. That attribute does *NOT* exist for C-based instances.
+#          #
+#          #Actually, the most efficient detection heuristic would probably be:
+#          #* Define yet another global
+#          #  "_REITERABLE_TYPE_TO_IS_WEAKREFFABLE" dictionary mapping from
+#          #  reiterable types to boolean "True" only if those types can be
+#          #  weakly referenced. This dictionary can be pre-initialized for
+#          #  efficiency with the most common builtin C-based reiterable types
+#          #  in a global context as follows:
+#          #      _REITERABLE_TYPE_TO_IS_WEAKREFFABLE = {
+#          #          DefaultDict: False,
+#          #          dict: False,
+#          #          deque: True,
+#          #          frozenset: True,
+#          #          set: True,
+#          #      }
+#          #  We don't bother LRU-bounding that. Size is irrelevant here.
+#          #* Likewise, define yet another globl
+#          #  "_REITERABLE_TYPE_TO_IS_LENGTHHINTED" dictionary mapping from
+#          #  reiterable types to boolean "True" only if those types define
+#          #  iterators defining semantically meaningful __length_hint__()
+#          #  dunder methods. Since detecting that at runtime is infeasible, we
+#          #  simply preallocate that to those we do know about:
+#          #      _REITERABLE_TYPE_TO_IS_LENGTHHINTED = {
+#          #          deque: True,  # <-- unsure if true, actually *shrug*
+#          #          frozenset: True,
+#          #          set: True,
+#          #      }
+
+#          #* Given that, we then efficiently detect weak-referenceability:
+#
+#          REITERABLE_TYPE = reiterable.__class__
+#
+#          #FIXME: Again, optimize ...get() method access, please.
+#          reiterable_is_weakreffable = (
+#              _REITERABLE_TYPE_TO_IS_WEAKREFFABLE.get(REITERABLE_TYPE))
+#
+#          if reiterable_is_weakreffable is None:
+#              reiterable_dict = getattr(reiterable, '__dict__')
+#              #FIXME: Alternately, we could try just taking a weak proxy
+#              #of this reiterable and catching exceptions. Although
+#              #slower, this caching operation only occurs once per type.
+#              #For now, let's run with this faster heuristic.
+#              if not reiterable_dict:
+#                  reiterable_is_weakreffable = False
+#              else:
+#                  reiterable_slots = reiterable_dict.get('__slots__')
+#                  reiterable_is_weakreffable = (
+#                      reiterable_slots and
+#                      '__weakref__' not in reiterable_slots
+#                  )
+#              _REITERABLE_TYPE_TO_IS_WEAKREFFABLE[REITERABLE_TYPE] = (
+#                  reiterable_is_weakreffable)
+#
+#          # If this reiterable is a C-based container that does *NOT* support
+#          # weak references, reduce to simply returning the first item of this
+#          # reiterable.
+#          if not reiterable_is_weakreffable:
+#              return next(iter(reiterable))
+#
+#          REITERABLE_ID = id(reiterable)
+#
+#          #FIXME: Optimize by storing and calling a bound
+#          #"_REITERABLE_ID_TO_ITER_get" method instead, please.
+#          reiterable_iter = _REITERABLE_ID_TO_ITER.get(REITERABLE_ID)
+#
+#          if reiterable_iter:
+#              #FIXME: Note that this can be conditionally optimized for
+#              #iterators that define the PEP 424-compliant __length_hint__()
+#              #dunder method -- which thankfully appears to be *ALL* iterators
+#              #over C-based reiterables (e.g., dicts, sets). For these objects,
+#              #__length_hint__() provides the number of remaining items in the
+#              #iterator. Ergo, this can be optimized as follows:
+#              #    if reiterable_iter.__length_hint__():
+#              #        return next(reiterable_iter)
+#              #    else:
+#              #        ...
+#              #
+#              #The issue, of course, is that that *ONLY* works for strict type
+#              #hints constrained to C-based iterables (e.g.,
+#              #"typing.Dict[...]"). General-purpose type hints like
+#              #"typing.Mapping[...]" would be inapplicable, sadly. For the
+#              #latter, dynamically testing for the existence of a semantically
+#              #meaningful __length_hint__() getter would consume far more time
+#              #than calling that getter would actually save. *shrug*
+#              try:
+#                  return next(reiterable_iter)
+#              except StopIteration:
+#                  #FIXME: Violates DRY a bit, but more efficient. *shrug*
+#                  reiterable_weakproxy = _REITERABLE_ID_TO_WEAKPROXY[
+#                      REITERABLE_ID]
+#                  _REITERABLE_ID_TO_ITER[REITERABLE_ID] = iter(
+#                      reiterable_weakproxy)
+#                  return next(reiterable_iter)
+#
+#          if len(_REITERABLE_ID_TO_WEAKPROXY) >= _REITERABLE_CACHE_MAX_LEN:
+#               #FIXME: Efficiently kick out the least-used item from both the
+#               #"_REITERABLE_ID_TO_WEAKPROXY" and "_REITERABLE_ID_TO_ITER"
+#               #dictionaries here. Research exactly how to do that. Didn't we
+#               #already implement an efficient LRU somewhere in @beartype?
+#
+#          reiterable_weakproxy = _REITERABLE_ID_TO_WEAKPROXY[REITERABLE_ID] = (
+#              proxy(reiterable))
+#          _REITERABLE_ID_TO_ITER[REITERABLE_ID] = iter(reiterable_weakproxy)
+#          return next(reiterable_iter)
+#FIXME: Pretty boss, if we do say so. And we do. There are also considerable
+#opportunities for both macro- and microoptimization. The biggest
+#macrooptimization would be doing away entirely with the
+#"_REITERABLE_ID_TO_WEAKPROXY" cache. Strictly speaking, we only actually need
+#the "_REITERABLE_ID_TO_ITER" cache. Doing away with the
+#"_REITERABLE_ID_TO_WEAKPROXY" cache is *PROBABLY* the right thing to do in most
+#cases. Why? Because we don't necessarily expect that @beartype type-checkers
+#will exhaust all available items for most reiterables. But we *DO* know that
+#all reiterables that will be type-checked will be type-checked at least once.
+#In other words, the trailing code in _get_reiterable_item_next() is guaranteed
+#to *ALWAYS* happen at least once per reiterable (so we should optimize that);
+#conversely, the leading code that restarts iteration from the beginning only
+#happens in edge cases for smaller reiterables passed or returned frequently
+#between @beartype-decorated callables (so we shouldn't bother optimizing that).
+#Optimizing away "_REITERABLE_ID_TO_WEAKPROXY" then yields:
+#
+#      #FIXME: Don't even bother calling this getter with "dict" objects. The
+#      #caller should explicitly perform an "pith.__class__ is dict" check to
+#      #switch to more efficient "next(iter(pith.keys())" and
+#      #"next(iter(pith.values())" logic when the pith is a "dict" object. Note
+#      #that user-defined "dict" subclasses are fine, however. *facepalm*
+#      def _get_reiterable_item_next(
+#          reiterable: _BeartypeReiterableTypes) -> object:
+#
+#          REITERABLE_TYPE = reiterable.__class__
+#
+#          #FIXME: Again, optimize ...get() method access, please.
+#          reiterable_is_weakreffable = (
+#              _REITERABLE_TYPE_TO_IS_WEAKREFFABLE.get(REITERABLE_TYPE))
+#
+#          if reiterable_is_weakreffable is None:
+#              reiterable_dict = getattr(reiterable, '__dict__')
+#              #FIXME: Alternately, we could try just taking a weak proxy
+#              #of this reiterable and catching exceptions. Although
+#              #slower, this caching operation only occurs once per type.
+#              #For now, let's run with this faster heuristic.
+#              if not reiterable_dict:
+#                  reiterable_is_weakreffable = False
+#              else:
+#                  reiterable_slots = reiterable_dict.get('__slots__')
+#                  reiterable_is_weakreffable = (
+#                      reiterable_slots and
+#                      '__weakref__' not in reiterable_slots
+#                  )
+#              _REITERABLE_TYPE_TO_IS_WEAKREFFABLE[REITERABLE_TYPE] = (
+#                  reiterable_is_weakreffable)
+#
+#          # If this reiterable is a C-based container that does *NOT* support
+#          # weak references, reduce to simply returning the first item of this
+#          # reiterable.
+#          if not reiterable_is_weakreffable:
+#              return next(iter(reiterable))
+#
+#          REITERABLE_ID = id(reiterable)
+#
+#          #FIXME: Optimize by storing and calling a bound
+#          #"_REITERABLE_ID_TO_ITER_get" method instead, please.
+#          reiterable_iter = _REITERABLE_ID_TO_ITER.get(REITERABLE_ID)
+#
+#          if reiterable_iter:
+#              #FIXME: Optimize us up, yo!
+#              if _REITERABLE_TYPE_TO_IS_LENGTHHINTED.get(REITERABLE_TYPE):
+#                  if reiterable_iter.__length_hint__():
+#                      return next(reiterable_iter)
+#              else:
+#                  try:
+#                      return next(reiterable_iter)
+#                  except StopIteration:
+#                      pass
+#          elif len(_REITERABLE_ID_TO_ITER) >= _REITERABLE_CACHE_MAX_LEN:
+#               #FIXME: Efficiently kick out the least-used item from the
+#               #"_REITERABLE_ID_TO_ITER" dictionary here. Research exactly how
+#               #to do that. Didn't we already implement an efficient LRU
+#               #somewhere in @beartype?
+#               #FIXME: *AH-HA!* Forget LRU. Seriously. LRU would impose too
+#               #much overhead here, as we'd need to update the LRU on each
+#               #access. Instead, let's just friggin *CLEAR* the entire cache
+#               #here. Yes, that's right! Nuke it from orbit, bois! So, what?
+#               #Right? Who cares if we start over from zero? Nobody! It's
+#               #minimal overhead to just start iterating things all over again.
+#               #And if the cache is full up, that's a good indication that the
+#               #caller has gone off the rails a bit, anyway.
+#               _REITERABLE_ID_TO_ITER.clear()  # <-- *BOOM STICK*
+#
+#          reiterable_iter = _REITERABLE_ID_TO_ITER[REITERABLE_ID] = iter(
+#              proxy(reiterable))
+#          return next(reiterable_iter)
+#
+#Seems legitimately boss, yes? Everything above is feasible and *REASONABLY*
+#efficient -- but is that efficient enough? Honestly, that's probably fast
+#enough for *MOST* use cases. If users justifiably complain about performance
+#degradations, we could always provide a new "BeartypeConf" parameter defaulting
+#to enabled to control this behaviour. *shrug*
+
+#FIXME: Note that randomly checking mapping (e.g., "dict") keys and/or values
+#will be non-trivial, as there exists no out-of-the-box O(1) approach in either
+#the general case or the specific case of a "dict". Actually, there does -- but
+#we'll need to either internally or externally maintain one dict.items()
+#iterator for each passed mapping. We should probably investigate the space
+#costs of that *BEFORE* doing so. Assuming minimal costs, one solution under
+#Python >= 3.8 might resemble:
+#* Define a new _get_dict_random_key() function resembling:
+#      def _get_dict_nonempty_random_key(mapping: MappingType) -> object:
+#          '''
+#          Caveats
+#          ----------
+#          **This mapping is assumed to be non-empty.** If this is *not* the
+#          case, this function raises a :class:`StopIteration` exception.
+#          '''
+#          items_iter = getattr(mapping, '__beartype_items_iter', None)
+#          if items_iter is None:
+#              #FIXME: This should probably be a weak reference to prevent
+#              #unwanted reference cycles and hence memory leaks.
+#              #FIXME: We need to protect this both here and below with a
+#              #"try: ... except Exception: ..." block, where the body of the
+#              #"except Exception:" condition should probably just return
+#              #"beartype._util.utilobject.SENTINEL", as the only type hints
+#              #that would ever satisfy are type hints *ALL* objects satisfy
+#              #(e.g., "Any", "object").
+#              mapping.__beartype_items_iter = iter(mapping.items())
+#          try:
+#              return next(mapping.__beartype_items_iter)
+#          # If we get to the end (i.e., the prior call to next() raises a
+#          # "StopIteration" exception) *OR* anything else happens (i.e., the
+#          # prior call to next() raises a "RuntimeError" exception due to the
+#          # underlying mapping having since been externally mutated), just
+#          # start over. :p
+#          except Exception:
+#              mapping.__beartype_items_iter = None
+#
+#              # We could also recursively call ourselves: e.g.,
+#              #     return _get_dict_random_key(mapping)
+#              # However, that would be both inefficient and dangerous.
+#              mapping.__beartype_items_iter = iter(mapping.items())
+#              return next(mapping.__beartype_items_iter)
+#* In "beartype._decor._main":
+#     import _get_dict_nonempty_random_key as __beartype_get_dict_nonempty_random_key
+#* In code generated by this submodule, internally call that helper when
+#  checking keys of non-empty mappings *THAT ARE UNSLOTTED* (for obvious
+#  reasons) ala:
+#  (
+#     {hint_curr_pith} and
+#     not hasattr({hint_curr_pith}, '__slots__') and
+#     {!INSERT_CHILD_TEST_HERE@?(
+#         {hint_child_pith} := __beartype_get_dict_nonempty_random_key({hint_curr_pith}))
+#  )
+#  Obviously not quite right, but gives one the general gist of the thing.
+#
+#We could get around the slots limitation by using an external LRU cache
+#mapping from "dict" object ID to items iterator, and maybe that *IS* what we
+#should do. Actually... *NO.* We absolutely should *NOT* do that sort of thing
+#anywhere in the codebase, as doing so would guaranteeably induce memory leaks
+#by preventing "dict" objects cached in that LRU from being garbage collected.
+#
+#Note that we basically can't do this under Python < 3.8, due to the lack of
+#assignment expressions there. Since _get_dict_nonempty_random_key() returns a
+#new random key each call, we can't repeatedly call that for each child pith
+#and expect the same random key to be returned. So, Python >= 3.8 only. *shrug*
+#
+#Note that the above applies to both immutable mappings (i.e., objects
+#satisfying "Mapping" but *NOT* "MutableMapping"), which is basically none of
+#them, and mutable mappings. Why? Because we don't particularly care if the
+#caller externally modifies the underlying mapping between type-checks, even
+#though the result is the above call to "next(mapping.__beartype_items_iter)"
+#raising a "RuntimeError". Who cares? Whenever an exception occurs, we just
+#restart iteration over from the beginning and carry on. *GOOD 'NUFF.*
+#FIXME: *YIKES.* So, as expected, the above approach fundamentally fails on
+#builtin dicts and sets. Why? Because *ALL* builtin types prohibit
+#monkey-patching, which the above technically is. Instead, we need a
+#fundamentally different approach.
+#
+#That approach is to globally (but thread-safely, obviously) cache *STRONG*
+#references to iterators over dictionary "ItemsView" objects. Note that we
+#can't cache weak references, as the garbage collector would almost certainly
+#immediately dispose of them, entirely defeating the point. Of course, these
+#references implicitly prevent garbage collection of the underlying
+#dictionaries, which means we *ALSO* need a means of routinely removing these
+#references from our global cache when these references are the only remaining
+#references to the underlying dictionaries. Can we do any of this? We can.
+#
+#First, note that we can trivially obtain the number of live references to any
+#arbitrary object by calling "sys.getrefcount(obj)". Note, however, that the
+#count returned by this function is mildly non-deterministic. In particular,
+#off-by-one issues are not merely edge cases but commonplace. Ergo:
+#
+#    from sys import getrefcount
+#
+#    def is_obj_nearly_dead(obj: object) -> bool:
+#        '''
+#        ``True`` only if there only exists one external strong reference to
+#        the passed object.
+#        '''
+#
+#        # Note that the integer returned by this getter is intentionally *NOT*
+#        # tested for equality with "1". Why? Because:
+#        # * The "obj" parameter passed to this tester is an ignorable strong
+#        #   reference to this object.
+#        # * The "obj" parameter passed to the getrefcount() getter is yet
+#        #   another strong reference to this object.
+#        return getrefcount(obj) <= 3
+#
+#Second, note that neither the iterator API nor the "ItemsView" API provide a
+#public means of obtaining a strong reference to the underlying dictionary.
+#This means we *MUST* necessarily maintain for each dictionary a 2-tuple
+#"(mapping, mapping_iter)", where:
+#* "mapping" is a strong reference to that dictionary.
+#* "mapping_iter" is an iterator over that dictionary's "ItemsView" object.
+#
+#This implies that we want to:
+#* Define a new "beartype._util.cache.utilcachemapiter" submodule.
+#* In that submodule:
+#  * Define a new global variable resembling:
+#      # Note that this is unbounded. There's probably no reasonable reason to
+#      # use an LRU-style bounded cache here... or maybe there is for safety to
+#      # avoid exhausting memory. Right.
+#      #
+#      # So, this should obviously be LRU-bounded at some point. Since Python's
+#      # standard @lru decorator is inefficient, we'll need to build that our
+#      # ourselves, which means this is *NOT* an immediate priority.
+#      _MAP_ITER_CACHE = {}
+#      '''
+#      Mapping from mapping identifiers to 2-tuples
+#      ``(mapping: Mapping, mapping_iter: Iterator)``,
+#      where ``mapping`` is a strong reference to the mapping whose key is that
+#      mapping's identifier and ``mapping_iter`` is an iterator over that
+#      mapping's ``ItemsView`` object.
+#      '''
+#  * Define a new asynchronous cleanup_cache() function. See the
+#    cleanup_beartype() function defined below for inspiration.
+#* Extensively unit test that submodule.
+#
+#Third, note that this means the above is_obj_nearly_dead() fails to apply to
+#this edge case. In our case, a cached dictionary is nearly dead if and only if
+#the following condition applies:
+#
+#    def is_cached_mapping_nearly_dead(mapping: Mapping) -> bool:
+#        '''
+#        ``True`` only if there only exists one external strong reference to
+#        the passed mapping internally cached by the :mod:`beartype.beartype`
+#        decorator.
+#        '''
+#
+#        # Note that the integer returned by this getter is intentionally *NOT*
+#        # tested for equality with "1". Why? Because ignorable strong
+#        # references to this mapping include:
+#        # * The "mapping" parameter passed to this tester.
+#        # * The "mapping" parameter passed to the getrefcount() getter.
+#        # * This mapping cached by the beartype-specific global container
+#        #   caching these mappings.
+#        # * The iterator over this mapping cached by the same container.
+#        return getrefcount(mapping) <= 5   # <--- yikes!
+#
+#Fourth, note that there are many different means of routinely removing these
+#stale references from our global cache (i.e., references that are the only
+#remaining references to the underlying dictionaries). For example, we could
+#routinely iterate over our entire cache, find all stale references, and remove
+#them. This is the brute-force approach. Of course, this approach is both slow
+#and invites needlessly repeated work across repeated routine iterations. Ergo,
+#rather than routinely iterating *ALL* cache entries, we instead only want to
+#routinely inspect a single *RANDOM* cache entry on each scheduled callback of
+#our cleanup routine. This is the O(1) beartype approach and still eventually
+#gets us where we want to go (i.e., complete cleanup of all stale references)
+#with minimal costs. A random walk wins yet again.
+#
+#Fifth, note that there are many different means of routinely scheduling work.
+#We ignore the existence of the GIL throughout the following discussion, both
+#because we have no choice *AND* because the randomized cleanup we need to
+#perform on each scheduled callback is an O(1) operation with negligible
+#constant factors and thus effectively instantaneous rather than CPU- or
+#IO-bound. The antiquated approach is "threading.Timer". The issue with the
+#entire "threading" module is that it is implemented with OS-level threads,
+#which are ludicrously expensive and thus fail to scale. Our usage of the
+#"threading" module in beartype would impose undue costs on downstream apps by
+#needlessly consuming a precious thread, preventing apps from doing so. That's
+#bad. Instead, we *MUST* use coroutines, which are implemented in Python itself
+#rather than exposed to the OS and thus suffer no such scalability concerns,
+#declared as either:
+#* Old-school coroutines via the @asyncio.coroutine decorator. Yielding under
+#  this approach is trivial (and possibly more efficient): e.g.,
+#       yield
+#* New-school coroutines via the builtin "async def" syntax. Yielding under
+#  this approach is non-trivial (and possibly less efficient): e.g.,
+#       await asyncio.sleep_ms(0)
+#
+#In general, the "async def" approach is strongly favoured by the community.
+#Note that yielding control in the "async def" approach is somewhat more
+#cumbersome and possibly less efficient than simply performing a "yield".
+#Clearly, a bit of research here is warranted. Note this online commentary:
+#    In performance-critical code yield does offer a small advantage. There are
+#    other tricks such as yielding an integer (number of milliseconds to
+#    pause). In the great majority of cases code clarity trumps the small
+#    performance gain achieved by these hacks. In my opinion, of course.
+#
+#In either case, we declare an asynchronous coroutine. We then need to schedule
+#that coroutine with the global event loop (if any). The canonical way of doing
+#this is to:
+#* Pass our "async def" function to the asyncio.create_task() function.
+#  Although alternatives exist (e.g., futures), this function is officially
+#  documented as being the preferred approach:
+#    create_task() (added in Python 3.7) is the preferable way for spawning new
+#    tasks.
+#  Of course, note this requires Python >= 3.7. We could care less. *shrug*
+#* Pass that task to the asyncio.run() function... or something, something.
+#  Clearly, we still need to research how to routinely schedule that task with
+#  "asyncio" rather than running it only once. In theory, that'll be trivial.
+#
+#Here's a simple example:
+#
+#    async def cleanup_beartype(event_loop):
+#        # Disregard how simple this is, it's just for example
+#        s = await asyncio.create_subprocess_exec("ls", loop=event_loop)
+#
+#    def schedule_beartype_cleanup():
+#        event_loop = asyncio.get_event_loop()
+#        event_loop.run_until_complete(asyncio.wait_for(
+#            cleanup_beartype(event_loop), 1000))
+#
+#The above example was culled from this StackOverflow post:
+#    https://stackoverflow.com/questions/45010178/how-to-use-asyncio-event-loop-in-library-function
+#Unlike the asyncio.create_task() approach, that works on Python >= 3.6.
+#Anyway, extensive research is warranted here.
+#
+#Sixthly, note that the schedule_beartype_cleanup() function should be called
+#only *ONCE* per active Python process by the first call to the @beartype
+#decorator passed a callable annotated by one or more "dict" or
+#"typing.Mapping" type hints. We don't pay these costs unless we have to. In
+#particular, do *NOT* unconditionally call the schedule_beartype_cleanup()
+#function on the first importation of the "beartype" package.
+#
+#Lastly, note there technically exists a trivial alternative to the above
+#asynchronous approach: the "gc.callbacks" list, which allows us to schedule
+#arbitrary user-defined standard non-asynchronous callback functions routinely
+#called by the garbage collector either immediately before or after each
+#collection. So what's the issue? Simple: end users are free to either
+#explicitly disable the garbage collector *OR* compile or interpreter their
+#apps under a non-CPython executable that does not perform garbage collection.
+#Ergo, this alternative fails to generalize and is thus largely useless.
+#FIXME: Actually... let's not do the "asyncio" approach -- at least not
+#initially. Why? The simplest reason is that absolutely no one expects a
+#low-level decorator to start adding scheduled asynchronous tasks to the global
+#event loop. The less simple reason is that doing so would probably have
+#negative side effects to at least one downstream consumer, the likes of which
+#we could never possibly predict.
+#
+#So, what can we do instead? Simple. We do this by:
+#* If garbage collection is enabled, registering a new cleanup callback with
+#  "gc.callbacks".
+#* Else, we get creative. First, note that garbage collection is really only
+#  ever disabled in the real world when compiling Python to a lower-level
+#  language (typically, C). Ergo, efficiency isn't nearly as much of a concern
+#  in this currently uncommon edge case. So, here's what we do:
+#  * After the first call to the @beartype decorator passed a callable
+#    annotated by one or more mapping or set type hints, globally set a private
+#    "beartype" boolean -- say, "WAS_HINT_CLEANABLE" -- noting this to have
+#    been the case.
+#  * In the _code_check_params() function generating code type-checking *ALL*
+#    annotated non-ignorable parameters:
+#    * If "WAS_HINT_CLEANABLE" is True, conditionally append code calling our
+#      cleanup routine *AFTER* code type-checking these parameters. While
+#      mildly inefficient, function calls incur considerably less overhead
+#      when compiled away from interpreted Python bytecode.
+#FIXME: Note that the above scheme by definition *REQUIRES* assignment
+#expressions and thus Python >= 3.8 for general-purpose O(1) type-checking of
+#arbitrarily nested dictionaries and sets. Why? Because each time we iterate an
+#iterator over those data structures we lose access to the previously iterated
+#value, which means there is *NO* sane means of type-checking nested
+#dictionaries or sets without assignment expressions. But that's unavoidable
+#and Python <= 3.7 is the past, so that's largely fine.
+#
+#What we can do under Python <= 3.7, however, is the following:
+#* If the (possibly nested) type hint is of the form
+#  "{checkable}[...,{dict_or_set}[{class},{class}],...]" where
+#  "{checkable}" is an arbitrary parent type hint safely checkable under Python
+#  <= 3.7 (e.g., lists, unions), "{dict_or_set}" is (wait for it) either "dict"
+#  or "set", and "{class}" is an arbitrary type, then that hint *IS* safely
+#  checkable under Python <= 3.7. Note that items (i.e., keys and values) can
+#  both be checked in O(1) time under Python <= 3.7 by just validating the key
+#  and value of a different key-value pair (e.g., by iterating once for the key
+#  and then again for the value). That does have the disadvantage of then
+#  requiring O(n) iteration to raise a human-readable exception if a dictionary
+#  value fails a type-check, but we're largely okay with that. Again, this only
+#  applies to an edge case under obsolete Python versions, so... *shrug*
+#* Else, a non-fatal warning should be emitted and the portion of that type
+#  hint that *CANNOT* be safely checked under Python <= 3.7 should be ignored.
+#FIXME: Note that mapping views now provide a "mapping" attribute enabling
+#direct access of the mapping mapped by that view under Python >= 3.10:
+#    The views returned by dict.keys(), dict.values() and dict.items() now all
+#    have a mapping attribute that gives a types.MappingProxyType object
+#    wrapping the original dictionary.
+#This means that we do *NOT* need to explicitly cache the "mapping" object
+#mapped by any cached view under Python >= 3.10, reducing space consumption.
+
+#FIXME: *WOOPS.* The "CacheLruStrong" class is absolutely awesome and we'll
+#absolutely be reusing that for various supplementary purposes across the
+#codebase (e.g., for perfect O(1) tuple type-checking below). However, this
+#class sadly doesn't get us where we need to be for full O(1) dictionary and
+#set type-checking. Why? Two main reasons:
+#* *ITERATIVE ACCESS.* Our routinely scheduled cleanup function needs to
+#  iteratively or randomly access arbitrary cache items for inspection to
+#  decide whether they need to be harvested or not.
+#* *VARIABLE OBJECT SIZES.* We gradually realized, given the plethora of
+#  related "FIXME:" comments below, that we'll eventually want to cache a
+#  variety of possible types of objects across different caches -- each cache
+#  caching a unique type of object. This makes less and less sense the more one
+#  considers, however. For example, why have an LRU cache of default size 256
+#  specific to iterators for a downstream consumer that only passes one
+#  iterator to a single @beartype-decorated callable?
+#
+#The solution to both is simple, but not: we define a new derivative
+#"LRUDuffleCacheStrong" class. The motivation for using the term "duffle" is
+#that, just like a duffle bag, a duffle cache:
+#* Provides random access.
+#* Elegantly stretches to contains a variable number of arbitrary objects of
+#  variable size.
+#
+#The "LRUDuffleCacheStrong" class satisfies both concerns by caching to a
+#maximum *OBJECT SIZE CAPACITY* rather than merely to an *OBJECT NUMBER
+#CAPACITY.* Whereas the "CacheLruStrong" class treats all cached objects as
+#having a uniform size of 1, the "LRUDuffleCacheStrong" class instead assigns
+#each cached object an estimated abstract size (EAS) as a strictly positive
+#integer intended to reflect its actual transitive in-memory size -- where a
+#cached object of EAS 1 is likely to be the smallest object in that cache.
+#While estimating EAS will depend on object type, the following should apply:
+#* EAS estimators *MUST* run in O(1) time. That is, estimating the abstract
+#  size of an object *MUST* be implementable in constant time with negligible
+#  constant factors. This means that the standard approach of recursively
+#  inspecting the physical in-memory sizes of all objects visitable from the
+#  target object should *NOT* be employed.
+#* For containers:
+#  * Note that type hints provide us the expected height
+#    "sizeable_height" of any data structure, where "sizeable_height" is
+#    defined as the number of "[" braces in a type hint ignoring those that do
+#    *NOT* connote semantic depth (e.g., "Optional", "Union", "Annotated"). So:
+#    * The "sizeable_height" for a type hint "list[list[list[int]]]" is 3.
+#    * Since any unsubscripted type hint (e.g., "list") is implicitly
+#      subscripted by "[Any]", the "sizeable_height" for the type hints "list"
+#      and "list[int]" is both 1.
+#  * Note also that most containers satisfy the "collections.abc.Sizeable" ABC.
+#  * Given that, we can trivially estimate the EAS "sizeable_bigo_size" of any
+#    type-hinted sizeable object "sizeable" as follows:
+#      sizeable_bigo_size = len(sizeable) ** sizeable_height
+#  Ergo, a list of length 100 type-hinted as "list[list[int]]" has a size of:
+#      sizeable_bigo_size = 100 ** 2 = 10,000
+#* For dictionaries, the "sizeable_bigo_size" provided by the equation above
+#  should be multiplied by two to account for the increased space consumption
+#  due to storing key-value pairs.
+#
+#Here's then how the "LRUDuffleCacheStrong" class is implemented:
+#* The "LRUDuffleCacheStrong" class should *NOT* subclass the
+#  "CacheLruStrong" class but copy-and-paste from the latter into the former.
+#  This is both for efficiency and maintainability; it's likely their
+#  implementations will mildly diverge.
+#* The LRUDuffleCacheStrong.__init__() method should be implemented like this:
+#      def __init__(
+#          self,
+#          bigo_size_max: int,
+#          value_metadata_len: 'Optional[int]' = 0,
+#      )
+#          assert bigo_size_max > 0
+#          assert value_metadata_len >= 0
+#
+#          # Classify all passed parameters as instance variables.
+#          self._EAS_MAX = bigo_size_max
+#          self._FIXED_LIST_SIZE = value_metadata_len + 2
+#
+#          # Initialize all remaining instance variables.
+#          self._bigo_size_cur = 0
+#          self._iter = None
+#* Note the above assignment of these new instance variables:
+#  * "_EAS_MAX", the maximum capacity of this LRU cache in EAS units. Note that
+#    this capacity should ideally default to something that *DYNAMICALLY SCALES
+#    WITH THE RAM OF THE LOCAL MACHINE.* Ergo, "_bigo_size_max" should be
+#    significantly larger in a standard desktop system with 32GB RAM than it is
+#    on a Raspberry Pi 2 with 1GB RAM: specifically, 32 times larger.
+#  * "_bigo_size_cur", the current capacity of this LRU cache in EAS units.
+#  * "_FIXED_LIST_SIZE", the number of additional supplementary objects to
+#    be cached with each associated value of this LRU cache. The idea here is
+#    that each key-value pair of this cache is an arbitrary hashable object
+#    (the key) mapping to a "FixedList(size=self._FIXED_LIST_SIZE)"
+#    (the value) whose 0-based indices provide (in order):
+#    1. The EAS of that object. For completeness, we should also add to the
+#       "sizeable_bigo_size" estimate given above the additional estimated cost
+#       of this "FixedList". Since the length of this "FixedList" is guaranteed
+#       to be exactly "self._value_metadata_len + 2", this then gives a final
+#       EAS of that object as:
+#         sizeable_bigo_size = (
+#             self._value_metadata_len + 2 + len(sizeable) ** sizeable_height)
+#    2. A strong reference to the primary object being cached under this key.
+#       For dictionaries and sets, this is an iterator over those dictionaries
+#       and sets.
+#    3...self._value_metadata_len + 2: Additional supplementary objects to be
+#       cached along with that object. For dictionaries and sets, exactly one
+#       supplementary object must be cached, so this is:
+#       3. The underlying dictionary or set being iterated over, so we can
+#          lookup the number of existing strong references to that dictionary
+#          or set during cleanup and decide whether to uncache that or not.
+#  * "_iter", an iterator over this dictionary. Yes, we *COULD* implement
+#    random access (e.g., with a linked list or list), but doing so introduces
+#    extreme complications and inefficiencies in both space and time. Instead,
+#    persisting a simple iterator over this dictionary suffices.
+#* Allow any "LRUDuffleCacheStrong" instance to be trivially incremented
+#  (e.g., during garbage collection cleanup) as an iterator by also defining:
+#      def get_pair_next_or_none(
+#          self,
+#          __dict_len = dict.__len__,
+#      ) -> 'Optional[Tuple[Hashable, FixedList]]':
+#          '''
+#          Next most recently used key-value pair of this cache if this cache
+#          is non-empty *or* ``None`` otherwise (i.e., if this cache is empty).
+#
+#          The first call to this method returns the least recently used
+#          key-value pair of this cache. Each successive call returns the next
+#          least recently used key-value pair of this cache until finally
+#          returning the most recently used key-value pair of this cache, at
+#          which time the call following that call rewinds time by again
+#          returning the least recently used key-value pair of this cache.
+#          '''
+#
+#          #FIXME: Probably nest this in a "with self._thread_lock:" block.
+#
+#          # If this cache is empty, return None.
+#          if not __dict_len(self):
+#              return None
+#          # Else, this cache is non-empty.
+#
+#          # Attempt to...
+#          try:
+#              # Return the next recent key-value pair of this cache.
+#              return self._iter.__next__()
+#          # If doing so raises *ANY* exception, this iterator has become
+#          # desynchronized from this cache. In this case...
+#          #
+#          # Note this implicitly handles the initial edge case in which this
+#          # cache has yet to be iterated (i.e., "self._iter == None"). Since
+#          # this is *ONLY* the case for the first call to this method for the
+#          # entire lifetime of the active Python process, the negligible
+#          # overhead of handling this exception is preferable to violating DRY
+#          # by duplicating this logic with an explicit
+#          # "if self._iter == None:" block.
+#          except:
+#              # Reinitialize this iterator.
+#              self._iter = self.items()
+#
+#              # Return the least recent such pair.
+#              return self._iter.__next__()
+#* Refactor the __setitem__() method. Specifically, when caching a new
+#  key-value pair with EAS "bigo_size_item" such that:
+#      while bigo_size_item + self._bigo_size_cur > self._bigo_size_max:
+#  ...we need to iteratively remove the least recently used key-value pair of
+#  this cache (which, yes, technically has O(n) worst-case time, which is
+#  non-ideal, which may be why nobody does this, but that's sort-of okay here,
+#  since we're doing something monstrously productive each iteration by freeing
+#  up critical space and avoiding memory leaks, which seems more than worth the
+#  cost of iteration, especially as we expect O(1) average-case time) until
+#  this cache can fit that pair into itself. Once it does, we:
+#      # Bump the current EAS of this cache by the EAS of this pair.
+#      self._bigo_size_cur += bigo_size_item
+#  Oh, and there's an obvious edge case here: if "bigo_size_item >
+#  self._bigo_size_max", we do *NOT* attempt to do anything with that object.
+#  We don't cache it or an iterator over it. It's too bid. Instead, we just
+#  type-check the first item of that object in O(1) time. *shrug*
+#
+#Seems sweet to us. We can store arbitrarily large nested containers in our
+#duffle cache without exhausting memory, which is actually more than the
+#brute-force LRU cache can say. We get trivial iteration persistence. We also
+#avoid a proliferation of different LRU caches, because a single
+#"LRUDuffleCacheStrong" instance can flexibly store heterogeneous types.
+#FIXME: *RIGHT.* So, "LRUDuffleCacheStrong" is mostly awesome as defined above.
+#We'd just like to make a few minor tweaks for improved robustness:
+#
+#* Drop the "value_metadata_len" parameter from the
+#  LRUDuffleCacheStrong.__init__() method. We'd prefer to have that parameter
+#  individually passed to each cache_item() call (see below) rather than
+#  globally, as the former enables different types of cached objects to have a
+#  different quantity of metadata cached with those objects.
+#* Drop the __setitem__() implementation borrow from "CacheLruStrong". Instead,
+#  defer to the existing dict.__setitem__() implementation. Why? Because we
+#  need to pass additional cache-specific parameters to our own
+#  __setitem__()-like non-dunder method, which __setitem__() doesn't support.
+#* Define a new cache_obj() method resembling CacheLruStrong.__setitem__() but
+#  even more virile and awesome with signature resembling:
+#      def cache_value(
+#          self,
+#
+#          # Mandatory parameters.
+#          key: 'Hashable',
+#          value: object,
+#          *metadata: object,
+#
+#          # Optional parameters.
+#          value_height: 'Optional[int]' = 1,
+#      ) -> None:
+
+#FIXME: Here's a reasonably clever idea for perfect O(1) tuple type-checking
+#guaranteed to check all n items of an arbitrary tuple in exactly n calls, with
+#each subsequent call performing *NO* type-checking by reducing to a noop. How?
+#Simple! We:
+#* Augment our existing "CacheLruStrong" data structure to optionally accept a
+#  new initialization-time "value_maker" factory function defaulting to "None".
+#  If non-"None", "CacheLruStrong" will implicitly call that function on each
+#  attempt to access a missing key by assigning the object returned by that
+#  call as the key of a new key-value pair -- or, in other words, by behaving
+#  exactly like "collections.defaultdict".
+#* Globally define a new "_LRU_CACHE_TUPLE_TO_COUNTER" cache somewhere as an
+#  instance of "CacheLruStrong" whose "value_maker" factory function is
+#  initialized to a lambda function simply returning a new
+#  "collections.Counter" object that starts counting at 0. Since tuples
+#  themselves are hashable and thus permissible for direct use as dictionary
+#  keys, this cache maps from tuples (recently passed to or returned from
+#  @beartype-decorated callables) to either:
+#  * If that tuple has been type-checked to completion, "True" or any other
+#    arbitrary sentinel placeholder, really. "True" is simpler, however,
+#    because the resulting object needs to be accessible from dynamically
+#    generated wrapper functions.
+#  * Else, a counter such that the non-negative integer returned by
+#    "next(counter)" is the 0-based index of the next item of that tuple to be
+#    type-checked.
+#
+#Given that low-level infrastructure, the make_func_pith_code() function below
+#then generates code perfectly type-checking arbitrary tuples in O(1) time that
+#should ideally resemble (where "__beartype_pith_j" is the current pith
+#referring to this tuple):
+#    (
+#        _LRU_CACHE_TUPLE_TO_COUNTER[__beartype_pith_j] is True or
+#        {INSERT_CHILD_TYPE_CHECK_HERE}(
+#            __beartype_pith_k := __beartype_pith_j[
+#                next(_LRU_CACHE_TUPLE_TO_COUNTER[__beartype_pith_j])]
+#        )
+#    )
+#
+#Awesome, eh? The same concept trivially generalizes to immutable sequences
+#(i.e., "Sequence" type hints that are *NOT* "MutableSequence" type hints).
+#Sadly, since many users use "Sequence" to interchangeably denote both
+#immutable and mutable sequences, we probably have no means of reliably
+#distinguishing the two. So it goes! So, just tuples then in practice. *sigh*
+
+#FIXME: Huzzah! We finally invented a reasonably clever means of (more or less)
+#safely type-checking one-shot iterables like generators and iterators in O(1)
+#time without destroying those iterables. Yes, doing so requires proxying those
+#iterables with iterables of our own. Yes, this is non-ideal but not nearly as
+#bad as you might think. Why? Because *NO ONE CARES ABOUT ONE-SHOT ITERABLES.*
+#They're one-shot. By definition, you can't really care about them, because
+#they don't last long enough. You certainly can't cache them or stash them in
+#data structures or really do anything with them beside pass or return them
+#between callables until they inevitably get exhausted.
+#
+#This means that proxying one-shot iterables is almost always safe. Moreover,
+#we devised a clever means of proxying that introduces negligible overhead
+#while preserving our O(1) guarantee. First, let's examine the standard
+#brute-force approach to proxying one-shot iterables:
+#
+#    class BeartypeIteratorProxy(object):
+#        def __init__(self, iterator: 'Iterator') -> None:
+#            self._iterator = iterator
+#
+#        def __next__(self) -> object:
+#            item_next = next(self._iterator)
+#
+#            if not {INSERT_TYPE_CHECKS_HERE}(item_next):
+#                raise SomeBeartypeException(f'Iterator {item_next} bad!')
+#
+#            return item_next
+#
+#That's bad, because that's an O(n) type-check run on every single iteration.
+#Instead, we do this:
+#
+#    class BeartypeIteratorProxy(object):
+#        def __init__(self, iterator: 'Iterator') -> None:
+#            self._iterator = iterator
+#
+#        def __next__(self) -> object:
+#            # Here is where the magic happens, folks.
+#            self.__next__ = self._iterator.__next__
+#
+#            item_next = self.__next__(self._iterator)
+#
+#            if not {INSERT_TYPE_CHECKS_HERE}(item_next):
+#                raise SomeBeartypeException(f'Iterator {item_next} bad!')
+#
+#            return item_next
+#
+#See what we did there? We dynamically monkey-patch away the
+#BeartypeIteratorProxy.__next__() method by replacing that method with the
+#underlying __next__() method of the proxied iterator immediately after
+#type-checking one and only one item of that iterator.
+#
+#The devil, of course, is in that details. Assuming a method can monkey-patch
+#itself away (we're pretty sure it can, as that's the basis of most efficient
+#decorators that cache property method results, *BUT WE SHOULD ABSOLUTELY
+#VERIFY THAT THIS IS THE CASE), the trick is then to gracefully handle
+#reentrancy. That is to say, although we have technically monkey-patched away
+#the BeartypeIteratorProxy.__next__() method, that object is still a live
+#object that *WILL BE RECREATED ON EACH CALL TO THE SAME* @beartype-decorated
+#callable. Yikes! So, clearly we yet again cache with an "CacheLruStrong" cache
+#specific to iterators... or perhaps something like "CacheLruStrong" that
+#provides a callback mechanism to enable arbitrary objects to remove themselves
+#from the cache. Yes! Perhaps just augment our existing "CacheLruStrong" strong
+#with some sort of callback or hook support?
+#
+#In any case, the idea here is that the "BeartypeIteratorProxy" class defined
+#above should internally:
+#* Store a weak rather than strong reference to the underlying iterator.
+#* Register a callback with that weak reference such that:
+#  * When the underlying iterator is garbage-collected, the wrapping
+#    "BeartypeIteratorProxy" proxy removes itself from its "CacheLruStrong"
+#    proxy.
+#
+#Of course, we're still not quite done yet. Why? Because we want to avoid
+#unnecessarily wrapping "BeartypeIteratorProxy" instances in
+#"BeartypeIteratorProxy" instances. This will happen whenever such an instance
+#is passed to a @beartype-decorated callable annotated as accepting or
+#returning an iterator. How can we avoid that? Simple. Whenever we detect that
+#an iterator to be type-checked is already a "BeartypeIteratorProxy" instance,
+#we just efficiently restore the __next__() method of that instance to its
+#pre-monkey-patched version: e.g.,
+#    (
+#        isinstance(__beartype_pith_n, BeartypeIteratorProxy) and
+#        # Unsure if this sort of assignment expression hack actually works.
+#        # It probably doesn't. So, this may need to be sealed away into a
+#        # utility function performing the same operation. *shrug*
+#        __beartype_pith_n.__next__ = BeartypeIteratorProxy.__next__
+#    )
+
+#FIXME: Huzzah! The prior commentary on type-checking iterators in O(1) time
+#also generalizes to most of the other non-trivial objects we had no idea how
+#to type-check -- notably, callables. How? Simple. *WE PROXY CALLABLES WITH
+#OBJECTS WHOSE* __call__() methods:
+#* Type-check parameters to be passed to the underlying callable.
+#* Call the underlying callable.
+#* Type-check the return value.
+#* Monkey-patch themselves away by replacing themselves (i.e., the __call__()
+#  methods of that object) with the underlying callable. The only issue here,
+#  and it might be a deal-breaker, is whether or not a bound method can simply
+#  be replaced with either an unbound function *OR* a bound method of another
+#  object entirely. Maybe it can? We suspect it can in both cases, but research
+#  will certainly be required here.
+#
+#Again, cache such objects to avoid reentrancy issues. That said, there is a
+#significant complication here that one-shot iterables do *NOT* suffer:
+#proxying. Unlike one-shot iterables, callables are often expected to retain
+#their object identities. Proxying disrupts that. I still believe that we
+#should enable proxying across the board by default despite that, because less
+#than 1% of our users will manually enable an option enabling proxying, simply
+#because they'll never think to go look for it and when they do find it will be
+#understandably hesitant to enable it when everything else is working. Users
+#(including myself) typically only enable options when they encounter issues
+#requiring they do so. Ergo, proxy by default. But we *ABSOLUTELY* need to
+#allow users to conditionally disable proxying on a per-decoration basis --
+#especially when proxying callables.
+#
+#So we propose adding a new optional "is_proxying" parameter to the @beartype
+#decorator. Unfortunately, doing so in an efficient manner will prove highly
+#non-trivial. Why? Because the standard approach of doing so is *PROBABLY*
+#extremely inefficient. We need to test that hypothesis, of course, but the
+#standard approach to adding optional parameters to decorators is to nest a
+#closure in a closure in a function. We don't need the innermost closure, of
+#course, because we dynamically generate it at runtime. We would need the
+#outermost closure, though, to support optional decorator parameters under the
+#standard approach. That seems outrageously expensive, because each call to the
+#@beartype decorator would then internally generate and return a new closure!
+#Yikes. We can avoid that by instead, on each @beartype call:
+#* Create a new functools.partial()-based wrapper decorator passed our
+#  @beartype decorator and all options passed to the current @beartype call.
+#* Cache that wrapper decorator into a new private "CacheLruStrong" instance.
+#* Return that decorator.
+#* Return the previously cached wrapper decorator on the next @beartype call
+#  passed the same options (rather than recreating that decorator).
+#
+#Naturally, this requires these options to be hashable. Certainly, booleans
+#are, so this smart approach supports a new optional "is_proxying" parameter.
+#FIXME: Note that the above approach should only be employed as a last-ditch
+#fallback in the event that the passed callable both:
+#* Lacks a non-None "__annotations__" dictionary.
+#* Is *not* annotated by the third-party optional "typeshed" dependency.
+#
+#If the passed callable satisfies either of those two constraints, the existing
+#type hints annotating that callable should be trivially inspected instead in
+#O(1) time (e.g., by just performing a brute-force dictionary comparison from
+#that callable's "__annotations__" dictionary to a dictionary that we
+#internally construct and cache based on the type hints annotating the
+#currently decorated callable, except that doesn't quite work because the
+#"__annotations__" dictionary maps from parameter and return names whereas the
+#"typing.Callable" and "collections.abc.Callable" syntax omits those names,
+#which begs the question of how the latter syntax handles positional versus
+#keyword arguments anyway)... *OR SOMETHING.*
+#
+#Fascinatingly, "Callable" syntax supports *NO* distinction between mandatory,
+#optional, positional, or keyword arguments, because PEP 484 gonna PEP 484:
+#    "There is no syntax to indicate optional or keyword arguments; such
+#     function types are rarely used as callback types."
+#
+#Note that mapping from the return type hint given by "typing.Callable" syntax
+#into the "__annotations__" dictionary is trivial, because the return is always
+#unconditionally named "return" in that dictionary. So, we then just have to
+#resolve how to ignore parameter names. Actually, handling mandatory positional
+#parameters (i.e., positional parameters lacking defaults) on the passed
+#callable should also be trivial, because they *MUST* strictly correspond to
+#the first n child type hints of the first argument of the expected parent
+#"typing.Callable" type hint. It's optional positional parameters and keyword
+#arguments that are the rub. *shrug*
+#
+#Obviously, we'll want to dynamically generate the full test based on the
+#expected parent "typing.Callable" type hint. For sanity, do this iteratively
+#by generating code testing arbitrary "__annotations__" against a "Callable"
+#type hint (in increasing order of complexity):
+#* Passed *NO* parameters and returning something typed.
+#* Passed *ONE* parameter and returning something typed.
+#* Passed *TWO* parameters and returning something typed.
+#* Passed an arbitrary number of parameters and returning something typed.
+#
+#Note that test should ideally avoid iteration. We're fairly certain we can do
+#that by mapping various attributes from the code object of the passed callable
+#into something that enables us to produce a tuple of type hints matching the
+#first argument of the expected parent "Callable" type hint.
+#
+#*BINGO!* The value of the "func.__code__.co_varnames" attribute is a tuple of
+#both parameter names *AND* local variables. Fortunately, the parameter names
+#come first. Unfortunately, there are two types: standard and keyword-only.
+#Altogether, an expression yielding a tuple of the names of all parameters
+#(excluding local variables) is given by:
+#
+#    #FIXME: Insufficient. Variadic parameters also exist. Also, note that this
+#    #has already been efficiently implemented as get_func_arg_names()!
+#    func_codeobj = get_func_unwrapped_codeobj(func)
+#
+#    # Tuple of the names of all parameters accepted by this callable.
+#    func_param_names = func_codeobj.co_varnames[
+#        :func_codeobj.co_argcount + func_codeobj.co_kwonlyargcount]
+#
+#Note that "func_param_names" probably excludes variadic positional and keyword
+#argument names, but that's probably fine, because "Callable" type hint syntax
+#doesn't appear to explicitly support that sort of thing anyway. I mean, how
+#would it? Probably using the "..." singleton ellipse object, I'm sure. But
+#that's completely undefined, so it seems doubtful anyone's actually doing it.
+#
+#We then need to use that tuple to slice "func.__annotations__". Of course, you
+#can't slice a dictionary in Python, because Python dictionaries are much less
+#useful than they should be. See also:
+#    https://stackoverflow.com/questions/29216889/slicing-a-dictionary
+#
+#The simplest and fastest approach we can currently think of is given by:
+#    func_param_name_to_hint = func.__annotations__
+#
+#    # Generator comprehension producing type hints for this callable's
+#    # parameters in the same order expected by the first argument of the
+#    # "Callable" type hint.
+#    func_param_hints = (
+#        func_param_name_to_hint[func_param_name]
+#        for func_param_name in func_param_names
+#    )
+#
+#Note that because we know the exact number of expected parameters up front
+#(i.e., as the len() of the first argument of the "Callable" type hint), we can
+#generate optimal code *WITHOUT* a generator or other comprehension and thus
+#*WITHOUT* iteration. Yes, this is literally loop unrolling in Python, which is
+#both hilarious and exactly what CPython developers get for failing to support
+#generally useful operations on dictionaries and sets: e.g.,
+#
+#    callable_type_hint = ... # Give this a name for reference below.
+#
+#    # Number of non-variadic parameters expected to be accepted by this
+#    # caller-passed callable.
+#    FUNC_PARAM_LEN_EXPECTED = len(callable_type_hint[0])
+#
+#    # Generator comprehension producing type hints for this callable's
+#    # parameters in the same order expected by the first argument of the
+#    # "Callable" type hint.
+#    func_param_hints = (
+#        func_param_name_to_hint[func_param_names[0]],
+#        func_param_name_to_hint[func_param_names[1]],
+#        ...
+#        func_param_name_to_hint[func_param_names[FUNC_PARAM_LEN_EXPECTED]],
+#    )
+#
+#Clearly, there's *LOADS* of additional preliminary validation that needs to
+#happen here as well. Since "Callable" type hint syntax *REQUIRES* a return
+#type hint to be specified (yes, this is absolutely non-optional), we also need
+#to ensure that "func_param_name_to_hint" contains the 'return' key.
+#
+#Given all that, the final test would then resemble something like:
+#
+#    (
+#        __beartype_pith_n_func_param_name_to_hint := (
+#            func.__annotations__ or LOOKUP_IN_TYPESHED_SOMEHOW) and
+#        'return' in __beartype_pith_n_func_param_name_to_hint and
+#        __beartype_pith_n_func_codeobj := getattr(
+#            __beartype_pith_n, '__code__', None) and
+#        # Just ignore C-based callables and assume they're valid. Unsure what
+#        # else we can do with them. Okay, we could also proxy them here, but
+#        # that seems a bit lame. Just accept them as is for now, perhaps?
+#        __beartype_pith_n_func_codeobj is None or (
+#            __beartype_pith_n_func_param_names := (
+#                __beartype_pith_n_func_codeobj.co_varnames) and
+#            len(__beartype_pith_n_func_param_names) == {FUNC_PARAM_LEN_EXPECTED} and
+#            (
+#                __beartype_pith_n_func_param_name_to_hint[__beartype_pith_n_func_param_names[0]],
+#                __beartype_pith_n_func_param_name_to_hint[__beartype_pith_n_func_param_names[1]],
+#                ...
+#                __beartype_pith_n_func_param_name_to_hint[__beartype_pith_n_func_param_names[FUNC_PARAM_LEN_EXPECTED]],
+#                __beartype_pith_n_func_param_name_to_hint['return']
+#            ) == {callable_type_hint}
+#        )
+#    )
+#
+#*YUP.* That's super hot, that is. We're sweating.
+#
+#Note this test is effectively O(1) but really O(FUNC_PARAM_LEN_EXPECTED) where
+#FUNC_PARAM_LEN_EXPECTED is sufficiently small that it's basically O(1). That
+#said, the constant factors are non-negligible. Fortunately, callables *NEVER*
+#change once declared. You should now be thinking what we're thinking:
+#*CACHING*. That's right. Just stuff the results of the above test (i.e., a
+#boolean) into our duffel LRU cache keyed on the fully-qualified name of that
+#callable. We only want to pay the above price once per callable, if we can
+#help it, which we absolutely can, so let's do that please.
+#
+#*NOTE THAT ASSIGNMENT EXPRESSIONS ARE EFFECTIVELY MANDATORY.* I mean, there's
+#basically no way we can avoid them, so let's just require them. By the time we
+#get here anyway, Python 3.6 will be obsolete, which just leaves Python 3.7. We
+#could just emit warnings when decorating callables annotated by "Callable"
+#type hints under Python 3.7. </insert_shrug>
+#
+#*NOTE THAT BUILTINS DO NOT HAVE CODE OBJECTS,* complicating matters. At this
+#point, we could care less, but we'll have to care sometime that is not now.
+#FIXME: *OH.* Note that things are slightly less trivial than detailed above.
+#It's not enough for a callable to be annotated, of course; that callable also
+#needs to be annotated *AND* type-checked by a runtime type checker like
+#@beartype or @typeguard. The same, of course, does *NOT* apply to "typeshed"
+#annotations, because we generally expect stdlib callables to do exactly what
+#they say and nothing more or less. This means the above approach should only
+#be employed as a last-ditch fallback in the event that the passed callable
+#does *NOT* satisfy any of the following:
+#* Is decorated by a runtime type checker *AND* has a non-None
+#  "__annotations__" dictionary.
+#* Is annotated by the third-party optional "typeshed" dependency.
+#
+#Trivial, but worth noting.
+#FIXME: Lastly, note that everywhere we say "typeshed" above, we *REALLY* mean
+#a PEP 561-compliant search for stub files annotating that callable.
+#Unsurprisingly, the search algorithm is non-trivial, which will impact the
+#performance gains associated with type-checking annotations in the first
+#place. Ergo, we might consider omitting aspects of this search that are both
+#highly inefficient *AND* unlikely to yield positive hits. See also:
+#    https://www.python.org/dev/peps/pep-0561/
+
+#FIXME: *IT'S CONFIGURATION TIME.* So, let's talk about how we efficiently
+#handle @beartype configuration like the "is_proxying" boolean introduced
+#above. It's worth getting this right the first time. Happily, we got this
+#right the first time with a balls-crazy scheme that gives us O(1)
+#configurability that supports global defaults that can be both trivially
+#changed globally *AND* overridden by passed optional @beartype parameters.
+#
+#Note this scheme does *NOT* require us to litter the codebase with cumbersome
+#and inefficient logic like:
+#    muh_setting = (
+#        beartype_params.muh_setting if beartype_params.muh_setting is not None else
+#        beartype._global_config.muh_setting)
+#
+#What is this magic we speak of? *SIMPLE.* We twist class variable MRO lookup
+#in our favour. Since CPython already efficiently implements such lookup with a
+#fast C implementation, we can hijack that implementation for our own sordid
+#purposes to do something completely different. Note that only *CLASS* variable
+#MRO lookup suffices. Since classes are global singletons, all subclasses will
+#implicitly perform efficient lookups for undefined class variables in their
+#superclass -- which is exactly what we want and need here.
+#
+#Specifically:
+#* Define a new private "beartype._config" submodule.
+#* In that submodule:
+#  * Define a new public "BeartypeConfigGlobal" class declaring all
+#    configuration settings as class variables defaulting to their desired
+#    arbitrary global defaults: e.g.,
+#        class BeartypeConfigGlobal(object):
+#            '''
+#            **Global beartype configuration.**
+#            '''
+#
+#            is_proxying = True
+#            ...
+#* Publicly expose that class to external users as a new public
+#  "beartype.config" *PSEUDO-MODULE.* In reality, that object will simply be an
+#  alias of "beartype._config.BeartypeConfigGlobal". But users shouldn't know
+#  that. They should just treat that object as if it was a module. To effect
+#  this, just establish this alias in the "beartype.__init__" submodule: e.g.,
+#      from beartype._config import BeartypeConfigGlobal
+#
+#      # It really is that simple, folks. Maybe. Gods, let it be that simple.
+#      config = BeartypeConfigGlobal
+#* Privatize the existing public "beartype._decor.decormain" submodule to a new
+#  "beartype._decor._template" submodule.
+#* In that submodule:
+#  * Rename the existing @beartype decorator to beartype_template(). That
+#    function will now only be called internally rather than externally.
+#* Define a new private "beartype._decor.decorcache" submodule.
+#* In that submodule:
+#  * Define a new "BEARTYPE_PARAMS_TO_DECOR" dictionary mapping from a *TUPLE*
+#    of positional arguments listed in the exact same order as the optional
+#    parameters accepted by the new @beartype decorator discussed below to
+#    subclasses to dynamically generated @beartype decorators configured by
+#    those subclasses. This tuple should just literally be the argument tuple
+#    passed to the @beartype decorator, which is probably easiest to achieve if
+#    we force @beartype parameters to be passed as keyword-only arguments:
+#
+#        # Keyword-only arguments require Python >= 3.8. Under older Pythons,
+#        # just drop the "*". Under older Pythons, let's just *NOT ALLOW
+#        # CONFIGURATION AT ALL.* So, this gives us:
+#        if IS_PYTHON_AT_LEAST_3_8:
+#            def beartype(*, is_proxying: bool = None, ...) -> Callable:
+#                BEARTYPE_PARAMS = (is_proxying, ...)
+#
+#                beartype_decor = BEARTYPE_PARAMS_TO_DECOR.get(BEARTYPE_PARAMS)
+#                if beartype_decor:
+#                    return beartype_decor
+#
+#                # Else, we need to make a new @beartype decorator passed
+#                # these parameters, cache that decorator in
+#                # "BEARTYPE_PARAMS_TO_DECOR", and return that decorator.
+#        else:
+#            # Probably not quite right, but close enough.
+#            beartype = beartype_template
+#
+#    We need a hashable tuple for lookup purposes. That's *ABSOLUTELY* the
+#    fastest way, given that we expect keyword arguments. So, we're moving on.
+#    Also, do *NOT* bother with LRU caching here, as the expected size of that
+#    dictionary will almost certainly always be less than 10 and surely 100.
+#* Define a new private "beartype._decor.decormain" submodule.
+#* In that submodule:
+#  * Define a new @beartype decorator accepting *ALL* of the *EXACT* same
+#    class variables declared by the "BeartypeConfigGlobal" class as optional
+#    parameters of the same name but *UNCONDITIONALLY* defaulting to "None".
+#    That last bit is critical. Do *NOT* default them to what the
+#    "BeartypeConfigGlobal" superclass defaults them to, as that would obstruct
+#    our purposes, which is to have lookups punted upward to the
+#    "BeartypeConfigGlobal" superclass only when undefined in a subclass.
+#  * The purpose of this new @beartype decorator is to (in order):
+#    * First lookup the passed parameters to get an existing decorator passed
+#      those parameters, as already implemented above. (This is trivial.)
+#    * If we need to make a new decorator, this is also mostly trivial. Just:
+#      * Define a new local dictionary "BEARTYPE_PARAM_NAME_TO_VALUE" bundling
+#        these optional parameters for efficient lookup: e.g.,
+#            BEARTYPE_PARAM_NAME_TO_VALUE = {
+#                'is_proxying': is_proxying,
+#                ...
+#            }
+#      * Dynamically create a new "BeartypeConfigGlobal" subclass *SETTING THE
+#        DESIRED CLASS VARIABLES* based on all of the passed optional
+#        parameters whose values are *NOT* "None". For example, if the only
+#        passed non-"None" optional parameter was "is_proxying", this would be:
+#            class _BeartypeConfigDecor{ARBITRARY_NUMBER}(BeartypeConfigGlobal):
+#                is_proxying = False
+#        This will probably require a bit of iteration to filter out all
+#        non-"None" optional parameters. Note that the simplest way to
+#        implement this would probably be to just dynamically declare an empty
+#        subclass and then monkey-patch that subclass' dictionary with the
+#        desired non-"None" optional parameters: e.g.,
+#            # Pseudo-code, but close enough.
+#            BeartypeConfigDecor = eval(
+#                f'''class _BeartypeConfigDecor{ARBITRARY_NUMBER}(BeartypeConfigGlobal): pass''')
+#
+#            # Yes, this is a bit lame, but it suffices for now. Remember,
+#            # we're caching this class, so the logic constructing this class
+#            # doesn't need to be lightning fast. It's *FAR* more critical that
+#            # the logic looking up this class in this class be lightning fast.
+#            #
+#            # Do *NOT* try to embed this logic into the above evaluation
+#            # (e.g., as f-expressions). Yes, that sort of hackery is trivial
+#            # with booleans but rapidly gets hairy with containers. So, I
+#            # *GUESS* we could do that for booleans. Just remember that that
+#            # doesn't generalize to the general case. Actually, don't bother.
+#            # The following suffices and doesn't violate DRY, which is the
+#            # only important thing here.
+#            BeartypeConfigDecor.__dict__.update({
+#                arg_name: arg_value
+#                arg_name, arg_value in BEARTYPE_PARAM_NAME_TO_VALUE.items()
+#                if arg_value is not None
+#            })
+#      * Dynamically *COPY* the beartype_template() function into a new
+#        function specific to that subclass, which means that function is
+#        actually just a template. We'll never actually the original function
+#        itself; we just use that function as the basis for dynamically
+#        generating new decorators on-the-fly. Heh! Fortunately, we only need
+#        a shallow function copy. That is to say, we want the code objects to
+#        remain the same. Note that the most efficient means of implementing
+#        this is given directly be this StackOverflow answer:
+#            https://stackoverflow.com/a/13503277/2809027
+#        Note that that answer can be slightly improved to resemble:
+#            WRAPPER_ASSIGNMENTS = functools.WRAPPER_ASSIGNMENTS + ('__kwdefaults__',)
+#            def copy_func(f):
+#                g = types.FunctionType(f.__code__, f.__globals__, name=f.__name__,
+#                                       argdefs=f.__defaults__,
+#                                       closure=f.__closure__)
+#                g = functools.update_wrapper(g, f, WRAPPER_ASSIGNMENTS)
+#                return g
+#        That's the most general form. Of course, we don't particularly care
+#        about copying metadata, since we don't expect anyone to care about
+#        these dynamically generated decorators. That means we can reduce the
+#        above to simply:
+#            def copy_func(f):
+#                return types.FunctionType(
+#                    f.__code__,
+#                    f.__globals__,
+#                    name=f.__name__,
+#                    argdefs=f.__defaults__,
+#                    closure=f.__closure__,
+#                )
+#      * Monkey-patch the new decorator returned by
+#        "copy_func(beartype_template)" with the new subclass: e.g.,
+#            beartype_decor = copy_func(beartype_template)
+#            beartype_decor.__beartype_config = BeartypeConfigDecor
+#        *HMMM.* Minor snag. That doesn't work, but the beartype_template()
+#        template won't have access to that "__beartype_config". Instead, we'll
+#        need to:
+#        * Augment the signature of the beartype_template() template to accept
+#          a new optional "config" parameter default to "None": e.g.,.
+#          def beartype_template(
+#              func: Callable, config: BeartypeConfigGlobal = None) -> Callable:
+#        * Either refactor the copy_func() function defined above to accept a
+#          caller-defined "argdefs" parameter *OR* (more reasonably) just
+#          inline the body of that function in @beartype as:
+#            beartype_decor = types.FunctionType(
+#                f.__code__,
+#                f.__globals__,
+#                name=f.__name__,
+#                # Yup. In theory, that should do it, if we recall the internal
+#                # data structure of this parameter correctly.
+#                argdefs=(BeartypeConfigDecor,),
+#                closure=f.__closure__,
+#            )
+#      * Cache and return that decorator:
+#            BEARTYPE_PARAMS_TO_DECOR[BEARTYPE_PARAMS] = beartype_decor
+#            return beartype_decor
+#
+#Pretty trivial, honestly. We've basically already implemented all of the hard
+#stuff above, which is nice.
+#
+#Note that the beartype_template() function will now accept an optional
+#"config" parameter -- which will, of course, *ALWAYS* be non-"None" by the
+#logic above. Assert this, of course. We can then trivially expose that
+#"config" to lower-level beartype functions by just stuffing it into the
+#existing "BeartypeCall" class: e.g.,
+#    # Welp, that was trivial.
+#    func_data.config = config
+#
+#Since we pass "func_data" everywhere, we get configuration for free. Muhaha!
+
+#FIXME: Propagate generic subscriptions both to *AND* from pseudo-superclasses.
+#First, consider the simpler case of propagating a generic subscription to
+#pseudo-superclasses: e.g.,
+#    from typing import List
+#    class MuhList(List): pass
+#
+#    @beartype
+#    def muh_lister(muh_list: MuhList[int]) -> None: pass
+#
+#During internal type hint visitation, @beartype should propagate the "int"
+#child type hint subscripting the "MuhList" type hint up to the "List"
+#pseudo-superclass under Python >= 3.9. Under older Python versions, leaving
+#"List" unsubscripted appears to raise exceptions at parse time. *shrug*
+#
+#Of the two cases, this first case is *SIGNIFICANTLY* more important than the
+#second case documented below. Why? Because mypy (probably) supports this first
+#but *NOT* second case, for  which mypy explicitly raises an "error". Since
+#mypy has effectively defined the standard interpretation of type hints,
+#there's little profit in contravening that ad-hoc standard by supporting
+#something unsupported under mypy -- especially because doing so would then
+#expose end user codebases to mypy errors. Sure, that's "not our problem, man,"
+#but it kind of is, because community standards exist for a reason -- even if
+#they're ad-hoc community standards we politely disagree with.
+#
+#Nonetheless, here's the second case. Consider the reverse case of propagating
+#a generic subscription from a pseudo-superclass down to its unsubscripted
+#generic: e.g.,
+#    from typing import Generic, TypeVar
+#
+#    T = TypeVar('T')
+#    class MuhGeneric(Generic[T]):
+#        def __init__(self, muh_param: T): pass
+#
+#    @beartype
+#    def muh_genericizer(generic: MuhGeneric, T) -> None: pass
+#
+#During internal type hint visitation, @beartype should propagate the "T"
+#child type hint subscripting the "Generic" pseudo-superclass down to the
+#"MuhGeneric" type hint under Python >= 3.9 and possibly older versions. Doing
+#so would reduce DRY violations, because there's no tangible reason why users
+#should have to perpetually subscript "MuhGeneric" when its pseudo-superclass
+#already has been. Of course, mypy doesn't see it that way. *shrug*
+
+#FIXME: When time permits, we can augment the pretty lame approach by
+#publishing our own "BeartypeDict" class that supports efficient random access
+#of both keys and values. Note that:
+#* The existing third-party "randomdict" package provides baseline logic that
+#  *MIGHT* be useful in getting "BeartypeDict" off the ground. The issue with
+#  "randomdict", however, is that it internally leverages a "list", which
+#  probably then constrains key-value pair deletions on the exterior
+#  "randomdict" object to an O(n) rather than O(1) operation, which is
+#  absolutely unacceptable.
+#* StackOverflow questions provide a number of solutions that appear to be
+#  entirely O(1), but which require maintaining considerably more internal data
+#  structures, which is also unacceptable (albeit less so), due to increased
+#  space consumption that probably grows unacceptable fast and thus fails to
+#  generally scale.
+#* Since we don't control "typing", we'll also need to augment "BeartypeDict"
+#  with a "__class_getitem__" dunder method (or whatever that is called) to
+#  enable that class to be subscripted with "typing"-style types ala:
+#     def muh_func(muh_mapping: BeartypeDict[str, int]) -> None: pass
+#In short, we'll need to conduct considerably more research here.
+#FIXME: Actually, none of the above is necessary or desirable. Rather than
+#designing a random access "BeartypeDict" class, it would be *FAR* more useful
+#to design a series of beartype-specific container types in a new external
+#"beartypes" package, each of which performs O(1) type-checking *ON INSERTION
+#OF EACH CONTAINER ITEM.* This should be stupidly fast under standard use
+#cases, because we typically expect an item to be inserted only once but
+#accessed many, many times. By just checking on insertion, we avoid *ALL* of
+#the complications of trying to type-check after the fact during sequential
+#non-random iteration over items.
+#
+#Indeed, there appears to be a number of similar projects with the same idea,
+#with the caveat that these projects *ALL* leverage package-specific constructs
+#rather than PEP-compliant type hints -- a significant negative. The most
+#interesting of these are:
+#* "typed_python", a fascinating package with a variety of novel ideas at play.
+#  In addition to providing package-specific container types that perform
+#  PEP-noncompliant type-checking on item insertion *IMPLEMENTED THAT AT THE C
+#  LEVEL* rather than in pure Python (which is both horrible and fascinating,
+#  mainly because... why bother? I mean, PyPy, Nuitka, and Cython already
+#  exist, so why go to all that trouble to work in C rather than Python?),
+#  this package also offers:
+#  * "typed_python.Entrypoint", which looks balls-cray-cray. This is probably
+#    the most interesting aspect of this package, presuming it actually behaves
+#    as advertised, which it almost certainly doesn't. Nonetheless, it appears
+#    to be a bit of a cross between Nuitka and beartype. To quote:
+#    "Simply stick the @typed_python.Entrypoint decorator around any function
+#     that uses "typed_python" primitives to get a fast version of it:
+#     @Entrypoint
+#     def sum(someList, zero):
+#         for x in someList:
+#             zero += x
+#         return x
+#     ...will generate specialized code for different data types
+#     ("ListOf(int)", say, or "ListOf(float)", or even "Dict(int)") that's not
+#     only many times faster than the python equivalent, but that can operate
+#     using multiple processors. Compilation occurs each time you call the
+#     method with a new combination of types." The "that can operate using
+#     multiple processors" part is particularly novel, as it implies
+#     circumvention of the GIL. "typed_python" appears to implement this magic
+#     by leveraging LLVM to compile Python down to C. Again, we strongly doubt
+#     any of this actually works under real-world industrial constraints, but
+#     it's still a fascinating thought experiment.
+#  * "type_python.Class", a generic-style class one subclasses to generate
+#    "strongly typed class with a packed memory layout." The "strongly typed"
+#    part isn't terribly interesting, as it's PEP-noncompliant. The "packed
+#    memory layout" part, however, *IS* interesting. Reducing space consumption
+#    by presumably compiling to C is intriguing, if tangential to our concerns.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/codecls.py
@@ -0,0 +1,354 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **type-checking code classes** (i.e., low-level classes storing
+metadata describing each iteration of the breadth-first search (BFS) dynamically
+generating pure-Python code snippets type-checking arbitrary objects against
+PEP-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+# All "FIXME:" comments for this submodule reside in this package's "__init__"
+# submodule to improve maintainability and readability here.
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    TYPE_CHECKING,
+)
+from beartype._check.code.snip.codesnipstr import (
+    CODE_HINT_CHILD_PLACEHOLDER_PREFIX,
+    CODE_HINT_CHILD_PLACEHOLDER_SUFFIX,
+)
+from beartype._util.cache.pool.utilcachepoollistfixed import (
+    FIXED_LIST_SIZE_MEDIUM,
+    FixedList,
+)
+
+# ....................{ CLASSES                            }....................
+#FIXME: Unit test us up, please.
+class HintsMeta(FixedList):
+    '''
+    **Type-checking metadata list** (i.e., low-level fixed list of all metadata
+    describing all visitable hints currently discovered by the breadth-first
+    search (BFS) dynamically generating pure-Python code snippets type-checking
+    arbitrary objects against type hints).
+
+    This list acts as a standard First In First Out (FILO) queue, enabling this
+    BFS to be implemented as an efficient imperative algorithm rather than an
+    inefficient -- and dangerous, due to both unavoidable stack exhaustion and
+    avoidable infinite recursion -- recursive algorithm.
+
+    Note that this list is guaranteed by the previously called
+    ``_die_if_hint_repr_exceeds_child_limit()`` function to be larger than the
+    number of hints transitively visitable from this root hint. Ergo, *all*
+    indexation into this list performed by this BFS is guaranteed to be safe.
+
+    Attributes
+    ----------
+    index_last : int
+        0-based index of metadata describing the last visitable hint in this
+        list. For efficiency, this integer also uniquely identifies the
+        current child type hint of the currently visited parent type hint.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently
+    # called @beartype decorations. Slotting has been shown to reduce read and
+    # write costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        'index_last',
+    )
+
+    # Squelch false negatives from mypy. This is absurd. This is mypy. See:
+    #     https://github.com/python/mypy/issues/5941
+    if TYPE_CHECKING:
+        index_last: int
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self) -> None:
+        '''
+        Initialize this type-checking metadata list.
+        '''
+
+        # Initialize our superclass.
+        super().__init__(
+            size=FIXED_LIST_SIZE_MEDIUM,
+
+            #FIXME: *NO*. We actually need these to be independent copies. Ergo,
+            #there's *NO* alternative but to iteratively define one new instance
+            #of this dataclass for each index of this list. Indeed, this is
+            #actually a profound benefit. How? We can precompute the values of
+            #* "hint_curr_placeholder" *AT PYTHON STARTUP*. Just iteratively
+            #  assign each "hint_curr_placeholder" according to its index. Do so
+            #  based on the current logic of the enqueue_hint_child() method.
+            #* "pith_curr_var_name" *AT PYTHON STARTUP* in the exact same way.
+            #
+            #Indeed, this suggests we probably no longer need either:
+            #* "pith_curr_var_name_index".
+            #* The entire "codesnipcls" submodule.
+            #
+            #Well, isn't this turning out to be a significant facepalm.
+            #FIXME: Actually, the default of "None" here is fine. Let's instead:
+            #* Redefine the __getitem__() dunder method to dynamically inspect
+            #  the item at the passed index. If:
+            #    * "None", then replace this item with a new "HintMeta" instance
+            #      suitable for the passed index.
+            #    * Else, return the existing "HintMeta" instance at this index.
+            #* Refactor the enqueue_hint_child() method to then reassign the
+            #  fields of this "HintMeta" instance to the desired values.
+            #
+            #This approach avoids expensive up-front computation at app startup,
+            #instead amortizing these costs across the app lifetime. Heh.
+            # obj_init=HintMeta(),
+        )
+
+        # 0-based index of metadata describing the last visitable hint in this
+        # list, initialized to "-1" to ensure that the initial incrementation of
+        # this index by the enqueue_hint_child() method initializes index 0 of
+        # this list.
+        self.index_last = 0
+
+    # ..................{ METHODS                            }..................
+    def enqueue_hint_child(self, pith_child_expr: str) -> str:
+        '''
+        **Enqueue** (i.e., append) a new tuple of metadata describing the
+        currently iterated child type hint to the end of the ``hints_meta``
+        queue, enabling this hint to be visited by the ongoing breadth-first
+        search (BFS) traversing over this queue.
+
+        Parameters
+        ----------
+        pith_child_expr : str
+            Python code snippet evaluating to the child pith to be type-checked
+            against the currently iterated child type hint.
+
+        This closure also implicitly expects the following local variables of
+        the outer scope to be set to relevant values:
+
+        hint_child : object
+            Currently iterated child type hint subscripting the currently
+            visited type hint.
+
+        Returns
+        -------
+        str
+            Placeholder string to be subsequently replaced by code type-checking
+            this child pith against this child type hint.
+        '''
+        # print(f'pith_child_expr: {pith_child_expr}')
+
+        # Increment the 0-based index of metadata describing the last visitable
+        # hint in this list (which also serves as the unique identifier of the
+        # currently iterated child hint) *BEFORE* overwriting the existing
+        # metadata at this index.
+        #
+        # Note this index is guaranteed to *NOT* exceed the fixed length of this
+        # list, by prior validation.
+        self.index_last += 1
+
+        # Placeholder string to be globally replaced by code type-checking the
+        # child pith against this child hint, intentionally prefixed and
+        # suffixed by characters that:
+        #
+        # * Are intentionally invalid as Python code, guaranteeing that the
+        #   top-level call to the exec() builtin performed by the @beartype
+        #   decorator will raise a "SyntaxError" exception if the caller fails
+        #   to replace all placeholder substrings generated by this method.
+        # * Protect the identifier embedded in this substring against ambiguous
+        #   global replacements of larger identifiers containing this
+        #   identifier. If this identifier were *NOT* protected in this manner,
+        #   then the first substring "0" generated by this method would
+        #   ambiguously overlap with the subsequent substring "10" generated by
+        #   this method, which would then produce catastrophically erroneous and
+        #   undebuggable Python code.
+        hint_child_placeholder = (
+            f'{CODE_HINT_CHILD_PLACEHOLDER_PREFIX}'
+            f'{str(self.index_last)}'
+            f'{CODE_HINT_CHILD_PLACEHOLDER_SUFFIX}'
+        )
+
+        #FIXME: Implement us up, please. This will prove non-trivial. *sigh*
+        # # Create and insert a new tuple of metadata describing this child hint
+        # # at this index of this list.
+        # #
+        # # Note that this assignment is guaranteed to be safe, as
+        # # "FIXED_LIST_SIZE_MEDIUM" is guaranteed to be substantially larger than
+        # # "hints_meta_index_last".
+        # self[self.index_last] = (
+        #     hint_child,
+        #     hint_child_placeholder,
+        #     pith_child_expr,
+        #     pith_curr_var_name_index,
+        #     indent_level_child,
+        # )
+
+        # Return this placeholder string.
+        return hint_child_placeholder
+
+
+#FIXME: Unit test us up, please.
+class HintMeta(object):
+    '''
+    **Type-checking metadata dataclass** (i.e., low-level class storing metadata
+    describing each iteration of the breadth-first search (BFS) dynamically
+    generating pure-Python code snippets type-checking arbitrary objects against
+    type hints).
+
+    Attributes
+    ----------
+    hint_curr : object
+        Type hint currently visited by this BFS.
+    hint_curr_placeholder : str
+        **Type-checking placeholder substring** to be globally replaced in the
+        **returned Python code snippet** (i.e., the ``func_wrapper_code`` local)
+        by a Python code snippet type-checking the **current pith expression**
+        (i.e., the ``pith_curr_var_name`` local) against the currently visited
+        hint (i.e., the :attr:`hint_curr` instance variable).
+
+        This substring provides indirection enabling the currently visited
+        parent hint to defer and delegate the generation of code type-checking
+        each child argument of that hint to the later time at which that child
+        argument is visited.
+
+        Example
+        -------
+        For example, the
+        :func:`beartype._check.code.codemake.make_check_expr` factory might
+        generate intermediary code resembling the following on visiting the
+        :obj:`typing.Union` parent type hint of a subscripted ``Union[int,
+        str]`` type hint *before* visiting either the :class:`int` or
+        :class:`str` child type hints of that parent type hint:
+
+        .. code-block:: python
+
+           if not (
+               @{0}! or
+               @{1}!
+           ):
+               raise get_func_pith_violation(
+                   func=__beartype_func,
+                   pith_name=$%PITH_ROOT_NAME/~,
+                   pith_value=__beartype_pith_root,
+               )
+
+        Note the unique substrings ``"@{0}!"`` and ``"@{1}!"`` in that code,
+        which that factory iteratively replaces with code type-checking each of
+        the child type hints (e.g., :class:`int`, :class:`str`) subscripting
+        that :obj:`typing.Union` parent type hint. The final code memoized by
+        that factory might then resemble:
+
+        .. code-block:: python
+
+           if not (
+               isinstance(__beartype_pith_root, int) or
+               isinstance(__beartype_pith_root, str)
+           ):
+               raise get_func_pith_violation(
+                   func=__beartype_func,
+                   pith_name=$%PITH_ROOT_NAME/~,
+                   pith_value=__beartype_pith_root,
+               )
+    pith_curr_expr : str
+        **Pith expression** (i.e., Python code snippet evaluating to the value
+        of) the current **pith** (i.e., possibly nested object of the passed
+        parameter or return to be type-checked against the currently visited
+        type hint).
+
+        Note that this expression is intentionally *not* an assignment
+        expression but rather the original inefficient expression provided by
+        the parent type hint of the currently visited type hint.
+    pith_curr_var_name_index : int
+        **Pith variable name index** (i.e., 0-based integer suffixing the name
+        of each local variable assigned the value of the current pith in a
+        assignment expression, thus uniquifying this variable in the body of the
+        current wrapper function). Indexing the
+        :obj:`beartype._check.code.snip.codesnipcls.PITH_INDEX_TO_VAR_NAME`
+        dictionary singleton by this integer efficiently yields the current
+        **pith variable name** locally storing the value of the current pith.
+
+        Note that this integer is intentionally incremented as an efficient
+        low-level scalar rather than as an inefficient high-level
+        :class:`itertools.Counter` object. Since both are equally thread-safe in
+        the internal context of a function body, the former is preferable.
+    indent_level_curr : int
+        **Indentation level** (i.e., 1-based positive integer providing the
+        current level of indentation appropriate for the currently visited type
+        hint). Indexing the
+        :obj:`beartype._data.code.datacodeindent.INDENT_LEVEL_TO_CODE`
+        dictionary singleton by this integer efficiently yields the current
+        **indendation string** suitable for prefixing each line of code
+        type-checking the current pith against the current type hint.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        'hint_curr',
+        'hint_curr_placeholder',
+        'pith_curr_expr',
+        'pith_curr_var_name_index',
+        'indent_level_curr',
+    )
+
+    # Squelch false negatives from mypy. This is absurd. This is mypy. See:
+    #     https://github.com/python/mypy/issues/5941
+    if TYPE_CHECKING:
+        hint_curr: object
+        hint_curr_placeholder: str
+        pith_curr_expr: str
+        pith_curr_var_name_index: int
+        indent_level_curr: int
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+
+        # Mandatory parameters.
+        hint_curr_placeholder: str,
+        pith_curr_var_name_index: int,
+
+        # Optional parameters.
+        hint_curr: object = None,
+        pith_curr_expr: str = '',
+        indent_level_curr: int = 2,
+    ) -> None:
+        '''
+        Initialize this type-checking metadata dataclass.
+
+        Parameters
+        ----------
+        hint_curr : object
+            Type hint currently visited by this BFS.
+        hint_curr_placeholder : str
+            Type-checking placeholder substring. See the class docstring.
+        pith_curr_expr : str
+            Pith expression. See the class docstring.
+        pith_curr_var_name_index : int
+            Pith variable name index. See the class docstring.
+        indent_level_curr : int
+            Indentation level. See the class docstring.
+        '''
+        assert isinstance(hint_curr_placeholder, str)
+        assert isinstance(pith_curr_expr, str)
+        assert isinstance(pith_curr_var_name_index, int)
+        assert isinstance(indent_level_curr, int)
+        assert hint_curr_placeholder
+        assert pith_curr_expr
+        assert pith_curr_var_name_index >= 0
+        assert indent_level_curr > 1
+
+        # Classify all passed parameters.
+        self.hint_curr = hint_curr
+        self.hint_curr_placeholder = hint_curr_placeholder
+        self.pith_curr_expr = pith_curr_expr
+        self.pith_curr_var_name_index = pith_curr_var_name_index
+        self.indent_level_curr = indent_level_curr
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/codemagic.py
@@ -0,0 +1,155 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype decorator **type-checking expression magic** (i.e., global string
+constants embedded in the implementations of boolean expressions type-checking
+arbitrary objects against arbitrary PEP-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from itertools import count
+
+# ....................{ EXCEPTION                          }....................
+EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL = (
+    f'{EXCEPTION_PLACEHOLDER}wrapper parameter ')
+'''
+Human-readable substring describing a new wrapper parameter required by the
+current root type hint in exception messages.
+'''
+
+
+EXCEPTION_PREFIX_HINT = f'{EXCEPTION_PLACEHOLDER}type hint '
+'''
+Human-readable substring describing the current root type hint generically
+(i.e., agnostic of the specific PEP standard to which this hint conforms) in
+exception messages.
+'''
+
+#FIXME: Preserved for documentation purposes. When time permits, centralized
+#this documentation into the docstring of a new "HintMeta" dataclass, please.
+# # ....................{ HINT ~ meta                        }....................
+# # Iterator yielding the next integer incrementation starting at 0, to be safely
+# # deleted *AFTER* defining the following 0-based indices via this iterator.
+# __hint_meta_index_counter = count(start=0, step=1)
+#
+#
+# HINT_META_INDEX_HINT = next(__hint_meta_index_counter)
+# '''
+# 0-based index into each tuple of hint metadata providing the currently
+# visited hint.
+#
+# For both space and time efficiency, this metadata is intentionally stored as
+# 0-based integer indices of an unnamed tuple rather than:
+#
+# * Human-readable fields of a named tuple, which incurs space and time costs we
+#   would rather *not* pay.
+# * 0-based integer indices of a tiny fixed list. Previously, this metadata was
+#   actually stored as a fixed list. However, exhaustive profiling demonstrated
+#   that reinitializing each such list by slice-assigning that list's items from
+#   a tuple to be faster than individually assigning these items:
+#
+#   .. code-block:: shell-session
+#
+#      $ echo 'Slice w/ tuple:' && command python3 -m timeit -s \
+#           'muh_list = ["a", "b", "c", "d",]' \
+#           'muh_list[:] = ("e", "f", "g", "h",)'
+#      Slice w/ tuple:
+#      2000000 loops, best of 5: 131 nsec per loop
+#      $ echo 'Slice w/o tuple:' && command python3 -m timeit -s \
+#           'muh_list = ["a", "b", "c", "d",]' \
+#           'muh_list[:] = "e", "f", "g", "h"'
+#      Slice w/o tuple:
+#      2000000 loops, best of 5: 138 nsec per loop
+#      $ echo 'Separate:' && command python3 -m timeit -s \
+#           'muh_list = ["a", "b", "c", "d",]' \
+#           'muh_list[0] = "e"
+#      muh_list[1] = "f"
+#      muh_list[2] = "g"
+#      muh_list[3] = "h"'
+#      Separate:
+#      2000000 loops, best of 5: 199 nsec per loop
+#
+# So, not only does there exist no performance benefit to flattened fixed lists,
+# there exists demonstrable performance costs.
+# '''
+#
+#
+# HINT_META_INDEX_PLACEHOLDER = next(__hint_meta_index_counter)
+# '''
+# 0-based index into each tuple of hint metadata providing the **current
+# placeholder type-checking substring** (i.e., placeholder to be globally
+# replaced by a Python code snippet type-checking the current pith expression
+# against the hint described by this metadata on visiting that hint).
+#
+# This substring provides indirection enabling the currently visited parent hint
+# to defer and delegate the generation of code type-checking each child argument
+# of that hint to the later time at which that child argument is visited.
+#
+# Example
+# -------
+# For example, the
+# :func:`beartype._decor._hint._pep._pephint.make_func_pith_code` function might
+# generate intermediary code resembling the following on visiting the
+# :data:`Union` parent of a ``Union[int, str]`` object *before* visiting either
+# the :class:`int` or :class:`str` children of that object:
+#
+#     if not (
+#         @{0}! or
+#         @{1}!
+#     ):
+#         raise get_func_pith_violation(
+#             func=__beartype_func,
+#             pith_name=$%PITH_ROOT_NAME/~,
+#             pith_value=__beartype_pith_root,
+#         )
+#
+# Note the unique substrings ``"@{0}!"`` and ``"@{1}!"`` in that code, which that
+# function iteratively replaces with code type-checking each of the child
+# arguments of that :data:`Union` parent (i.e., :class:`int`, :class:`str`). The
+# final code memoized by that function might then resemble:
+#
+#     if not (
+#         isinstance(__beartype_pith_root, int) or
+#         isinstance(__beartype_pith_root, str)
+#     ):
+#         raise get_func_pith_violation(
+#             func=__beartype_func,
+#             pith_name=$%PITH_ROOT_NAME/~,
+#             pith_value=__beartype_pith_root,
+#         )
+# '''
+#
+#
+# HINT_META_INDEX_PITH_EXPR = next(__hint_meta_index_counter)
+# '''
+# 0-based index into each tuple of hint metadata providing the **current
+# pith expression** (i.e., Python code snippet evaluating to the current possibly
+# nested object of the passed parameter or return value to be type-checked
+# against the currently visited hint).
+# '''
+#
+#
+# HINT_META_INDEX_PITH_VAR_NAME = next(__hint_meta_index_counter)
+# '''
+# 0-based index into each tuple of hint metadata providing the **current pith
+# variable name** (i.e., name of the unique local variable assigned the value of
+# the current pith either by a prior assignment statement or expression).
+# '''
+#
+#
+# HINT_META_INDEX_INDENT_LEVEL = next(__hint_meta_index_counter)
+# '''
+# 0-based index into each tuple of hint metadata providing the **current
+# indentation level** (i.e., 1-based positive integer describing the current level
+# of indentation appropriate for the currently visited hint).
+# '''
+#
+#
+# # Delete the above counter for safety and sanity in equal measure.
+# del __hint_meta_index_counter
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/codemake.py
@@ -0,0 +1,2231 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **type-checking code factories** (i.e., low-level callables dynamically
+generating pure-Python code snippets type-checking arbitrary objects against
+PEP-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+# All "FIXME:" comments for this submodule reside in this package's "__init__"
+# submodule to improve maintainability and readability here.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeDecorHintPepException,
+    BeartypeDecorHintPepUnsupportedException,
+    BeartypeDecorHintPep593Exception,
+)
+from beartype.typing import Optional
+from beartype._cave._cavefast import TestableTypes
+from beartype._check.checkmagic import (
+    ARG_NAME_CLS_STACK,
+    ARG_NAME_GETRANDBITS,
+    VAR_NAME_PITH_ROOT,
+)
+from beartype._check.code.codemagic import (
+    EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL,
+    EXCEPTION_PREFIX_HINT,
+)
+from beartype._check.code.codescope import (
+    add_func_scope_type,
+    add_func_scope_types,
+    add_func_scope_type_or_types,
+    express_func_scope_type_ref,
+)
+from beartype._check.code.snip.codesnipcls import PITH_INDEX_TO_VAR_NAME
+from beartype._check.code.snip.codesnipstr import (
+    CODE_HINT_CHILD_PLACEHOLDER_PREFIX,
+    CODE_HINT_CHILD_PLACEHOLDER_SUFFIX,
+    CODE_PEP484_INSTANCE_format,
+    CODE_PEP484585_GENERIC_CHILD_format,
+    CODE_PEP484585_GENERIC_PREFIX,
+    CODE_PEP484585_GENERIC_SUFFIX,
+    CODE_PEP484585_MAPPING_format,
+    CODE_PEP484585_MAPPING_KEY_ONLY_format,
+    CODE_PEP484585_MAPPING_KEY_VALUE_format,
+    CODE_PEP484585_MAPPING_VALUE_ONLY_format,
+    CODE_PEP484585_MAPPING_KEY_ONLY_PITH_CHILD_EXPR_format,
+    CODE_PEP484585_MAPPING_VALUE_ONLY_PITH_CHILD_EXPR_format,
+    CODE_PEP484585_MAPPING_KEY_VALUE_PITH_CHILD_EXPR_format,
+    CODE_PEP484585_SEQUENCE_ARGS_1_format,
+    CODE_PEP484585_SEQUENCE_ARGS_1_PITH_CHILD_EXPR_format,
+    CODE_PEP484585_SUBCLASS_format,
+    CODE_PEP484585_TUPLE_FIXED_EMPTY_format,
+    CODE_PEP484585_TUPLE_FIXED_LEN_format,
+    CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD_format,
+    CODE_PEP484585_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR_format,
+    CODE_PEP484585_TUPLE_FIXED_PREFIX,
+    CODE_PEP484585_TUPLE_FIXED_SUFFIX,
+    CODE_PEP484604_UNION_CHILD_PEP_format,
+    CODE_PEP484604_UNION_CHILD_NONPEP_format,
+    CODE_PEP484604_UNION_PREFIX,
+    CODE_PEP484604_UNION_SUFFIX,
+    CODE_PEP572_PITH_ASSIGN_EXPR_format,
+    CODE_PEP586_LITERAL_format,
+    CODE_PEP586_PREFIX_format,
+    CODE_PEP586_SUFFIX,
+    CODE_PEP593_VALIDATOR_IS_format,
+    CODE_PEP593_VALIDATOR_METAHINT_format,
+    CODE_PEP593_VALIDATOR_PREFIX,
+    CODE_PEP593_VALIDATOR_SUFFIX_format,
+)
+from beartype._check.convert.convsanify import (
+    sanify_hint_child_if_unignorable_or_none,
+    sanify_hint_child,
+)
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.code.datacodeindent import INDENT_LEVEL_TO_CODE
+from beartype._data.code.datacodemagic import (
+    LINE_RSTRIP_INDEX_AND,
+    LINE_RSTRIP_INDEX_OR,
+)
+from beartype._data.error.dataerrmagic import (
+    EXCEPTION_PLACEHOLDER as EXCEPTION_PREFIX)
+from beartype._data.hint.datahinttyping import (
+    CodeGenerated,
+    LexicalScope,
+    TypeStack,
+)
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignAnnotated,
+    HintSignForwardRef,
+    HintSignGeneric,
+    HintSignLiteral,
+    # HintSignNone,
+    HintSignTuple,
+    HintSignType,
+)
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_MAPPING,
+    HINT_SIGNS_ORIGIN_ISINSTANCEABLE,
+    HINT_SIGNS_SEQUENCE_ARGS_1,
+    HINT_SIGNS_SUPPORTED_DEEP,
+    HINT_SIGNS_UNION,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.cache.pool.utilcachepoollistfixed import (
+    FIXED_LIST_SIZE_MEDIUM,
+    acquire_fixed_list,
+    release_fixed_list,
+)
+from beartype._util.cache.pool.utilcachepoolobjecttyped import (
+    acquire_object_typed,
+    release_object_typed,
+)
+from beartype._util.func.utilfuncscope import add_func_scope_attr
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585 import (
+    is_hint_pep484585_tuple_empty)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585 import (
+    get_hint_pep484585_args)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+    get_hint_pep484585_generic_type,
+    iter_hint_pep484585_generic_bases_unerased_tree,
+)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585type import (
+    get_hint_pep484585_type_superclass)
+from beartype._util.hint.pep.proposal.utilpep586 import (
+    get_hint_pep586_literals)
+from beartype._util.hint.pep.proposal.utilpep593 import (
+    get_hint_pep593_metadata,
+    get_hint_pep593_metahint,
+)
+from beartype._util.hint.pep.utilpepget import (
+    get_hint_pep_args,
+    get_hint_pep_sign,
+    get_hint_pep_sign_or_none,
+    get_hint_pep_origin_type_isinstanceable,
+)
+from beartype._util.hint.pep.utilpeptest import (
+    die_if_hint_pep_unsupported,
+    is_hint_pep,
+    is_hint_pep_args,
+)
+from beartype._util.hint.utilhinttest import is_hint_ignorable
+from beartype._util.kind.map.utilmapset import update_mapping
+from beartype._util.text.utiltextmunge import replace_str_substrs
+from beartype._util.text.utiltextrepr import represent_object
+from random import getrandbits
+
+# ....................{ MAKERS                             }....................
+@callable_cached
+def make_check_expr(
+    # ..................{ ARGS ~ mandatory                   }..................
+    hint: object,
+    conf: BeartypeConf,
+
+    # ..................{ ARGS ~ optional                    }..................
+    cls_stack: TypeStack = None,
+) -> CodeGenerated:
+    '''
+    **Type-checking expression factory** (i.e., low-level callable dynamically
+    generating a pure-Python boolean expression type-checking an arbitrary
+    object against the passed PEP-compliant type hint).
+
+    This code factory performs a breadth-first search (BFS) over the abstract
+    graph of nested type hints reachable from the subscripted arguments of the
+    passed root type hint. For each such (possibly nested) hint, this factory
+    embeds one or more boolean subexpressions validating a (possibly nested
+    sub)object of an arbitrary object against that hint into the full boolean
+    expression created and returned by this factory. In short, this factory is
+    the beating heart of :mod:`beartype`. We applaud you for your perseverance.
+    You finally found the essence of the Great Bear. You did it!! Now, we clap.
+
+    This code factory is memoized for efficiency.
+
+    Caveats
+    -------
+    **This factory intentionally accepts no** ``exception_prefix``
+    **parameter.** Why? Since that parameter is typically specific to the
+    context-sensitive use case of the caller, accepting that parameter would
+    prevent this factory from memoizing the passed hint with the returned code,
+    which would rather defeat the point. Instead, this factory only:
+
+    * Returns generic non-working code containing the placeholder
+      :data:`VAR_NAME_PITH_ROOT` substring that the caller is required to
+      globally replace by either the name of the current parameter *or*
+      ``return`` for return values (e.g., by calling the builtin
+      :meth:`str.replace` method) to generate the desired non-generic working
+      code type-checking that parameter or return value.
+    * Raises generic non-human-readable exceptions containing the placeholder
+      :attr:`beartype._util.error.utilerrraise.EXCEPTION_PLACEHOLDER` substring
+      that the caller is required to explicitly catch and raise non-generic
+      human-readable exceptions from by calling the
+      :func:`beartype._util.error.utilerrraise.reraise_exception_placeholder`
+      function.
+
+    Parameters
+    ----------
+    hint : object
+        PEP-compliant type hint to be type-checked.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+
+    Returns
+    -------
+    CodeGenerated
+        Tuple containing the Python code snippet dynamically generated by this
+        code generator and metadata describing that code. See the
+        :attr:`beartype._data.hint.datahinttyping.CodeGenerated` type hint for details.
+
+    Raises
+    ------
+    BeartypeDecorHintPepException
+        If this object is *not* a PEP-compliant type hint.
+    BeartypeDecorHintPepUnsupportedException
+        If this object is a PEP-compliant type hint currently unsupported by
+        the :func:`beartype.beartype` decorator.
+    BeartypeDecorHintPep484Exception
+        If one or more PEP-compliant type hints visitable from this object are
+        nested :attr:`typing.NoReturn` child hints, since
+        :attr:`typing.NoReturn` is valid *only* as a non-nested return hint.
+    BeartypeDecorHintPep593Exception
+        If one or more PEP-compliant type hints visitable from this object
+        subscript the :pep:`593`-compliant :class:`typing.Annotated` class such
+        that:
+
+        * The second argument subscripting that class is an instance of the
+          :class:`beartype.vale.Is` class.
+        * One or more further arguments subscripting that class are *not*
+          instances of the :class:`beartype.vale.Is` class.
+
+    Warns
+    -----
+    BeartypeDecorHintPep585DeprecationWarning
+        If one or more :pep:`484`-compliant type hints visitable from this
+        object have been deprecated by :pep:`585`.
+    '''
+
+    # ..................{ LOCALS ~ hint : root               }..................
+    # Top-level hint relocalized for disambiguity.
+    hint_root = hint
+
+    # Delete the passed parameter whose name is ambiguous within the context of
+    # this function for similar disambiguity.
+    del hint
+
+    # ..................{ LOCALS ~ hint : current            }..................
+    # Currently visited hint.
+    hint_curr = None
+
+    # Current unsubscripted typing attribute associated with this hint (e.g.,
+    # "Union" if "hint_curr == Union[int, str]").
+    hint_curr_sign = None
+
+    # Python expression evaluating to an isinstanceable type (e.g., origin type)
+    # associated with the currently visited type hint if any.
+    hint_curr_expr = None
+
+    # Placeholder string to be globally replaced in the Python code snippet to
+    # be returned (i.e., "func_wrapper_code") by a Python code snippet
+    # type-checking the current pith expression (i.e.,
+    # "pith_curr_var_name") against the currently visited hint (i.e.,
+    # "hint_curr").
+    hint_curr_placeholder = None
+
+    # Full Python expression evaluating to the value of the current pith (i.e.,
+    # possibly nested object of the passed parameter or return value to be
+    # type-checked against the currently visited hint).
+    #
+    # Note that this is intentionally *NOT* an assignment expression but rather
+    # the original inefficient expression provided by the parent type hint of
+    # the currently visited hint.
+    pith_curr_expr = None
+
+    # Name of the current pith variable (i.e., local Python variable in the
+    # body of the wrapper function whose value is that of the current pith).
+    # This name is either:
+    # * Initially, the name of the currently type-checked parameter or return.
+    # * On subsequently type-checking nested items of the parameter or return,
+    #   the name of the local variable uniquely assigned to by the assignment
+    #   expression defined by "pith_curr_assign_expr" (i.e., the left-hand side
+    #   (LHS) of that assignment expression).
+    pith_curr_var_name = VAR_NAME_PITH_ROOT
+
+    # ..................{ LOCALS ~ hint : child              }..................
+    # Currently iterated PEP-compliant child hint subscripting the currently
+    # visited hint, initialized to the root hint to enable the subsequently
+    # called _enqueue_hint_child() function to enqueue the root hint.
+    hint_child = hint_root
+
+    # Current unsubscripted typing attribute associated with this child hint
+    # (e.g., "Union" if "hint_child == Union[int, str]").
+    hint_child_sign = None
+
+    # ..................{ LOCALS ~ hint : childs             }..................
+    # Current tuple of all child hints subscripting the currently visited hint
+    # (e.g., "(int, str)" if "hint_curr == Union[int, str]").
+    hint_childs: tuple = None  # type: ignore[assignment]
+
+    # Current list of all output child hints to replace the Current tuple of all
+    # input child hints subscripting the currently visited hint with.
+    hint_childs_new: list = None  # type: ignore[assignment]
+
+    # Number of child hints subscripting the currently visited hint.
+    hint_childs_len: int = None  # type: ignore[assignment]
+
+    # 0-based index of the currently iterated child hint of the "hint_childs"
+    # tuple.
+    hint_childs_index: int = None  # type: ignore[assignment]
+
+    # Current tuple of all child child hints subscripting the currently visited
+    # child hint (e.g., "(int, str)" if "hint_child == Union[int, str]").
+    hint_child_childs: tuple = None  # type: ignore[assignment]
+
+    # ..................{ LOCALS ~ hint : metadata           }..................
+    # Tuple of metadata describing the currently visited hint, appended by
+    # the previously visited parent hint to the "hints_meta" stack.
+    hint_curr_meta: tuple = None  # type: ignore[assignment]
+
+    # Fixed list of all metadata describing all visitable hints currently
+    # discovered by the breadth-first search (BFS) below. This list acts as a
+    # standard First In First Out (FILO) queue, enabling this BFS to be
+    # implemented as an efficient imperative algorithm rather than an
+    # inefficient (and dangerous, due to both unavoidable stack exhaustion and
+    # avoidable infinite recursion) recursive algorithm.
+    #
+    # Note that this list is guaranteed by the previously called
+    # _die_if_hint_repr_exceeds_child_limit() function to be larger than the
+    # number of hints transitively visitable from this root hint. Ergo, *ALL*
+    # indexation into this list performed by this BFS is guaranteed to be safe.
+    # Ergo, avoid explicitly testing below that the "hints_meta_index_last"
+    # integer maintained by this BFS is strictly less than
+    # "FIXED_LIST_SIZE_MEDIUM", as this constraint is already guaranteed to be
+    # the case.
+    hints_meta = acquire_fixed_list(FIXED_LIST_SIZE_MEDIUM)
+
+    # 0-based index of metadata describing the currently visited hint in the
+    # "hints_meta" list.
+    hints_meta_index_curr = 0
+
+    # 0-based index of metadata describing the last visitable hint in the
+    # "hints_meta" list, initialized to "-1" to ensure that the initial
+    # incrementation of this index by the _enqueue_hint_child() directly called
+    # below initializes index 0 of the "hints_meta" fixed list.
+    #
+    # For efficiency, this integer also uniquely identifies the currently
+    # iterated child type hint of the currently visited parent type hint.
+    hints_meta_index_last = -1
+
+    # ..................{ LOCALS ~ func : code               }..................
+    # Python code snippet type-checking the current pith against the currently
+    # visited hint (to be appended to the "func_wrapper_code" string).
+    func_curr_code: str = None  # type: ignore[assignment]
+
+    # ..................{ LOCALS ~ func : code : locals      }..................
+    # Local scope (i.e., dictionary mapping from the name to value of each
+    # attribute referenced in the signature) of this wrapper function required
+    # by this Python code snippet.
+    func_wrapper_scope: LexicalScope = {}
+
+    # True only if one or more PEP-compliant type hints visitable from this
+    # root hint require a pseudo-random integer. If true, the higher-level
+    # beartype._decor.wrap.wrapmain.generate_code() function prefixes the body
+    # of this wrapper function with code generating such an integer.
+    is_var_random_int_needed = False
+
+    # ..................{ LOCALS ~ indentation               }..................
+    # Python code snippet expanding to the current level of indentation
+    # appropriate for the currently visited hint.
+    indent_curr: str = None  # type: ignore[assignment]
+
+    # 1-based indentation level describing the current level of indentation
+    # appropriate for the currently visited hint.
+    indent_level_curr = 2
+
+    # 1-based indentation level describing the current level of indentation
+    # appropriate for the currently iterated child hint, initialized to the
+    # root hint indentation level to enable the subsequently called
+    # _enqueue_hint_child() function to enqueue the root hint.
+    indent_level_child = indent_level_curr
+
+    # ..................{ LOCALS ~ pep : 484                 }..................
+    # Set of the unqualified classnames referred to by all relative forward
+    # references visitable from this root hint if any *OR* "None" otherwise
+    # (i.e., if no such forward references are visitable).
+    hint_refs_type_basename: Optional[set] = None
+
+    # ..................{ LOCALS ~ pep : 572                 }..................
+    # The following local variables isolated to this subsection are only
+    # relevant when the currently visited hint is *NOT* the root hint (i.e.,
+    # "hint_root"). If the currently visited hint is the root hint, the current
+    # pith has already been localized to a local variable whose name is the
+    # value of the "VAR_NAME_PITH_ROOT" string global and thus need *NOT* be
+    # relocalized to another local variable using an assignment expression.
+    #
+    # These variables enable a non-trivial runtime optimization eliminating
+    # repeated computations to obtain the child pith needed to type-check child
+    # hints. For example, if the current hint constrains the current pith to be
+    # a standard sequence, the child pith of that parent pith is a random item
+    # selected from this sequence; since obtaining this child pith is
+    # non-trivial, the computation required to do so is performed only once by
+    # assigning this child pith to a unique local variable during type-checking
+    # and then repeatedly type-checking that variable rather than the logic
+    # required to continually reacquire this child pith: e.g.,
+    #
+    #     # Type-checking conditional for "List[List[str]]" under Python < 3.8.
+    #     if not (
+    #         isinstance(__beartype_pith_0, list) and
+    #         (
+    #             isinstance(__beartype_pith_0[__beartype_random_int % len(__beartype_pith_0)], list) and
+    #             isinstance(__beartype_pith_0[__beartype_random_int % len(__beartype_pith_0)][__beartype_random_int % len(__beartype_pith_0[__beartype_random_int % len(__beartype_pith_0)])], str) if __beartype_pith_0[__beartype_random_int % len(__beartype_pith_0)] else True
+    #         ) if __beartype_pith_0 else True
+    #     ):
+    #
+    #     # The same conditional under Python >= 3.8.
+    #     if not (
+    #         isinstance(__beartype_pith_0, list) and
+    #         (
+    #             isinstance(__beartype_pith_1 := __beartype_pith_0[__beartype_random_int % len(__beartype_pith_0)], list) and
+    #             isinstance(__beartype_pith_1[__beartype_random_int % len(__beartype_pith_1)], str) if __beartype_pith_1 else True
+    #         ) if __beartype_pith_0 else True
+    #     ):
+    #
+    # Note that:
+    # * The random item selected from the root pith (i.e., "__beartype_pith_1
+    #   := __beartype_pith_0[__beartype_random_int % len(__beartype_pith_0)")
+    #   only occurs once under Python >= 3.8 but repeatedly under Python < 3.8.
+    #   In both cases, the same semantic type-checking is performed regardless
+    #   of optimization.
+    # * This optimization implicitly "bottoms out" when the currently visited
+    #   hint is *NOT* subscripted by unignorable child hints. If all child hints
+    #   of the currently visited hint are either ignorable (e.g., "object",
+    #   "Any") *OR* are unignorable isinstanceable types (e.g., "int", "str"),
+    #   the currently visited hint has *NO* meaningful child hints and is thus
+    #   effectively a leaf node with respect to performing this optimization.
+
+    # Integer suffixing the name of each local variable assigned the value of
+    # the current pith in a assignment expression, thus uniquifying this
+    # variable in the body of the current wrapper function.
+    #
+    # Note that this integer is intentionally incremented as an efficient
+    # low-level scalar rather than as an inefficient high-level
+    # "itertools.Counter" object. Since both are equally thread-safe in the
+    # internal context of this function body, the former is preferable.
+    pith_curr_var_name_index = 0
+
+    # Assignment expression assigning this full Python expression to the unique
+    # local variable assigned the value of this expression.
+    pith_curr_assign_expr: str = None  # type: ignore[assignment]
+
+    # ..................{ CLOSURES                           }..................
+    # Closures centralizing frequently repeated logic, addressing Don't Repeat
+    # Yourself (DRY) concerns during the breadth-first search (BFS) below.
+
+    def _enqueue_hint_child(pith_child_expr: str) -> str:
+        '''
+        **Enqueue** (i.e., append) a new tuple of metadata describing the
+        currently iterated child type hint to the end of the ``hints_meta``
+        queue, enabling this hint to be visited by the ongoing breadth-first
+        search (BFS) traversing over this queue.
+
+        Parameters
+        ----------
+        pith_child_expr : str
+            Python code snippet evaluating to the child pith to be type-checked
+            against the currently iterated child type hint.
+
+        This closure also implicitly expects the following local variables of
+        the outer scope to be set to relevant values:
+
+        hint_child : object
+            Currently iterated child type hint subscripting the currently
+            visited type hint.
+
+        Returns
+        -------
+        str
+            Placeholder string to be subsequently replaced by code type-checking
+            this child pith against this child type hint.
+        '''
+        # print(f'pith_child_expr: {pith_child_expr}')
+
+        # Allow these local variables of the outer scope to be modified below.
+        nonlocal hints_meta_index_last
+
+        # Increment both the 0-based index of metadata describing the last
+        # visitable hint in the "hints_meta" list and the unique identifier of
+        # the currently iterated child hint *BEFORE* overwriting the existing
+        # metadata at this index.
+        #
+        # Note this index is guaranteed to *NOT* exceed the fixed length of
+        # this list, by prior validation.
+        hints_meta_index_last += 1
+
+        # Placeholder string to be globally replaced by code type-checking the
+        # child pith against this child hint, intentionally prefixed and
+        # suffixed by characters that:
+        #
+        # * Are intentionally invalid as Python code, guaranteeing that the
+        #   top-level call to the exec() builtin performed by the @beartype
+        #   decorator will raise a "SyntaxError" exception if the caller fails
+        #   to replace all placeholder substrings generated by this method.
+        # * Protect the identifier embedded in this substring against ambiguous
+        #   global replacements of larger identifiers containing this
+        #   identifier. If this identifier were *NOT* protected in this manner,
+        #   then the first substring "0" generated by this method would
+        #   ambiguously overlap with the subsequent substring "10" generated by
+        #   this method, which would then produce catastrophically erroneous
+        #   and undebuggable Python code.
+        hint_child_placeholder = (
+            f'{CODE_HINT_CHILD_PLACEHOLDER_PREFIX}'
+            f'{str(hints_meta_index_last)}'
+            f'{CODE_HINT_CHILD_PLACEHOLDER_SUFFIX}'
+        )
+
+        # Create and insert a new tuple of metadata describing this child hint
+        # at this index of this list.
+        #
+        # Note that this assignment is guaranteed to be safe, as
+        # "FIXED_LIST_SIZE_MEDIUM" is guaranteed to be substantially larger than
+        # "hints_meta_index_last".
+        hints_meta[hints_meta_index_last] = (
+            hint_child,
+            hint_child_placeholder,
+            pith_child_expr,
+            pith_curr_var_name_index,
+            indent_level_child,
+        )
+
+        # Return this placeholder string.
+        return hint_child_placeholder
+
+    # ..................{ LOCALS ~ closure                   }..................
+    # Local variables calling one or more closures declared above and thus
+    # deferred until after declaring those closures.
+
+    # Placeholder string to be globally replaced in the Python code snippet to
+    # be returned (i.e., "func_wrapper_code") by a Python code snippet
+    # type-checking the child pith expression (i.e., "pith_child_expr") against
+    # the currently iterated child hint (i.e., "hint_child"), initialized to a
+    # placeholder describing the root hint.
+    hint_child_placeholder = _enqueue_hint_child(VAR_NAME_PITH_ROOT)
+
+    # Python code snippet type-checking the root pith against the root hint,
+    # localized separately from the "func_wrapper_code" snippet to enable this
+    # function to validate this code to be valid *BEFORE* returning this code.
+    func_root_code = hint_child_placeholder
+
+    # Python code snippet to be returned, seeded with a placeholder to be
+    # replaced on the first iteration of the breadth-first search performed
+    # below with a snippet type-checking the root pith against the root hint.
+    func_wrapper_code = func_root_code
+
+    # ..................{ SEARCH                             }..................
+    # While the 0-based index of metadata describing the next visited hint in
+    # the "hints_meta" list does *NOT* exceed that describing the last
+    # visitable hint in this list, there remains at least one hint to be
+    # visited in the breadth-first search performed by this iteration.
+    while hints_meta_index_curr <= hints_meta_index_last:
+        # Metadata describing the currently visited hint.
+        hint_curr_meta = hints_meta[hints_meta_index_curr]
+
+        # Assert this metadata is a tuple as expected. This enables us to
+        # distinguish between proper access of used items and improper access
+        # of unused items of the parent fixed list containing this tuple, since
+        # an unused item of this list is initialized to "None" by default.
+        assert hint_curr_meta.__class__ is tuple, (
+            f'Current hint metadata {repr(hint_curr_meta)} at '
+            f'index {hints_meta_index_curr} not tuple.'
+        )
+
+        #FIXME: ...heh. It's time, people. Sadly, it turns out that redefining
+        #the _enqueue_hint() closure on *EVERY* call to this function is a huge
+        #time sink -- far huger than anything else, actually. Therefore:
+        #* Define a new "HintMeta" dataclass defining one slotted field for each
+        #  of these metadata.
+        #* Refactor the _enqueue_hint() closure into a HintMeta.enqueue_hint()
+        #  method.
+        #* Replace all calls to the _enqueue_hint() closure with calls to the
+        #  HintMeta.enqueue_hint() method.
+        #* Remove the _enqueue_hint() closure.
+        #* Remove all of the following locals from this function in favour of
+        #  the "HintMeta" slotted fields of the same names:
+        #  * hint_curr.
+        #  * hint_curr_placeholder.
+        #  * pith_curr_expr.
+        #  * pith_curr_var_name_index.
+        #  * indent_level_curr.
+
+        # Localize metadata for both efficiency and f-string purposes.
+        #
+        # Note that list unpacking is substantially more efficient than
+        # manually indexing list items; the former requires only a single Python
+        # statement, whereas the latter requires "n" Python statements.
+        (
+            hint_curr,
+            hint_curr_placeholder,
+            pith_curr_expr,
+            pith_curr_var_name_index,
+            indent_level_curr,
+        ) = hint_curr_meta
+        # print(f'Visiting type hint {repr(hint_curr)}...')
+
+        #FIXME: Comment this sanity check out after we're sufficiently
+        #convinced this algorithm behaves as expected. While useful, this check
+        #requires a linear search over the entire code and is thus costly.
+        # assert hint_curr_placeholder in func_wrapper_code, (
+        #     '{} {!r} placeholder {} not found in wrapper body:\n{}'.format(
+        #         hint_curr_exception_prefix, hint, hint_curr_placeholder, func_wrapper_code))
+
+        # ................{ PEP                                }................
+        # If this hint is PEP-compliant...
+        if is_hint_pep(hint_curr):
+            #FIXME: Refactor to call warn_if_hint_pep_unsupported() instead.
+            #Actually...wait. This is probably still a valid test here. We'll
+            #need to instead augment the is_hint_ignorable() function to
+            #additionally test whether the passed hint is unsupported, in which
+            #case that function should return false as well as emit a non-fatal
+            #warning ala the new warn_if_hint_pep_unsupported() function --
+            #which should probably simply be removed now. *sigh*
+            #FIXME: Actually, in that case, we can simply reduce the following
+            #two calls to simply:
+            #    die_if_hint_pep_ignorable(
+            #        hint=hint_curr, exception_prefix=hint_curr_exception_prefix)
+            #Of course, this implies we want to refactor the
+            #die_if_hint_pep_unsupported() function into
+            #die_if_hint_pep_ignorable()... probably.
+
+            # If this hint is currently unsupported, raise an exception.
+            #
+            # Note the human-readable label prefixing the representations of
+            # child PEP-compliant type hints is unconditionally passed. Since
+            # the root hint has already been validated to be supported by
+            # the above call to the same function, this call is guaranteed to
+            # *NEVER* raise an exception for that hint.
+            die_if_hint_pep_unsupported(
+                hint=hint_curr, exception_prefix=EXCEPTION_PREFIX)
+            # Else, this hint is supported.
+
+            # Assert that this hint is unignorable. Iteration below generating
+            # code for child hints of the current parent hint is *REQUIRED* to
+            # explicitly ignore ignorable child hints. Since the caller has
+            # explicitly ignored ignorable root hints, these two guarantees
+            # together ensure that all hints visited by this breadth-first
+            # search *SHOULD* be unignorable. Naturally, we validate that here.
+            assert not is_hint_ignorable(hint_curr), (
+                f'{EXCEPTION_PREFIX}ignorable type hint '
+                f'{repr(hint_curr)} not ignored.'
+            )
+
+            # Sign uniquely identifying this hint.
+            hint_curr_sign = get_hint_pep_sign(hint_curr)
+            # print(f'Visiting PEP type hint {repr(hint_curr)} sign {repr(hint_curr_sign)}...')
+
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # NOTE: Whenever adding support for (i.e., when generating code
+            # type-checking) a new "typing" attribute below, similar support
+            # for that attribute *MUST* also be added to the parallel:
+            # * "beartype._check.error" subpackage, which raises exceptions on
+            #   the current pith failing this check.
+            # * "beartype._data.hint.pep.sign.datapepsignset.HINT_SIGNS_SUPPORTED_DEEP"
+            #   frozen set of all signs for which this function generates deeply
+            #   type-checking code.
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+            #FIXME: Python 3.10 provides proper syntactic support for "case"
+            #statements, which should allow us to dramatically optimize this
+            #"if" logic into equivalent "case" logic *AFTER* we drop support
+            #for Python 3.9. Of course, that will be basically never, so we'll
+            #have to preserve this for basically forever. What you gonna do?
+            #FIXME: Actually, we should probably just leverage a hypothetical
+            #"beartype.vale.IsInline[...]" validator to coerce this slow O(n)
+            #procedural logic into fast O(1) object-oriented logic. Of course,
+            #object-oriented logic is itself slow -- so we only do this if we
+            #can sufficiently memoize that logic. Consideration!
+
+            # Switch on (as in, pretend Python provides a "case" statement)
+            # the sign identifying this hint to decide which type of code to
+            # generate to type-check the current pith against the current hint.
+            #
+            # This decision is intentionally implemented as a linear series of
+            # tests ordered in descending likelihood for efficiency. While
+            # alternative implementations (that are more readily readable and
+            # maintainable) do exist, these alternatives all appear to be
+            # substantially less efficient.
+            #
+            # Consider the standard alternative of sequestering the body of
+            # each test implemented below into either:
+            #
+            # * A discrete private function called by this function. This
+            #   approach requires maintaining a global private dictionary
+            #   mapping from each support unsubscripted typing attribute to
+            #   the function generating code for that attribute: e.g.,
+            #      def pep_code_check_union(...): ...
+            #      _HINT_TYPING_ATTR_ARGLESS_TO_CODER = {
+            #          typing.Union: pep_code_check_union,
+            #      }
+            #   Each iteration of this loop then looks up the function
+            #   generating code for the current attribute from this dictionary
+            #   and calls that function to do so. Function calls come with
+            #   substantial overhead in Python, impacting performance more
+            #   than the comparable linear series of tests implemented below.
+            #   Additionally, these functions *MUST* mutate local variables of
+            #   this function by some arcane means -- either:
+            #   * Passing these locals to each such function, returning these
+            #     locals from each such function, and assigning these return
+            #     values to these locals in this function after each such call.
+            #   * Passing a single composite fixed list of these locals to each
+            #     such function, which then mutates these locals in-place,
+            #     which then necessitates this function permanently store these
+            #     locals in such a list rather than as local variables.
+            # * A discrete closure of this function, which adequately resolves
+            #   the aforementioned locality issue via the "nonlocal" keyword at
+            #   a substantial up-front performance cost of redeclaring these
+            #   closures on each invocation of this function.
+            #
+            # ..............{ SHALLOW                            }..............
+            # Perform shallow type-checking logic (i.e., logic that does *NOT*
+            # recurse and thus "bottoms out" at this hint) *BEFORE* deep
+            # type-checking logic. The latter needs additional setup (e.g.,
+            # generation of assignment expressions) *NOT* needed by the former,
+            # whose requirements are more understandably minimalist. Note that:
+            # * Shallow type-checking code should access this pith via
+            #   "pith_curr_expr". Since this code does *NOT* recurse,
+            #   "pith_curr_expr" accesses this pith optimally efficiently
+            # * Deep type-checking code should access this pith via
+            #   "pith_assign_expr". Since that code *DOES* recurse, only
+            #   "pith_assign_expr" accesses this pith optimally efficiently;
+            #   "pith_curr_expr" accesses this pith extremely inefficiently.
+            #
+            # ..............{ ORIGIN                             }..............
+            # If this hint both...
+            if (
+                # Originates from an origin type and may thus be shallowly
+                # type-checked against that type *AND is either...
+                hint_curr_sign in HINT_SIGNS_ORIGIN_ISINSTANCEABLE and (
+                    # Unsubscripted *OR*...
+                    not is_hint_pep_args(hint_curr) or
+                    #FIXME: Remove this branch *AFTER* deeply supporting all
+                    #hints.
+                    # Currently unsupported with deep type-checking...
+                    hint_curr_sign not in HINT_SIGNS_SUPPORTED_DEEP
+                )
+            ):
+            # Then generate trivial code shallowly type-checking the current
+            # pith as an instance of the origin type originating this sign
+            # (e.g., "list" for the hint "typing.List[int]").
+                # Code type-checking the current pith against this origin type.
+                func_curr_code = CODE_PEP484_INSTANCE_format(
+                    pith_curr_expr=pith_curr_expr,
+                    # Python expression evaluating to this origin type.
+                    hint_curr_expr=add_func_scope_type(
+                        # Origin type of this hint if any *OR* raise an
+                        # exception -- which should *NEVER* happen, as this hint
+                        # was validated above to be supported.
+                        cls=get_hint_pep_origin_type_isinstanceable(hint_curr),
+                        func_scope=func_wrapper_scope,
+                        exception_prefix=EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL,
+                    ),
+                )
+            # Else, this hint is either subscripted, not shallowly
+            # type-checkable, *OR* deeply type-checkable.
+            #
+            # ..............{ FORWARDREF                         }..............
+            # If this hint is a forward reference...
+            elif hint_curr_sign is HintSignForwardRef:
+                # Render this forward reference accessible to the body of this
+                # wrapper function by populating:
+                # * A Python expression evaluating to the class referred to by
+                #   this forward reference when accessed via the private
+                #   "__beartypistry" parameter.
+                # * A set of the unqualified classnames referred to by all
+                #   relative forward references, including this reference if
+                #   relative. If this set was previously uninstantiated (i.e.,
+                #   "None"), this assignment initializes this local to the new
+                #   set instantiated by this call; else, this assignment
+                #   preserves this local set as is.
+                hint_curr_expr, hint_refs_type_basename = (
+                    express_func_scope_type_ref(
+                        forwardref=hint_curr,
+                        forwardrefs_class_basename=hint_refs_type_basename,
+                        func_scope=func_wrapper_scope,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    ))
+
+                # Code type-checking the current pith against this class.
+                func_curr_code = CODE_PEP484_INSTANCE_format(
+                    pith_curr_expr=pith_curr_expr,
+                    hint_curr_expr=hint_curr_expr,
+                )
+            # Else, this hint is *NOT* a forward reference.
+            #
+            # Since this hint is *NOT* shallowly type-checkable, this hint
+            # *MUST* be deeply type-checkable. So, we do so now.
+            #
+            # ..............{ DEEP                               }..............
+            # Perform deep type-checking logic (i.e., logic that is guaranteed
+            # to recurse and thus *NOT* "bottom out" at this hint).
+            else:
+                # Tuple of all arguments subscripting this hint if any *OR* the
+                # empty tuple otherwise (e.g., if this hint is its own
+                # unsubscripted "typing" attribute).
+                #
+                # Note that the "__args__" dunder attribute is *NOT* guaranteed
+                # to exist for arbitrary PEP-compliant type hints. Ergo, we
+                # obtain this attribute via a higher-level utility getter
+                # instead.
+                hint_childs = get_hint_pep_args(hint_curr)
+                hint_childs_len = len(hint_childs)
+
+                # Python code snippet expanding to the current level of
+                # indentation appropriate for the current hint.
+                indent_curr = INDENT_LEVEL_TO_CODE[indent_level_curr]
+
+                # 1-based indentation level describing the current level of
+                # indentation appropriate for the currently iterated child hint.
+                indent_level_child = indent_level_curr + 1
+
+                # ............{ DEEP ~ expression                  }............
+                #FIXME: Unit test that this is behaving as expected. Doing so
+                #will require further generalizations, including:
+                #* In the "beartype._decor.decormain" submodule:
+                #  * Detect when running under tests.
+                #  * When running under tests, define a new
+                #    "func_wrapper.__beartype_wrapper_code" attribute added to
+                #    decorated callables to be the "func_wrapper_code" string
+                #    rather than True. Note that this obviously isn't the right way
+                #    to do source code association. Ideally, we'd at least
+                #    interface with the stdlib "linecache" module (e.g., by calling
+                #    the linecache.lazycache() function intended to be used to
+                #    cache the source code for non-file-based modules) and possibly
+                #    even go so far as to define a PEP 302-compatible beartype
+                #    module loader. That's out of scope, so this suffices for now.
+                #* In the "beartype_test.a00_unit.data._data_hint_pep" submodule:
+                #  * Add a new "_PepHintMetadata.code_str_match_regexes" field,
+                #    defined as an iterable of regular expressions matching
+                #    substrings of the "func_wrapper.__beartype_wrapper_code"
+                #    attribute that are expected to exist.
+                #  * For most "HINTS_PEP_META" entries, default this field to
+                #    merely the empty tuple.
+                #  * For deeply nested "HINTS_PEP_META" entries, define this
+                #    field as follows:
+                #        code_str_match_regexes=(r'\s+:=\s+',)
+                #* In the "beartype_test.a00_unit.pep.p484.test_p484" submodule:
+                #  * Match the "pep_hinted.__beartype_wrapper_code" string against
+                #    all regular expressions in the "code_str_match_regexes"
+                #    iterable for the currently iterated "pep_hint_meta".
+                #
+                #This is fairly important, as we have no other reusable means of
+                #ascertaining whether this is actually being applied in general.
+                #FIXME: That's all great, except for the
+                #"func_wrapper.__beartype_wrapper_code" part. Don't do that,
+                #please. We really do just want to do this right the first time. As
+                #expected, the key to doing so is the linecache.lazycache()
+                #function, whose implementation under Python 3.7 reads:
+                #
+                #    def lazycache(filename, module_globals):
+                #        """Seed the cache for filename with module_globals.
+                #
+                #        The module loader will be asked for the source only when getlines is
+                #        called, not immediately.
+                #
+                #        If there is an entry in the cache already, it is not altered.
+                #
+                #        :return: True if a lazy load is registered in the cache,
+                #            otherwise False. To register such a load a module loader with a
+                #            get_source method must be found, the filename must be a cachable
+                #            filename, and the filename must not be already cached.
+                #        """
+                #        if filename in cache:
+                #            if len(cache[filename]) == 1:
+                #                return True
+                #            else:
+                #                return False
+                #        if not filename or (filename.startswith('<') and filename.endswith('>')):
+                #            return False
+                #        # Try for a __loader__, if available
+                #        if module_globals and '__loader__' in module_globals:
+                #            name = module_globals.get('__name__')
+                #            loader = module_globals['__loader__']
+                #            get_source = getattr(loader, 'get_source', None)
+                #
+                #            if name and get_source:
+                #                get_lines = functools.partial(get_source, name)
+                #                cache[filename] = (get_lines,)
+                #                return True
+                #        return False
+                #
+                #Given that, what we need to do is:
+                #* Define a new "beartype._decor._pep302" submodule implementing a
+                #  PEP 302-compatible loader for @beartype-generated wrapper
+                #  functions, enabling external callers (including the stdlib
+                #  "linecache" module) to obtain the source for these functions.
+                #  For space efficiency, this submodule should internally store
+                #  code in a compressed format -- which probably means "gzip" for
+                #  maximal portability. This submodule should at least define these
+                #  attributes:
+                #  * "_FUNC_WRAPPER_MODULE_NAME_TO_CODE", a dictionary mapping from
+                #    the unique fake module names assigned to @beartype-generated
+                #    wrapper functions by the @beartype decorator to the compressed
+                #    source strings for those fake modules.
+                #  * get_source(), a function accepting one unique fake module name
+                #    assigned to an arbitrary @beartype-generated wrapper function
+                #    by the @beartype decorator and returning the uncompressed
+                #    source string for that fake module. Clearly, this function
+                #    should internally access the
+                #    "_FUNC_WRAPPER_MODULE_NAME_TO_CODE" dictionary and either:
+                #    * If the passed module name has *NOT* already been registered
+                #      to that dictionary, raise an exception.
+                #    * Else, uncompress the compressed source string previously
+                #      registered under that module name with that dictionary and
+                #      return that uncompressed string. Don't worry about caching
+                #      uncompressed strings here; that's exactly what the stdlib
+                #      "linecache" module already does on our behalf.
+                #    Ergo, this function should have signature resembling:
+                #        def get_source(func_wrapper_module_name: str) -> str:
+                #  * set_source(), a function accepting one unique fake module name
+                #    assigned to an arbitrary @beartype-generated wrapper function
+                #    by the @beartype decorator as well as as the uncompressed
+                #    source string for that fake module. Clearly, this function
+                #    should internally
+                #    "_FUNC_WRAPPER_MODULE_NAME_TO_CODE" dictionary and either:
+                #    * If the passed module name has already been registered to
+                #      that dictionary, raise an exception.
+                #    * Else, compress the passed uncompressed source string and
+                #      register that compressed string under that module name with
+                #      that dictionary.
+                #* In the "beartype._decor.decormain" submodule:
+                #  * Do... something? Oh, boy. Why didn't we finish this comment?
+
+                # If the expression yielding the current pith is neither...
+                if not (
+                    # The root pith *NOR*...
+                    #
+                    # Note that this is merely a negligible optimization for the
+                    # common case in which the current pith is the root pith
+                    # (i.e., this is the first iteration of the outermost loop).
+                    # The subsequent call to the str.isidentifier() method is
+                    # *MUCH* more expensive than this object identity test.
+                    pith_curr_expr is VAR_NAME_PITH_ROOT or
+                    # A simple Python identifier *NOR*...
+                    pith_curr_expr.isidentifier() or
+                    # A complex Python expression already containing the
+                    # assignment expression-specific "walrus" operator ":=".
+                    # Since this implies this expression to already be an
+                    # assignment expression, needlessly reassigning the local
+                    # variable to which this assignment expression was
+                    # previously assigned to yet another redundant local
+                    # variable only harms efficiency for *NO* tangible gain
+                    # (e.g., expanding the efficient assignment expression
+                    # "__beartype_pith_1 := next(iter(__beartype_pith_0))" to
+                    # the inefficient assignment expression
+                    # "__beartype_pith_2 := __beartype_pith_1 :=
+                    # next(iter(__beartype_pith_0))").
+                    #
+                    # Note that this edge case is induced by closure calls
+                    # performed below of the form:
+                    #    _enqueue_hint_child(pith_curr_assign_expr)
+                    #
+                    # As of this writing, the only such edge case is a PEP 484-
+                    # or 604-compliant union containing *ONLY* two or more
+                    # PEP-compliant type hints (e.g., "list[str] | set[bytes]").
+                    ':=' in pith_curr_expr
+                ):
+                    # Then the current pith is safely assignable to a unique
+                    # local variable via an assignment expression.
+                    #
+                    # Note that we explicitly test against piths rather than
+                    # seemingly equivalent metadata to account for edge cases.
+                    # Notably, child hints of unions (and possibly other
+                    # "typing" objects) do *NOT* narrow the current pith and are
+                    # *NOT* the root hint. Ergo, a seemingly equivalent test
+                    # like "hints_meta_index_curr != 0" would generate false
+                    # positives and thus unnecessarily inefficient code.
+
+                    # Increment the integer suffixing the name of this variable
+                    # *BEFORE* defining this variable.
+                    pith_curr_var_name_index += 1
+
+                    # Name of this local variable.
+                    pith_curr_var_name = PITH_INDEX_TO_VAR_NAME[
+                        pith_curr_var_name_index]
+
+                    # Assignment expression assigning this full expression to
+                    # this local variable.
+                    pith_curr_assign_expr = CODE_PEP572_PITH_ASSIGN_EXPR_format(
+                        pith_curr_var_name=pith_curr_var_name,
+                        pith_curr_expr=pith_curr_expr,
+                    )
+                # Else, the current pith is *NOT* safely assignable to a unique
+                # local variable via an assignment expression. Since the
+                # expression yielding the current pith is a simple Python
+                # identifier, there is *NO* benefit to assigning that to another
+                # local variable via another assignment expression, which would
+                # just be an alias of the existing local variable assigned via
+                # the existing assignment expression. Moreover, whereas chained
+                # assignments are syntactically valid, chained assignment
+                # expressions are syntactically invalid unless explicitly
+                # protected by parens: e.g.,
+                #     >>> a = b =    'Mother*Teacher*Destroyer'  # <-- fine
+                #     >>> (a :=      "Mother's Abomination")     # <-- fine
+                #     >>> (a :=
+                #     ... (b := "Mother's Illumination"))        # <-- fine
+                #     >>> (a := b := "Mother's Illumination")    # <-- not fine
+                #     SyntaxError: invalid syntax
+                #
+                # In this case...
+                else:
+                    # Name of this local variable.
+                    pith_curr_var_name = PITH_INDEX_TO_VAR_NAME[
+                        pith_curr_var_name_index]
+
+                    # Preserve the Python code snippet evaluating to the value
+                    # of the current pith as is.
+                    pith_curr_assign_expr = pith_curr_expr
+
+                # ............{ UNION                              }............
+                # If this hint is a union (e.g., "typing.Union[bool, str]",
+                # typing.Optional[float]")...
+                #
+                # Note that unions are non-physical abstractions of physical
+                # types and thus *NOT* themselves subject to type-checking;
+                # only the subscripted arguments of unions are type-checked.
+                # This differs from "typing" pseudo-containers like
+                # "List[int]", in which both the parent "List" and child "int"
+                # types represent physical types to be type-checked. Ergo,
+                # unions themselves impose no narrowing of the current pith
+                # expression and thus *CANNOT* by definition benefit from
+                # assignment expressions. This differs from "typing"
+                # pseudo-containers, which narrow the current pith expression
+                # and thus do benefit from assignment expressions.
+                if hint_curr_sign in HINT_SIGNS_UNION:
+                    # Assert this union to be subscripted by one or more child
+                    # hints. Note this should *ALWAYS* be the case, as:
+                    # * The unsubscripted "typing.Union" object is explicitly
+                    #   listed in the "HINTS_REPR_IGNORABLE_SHALLOW" set and
+                    #   should thus have already been ignored when present.
+                    # * The "typing" module explicitly prohibits empty union
+                    #   subscription: e.g.,
+                    #       >>> typing.Union[]
+                    #       SyntaxError: invalid syntax
+                    #       >>> typing.Union[()]
+                    #       TypeError: Cannot take a Union of no types.
+                    assert hint_childs, (
+                        f'{EXCEPTION_PREFIX}union type hint '
+                        f'{repr(hint_curr)} unsubscripted.'
+                    )
+                    # Else, this union is subscripted by two or more arguments.
+                    # Why two rather than one? Because the "typing" module
+                    # reduces unions of one argument to that argument: e.g.,
+                    #     >>> import typing
+                    #     >>> typing.Union[int]
+                    #     int
+
+                    # 0-based index of the currently iterated child hint.
+                    hint_childs_index = 0
+
+                    # For efficiency, reuse a previously created list of all
+                    # new child hints of this parent union.
+                    hint_childs_new = acquire_object_typed(list)
+                    hint_childs_new.clear()
+
+                    # For each subscripted argument of this union...
+                    #
+                    # Note that this preliminary iteration:
+                    # * Modifies the "hint_childs" container being iterated over
+                    #   and is thus intentionally implemented as a cumbersome
+                    #   "while" loop rather than a convenient "for" loop.
+                    # * Exists for the sole purpose of explicitly flattening
+                    #   *ALL* child unions nested in this parent union. This
+                    #   iteration *CANNOT* be efficiently combined with the
+                    #   iteration performed below for that reason.
+                    # * Does *NOT* recursively flatten arbitrarily nested
+                    #   child unions regardless of nesting depth in this parent
+                    #   union. Doing so is non-trivial and currently *NOT*
+                    #   required by any existing edge cases. "Huzzah!"
+                    while hint_childs_index < hint_childs_len:
+                        # Current child hint of this union.
+                        hint_child = hint_childs[hint_childs_index]
+
+                        # This child hint sanified (i.e., sanitized) from this
+                        # child hint if this child hint is reducible *OR*
+                        # preserved as is otherwise (i.e., if this child hint is
+                        # irreducible).
+                        #
+                        # Note that:
+                        # * This sanification is intentionally performed
+                        #   *BEFORE* this child hint is tested as being either
+                        #   PEP-compliant or -noncompliant. Why? Because a small
+                        #   subset of low-level reduction routines performed by
+                        #   this high-level sanification actually expand a
+                        #   PEP-noncompliant type into a PEP-compliant type
+                        #   hint. This includes:
+                        #   * The PEP-noncompliant "float' and "complex" types,
+                        #     implicitly expanded to the PEP 484-compliant
+                        #     "float | int" and "complex | float | int" type
+                        #     hints (respectively) when the non-default
+                        #     "conf.is_pep484_tower=True" parameter is enabled.
+                        # * This sanification intentionally calls the
+                        #   lower-level sanify_hint_child() rather than the
+                        #   higher-level
+                        #   sanify_hint_child_if_unignorable_or_none() sanifier.
+                        #   Technically, the latter would suffice as well.
+                        #   Pragmatically, both are semantically equivalent here
+                        #   but the former is faster. Why? By definition, this
+                        #   union is unignorable. If this union were ignorable,
+                        #   the parent hint containing this union would already
+                        #   have ignored this union. Moreover, *ALL* child
+                        #   hints subscripting an unignorable union are
+                        #   necessarily also unignorable. It follows that this
+                        #   child hint need *NOT* be tested for ignorability.
+                        # print(f'Sanifying union child hint {repr(hint_child)} under {repr(conf)}...')
+                        hint_child = sanify_hint_child(
+                            hint=hint_child,
+                            conf=conf,
+                            cls_stack=cls_stack,
+                            exception_prefix=EXCEPTION_PREFIX,
+                        )
+                        # print(f'Sanified union child hint to {repr(hint_child)}...')
+
+                        # Sign of this sanified child hint if this hint is
+                        # PEP-compliant *OR* "None" otherwise (i.e., if this
+                        # hint is PEP-noncompliant).
+                        hint_child_sign = get_hint_pep_sign_or_none(hint_child)
+
+                        # If this child hint is itself a child union nested in
+                        # this parent union, explicitly flatten this nested
+                        # union by appending *ALL* child child hints
+                        # subscripting this child union onto this parent union.
+                        #
+                        # Note that this edge case currently *ONLY* arises when
+                        # this child hint has been expanded by the above call to
+                        # the sanify_hint_child() function from a non-union (e.g.,
+                        # "float") into a union (e.g., "float | int"). The
+                        # standard PEP 484-compliant "typing.Union" factory
+                        # already implicitly flattens nested unions: e.g.,
+                        #     >>> from typing import Union
+                        #     >>> Union[float, Union[int, str]]
+                        #     typing.Union[float, int, str]
+                        if hint_child_sign in HINT_SIGNS_UNION:
+                            # Tuple of all child child type hints subscripting
+                            # this child union.
+                            hint_child_childs = get_hint_pep_args(hint_child)
+                            # print(f'Expanding union {repr(hint_curr)} with child union {repr(hint_child_childs)}...')
+
+                            # Append these child child type hints to this parent
+                            # union.
+                            hint_childs_new.extend(hint_child_childs)
+                        # Else, this child hint is *NOT* itself a union. In this
+                        # case, append this child hint to this parent union.
+                        else:
+                            hint_childs_new.append(hint_child)
+
+                        # Increment the 0-based index of the currently iterated
+                        # child hint.
+                        hint_childs_index += 1
+
+                    # Freeze this temporary list back to this permanent tuple,
+                    # replacing the prior unflattened contents of this tuple.
+                    hint_childs = tuple(hint_childs_new)
+
+                    # Release this list back to its respective pool.
+                    release_object_typed(hint_childs_new)
+                    # print(f'Flattened union to {repr(hint_childs)}...')
+
+                    # For efficiency, reuse previously created sets of the
+                    # following (when available):
+                    # * "hint_childs_nonpep", the set of all PEP-noncompliant
+                    #   child hints subscripting this union.
+                    # * "hint_childs_pep", the set of all PEP-compliant child
+                    #   hints subscripting this union.
+                    #
+                    # Since these child hints require fundamentally different
+                    # forms of type-checking, prefiltering child hints into
+                    # these sets *BEFORE* generating code type-checking these
+                    # child hints improves both efficiency and maintainability.
+                    hint_childs_nonpep = acquire_object_typed(set)
+                    hint_childs_pep = acquire_object_typed(set)
+
+                    # Clear these sets prior to use below.
+                    hint_childs_nonpep.clear()
+                    hint_childs_pep.clear()
+
+                    # For each subscripted argument of this union...
+                    for hint_child in hint_childs:
+                        #FIXME: Uncomment as desired for debugging. This test is
+                        #currently a bit too costly to warrant uncommenting.
+                        # Assert that this child hint is *NOT* shallowly ignorable.
+                        # Why? Because any union containing one or more shallowly
+                        # ignorable child hints is deeply ignorable and should thus
+                        # have already been ignored after a call to the
+                        # is_hint_ignorable() tester passed this union on handling
+                        # the parent hint of this union.
+                        # assert (
+                        #     repr(hint_curr) not in HINTS_REPR_IGNORABLE_SHALLOW), (
+                        #     f'{hint_curr_exception_prefix} {repr(hint_curr)} child '
+                        #     f'{repr(hint_child)} ignorable but not ignored.')
+
+                        # If this child hint is PEP-compliant...
+                        if is_hint_pep(hint_child):
+                            # Filter this child hint into the set of
+                            # PEP-compliant child hints.
+                            #
+                            # Note that this PEP-compliant child hint *CANNOT*
+                            # also be filtered into the set of PEP-noncompliant
+                            # child hints, even if this child hint originates
+                            # from a non-"typing" type (e.g., "List[int]" from
+                            # "list"). Why? Because that would then induce
+                            # false positives when the current pith shallowly
+                            # satisfies this non-"typing" type but does *NOT*
+                            # deeply satisfy this child hint.
+                            hint_childs_pep.add(hint_child)
+                        # Else, this child hint is PEP-noncompliant. In this
+                        # case, filter this child hint into the list of
+                        # PEP-noncompliant arguments.
+                        else:
+                            hint_childs_nonpep.add(hint_child)
+
+                    # Initialize the code type-checking the current pith against
+                    # these arguments to the substring prefixing all such code.
+                    func_curr_code = CODE_PEP484604_UNION_PREFIX
+
+                    # If this union is subscripted by one or more
+                    # PEP-noncompliant child hints, generate and append
+                    # efficient code type-checking these child hints *BEFORE*
+                    # less efficient code type-checking any PEP-compliant child
+                    # hints subscripting this union.
+                    if hint_childs_nonpep:
+                        func_curr_code += (
+                            CODE_PEP484604_UNION_CHILD_NONPEP_format(
+                                # Python expression yielding the value of the
+                                # current pith. Specifically...
+                                pith_curr_expr=(
+                                    # If this union is also subscripted by one
+                                    # or more PEP-compliant child hints, prefer
+                                    # the expression assigning this value to a
+                                    # local variable efficiently reused by
+                                    # subsequent code generated for those
+                                    # PEP-compliant child hints.
+                                    pith_curr_assign_expr
+                                    if hint_childs_pep else
+                                    # Else, this union is subscripted by *NO*
+                                    # PEP-compliant child hints. Since this is
+                                    # the first and only test generated for this
+                                    # union, prefer the expression yielding the
+                                    # value of the current pith *WITHOUT*
+                                    # assigning this value to a local variable,
+                                    # which would needlessly go unused.
+                                    pith_curr_expr
+                                ),
+                                # Python expression evaluating to a tuple of
+                                # these arguments.
+                                #
+                                # Note that we would ideally avoid coercing this
+                                # set into a tuple when this set only contains
+                                # one type by passing that type directly to the
+                                # _add_func_wrapper_local_type() function.
+                                # Sadly, the "set" class defines no convenient
+                                # or efficient means of retrieving the only item
+                                # of a 1-set. Indeed, the most efficient means
+                                # of doing so is to iterate over that set and
+                                # immediately halt iteration:
+                                #     for first_item in muh_set: break
+                                #
+                                # While we *COULD* technically leverage that
+                                # approach here, doing so would also mandate
+                                # adding multiple intermediate tests, mitigating
+                                # any performance gains. Ultimately, we avoid
+                                # doing so by falling back to the usual
+                                # approach. See also this relevant
+                                # self-StackOverflow post:
+                                #       https://stackoverflow.com/a/40054478/2809027
+                                hint_curr_expr=add_func_scope_types(
+                                    types=hint_childs_nonpep,
+                                    func_scope=func_wrapper_scope,
+                                    exception_prefix=(
+                                        EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL),
+                                ),
+                            ))
+
+                    # For the 0-based index and each child hint of this union...
+                    for hint_child_index, hint_child in enumerate(
+                        hint_childs_pep):
+                        # Code deeply type-checking this child hint.
+                        func_curr_code += CODE_PEP484604_UNION_CHILD_PEP_format(
+                            # Expression yielding the value of this pith.
+                            hint_child_placeholder=_enqueue_hint_child(
+                                # If either...
+                                #
+                                # Then prefer the expression efficiently reusing
+                                # the value previously assigned to a local
+                                # variable by either the above conditional or
+                                # prior iteration of the current conditional.
+                                pith_curr_var_name
+                                if (
+                                    # This union is also subscripted by one or
+                                    # more PEP-noncompliant child hints *OR*...
+                                    hint_childs_nonpep or
+                                    # This is any PEP-compliant child hint
+                                    # *EXCEPT* the first...
+                                    hint_child_index
+                                ) else
+                                # Then this union is not subscripted by any
+                                # PEP-noncompliant child hints *AND* this is the
+                                # first PEP-compliant child hint. In this case,
+                                # preface this code with an expression assigning
+                                # this value to a local variable efficiently
+                                # reused by code generated by subsequent
+                                # iteration.
+                                #
+                                # Note this child hint is guaranteed to be
+                                # followed by at least one more child hint. Why?
+                                # Because the "typing" module forces unions to
+                                # be subscripted by two or more child hints. By
+                                # deduction, those child hints *MUST* be
+                                # PEP-compliant. Ergo, we need *NOT* explicitly
+                                # validate that constraint here.
+                                pith_curr_assign_expr
+                            ))
+
+                    # If this code is *NOT* its initial value, this union is
+                    # subscripted by one or more unignorable child hints and
+                    # the above logic generated code type-checking these child
+                    # hints. In this case...
+                    if func_curr_code is not CODE_PEP484604_UNION_PREFIX:
+                        # Munge this code to...
+                        func_curr_code = (
+                            # Strip the erroneous " or" suffix appended by the
+                            # last child hint from this code.
+                            f'{func_curr_code[:LINE_RSTRIP_INDEX_OR]}'
+                            # Suffix this code by the substring suffixing all
+                            # such code.
+                            f'{CODE_PEP484604_UNION_SUFFIX}'
+                        # Format the "indent_curr" prefix into this code,
+                        # deferred above for efficiency.
+                        ).format(indent_curr=indent_curr)
+                    # Else, this snippet is its initial value and thus
+                    # ignorable.
+
+                    # Release this pair of sets back to their respective pools.
+                    release_object_typed(hint_childs_nonpep)
+                    release_object_typed(hint_childs_pep)
+                # Else, this hint is *NOT* a union.
+                #
+                # ..........{ SEQUENCES ~ variadic                 }............
+                # If this hint is either...
+                elif (
+                    # A standard sequence (e.g., "typing.List[int]") *OR*...
+                    hint_curr_sign in HINT_SIGNS_SEQUENCE_ARGS_1 or (
+                        # A tuple *AND*...
+                        hint_curr_sign is HintSignTuple and
+                        # This tuple is subscripted by exactly two child hints
+                        # *AND*...
+                        hint_childs_len == 2 and
+                        # The second child hint is just an unquoted ellipsis...
+                        hint_childs[1] is Ellipsis
+                    )
+                    # Then this hint is of the form "Tuple[{typename}, ...]",
+                    # typing a tuple accepting a variadic number of items all
+                    # satisfying the "{typename}" child hint. Since this case
+                    # is semantically equivalent to that of standard sequences,
+                    # we transparently handle both here for maintainability.
+                    #
+                    # See below for logic handling fixed-length tuples.
+                # Then this hint is either a single-argument sequence *OR* a
+                # similar hint semantically resembling a single-argument
+                # sequence subscripted by one argument and one or more
+                # ignorable arguments. In this case...
+                ):
+                    # Python expression evaluating to the origin type of this
+                    # sequence hint.
+                    hint_curr_expr = add_func_scope_type(
+                        # Origin type of this sequence hint.
+                        cls=get_hint_pep_origin_type_isinstanceable(hint_curr),
+                        func_scope=func_wrapper_scope,
+                        exception_prefix=EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL,
+                    )
+
+                    # print(f'Sequence type hint {hint_curr} origin type scoped: {hint_curr_expr}')
+
+                    # Possibly ignorable insane child hint subscripting this
+                    # sequence hint, defined as either...
+                    hint_child = (
+                        # If this hint is a variadic tuple, the parent "if"
+                        # statement above has already validated the contents of
+                        # this tuple. In this case, efficiently get the lone
+                        # child hint of this parent hint *WITHOUT* validation.
+                        hint_childs[0]
+                        if hint_curr_sign is HintSignTuple else
+                        # Else, this hint is a single-argument sequence, in
+                        # which case the contents of this sequence have yet to
+                        # be validated. In this case, inefficiently get the lone
+                        # child hint of this parent hint *WITH* validation.
+                        get_hint_pep484585_args(
+                            hint=hint_curr,
+                            args_len=1,
+                            exception_prefix=EXCEPTION_PREFIX,
+                        )
+                    )
+
+                    # Unignorable sane child hint sanified from this possibly
+                    # ignorable insane child hint *OR* "None" otherwise (i.e.,
+                    # if this child hint is ignorable).
+                    hint_child = sanify_hint_child_if_unignorable_or_none(
+                        hint=hint_child,
+                        conf=conf,
+                        cls_stack=cls_stack,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    )
+
+                    # If this child hint is unignorable, deeply type-check both
+                    # the type of the current pith *AND* a randomly indexed item
+                    # of this pith. Specifically...
+                    if hint_child is not None:
+                        # Record that a pseudo-random integer is now required.
+                        is_var_random_int_needed = True
+
+                        # Code type-checking this pith against this type.
+                        func_curr_code = CODE_PEP484585_SEQUENCE_ARGS_1_format(
+                            indent_curr=indent_curr,
+                            pith_curr_assign_expr=pith_curr_assign_expr,
+                            pith_curr_var_name=pith_curr_var_name,
+                            hint_curr_expr=hint_curr_expr,
+                            hint_child_placeholder=_enqueue_hint_child(
+                                # Python expression yielding the value of a
+                                # randomly indexed item of the current pith
+                                # (i.e., standard sequence) to be
+                                # type-checked against this child hint.
+                                CODE_PEP484585_SEQUENCE_ARGS_1_PITH_CHILD_EXPR_format(
+                                    pith_curr_var_name=pith_curr_var_name)),
+                        )
+                    # Else, this child hint is ignorable. In this case, fallback
+                    # to trivial code shallowly type-checking this pith as an
+                    # instance of this origin type.
+                    else:
+                        func_curr_code = CODE_PEP484_INSTANCE_format(
+                            pith_curr_expr=pith_curr_expr,
+                            hint_curr_expr=hint_curr_expr,
+                        )
+                # Else, this hint is neither a standard sequence *NOR* variadic
+                # tuple.
+                #
+                # ............{ SEQUENCES ~ tuple : fixed          }............
+                # If this hint is a tuple, this tuple is *NOT* of the variadic
+                # form and *MUST* thus be of the fixed-length form.
+                #
+                # Note that if this hint is a:
+                # * PEP 484-compliant "typing.Tuple"-based hint, this hint is
+                #   guaranteed to contain one or more child hints. Moreover, if
+                #   this hint contains exactly one child hint that is the empty
+                #   tuple, this hint is the empty fixed-length form
+                #   "typing.Tuple[()]".
+                # * PEP 585-compliant "tuple"-based hint, this hint is *NOT*
+                #   guaranteed to contain one or more child hints. If this hint
+                #   contains *NO* child hints, this hint is equivalent to the
+                #   empty fixed-length PEP 484-compliant form
+                #   "typing.Tuple[()]". Yes, PEP 585 even managed to violate
+                #   PEP 484-compliance. UUUURGH!
+                #
+                # While tuples are sequences, the "typing.Tuple" singleton that
+                # types tuples violates the syntactic norms established for
+                # other standard sequences by concurrently supporting two
+                # different syntaxes with equally different semantics:
+                # * "typing.Tuple[{typename}, ...]", typing a tuple whose items
+                #   all satisfy the "{typename}" child hint. Note that the
+                #   "..." substring here is a literal ellipses.
+                # * "typing.Tuple[{typename1}, {typename2}, ..., {typenameN}]",
+                #   typing a tuple whose:
+                #   * First item satisfies the "{typename1}" child hint.
+                #   * Second item satisfies the "{typename2}" child hint.
+                #   * Last item satisfies the "{typenameN}" child hint.
+                #   Note that the "..." substring here is *NOT* a literal
+                #   ellipses.
+                #
+                # This is what happens when unreadable APIs are promoted.
+                elif hint_curr_sign is HintSignTuple:
+                    # Assert this tuple is *NOT* of the syntactic form
+                    # "typing.Tuple[{typename}, ...]" handled by prior logic.
+                    assert (
+                        hint_childs_len <= 1 or
+                        hint_childs[1] is not Ellipsis
+                    ), (f'{EXCEPTION_PREFIX}variadic tuple type hint '
+                        f'{repr(hint_curr)} unhandled.')
+
+                    # Initialize the code type-checking this pith against this
+                    # tuple to the substring prefixing all such code.
+                    func_curr_code = CODE_PEP484585_TUPLE_FIXED_PREFIX
+
+                    # If this hint is the empty fixed-length tuple, generate
+                    # and append code type-checking the current pith to be the
+                    # empty tuple. This edge case constitutes a code smell.
+                    if is_hint_pep484585_tuple_empty(hint_curr):
+                        func_curr_code += (
+                            CODE_PEP484585_TUPLE_FIXED_EMPTY_format(
+                                pith_curr_var_name=pith_curr_var_name))
+                    # Else, that ridiculous edge case does *NOT* apply. In this
+                    # case...
+                    else:
+                        # Append code type-checking the length of this pith.
+                        func_curr_code += (
+                            CODE_PEP484585_TUPLE_FIXED_LEN_format(
+                                pith_curr_var_name=pith_curr_var_name,
+                                hint_childs_len=hint_childs_len,
+                            ))
+
+                        # For each possibly ignorable insane child hint of this
+                        # parent tuple...
+                        for hint_child_index, hint_child in enumerate(
+                            hint_childs):
+                            # Unignorable sane child hint sanified from this
+                            # possibly ignorable insane child hint *OR* "None"
+                            # otherwise (i.e., if this child hint is ignorable).
+                            hint_child = (
+                                sanify_hint_child_if_unignorable_or_none(
+                                    hint=hint_child,
+                                    conf=conf,
+                                    cls_stack=cls_stack,
+                                    exception_prefix=EXCEPTION_PREFIX,
+                                ))
+
+                            # If this child hint is unignorable, deeply
+                            # type-check this child pith.
+                            if hint_child is not None:
+                                func_curr_code += CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD_format(
+                                    hint_child_placeholder=_enqueue_hint_child(
+                                        # Python expression yielding the value
+                                        # of the currently indexed item of this
+                                        # tuple to be type-checked against this
+                                        # child hint.
+                                        CODE_PEP484585_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR_format(
+                                            pith_curr_var_name=pith_curr_var_name,
+                                            pith_child_index=hint_child_index,
+                                        )
+                                    ),
+                                )
+                            # Else, this child hint is ignorable.
+
+                    # Munge this code to...
+                    func_curr_code = (
+                        # Strip the erroneous " and" suffix appended by the
+                        # last child hint from this code.
+                        f'{func_curr_code[:LINE_RSTRIP_INDEX_AND]}'
+                        # Suffix this code by the substring suffixing all such
+                        # code.
+                        f'{CODE_PEP484585_TUPLE_FIXED_SUFFIX}'
+                    # Format...
+                    ).format(
+                        indent_curr=indent_curr,
+                        pith_curr_assign_expr=pith_curr_assign_expr,
+                    )
+                # Else, this hint is *NOT* a tuple.
+                #
+                # ..........{ MAPPINGS                             }............
+                # If this hint is a standard mapping (e.g., "dict[str, int]")...
+                elif hint_curr_sign in HINT_SIGNS_MAPPING:
+                    # Python expression evaluating to the origin type of this
+                    # mapping hint.
+                    hint_curr_expr = add_func_scope_type(
+                        # Origin type of this sequence.
+                        cls=get_hint_pep_origin_type_isinstanceable(hint_curr),
+                        func_scope=func_wrapper_scope,
+                        exception_prefix=EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL,
+                    )
+
+                    # 2-tuple of the possibly ignorable insane child key and
+                    # value hints subscripting this mapping hint.
+                    hint_childs = get_hint_pep484585_args(  # type: ignore[assignment]
+                        hint=hint_curr,
+                        args_len=2,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    )
+
+                    #FIXME: Consider also contextually considering child key
+                    #hints that reduce to "Hashable" to be ignorable. This
+                    #includes complex type hints like "Union[Hashable, str]",
+                    #which reduces to "Hashable". We can't particularly be
+                    #bothered at the moment. This is a microoptimization and
+                    #will probably require a non-trivial amount of work. *sigh*
+                    # Unignorable sane child key and value hints sanified from
+                    # these possibly ignorable insane child key and value hints
+                    # *OR* "None" otherwise (i.e., if ignorable).
+                    hint_child_key = sanify_hint_child_if_unignorable_or_none(
+                        hint=hint_childs[0],
+                        conf=conf,
+                        cls_stack=cls_stack,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    )
+                    hint_child_value = sanify_hint_child_if_unignorable_or_none(
+                        hint=hint_childs[1],  # type: ignore[has-type]
+                        conf=conf,
+                        cls_stack=cls_stack,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    )
+
+                    # If at least one of these child hints are unignorable...
+                    if hint_child_key or hint_child_value:
+                        # If this child key hint is unignorable...
+                        if hint_child_key:
+                            # If this child value hint is also unignorable...
+                            if hint_child_value:
+                                # Increase the indentation level of code
+                                # type-checking this child value pith.
+                                indent_level_child += 1
+
+                                # Increment the integer suffixing the name of a
+                                # unique local variable storing the value of
+                                # this child key pith *BEFORE* defining this
+                                # variable.
+                                pith_curr_var_name_index += 1
+
+                                # Name of this local variable.
+                                pith_curr_key_var_name = PITH_INDEX_TO_VAR_NAME[
+                                    pith_curr_var_name_index]
+
+                                # Expose this hint to the subsequent call to the
+                                # _enqueue_hint_child() closure.
+                                hint_child = hint_child_key
+
+                                # Placeholder string to be subsequently replaced
+                                # by code type-checking this child key pith
+                                # against this hint.
+                                hint_key_placeholder = _enqueue_hint_child(
+                                    pith_curr_key_var_name)
+
+                                # Expose this hint to the subsequent call to the
+                                # _enqueue_hint_child() closure.
+                                hint_child = hint_child_value
+
+                                # Placeholder string to be subsequently replaced
+                                # by code type-checking this child value pith
+                                # against this hint.
+                                hint_value_placeholder = _enqueue_hint_child(
+                                    CODE_PEP484585_MAPPING_KEY_VALUE_PITH_CHILD_EXPR_format(
+                                        pith_curr_var_name=pith_curr_var_name,
+                                        pith_curr_key_var_name=pith_curr_key_var_name,
+                                    ))
+
+                                # Code deeply type-checking these child key and
+                                # value piths against these hints.
+                                func_curr_code_key_value = (
+                                    CODE_PEP484585_MAPPING_KEY_VALUE_format(
+                                        indent_curr=indent_curr,
+                                        pith_curr_key_var_name=(  # pyright: ignore
+                                            pith_curr_key_var_name),
+                                        pith_curr_var_name=pith_curr_var_name,
+                                        hint_key_placeholder=(
+                                            hint_key_placeholder),
+                                        hint_value_placeholder=(
+                                            hint_value_placeholder),
+                                    ))
+                            # Else, this child value hint is ignorable. In this
+                            # case...
+                            else:
+                                # Expose this child key hint to the subsequent
+                                # call to the _enqueue_hint_child() closure.
+                                hint_child = hint_child_key
+
+                                # Code deeply type-checking only this child key
+                                # pith against this hint.
+                                func_curr_code_key_value = (
+                                    CODE_PEP484585_MAPPING_KEY_ONLY_format(
+                                        indent_curr=indent_curr,
+                                        # Placeholder string to be subsequently
+                                        # replaced by code type-checking this
+                                        # child key pith against this hint.
+                                        hint_key_placeholder=_enqueue_hint_child(
+                                            CODE_PEP484585_MAPPING_KEY_ONLY_PITH_CHILD_EXPR_format(
+                                                pith_curr_var_name=(
+                                                    pith_curr_var_name))),
+                                    ))
+                        # Else, this child key hint is ignorable. By process
+                        # of elimination, this child value hint *MUST* be
+                        # unignorable. In this case...
+                        else:
+                            # Expose this child value hint to the subsequent
+                            # call to the _enqueue_hint_child() closure.
+                            hint_child = hint_child_value
+
+                            # Code deeply type-checking only this child value
+                            # pith against this hint.
+                            func_curr_code_key_value = (
+                                CODE_PEP484585_MAPPING_VALUE_ONLY_format(
+                                    indent_curr=indent_curr,
+                                    # Placeholder string to be subsequently
+                                    # replaced by code type-checking this
+                                    # child value pith against this hint.
+                                    hint_value_placeholder=_enqueue_hint_child(
+                                        CODE_PEP484585_MAPPING_VALUE_ONLY_PITH_CHILD_EXPR_format(
+                                            pith_curr_var_name=(
+                                                pith_curr_var_name))),
+                                ))
+
+                        # Code deeply type-checking this pith as well as at
+                        # least one of these child key and value piths.
+                        func_curr_code = CODE_PEP484585_MAPPING_format(
+                            indent_curr=indent_curr,
+                            pith_curr_assign_expr=pith_curr_assign_expr,
+                            pith_curr_var_name=pith_curr_var_name,
+                            hint_curr_expr=hint_curr_expr,
+                            func_curr_code_key_value=func_curr_code_key_value,
+                        )
+                    # Else, these child key *AND* value hints are both
+                    # ignorable. In this case, fallback to trivial code
+                    # shallowly type-checking this pith as an instance of this
+                    # origin type.
+                    else:
+                        func_curr_code = CODE_PEP484_INSTANCE_format(
+                            pith_curr_expr=pith_curr_expr,
+                            hint_curr_expr=hint_curr_expr,
+                        )
+                # Else, this hint is *NOT* a mapping.
+                #
+                # ............{ ANNOTATED                          }............
+                # If this hint is a PEP 593-compliant type metahint, this
+                # metahint is guaranteed by the reduction performed above to be
+                # beartype-specific (i.e., metahint whose second argument is a
+                # beartype validator produced by subscripting a beartype
+                # validator factory). In this case...
+                elif hint_curr_sign is HintSignAnnotated:
+                    # Defer heavyweight imports.
+                    from beartype.vale._core._valecore import BeartypeValidator
+
+                    # Initialize the code type-checking this pith against this
+                    # metahint to the substring prefixing all such code.
+                    func_curr_code = CODE_PEP593_VALIDATOR_PREFIX
+
+                    # Unignorable sane metahint annotating this parent hint
+                    # sanified from this possibly ignorable insane metahint *OR*
+                    # "None" otherwise (i.e., if this metahint is ignorable).
+                    hint_child = sanify_hint_child_if_unignorable_or_none(
+                        hint=get_hint_pep593_metahint(hint_curr),
+                        conf=conf,
+                        cls_stack=cls_stack,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    )
+
+                    # Python expression yielding the value of the current pith,
+                    # defaulting to the name of the local variable assigned to
+                    # by the assignment expression performed below.
+                    hint_curr_expr = pith_curr_var_name
+
+                    # Tuple of the one or more beartype validators annotating
+                    # this metahint.
+                    hints_child = get_hint_pep593_metadata(hint_curr)
+                    # print(f'hints_child: {repr(hints_child)}')
+
+                    # If this metahint is ignorable...
+                    if hint_child is None:
+                        # If this metahint is annotated by only one beartype
+                        # validator, the most efficient expression yielding the
+                        # value of the current pith is simply the full Python
+                        # expression *WITHOUT* assigning that value to a
+                        # reusable local variable in an assignment expression.
+                        # *NO* assignment expression is needed in this case.
+                        #
+                        # Why? Because beartype validators are *NEVER* recursed
+                        # into. Each beartype validator is guaranteed to be the
+                        # leaf of a type-checking subtree, guaranteeing this
+                        # pith to be evaluated only once.
+                        if len(hints_child) == 1:
+                            hint_curr_expr = pith_curr_expr
+                        # Else, this metahint is annotated by two or more
+                        # beartype validators. In this case, the most efficient
+                        # expression yielding the value of the current pith is
+                        # the assignment expression assigning this value to a
+                        # reusable local variable.
+                        else:
+                            hint_curr_expr = pith_curr_assign_expr
+                    # Else, this metahint is unignorable. In this case...
+                    else:
+                        # Code deeply type-checking this metahint.
+                        func_curr_code += CODE_PEP593_VALIDATOR_METAHINT_format(
+                            indent_curr=indent_curr,
+                            # Python expression yielding the value of the
+                            # current pith assigned to a local variable
+                            # efficiently reused by code generated by the
+                            # following iteration.
+                            #
+                            # Note this child hint is guaranteed to be followed
+                            # by at least one more test expression referencing
+                            # this local variable. Why? Because the "typing"
+                            # module forces metahints to be subscripted by one
+                            # child hint and one or more arbitrary objects.
+                            # Ergo, we need *NOT* explicitly validate that here.
+                            hint_child_placeholder=_enqueue_hint_child(
+                                pith_curr_assign_expr),
+                        )
+                    # Else, this metahint is ignorable.
+
+                    # For the 0-based index and each beartype validator
+                    # annotating this metahint...
+                    for hint_child_index, hint_child in enumerate(hints_child):
+                        # print(f'Type-checking PEP 593 type hint {repr(hint_curr)} argument {repr(hint_child)}...')
+                        # If this is *NOT* a beartype validator, raise an
+                        # exception.
+                        #
+                        # Note that the previously called sanify_hint_child()
+                        # function validated only the first such to be a
+                        # beartype validator. All remaining arguments have yet
+                        # to be validated, so we do so now for consistency and
+                        # safety.
+                        if not isinstance(hint_child, BeartypeValidator):
+                            raise BeartypeDecorHintPep593Exception(
+                                f'{EXCEPTION_PREFIX}PEP 593 type hint '
+                                f'{repr(hint_curr)} subscripted by both '
+                                f'@beartype-specific and -agnostic metadata '
+                                f'(i.e., {represent_object(hint_child)} not '
+                                f'beartype validator).'
+                            )
+                        # Else, this argument is beartype-specific.
+                        #
+                        # If this is any beartype validator *EXCEPT* the first,
+                        # set the Python expression yielding the value of the
+                        # current pith to the name of the local variable
+                        # assigned to by the prior assignment expression. By
+                        # deduction, it *MUST* be the case now that either:
+                        # * This metahint was unignorable, in which case this
+                        #   assignment uselessly reduplicates the exact same
+                        #   assignment performed above. While non-ideal, this
+                        #   assignment is sufficiently efficient to make any
+                        #   optimizations here effectively worthless.
+                        # * This metahint was ignorable, in which case this
+                        #   expression was set above to the assignment
+                        #   expression assigning this pith for the first
+                        #   beartype validator. Since this iteration has already
+                        #   processed the first beartype validator, this
+                        #   assignment expression has already been performed.
+                        #   Avoid inefficiently re-performing this assignment
+                        #   expression for each additional beartype validator by
+                        #   efficiently reusing the previously assigned local.
+                        elif hint_child_index:
+                            hint_curr_expr = pith_curr_var_name
+                        # Else, this is the first beartype validator. See above.
+
+                        # Code deeply type-checking this validator.
+                        func_curr_code += CODE_PEP593_VALIDATOR_IS_format(
+                            indent_curr=indent_curr,
+                            # Python expression formatting the current pith into
+                            # the "{obj}" format substring previously embedded
+                            # by this validator into this code string.
+                            hint_child_expr=hint_child._is_valid_code.format(
+                                # Indentation unique to this child hint.
+                                indent=INDENT_LEVEL_TO_CODE[indent_level_child],
+                                obj=hint_curr_expr,
+                            ),
+                        )
+
+                        # Generate locals safely merging the locals required by
+                        # both this validator code *AND* the current code
+                        # type-checking this entire root hint.
+                        update_mapping(
+                            mapping_trg=func_wrapper_scope,
+                            mapping_src=hint_child._is_valid_code_locals,
+                        )
+
+                    # Munge this code to...
+                    func_curr_code = (
+                        # Strip the erroneous " and" suffix appended by the
+                        # last child hint from this code.
+                        f'{func_curr_code[:LINE_RSTRIP_INDEX_AND]}'
+                        # Suffix this code by the substring suffixing all such
+                        # code.
+                        f'{CODE_PEP593_VALIDATOR_SUFFIX_format(indent_curr=indent_curr)}'
+                    )
+                # Else, this hint is *NOT* a metahint.
+                #
+                # ............{ SUBCLASS                           }............
+                # If this hint is either a PEP 484- or 585-compliant subclass
+                # type hint...
+                elif hint_curr_sign is HintSignType:
+                    #FIXME: Optimization: if the superclass is an ignorable
+                    #class (e.g., "object", "Protocol"), this type hint is
+                    #ignorable (e.g., "Type[object]", "type[Protocol]"). We'll
+                    #thus want to:
+                    #* Add that detection logic to one or more
+                    #  is_hint_*_ignorable() testers elsewhere.
+                    #* Call is_hint_ignorable() below.
+                    #* Unit test such type hints to indeed be ignorable.
+
+                    # Superclass this pith is required to be a subclass of.
+                    hint_child = get_hint_pep484585_type_superclass(
+                        hint=hint_curr,
+                        exception_prefix=EXCEPTION_PREFIX,
+                    )
+
+                    # If this superclass is either a class *OR* tuple of
+                    # classes...
+                    if isinstance(hint_child, TestableTypes):
+                        # Python expression evaluating to this superclass.
+                        hint_curr_expr = add_func_scope_type_or_types(
+                            type_or_types=hint_child,  # type: ignore[arg-type]
+                            func_scope=func_wrapper_scope,
+                            exception_prefix=(
+                                EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL),
+                        )
+                    # Else, this superclass is *NOT* actually a class. By
+                    # process of elimination and the validation already
+                    # performed above by the
+                    # get_hint_pep484585_type_superclass() getter, this
+                    # superclass *MUST* be a forward reference to a class.
+                    else:
+                        # Render this forward reference accessible to the body
+                        # of this wrapper function. See above for commentary.
+                        hint_curr_expr, hint_refs_type_basename = (
+                            express_func_scope_type_ref(
+                                forwardref=hint_child,  # type: ignore[arg-type]
+                                forwardrefs_class_basename=(
+                                    hint_refs_type_basename),
+                                func_scope=func_wrapper_scope,
+                                exception_prefix=EXCEPTION_PREFIX,
+                            ))
+
+                    # Code type-checking this pith against this superclass.
+                    func_curr_code = CODE_PEP484585_SUBCLASS_format(
+                        pith_curr_assign_expr=pith_curr_assign_expr,
+                        pith_curr_var_name=pith_curr_var_name,
+                        hint_curr_expr=hint_curr_expr,
+                        indent_curr=indent_curr,
+                    )
+                # Else, this hint is neither a PEP 484- nor 585-compliant
+                # subclass type hint.
+                #
+                # ............{ GENERIC or PROTOCOL                }............
+                # If this hint is either a:
+                # * PEP 484-compliant generic (i.e., user-defined class
+                #   subclassing a combination of one or more of the
+                #   "typing.Generic" superclass and other "typing" non-class
+                #   pseudo-superclasses) *OR*...
+                # * PEP 544-compliant protocol (i.e., class subclassing a
+                #   combination of one or more of the "typing.Protocol"
+                #   superclass and other "typing" non-class
+                #   pseudo-superclasses) *OR*...
+                # * PEP 585-compliant generic (i.e., user-defined class
+                #   subclassing at least one non-class PEP 585-compliant
+                #   pseudo-superclasses) *OR*...
+                #
+                # ...then this hint is a PEP-compliant generic. In this case...
+                elif hint_curr_sign is HintSignGeneric:
+                    #FIXME: *THIS IS NON-IDEAL.* Ideally, we should propagate
+                    #*ALL* child type hints subscripting a generic up to *ALL*
+                    #pseudo-superclasses of that generic (e.g., the "int" child
+                    #hint subscripting a parent hint "MuhGeneric[int]" of type
+                    #"class MuhGeneric(list[T]): pass" up to its "list[T]"
+                    #pseudo-superclass).
+                    #
+                    #For now, we just strip *ALL* child type hints subscripting
+                    #a generic with the following call. This suffices, because
+                    #we just need this to work. So it goes, uneasy code
+                    #bedfellows.
+
+                    # Reduce this hint to the object originating this generic
+                    # (if any) by stripping all child type hints subscripting
+                    # this hint from this hint. Why? Because these child type
+                    # hints convey *NO* meaningful semantics and are thus safely
+                    # ignorable. Consider this simple example, in which the
+                    # subscription "[int]" not only conveys *NO* meaningful
+                    # semantics but actually conveys paradoxically conflicting
+                    # semantics contradicting the original generic declaration:
+                    #     class ListOfListsOfStrs(list[list[str]]): pass
+                    #     ListOfListsOfStrs[int]  # <-- *THIS MEANS NOTHING*
+                    #
+                    # Specifically:
+                    # * If this hint is an unsubscripted generic (e.g.,
+                    #   "typing.IO"), preserve this hint as is. In this case,
+                    #   this hint is a standard isinstanceable class.
+                    # * If this hint is a subscripted generic (e.g.,
+                    #   "typing.IO[str]"), reduce this hint to the object
+                    #   originating this generic (e.g., "typing.IO").
+                    hint_curr = get_hint_pep484585_generic_type(
+                        hint=hint_curr, exception_prefix=EXCEPTION_PREFIX)
+                    # print(f'Visiting generic type {repr(hint_curr)}...')
+
+                    # Initialize the code type-checking this pith against this
+                    # generic to the substring prefixing all such code.
+                    func_curr_code = CODE_PEP484585_GENERIC_PREFIX
+
+                    # For each unignorable unerased transitive pseudo-superclass
+                    # originally declared as a superclass of this generic...
+                    for hint_child in (
+                        iter_hint_pep484585_generic_bases_unerased_tree(
+                            hint=hint_curr,
+                            conf=conf,
+                            exception_prefix=EXCEPTION_PREFIX,
+                    )):
+                        # print(f'Visiting generic type hint {repr(hint_curr)} unerased base {repr(hint_child)}...')
+
+                        # Generate and append code type-checking this pith
+                        # against this superclass.
+                        func_curr_code += CODE_PEP484585_GENERIC_CHILD_format(
+                            hint_child_placeholder=_enqueue_hint_child(
+                                # Python expression efficiently reusing the
+                                # value of this pith previously assigned to a
+                                # local variable by the prior expression.
+                                pith_curr_var_name))
+
+                    # Munge this code to...
+                    func_curr_code = (
+                        # Strip the erroneous " and" suffix appended by the
+                        # last child hint from this code.
+                        f'{func_curr_code[:LINE_RSTRIP_INDEX_AND]}'
+                        # Suffix this code by the substring suffixing all such
+                        # code.
+                        f'{CODE_PEP484585_GENERIC_SUFFIX}'
+                    # Format...
+                    ).format(
+                        # Indentation deferred above for efficiency.
+                        indent_curr=indent_curr,
+                        pith_curr_assign_expr=pith_curr_assign_expr,
+                        # Python expression evaluating to this generic type.
+                        hint_curr_expr=add_func_scope_type(
+                            cls=hint_curr,
+                            func_scope=func_wrapper_scope,
+                            exception_prefix=(
+                                EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL),
+                        ),
+                    )
+                    # print(f'{hint_curr_exception_prefix} PEP generic {repr(hint)} handled.')
+                # Else, this hint is *NOT* a generic.
+                #
+                # ............{ LITERAL                            }............
+                # If this hint is a PEP 586-compliant type hint (i.e., the
+                # "typing.Literal" singleton subscripted by one or more literal
+                # objects), this hint is largely useless and thus intentionally
+                # detected last. Why? Because "typing.Literal" is subscriptable
+                # by objects that are instances of only *SIX* possible types,
+                # which is sufficiently limiting as to render this singleton
+                # patently absurd and a farce that we weep to even implement.
+                # In this case...
+                elif hint_curr_sign is HintSignLiteral:
+                    # Tuple of zero or more literal objects subscripting this
+                    # hint, intentionally replacing the current such tuple due
+                    # to the non-standard implementation of the third-party
+                    # "typing_extensions.Literal" type hint factory.
+                    hint_childs = get_hint_pep586_literals(
+                        hint=hint_curr, exception_prefix=EXCEPTION_PREFIX)
+
+                    # Initialize the code type-checking this pith against this
+                    # hint to the substring prefixing all such code.
+                    func_curr_code = CODE_PEP586_PREFIX_format(
+                        pith_curr_assign_expr=pith_curr_assign_expr,
+
+                        #FIXME: If "typing.Literal" is ever extended to support
+                        #substantially more types (and thus actually becomes
+                        #useful), optimize the construction of the "types" set
+                        #below to instead leverage a similar
+                        #"acquire_object_typed(set)" caching solution as that
+                        #currently employed for unions. For now, we only shrug.
+
+                        # Python expression evaluating to a tuple of the unique
+                        # types of all literal objects subscripting this hint.
+                        hint_child_types_expr=add_func_scope_types(
+                            # Set comprehension of all unique literal objects
+                            # subscripting this hint, implicitly discarding all
+                            # duplicate such objects.
+                            types={
+                                type(hint_child)
+                                for hint_child in hint_childs
+                            },
+                            func_scope=func_wrapper_scope,
+                            exception_prefix=(
+                                EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL),
+                        ),
+                    )
+
+                    # For each literal object subscripting this hint...
+                    for hint_child in hint_childs:
+                        # Generate and append efficient code type-checking
+                        # this data validator by embedding this code as is.
+                        func_curr_code += CODE_PEP586_LITERAL_format(
+                            pith_curr_var_name=pith_curr_var_name,
+                            # Python expression evaluating to this object.
+                            hint_child_expr=add_func_scope_attr(
+                                attr=hint_child,
+                                func_scope=func_wrapper_scope,
+                                exception_prefix=(
+                                    EXCEPTION_PREFIX_FUNC_WRAPPER_LOCAL),
+                            ),
+                        )
+
+                    # Munge this code to...
+                    func_curr_code = (
+                        # Strip the erroneous " or" suffix appended by the last
+                        # child hint from this code.
+                        f'{func_curr_code[:LINE_RSTRIP_INDEX_OR]}'
+                        # Suffix this code by the appropriate substring.
+                        f'{CODE_PEP586_SUFFIX}'
+                    ).format(indent_curr=indent_curr)
+                # Else, this hint is *NOT* a PEP 586-compliant type hint.
+
+                # ............{ UNSUPPORTED                        }............
+                # Else, this hint is neither shallowly nor deeply supported and
+                # is thus unsupported. Since an exception should have already
+                # been raised above in this case, this conditional branch
+                # *NEVER* be triggered. Nonetheless, raise an exception.
+                else:
+                    raise BeartypeDecorHintPepUnsupportedException(
+                        f'{EXCEPTION_PREFIX_HINT}'
+                        f'{repr(hint_curr)} unsupported but '
+                        f'erroneously detected as supported with '
+                        f'beartype sign {hint_curr_sign}.'
+                    )
+
+        # ................{ NON-PEP                            }................
+        # Else, this hint is *NOT* PEP-compliant.
+        #
+        # ................{ NON-PEP ~ type                     }................
+        # If this hint is a non-"typing" class...
+        #
+        # Note that:
+        # * This test is intentionally performed *AFTER* that testing whether
+        #   this hint is PEP-compliant, thus guaranteeing this hint to be a
+        #   PEP-noncompliant non-"typing" class rather than a PEP-compliant
+        #   type hint originating from such a class. Since many hints are both
+        #   PEP-compliant *AND* originate from such a class (e.g., the "List"
+        #   in "List[int]", PEP-compliant but originating from the
+        #   PEP-noncompliant builtin class "list"), testing these hints first
+        #   for PEP-compliance ensures we generate non-trivial code deeply
+        #   type-checking these hints instead of trivial code only shallowly
+        #   type-checking the non-"typing" classes from which they originate.
+        # * This class is guaranteed to be a subscripted argument of a
+        #   PEP-compliant type hint (e.g., the "int" in "Union[Dict[str, str],
+        #   int]") rather than the root type hint. Why? Because if this class
+        #   were the root type hint, it would have already been passed into a
+        #   faster submodule generating PEP-noncompliant code instead.
+        elif isinstance(hint_curr, type):
+            # Code type-checking the current pith against this type.
+            func_curr_code = CODE_PEP484_INSTANCE_format(
+                pith_curr_expr=pith_curr_expr,
+                # Python expression evaluating to this type.
+                hint_curr_expr=add_func_scope_type(
+                    cls=hint_curr,
+                    func_scope=func_wrapper_scope,
+                    exception_prefix=EXCEPTION_PREFIX_HINT,
+                ),
+            )
+        # ................{ NON-PEP ~ bad                      }................
+        # Else, this hint is neither PEP-compliant *NOR* a class. In this case,
+        # raise an exception. Note that:
+        # * This should *NEVER* happen, as the "typing" module goes to great
+        #   lengths to validate the integrity of PEP-compliant types at
+        #   declaration time.
+        # * The higher-level die_unless_hint_nonpep() validator is
+        #   intentionally *NOT* called here, as doing so would permit both:
+        #   * PEP-noncompliant forward references, which could admittedly be
+        #     disabled by passing "is_str_valid=False" to that call.
+        #   * PEP-noncompliant tuple unions, which currently *CANNOT* be
+        #     disabled by passing such an option to that call.
+        else:
+            raise BeartypeDecorHintPepException(
+                f'{EXCEPTION_PREFIX_HINT}{repr(hint_curr)} '
+                f'not PEP-compliant.'
+            )
+
+        # ................{ CLEANUP                            }................
+        # Inject this code into the body of this wrapper.
+        func_wrapper_code = replace_str_substrs(
+            text=func_wrapper_code,
+            old=hint_curr_placeholder,
+            new=func_curr_code,
+        )
+
+        # Nullify the metadata describing the previously visited hint in this
+        # list for safety.
+        hints_meta[hints_meta_index_curr] = None
+
+        # Increment the 0-based index of metadata describing the next visited
+        # hint in the "hints_meta" list *BEFORE* visiting that hint but *AFTER*
+        # performing all other logic for the currently visited hint.
+        hints_meta_index_curr += 1
+
+    # ..................{ CLEANUP                            }..................
+    # Release the fixed list of all such metadata.
+    release_fixed_list(hints_meta)
+
+    # If the Python code snippet to be returned remains unchanged from its
+    # initial value, the breadth-first search above failed to generate code. In
+    # this case, raise an exception.
+    #
+    # Note that this test is inexpensive, as the third character of the
+    # "func_root_code" code snippet is guaranteed to differ from that of
+    # "func_wrapper_code" code snippet if this function behaved as expected,
+    # which it should have... but may not have, which is why we're testing.
+    if func_wrapper_code == func_root_code:
+        raise BeartypeDecorHintPepException(
+            f'{EXCEPTION_PREFIX_HINT}{repr(hint_root)} unchecked.')
+    # Else, the breadth-first search above successfully generated code.
+
+    # ..................{ CODE ~ scope                       }..................
+    # If type-checking for the root pith requires the type stack, pass a hidden
+    # parameter to this wrapper function exposing this stack.
+    if cls_stack:
+        func_wrapper_scope[ARG_NAME_CLS_STACK] = cls_stack
+    # Else, type-checking for the root pith requires *NO* type stack.
+
+    # If type-checking for the root pith requires a pseudo-random integer, pass
+    # a hidden parameter to this wrapper function exposing the
+    # random.getrandbits() function required to generate this integer.
+    if is_var_random_int_needed:
+        func_wrapper_scope[ARG_NAME_GETRANDBITS] = getrandbits
+    # Else, type-checking for the root pith requires *NO* pseudo-random integer.
+
+    # ..................{ CODE ~ suffix                      }..................
+    # Tuple of the unqualified classnames referred to by all relative forward
+    # references visitable from this hint converted from that set to reduce
+    # space consumption after memoization by @callable_cached, defined as...
+    hint_refs_type_basename_tuple = (
+        # If *NO* relative forward references are visitable from this root
+        # hint, the empty tuple;
+        ()
+        if hint_refs_type_basename is None else
+        # Else, that set converted into a tuple.
+        tuple(hint_refs_type_basename)
+    )
+
+    # Return all metadata required by higher-level callers.
+    return (
+        func_wrapper_code,
+        func_wrapper_scope,
+        hint_refs_type_basename_tuple,
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/codescope.py
@@ -0,0 +1,648 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype decorator PEP-compliant code wrapper scope utilities** (i.e.,
+functions handling the possibly nested lexical scopes enclosing wrapper
+functions generated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Hah-hah! Finally figured out how to do recursive type hints... mostly.
+#It's a two-parter consisting of:
+#* *PART I.* In the first part:
+#  * Refactor our code generation algorithm to additionally maintain a stack of
+#    all parent type hints of the currently visited type hint. Note that we need
+#    to do this anyway to support the __beartype_hint__() protocol. See "FIXME:"
+#    comments in the "beartype.plug._plughintable" submodule pertaining to that
+#    protocol for further details on properly building out this stack.
+#  * When that algorithm visits a forward reference:
+#    * That algorithm calls the express_func_scope_type_ref() function
+#      generating type-checking code for that reference. Refactor that call to
+#      additionally pass that stack of parent hints to that function.
+#    * Refactor the express_func_scope_type_ref() function to:
+#      * If the passed forward reference is relative, additionally return that
+#        stack in the returned 3-tuple
+#        "(forwardref_expr, forwardrefs_class_basename, forwardref_parent_hints)",
+#        where "forwardref_parent_hints" is that stack.
+#* *PART II.* In the second part:
+#  * Refactor the beartype._decor.wrap.wrapmain._unmemoize_func_wrapper_code()
+#    function to additionally:
+#    * If the passed forward reference is relative *AND* the unqualified
+#      basename of an existing attribute in a local or global scope of the
+#      currently decorated callable *AND* the value of that attribute is a
+#      parent type hint on the stack of parent type hints returned by the
+#      previously called express_func_scope_type_ref() function, then
+#      *THIS REFERENCE INDICATES A RECURSIVE TYPE HINT.* In this case:
+#      * Replace this forward reference with a new recursive type-checking
+#        "beartype._check.forward.reference.fwdrefabc.BeartypeForwardRef_{forwardref}"
+#        subclass whose is_instance() tester method recursively calls itself
+#        indefinitely. If doing so generates a "RecursionError", @beartype
+#        considers that the user's problem. *wink*
+#
+#Done and done. Phew!
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintNonpepException
+from beartype.typing import (
+    Dict,
+    List,
+    Optional,
+    Tuple,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._check.forward.reference.fwdrefmake import (
+    make_forwardref_indexable_subtype)
+from beartype._check.forward.reference.fwdreftest import is_forwardref
+from beartype._check.code.snip.codesnipstr import (
+    CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_PREFIX,
+    CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_SUFFIX,
+)
+from beartype._data.cls.datacls import TYPES_SET_OR_TUPLE
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    Pep484585ForwardRef,
+    SetOrTupleTypes,
+    TypeOrTupleTypes,
+    TupleTypes,
+)
+from beartype._util.cls.pep.utilpep3119 import (
+    die_unless_type_isinstanceable,
+    die_unless_object_isinstanceable,
+)
+from beartype._util.cls.utilclstest import is_type_builtin
+from beartype._util.func.utilfuncscope import add_func_scope_attr
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585ref import (
+    get_hint_pep484585_ref_names)
+from beartype._util.utilobject import get_object_type_basename
+from collections.abc import Set
+
+# ....................{ ADDERS ~ type                      }....................
+#FIXME: Unit test us up, please.
+def add_func_scope_ref(
+    # Mandatory parameters.
+    func_scope: LexicalScope,
+    ref_module_name: Optional[str],
+    ref_name: str,
+
+    # Optional parameters.
+    exception_prefix: str = 'Globally or locally scoped forward reference ',
+) -> str:
+    '''
+    Add a new **scoped forward reference proxy** (i.e., new key-value pair of
+    the passed dictionary mapping from the name to value of each globally or
+    locally scoped attribute externally accessed elsewhere, whose key is a
+    machine-readable name internally generated by this function to uniquely
+    refer to a new forward reference proxy proxying the class with the passed
+    attribute name residing in the module with the passed module name) to the
+    passed scope *and* return that name.
+
+    Parameters
+    ----------
+    func_scope : LexicalScope
+        Local or global scope to add this class or tuple of classes to.
+    ref_module_name : Optional[str]
+        Possibly undefined fully-qualified module name referred to by this
+        forward reference.
+    ref_name : str
+        Possibly unqualified classname referred to by this forward reference.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to a sensible string.
+
+    Returns
+    -------
+    str
+        Name of this forward reference proxy in this scope generated by this
+        function.
+
+    Raises
+    ------
+    _BeartypeUtilCallableException
+        If an attribute with the same name as that internally generated by this
+        adder but having a different value already exists in this scope. This
+        adder uniquifies names by object identifier and should thus *never*
+        generate name collisions. This exception is thus intentionally raised
+        as a private rather than public exception.
+    '''
+
+    # Forward reference proxy referring to this class.
+    hint_ref = make_forwardref_indexable_subtype(ref_module_name, ref_name)
+
+    # Name of a new parameter passing this forward reference proxy.
+    hint_ref_arg_name = add_func_scope_attr(
+        func_scope=func_scope, attr=hint_ref)
+
+    # Return this name.
+    return hint_ref_arg_name
+
+# ....................{ ADDERS ~ type                      }....................
+#FIXME: Unit test us up, please.
+def add_func_scope_type_or_types(
+    # Mandatory parameters.
+    func_scope: LexicalScope,
+    type_or_types: TypeOrTupleTypes,
+
+    # Optional parameters.
+    exception_prefix: str = (
+        'Globally or locally scoped class or tuple of classes '),
+) -> str:
+    '''
+    Add a new **scoped class or tuple of classes** (i.e., new key-value pair of
+    the passed dictionary mapping from the name to value of each globally or
+    locally scoped attribute externally accessed elsewhere, whose key is a
+    machine-readable name internally generated by this function to uniquely
+    refer to the passed class or tuple of classes and whose value is that class
+    or tuple) to the passed scope *and* return that name.
+
+    This function additionally caches this tuple with the beartypistry
+    singleton to reduce space consumption for tuples duplicated across the
+    active Python interpreter.
+
+    Parameters
+    ----------
+    func_scope : LexicalScope
+        Local or global scope to add this class or tuple of classes to.
+    type_or_types : TypeOrTupleTypes
+        Arbitrary class or tuple of classes to be added to this scope.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to a sensible string.
+
+    Returns
+    -------
+    str
+        Name of this class or tuple in this scope generated by this function.
+
+    Raises
+    ------
+    BeartypeDecorHintNonpepException
+        If this hint is either:
+
+        * Neither a class nor tuple.
+        * A tuple that is empty.
+    BeartypeDecorHintPep3119Exception
+        If hint is:
+
+        * A class that is *not* isinstanceable (i.e., passable as the second
+          argument to the :func:`isinstance` builtin).
+        * A tuple of one or more items that are *not* isinstanceable classes.
+    _BeartypeUtilCallableException
+        If an attribute with the same name as that internally generated by this
+        adder but having a different value already exists in this scope. This
+        adder uniquifies names by object identifier and should thus *never*
+        generate name collisions. This exception is thus intentionally raised
+        as a private rather than public exception.
+    '''
+
+    # Return either...
+    return (
+        # If this hint is a class, the name of a new parameter passing this
+        # class;
+        add_func_scope_type(
+            func_scope=func_scope,
+            cls=type_or_types,
+            exception_prefix=exception_prefix,
+        )
+        if isinstance(type_or_types, type) else
+        # Else, this hint is *NOT* a class. In this case:
+        # * If this hint is a tuple of classes, the name of a new parameter
+        #   passing this tuple.
+        # * Else, raise an exception.
+        add_func_scope_types(
+            func_scope=func_scope,
+            types=type_or_types,
+            exception_prefix=exception_prefix,
+        )
+    )
+
+
+def add_func_scope_type(
+    # Mandatory parameters.
+    func_scope: LexicalScope,
+    cls: type,
+
+    # Optional parameters.
+    exception_prefix: str = 'Globally or locally scoped class ',
+) -> str:
+    '''
+    Add a new **scoped class** (i.e., new key-value pair of the passed
+    dictionary mapping from the name to value of each globally or locally scoped
+    attribute externally accessed elsewhere, whose key is a machine-readable
+    name internally generated by this function to uniquely refer to the passed
+    class and whose value is that class) to the passed scope *and* return that
+    name.
+
+    Parameters
+    ----------
+    func_scope : LexicalScope
+        Local or global scope to add this class to.
+    cls : type
+        Arbitrary class to be added to this scope.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to a sensible string.
+
+    Returns
+    -------
+    str
+        Name of this class in this scope generated by this function.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this class is *not* isinstanceable (i.e., passable as the second
+        argument to the :func:`isinstance` builtin).
+    _BeartypeUtilCallableException
+        If an attribute with the same name as that internally generated by this
+        adder but having a different value already exists in this scope. This
+        adder uniquifies names by object identifier and should thus *never*
+        generate name collisions. This exception is thus intentionally raised
+        as a private rather than public exception.
+    '''
+
+    # If this object is *NOT* an isinstanceable class, raise an exception.
+    die_unless_type_isinstanceable(cls=cls, exception_prefix=exception_prefix)
+    # Else, this object is an isinstanceable class.
+
+    # Return either...
+    return (
+        # If this type is a builtin (i.e., globally accessible C-based type
+        # requiring *no* explicit importation), the unqualified basename of
+        # this type as is, as this type requires no parametrization;
+        get_object_type_basename(cls)
+        if is_type_builtin(cls) else
+        # Else, the name of a new parameter passing this class.
+        add_func_scope_attr(
+            func_scope=func_scope, attr=cls, exception_prefix=exception_prefix)
+    )
+
+
+def add_func_scope_types(
+    # Mandatory parameters.
+    func_scope: LexicalScope,
+    types: SetOrTupleTypes,
+
+    # Optional parameters.
+    is_unique: Optional[bool] = None,
+    exception_prefix: str = (
+        'Globally or locally scoped set or tuple of classes '),
+) -> str:
+    '''
+    Add a new **scoped tuple of classes** (i.e., new key-value pair of the
+    passed dictionary mapping from the name to value of each globally or locally
+    scoped attribute externally accessed elsewhere, whose key is a
+    machine-readable name internally generated by this function to uniquely
+    refer to the passed set or tuple of classes and whose value is that tuple)
+    to the passed scope *and* return that machine-readable name.
+
+    This function additionally caches this tuple with the
+    :data:`._tuple_union_to_tuple_union` dictionary to reduce space consumption
+    for tuples duplicated across the active Python interpreter.
+
+    Parameters
+    ----------
+    func_scope : LexicalScope
+        Local or global scope to add this object to.
+    types : SetOrTupleOfTypes
+        Set or tuple of arbitrary types to be added to this scope.
+    is_unique : Optional[bool]
+        Tri-state boolean governing whether this function attempts to
+        deduplicate types in the ``types`` iterable. Specifically, either:
+
+        * :data:`True`, in which case the caller guarantees ``types`` to contain
+          *no* duplicate types.
+        * :data:`False`, in which case this function assumes ``types`` to
+          contain duplicate types by internally (in order):
+
+          #. Coercing this tuple into a set, thus implicitly ignoring both
+             duplicates and ordering of types in this tuple.
+          #. Coercing that set back into another tuple.
+          #. If these two tuples differ, the passed tuple contains one or more
+             duplicates; in this case, the duplicate-free tuple is cached and
+             passed.
+          #. Else, the passed tuple contains no duplicates; in this case, the
+             passed tuple is cached and passed.
+
+        * :data:`None`, in which case this function reduces this parameter to
+          either:
+
+          * :data:`True` if ``types`` is a :class:`tuple`.
+          * :data:`False` if ``types`` is a :class:`set`.
+
+        This tri-state boolean does *not* simply enable an edge-case
+        optimization, though it certainly does that; this boolean enables
+        callers to guarantee that this function caches and passes the passed
+        tuple rather than a new tuple internally created by this function.
+
+        Defaults to :data:`None`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to a sensible string.
+
+    Returns
+    -------
+    str
+        Name of this tuple in this scope generated by this function.
+
+    Raises
+    ------
+    BeartypeDecorHintNonpepException
+        If this hint is either:
+
+        * Neither a set nor tuple.
+        * A set or tuple that is empty.
+    BeartypeDecorHintPep3119Exception
+        If one or more items of this hint are *not* isinstanceable classes
+        (i.e., classes passable as the second argument to the
+        :func:`isinstance` builtin).
+    _BeartypeUtilCallableException
+        If an attribute with the same name as that internally generated by this
+        adder but having a different value already exists in this scope. This
+        adder uniquifies names by object identifier and should thus *never*
+        generate name collisions. This exception is thus intentionally raised
+        as a private rather than public exception.
+    '''
+    assert isinstance(is_unique, NoneTypeOr[bool]), (
+        f'{repr(is_unique)} neither bool nor "None".')
+
+    # ....................{ VALIDATE                       }....................
+    # If this container is neither a set nor tuple, raise an exception.
+    if not isinstance(types, TYPES_SET_OR_TUPLE):
+        raise BeartypeDecorHintNonpepException(
+            f'{exception_prefix}{repr(types)} neither set nor tuple.')
+    # Else, this container is either a set or tuple.
+    #
+    # If this container is empty, raise an exception.
+    elif not types:
+        raise BeartypeDecorHintNonpepException(f'{exception_prefix}empty.')
+    # Else, this container is non-empty.
+    #
+    # If this container only contains one type, register only this type.
+    elif len(types) == 1:
+        return add_func_scope_type(
+            # The first and only item of this container, accessed as either:
+            # * If this container is a tuple, that item with fast indexing.
+            # * If this container is a set, that item with slow iteration.
+            cls=types[0] if isinstance(types, tuple) else next(iter(types)),
+            func_scope=func_scope,
+            exception_prefix=exception_prefix,
+        )
+    # Else, this container either contains two or more types.
+
+    # If the caller did *NOT* explicitly pass the "is_unique" parameter, default
+    # this parameter to true *ONLY* if this container is a set.
+    if is_unique is None:
+        is_unique = isinstance(types, set)
+    # Else, the caller explicitly passed the "is_unique" parameter.
+    #
+    # In either case, "is_unique" is now a proper bool.
+    assert isinstance(is_unique, bool)
+
+    # ....................{ FORWARDREF                     }....................
+    # True only if this container contains one or more beartype-specific forward
+    # reference proxies. Although these proxies are technically isinstanceable
+    # classes, attempting to pass these proxies as the second parameter to the
+    # isinstance() builtin also raises exceptions when the underlying
+    # user-defined classes proxied by these proxies have yet to be declared.
+    # Since these proxies are thus *MUCH* more fragile than standard classes, we
+    # reduce the likelihood of exceptions by deprioritizing these proxies in
+    # this container (i.e., moving these proxies to the end of this container).
+    is_types_ref = False
+
+    # For each type in this container...
+    for cls in types:
+        # If this type is a beartype-specific forward reference proxy...
+        if is_forwardref(cls):
+            # print(f'Found forward reference proxy {repr(cls)}...')
+            # Note that this container contains at least one such proxy.
+            is_types_ref = True
+
+            # Halt iteration.
+            break
+
+    # If this container contains at least one such proxy...
+    if is_types_ref:
+        # List of all such proxies in this container.
+        #
+        # Note that we intentionally avoid instantiating this pair of lists
+        # above in the common case that this container contains no such proxies.
+        types_ref: List[type] = []
+
+        # List of all other types in this container (i.e., normal types that are
+        # *NOT* beartype-specific forward reference proxies).
+        types_nonref: List[type] = []
+
+        # For each type in this container...
+        for cls in types:
+            # If this type is such a proxy, append this proxy to the list of all
+            # such proxies.
+            if is_forwardref(cls):
+                types_ref.append(cls)
+            # Else, this type is *NOT* such a proxy. In this case...
+            else:
+                # print(f'Appending non-forward reference proxy {repr(cls)}...')
+
+                # If this non-proxy is *NOT* an isinstanceable class, raise an
+                # exception.
+                #
+                # Note that the companion "types_ref" tuple is intentionally
+                # *NOT* validated above. Why? Because doing so would prematurely
+                # invoke the __instancecheck__() dunder method on the metaclass
+                # of the proxies in that tuple, which would then erroneously
+                # attempt to resolve the possibly undefined types to which those
+                # proxies refer. Instead, simply accept that tuple of proxies as
+                # is for now and defer validating those proxies for later.
+                die_unless_type_isinstanceable(
+                    cls=cls, exception_prefix=exception_prefix)
+
+                # Append this proxy to the list of all non-proxy types
+                types_nonref.append(cls)
+
+        # If the caller guaranteed these tuples to be duplicate-free,
+        # efficiently concatenate these lists into a tuple such that all
+        # non-proxy types appear *BEFORE* all proxy types.
+        if is_unique:
+            types = tuple(types_nonref + types_ref)
+        # Else, the caller failed to guarantee these tuples to be
+        # duplicate-free. In this case, coerce these tuples into (in order):
+        # * Sets, thus ignoring duplicates and ordering.
+        # * Back into duplicate-free tuples.
+        else:
+            types = tuple(set(types_nonref)) + tuple(set(types_ref))
+        # Else, the caller guaranteed these tuples to be duplicate-free.
+    # Else, this container contains *NO* such proxies. In this case, preserve
+    # the ordering of items in this container as is.
+    else:
+        # If this container is a set, coerce this frozenset into a tuple.
+        if isinstance(types, Set):
+            types = tuple(types)
+        # Else, this container is *NOT* a set. By elimination, this container
+        # should now be a tuple.
+        #
+        # In either case, this container should now be a tuple.
+
+        # If this container is *NOT* a tuple or is a tuple containing one or
+        # more items that are *NOT* isinstanceable classes, raise an exception.
+        die_unless_object_isinstanceable(
+            obj=types, exception_prefix=exception_prefix)
+        # Else, this container is a tuple of only isinstanceable classes.
+
+        # If the caller failed to guarantee this tuple to be duplicate-free,
+        # coerce this tuple into (in order):
+        # * A set, thus ignoring duplicates and ordering.
+        # * Back into a duplicate-free tuple.
+        if not is_unique:
+            # print(f'Uniquifying type tuple {repr(types)} to...')
+            types = tuple(set(types))
+            # print(f'...uniquified type tuple {repr(types)}.')
+        # Else, the caller guaranteed this tuple to be duplicate-free.
+
+    # In either case, this container is now guaranteed to be a tuple containing
+    # only duplicate-free classes.
+    assert isinstance(types, tuple), (
+        f'{exception_prefix}{repr(types)} not tuple.')
+
+    # ....................{ CACHE                          }....................
+    # If this tuple has *NOT* already been cached, do so.
+    if types not in _tuple_union_to_tuple_union:
+        _tuple_union_to_tuple_union[types] = types
+    # Else, this tuple has already been cached. In this case, deduplicate this
+    # tuple by reusing the previously cached tuple.
+    else:
+        types = _tuple_union_to_tuple_union[types]
+
+    # ....................{ RETURN                         }....................
+    # Return the name of a new parameter passing this tuple.
+    return add_func_scope_attr(
+        attr=types, func_scope=func_scope, exception_prefix=exception_prefix)
+
+# ....................{ EXPRESSERS ~ type                  }....................
+def express_func_scope_type_ref(
+    # Mandatory parameters.
+    func_scope: LexicalScope,
+    forwardref: Pep484585ForwardRef,
+    forwardrefs_class_basename: Optional[set],
+
+    # Optional parameters.
+    exception_prefix: str = 'Globally or locally scoped forward reference ',
+) -> Tuple[str, Optional[set]]:
+    '''
+    Express the passed :pep:`484`- or :pep:`585`-compliant **forward reference**
+    (i.e., fully-qualified or unqualified name of an arbitrary class that
+    typically has yet to be declared) as a Python expression evaluating to this
+    forward reference when accessed via the beartypistry singleton added as a
+    new key-value pair of the passed dictionary, whose key is the string
+    :attr:`beartype._check.checkmagic.ARG_NAME_TYPISTRY` and whose value is the
+    beartypistry singleton.
+
+    Parameters
+    ----------
+    func_scope : LexicalScope
+        Local or global scope to add this forward reference to.
+    forwardref : Pep484585ForwardRef
+        Forward reference to be expressed relative to this scope.
+    forwardrefs_class_basename : Optional[set]
+        Set of all existing **relative forward references** (i.e., unqualified
+        basenames of all types referred to by all relative forward references
+        relative to this scope) if any *or* :data:`None` otherwise (i.e., if no
+        relative forward references have been expressed relative to this scope).
+    exception_prefix : str, optional
+        Human-readable substring describing this forward reference in exception
+        exception message. Defaults to a sensible string.
+
+    Returns
+    -------
+    Tuple[str, Optional[set]]
+        2-tuple ``(forwardref_expr, forwardrefs_class_basename)``, where:
+
+        * ``forwardref_expr`` is the Python expression evaluating to this
+          forward reference when accessed via the beartypistry singleton added
+          to this scope.
+        * ``forwardrefs_class_basename`` is either:
+
+          * If this forward reference is a fully-qualified classname, the
+            passed ``forwardrefs_class_basename`` set as is.
+          * If this forward reference is an unqualified classname, either:
+
+            * If the passed ``forwardrefs_class_basename`` set is *not*
+              :data:`None`, this set with this classname added to it.
+            * Else, a new set containing only this classname.
+
+    Raises
+    ------
+    BeartypeDecorHintForwardRefException
+        If this forward reference is *not* actually a forward reference.
+    '''
+
+    # Possibly undefined fully-qualified module name and possibly unqualified
+    # classname referred to by this forward reference.
+    ref_module_name, ref_name = get_hint_pep484585_ref_names(
+        hint=forwardref, exception_prefix=exception_prefix)
+
+    # If either...
+    if (
+        # This reference was instantiated with a module name...
+        ref_module_name or
+        # This classname contains one or more "." characters and is thus already
+        # (...hopefully) fully-qualified...
+        '.' in ref_name
+    # Then this classname is either absolute *OR* relative to some module. In
+    # either case, the class referred to by this reference can now be
+    # dynamically imported at a later time. In this case...
+    ):
+        # Name of the hidden parameter providing this forward reference
+        # proxy to be passed to this wrapper function.
+        ref_expr = add_func_scope_ref(
+            func_scope=func_scope,
+            ref_module_name=ref_module_name,
+            ref_name=ref_name,
+            exception_prefix=exception_prefix,
+        )
+    # Else, this classname is unqualified. In this case...
+    else:
+        assert isinstance(forwardrefs_class_basename, NoneTypeOr[set]), (
+            f'{repr(forwardrefs_class_basename)} neither set nor "None".')
+
+        # If this set of unqualified classnames referred to by all relative
+        # forward references has yet to be instantiated, do so.
+        if forwardrefs_class_basename is None:
+            forwardrefs_class_basename = set()
+        # In any case, this set now exists.
+
+        # Add this unqualified classname to this set.
+        forwardrefs_class_basename.add(ref_name)
+
+        # Placeholder substring to be replaced by the caller with a Python
+        # expression evaluating to this unqualified classname canonicalized
+        # relative to the module declaring the currently decorated callable
+        # when accessed via the private "__beartypistry" parameter.
+        ref_expr = (
+            f'{CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_PREFIX}'
+            f'{ref_name}'
+            f'{CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_SUFFIX}'
+        )
+
+    # Return a 2-tuple of this expression and set of unqualified classnames.
+    return ref_expr, forwardrefs_class_basename
+
+# ....................{ PRIVATE ~ globals                  }....................
+_tuple_union_to_tuple_union: Dict[TupleTypes, TupleTypes] = {}
+'''
+**Tuple union cache** (i.e., dictionary mapping from each tuple union passed to
+the :func:`.add_func_scope_types` adder to that same union, preventing tuple
+unions from being duplicated across calls to that adder).
+
+This cache serves a dual purpose. Notably, this cache both enables:
+
+* External callers to iterate over all previously instantiated forward reference
+  proxies. This is particularly useful when responding to module reloading,
+  which requires that *all* previously cached types be uncached.
+* A minor reduction in space complexity by de-duplicating duplicating tuple
+  unions. Since the existing ``callable_cached`` decorator could trivially do so
+  as well, however, this is only a negligible side effect.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/snip/codesnipcls.py
@@ -0,0 +1,97 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **type-checking expression snippet classes** (i.e., low-level classes
+dynamically and efficiently generating substrings intended to be interpolated
+into boolean expressions type-checking arbitrary objects against various type
+hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkmagic import VAR_NAME_PITH_PREFIX
+
+# ....................{ SUBCLASSES                         }....................
+class PithIndexToVarName(dict):
+    '''
+    **Local pith variable name cache** (i.e., dictionary mapping from the
+    1-based index uniquely identifying each **pith** (i.e., current parameter or
+    return value *or* item contained in the current parameter or return value
+    type-checked by the current call in the body of a runtime type-checker
+    dynamically generated by :mod:`beartype`) to the corresponding name of a
+    prospective local variable assigned that value in that body).
+
+    See Also
+    --------
+    :data:`.PITH_INDEX_TO_VAR_NAME`
+        Singleton instance of this dictionary subclass.
+    '''
+
+    # ....................{ DUNDERS                        }....................
+    def __missing__(self, pith_index: int) -> str:
+        '''
+        Dunder method explicitly called by the superclass
+        :meth:`dict.__getitem__` method implicitly called on the first ``[``-
+        and ``]``-delimited attempt to access a local pith variable name
+        uniquely identified by the passed 1-based index.
+
+        Parameters
+        ----------
+        pith_index : int
+            1-based index suffixing the local pith variable name to be created,
+            cached, and returned.
+
+        Returns
+        -------
+        str
+            Prospective name of this local pith variable.
+
+        Raises
+        ------
+        AssertionError
+            If either:
+
+            * ``pith_level`` is *not* an integer.
+            * ``pith_level`` is a **negative integer** (i.e., less than 0).
+        '''
+        assert isinstance(pith_index, int), f'{repr(pith_index)} not integer.'
+        assert pith_index >= 0, f'{pith_index} < 0.'
+        # print(f'Generating indentation level {indent_level}...')
+
+        # Prospective name of this local pith variable.
+        pith_var_name = f'{VAR_NAME_PITH_PREFIX}{pith_index}'
+
+        # Cache this name.
+        self[pith_index] = pith_var_name
+
+        # Return this name.
+        return pith_var_name
+
+# ....................{ MAPPINGS                           }....................
+PITH_INDEX_TO_VAR_NAME = PithIndexToVarName()
+'''
+**Indentation cache singleton** (i.e., global dictionary efficiently mapping
+from 1-based indentation levels to the corresponding indentation string
+constant).
+
+Caveats
+-------
+**Indentation string constants should always be accessed via this cache rather
+than manually generated.** This cache dynamically creates and efficiently caches
+indentation string constants on the first access of those constants, obviating
+the performance cost of string formatting required to create these constants.
+
+Examples
+--------
+.. code-block:: pycon
+
+   >>> from beartype._check.code.snip.codesnipcls import PITH_INDEX_TO_VAR_NAME
+   >>> PITH_INDEX_TO_VAR_NAME[1]
+   '__beartype_pith_1'
+   >>> PITH_INDEX_TO_VAR_NAME[2]
+   '__beartype_pith_2'
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/code/snip/codesnipstr.py
@@ -0,0 +1,606 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **type-checking expression snippets** (i.e., triple-quoted pure-Python
+string constants formatted and concatenated together to dynamically generate
+boolean expressions type-checking arbitrary objects against various type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkmagic import (
+    VAR_NAME_RANDOM_INT,
+)
+from collections.abc import Callable
+
+# ....................{ HINT ~ placeholder : child         }....................
+CODE_HINT_CHILD_PLACEHOLDER_PREFIX = '@['
+'''
+Prefix of each **placeholder hint child type-checking substring** (i.e.,
+placeholder to be globally replaced by a Python code snippet type-checking the
+current pith expression against the currently iterated child hint of the
+currently visited parent hint).
+'''
+
+
+CODE_HINT_CHILD_PLACEHOLDER_SUFFIX = ')!'
+'''
+Suffix of each **placeholder hint child type-checking substring** (i.e.,
+placeholder to be globally replaced by a Python code snippet type-checking the
+current pith expression against the currently iterated child hint of the
+currently visited parent hint).
+'''
+
+# ....................{ HINT ~ placeholder : forwardref    }....................
+CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_PREFIX = '${FORWARDREF:'
+'''
+Prefix of each **placeholder unqualified forward reference classname
+substring** (i.e., placeholder to be globally replaced by a Python code snippet
+evaluating to the currently visited unqualified forward reference hint
+canonicalized into a fully-qualified classname relative to the external
+caller-defined module declaring the currently decorated callable).
+'''
+
+
+CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_SUFFIX = ']?'
+'''
+Suffix of each **placeholder unqualified forward reference classname
+substring** (i.e., placeholder to be globally replaced by a Python code snippet
+evaluating to the currently visited unqualified forward reference hint
+canonicalized into a fully-qualified classname relative to the external
+caller-defined module declaring the currently decorated callable).
+'''
+
+# ....................{ HINT ~ pep : 572                   }....................
+CODE_PEP572_PITH_ASSIGN_EXPR = '''{pith_curr_var_name} := {pith_curr_expr}'''
+'''
+Assignment expression assigning the full Python expression yielding the value of
+the current pith to a unique local variable, enabling child type hints to obtain
+this pith via this efficient variable rather than via this inefficient full
+Python expression.
+'''
+
+
+#FIXME: Preserved for posterity in the likelihood we'll need this again. *sigh*
+# CODE_PEP572_PITH_ASSIGN_AND = '''
+# {indent_curr}    # Localize this pith as a stupidly fast assignment expression.
+# {indent_curr}    ({pith_curr_assign_expr}) is {pith_curr_var_name} and'''
+# '''
+# Code snippet embedding an assignment expression assigning the full Python
+# expression yielding the value of the current pith to a unique local variable.
+#
+# This snippet is itself intended to be embedded in higher-level code snippets as
+# the first child expression of those snippets, enabling subsequent expressions in
+# those snippets to efficiently obtain this pith via this efficient variable
+# rather than via this inefficient full Python expression.
+#
+# This snippet is a tautology that is guaranteed to evaluate to :data:`True` whose
+# side effect is this assignment expression. Note that there exist numerous less
+# efficient alternatives, including:
+#
+# * ``({pith_curr_assign_expr}).__class__``, which is also guaranteed to evaluate
+#   to :data:`True` but which implicitly triggers the ``__getattr__()`` dunder
+#   method and thus incurs a performance penalty for user-defined objects
+#   inefficiently overriding that method.
+# * ``isinstance({pith_curr_assign_expr}, object)``, which is also guaranteed to
+#   evaluate :data:`True` but which is surprisingly inefficient in all cases.
+# '''
+
+# ....................{ HINT ~ pep : (484|585) : generic   }....................
+CODE_PEP484585_GENERIC_PREFIX = '''(
+{indent_curr}    # True only if this pith is of this generic type.
+{indent_curr}    isinstance({pith_curr_assign_expr}, {hint_curr_expr}) and'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet prefixing all code
+type-checking the current pith against each unerased pseudo-superclass
+subclassed by a :pep:`484`-compliant **generic** (i.e., PEP-compliant type hint
+subclassing a combination of one or more of the :mod:`typing.Generic`
+superclass, the :mod:`typing.Protocol` superclass, and/or other :mod:`typing`
+non-class objects).
+
+Caveats
+-------
+The ``{indent_curr}`` format variable is intentionally brace-protected to
+efficiently defer its interpolation until the complete PEP-compliant code
+snippet type-checking the current pith against *all* subscripted arguments of
+this parent type has been generated.
+'''
+
+
+CODE_PEP484585_GENERIC_SUFFIX = '''
+{indent_curr})'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet suffixing all code
+type-checking the current pith against each unerased pseudo-superclass
+subclassed by a :pep:`484`-compliant generic.
+'''
+
+
+CODE_PEP484585_GENERIC_CHILD = '''
+{{indent_curr}}    # True only if this pith deeply satisfies this unerased
+{{indent_curr}}    # pseudo-superclass of this generic.
+{{indent_curr}}    {hint_child_placeholder} and'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking the current pith
+against the current unerased pseudo-superclass subclassed by a
+:pep:`484`-compliant generic.
+
+Caveats
+-------
+The caller is required to manually slice the trailing suffix ``" and"`` after
+applying this snippet to the last unerased pseudo-superclass of such a generic.
+While there exist alternate and more readable means of accomplishing this, this
+approach is the optimally efficient.
+
+The ``{indent_curr}`` format variable is intentionally brace-protected to
+efficiently defer its interpolation until the complete PEP-compliant code
+snippet type-checking the current pith against *all* subscripted arguments of
+this parent type has been generated.
+'''
+
+# ....................{ HINT ~ pep : (484|585) : mapping   }....................
+CODE_PEP484585_MAPPING = '''(
+{indent_curr}    # True only if this pith is of this mapping type *AND*...
+{indent_curr}    isinstance({pith_curr_assign_expr}, {hint_curr_expr}) and
+{indent_curr}    # True only if either this mapping is empty *OR* this mapping
+{indent_curr}    # is non-empty and...
+{indent_curr}    (not {pith_curr_var_name} or ({func_curr_code_key_value}))
+{indent_curr})'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking the current pith
+against a parent **standard mapping type** (i.e., type hint subscripted by
+exactly two child type hints constraining *all* key-value pairs of this pith,
+which necessarily satisfies the :class:`collections.abc.Mapping` protocol with
+guaranteed :math:`O(1)` indexation of at least the first pair).
+
+Caveats
+-------
+**This snippet cannot contain ternary conditionals.** See
+:data:`.CODE_PEP484585_SEQUENCE_ARGS_1` for further commentary.
+
+There exist numerous means of accessing the first key-value pair of a
+dictionary. The approach taken here is well-known to be the fastest, as
+documented at this `StackOverflow answer`_.
+
+.. _StackOverflow answer:
+   https://stackoverflow.com/a/70490285/2809027
+'''
+
+
+CODE_PEP484585_MAPPING_KEY_ONLY_PITH_CHILD_EXPR = (
+    '''next(iter({pith_curr_var_name}))''')
+'''
+:pep:`484`- and :pep:`585`-compliant Python expression efficiently yielding the
+first key of the current mapping pith.
+'''
+
+
+CODE_PEP484585_MAPPING_VALUE_ONLY_PITH_CHILD_EXPR = (
+    '''next(iter({pith_curr_var_name}.values()))''')
+'''
+:pep:`484`- and :pep:`585`-compliant Python expression efficiently yielding the
+first value of the current mapping pith when type-checking *only* the values of
+this mapping (i.e., when the keys of this mapping are ignorable).
+'''
+
+
+CODE_PEP484585_MAPPING_KEY_VALUE_PITH_CHILD_EXPR = (
+    '''{pith_curr_var_name}[{pith_curr_key_var_name}]''')
+'''
+:pep:`484`- and :pep:`585`-compliant Python expression efficiently yielding the
+first value of the current mapping pith when type-checking both the keys *and*
+values of this mapping (i.e., when the keys of this mapping are unignorable).
+'''
+
+
+CODE_PEP484585_MAPPING_KEY_ONLY = '''
+{indent_curr}        # True only if this key satisfies this hint.
+{indent_curr}        {hint_key_placeholder}'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking *only* the first
+key of the current pith against *only* the key child type hint subscripting a
+parent standard mapping type.
+
+This snippet intentionally avoids type-checking values and is thus suitable for
+type-checking mappings with ignorable value child type hints (e.g.,
+``dict[str, object]``).
+'''
+
+
+CODE_PEP484585_MAPPING_VALUE_ONLY = '''
+{indent_curr}        # True only if this value satisfies this hint.
+{indent_curr}        {hint_value_placeholder}'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking *only* the first
+value of the current pith against *only* the value child type hint subscripting
+a parent standard mapping type.
+
+This snippet intentionally avoids type-checking keys and is thus suitable for
+type-checking mappings with ignorable key child type hints (e.g.,
+``dict[object, str]``).
+'''
+
+
+CODE_PEP484585_MAPPING_KEY_VALUE = f'''
+{{indent_curr}}        # Localize the first key of this mapping.
+{{indent_curr}}        ({{pith_curr_key_var_name}} := {CODE_PEP484585_MAPPING_KEY_ONLY_PITH_CHILD_EXPR}) is {{pith_curr_key_var_name}} and
+{{indent_curr}}        # True only if this key satisfies this hint.
+{{indent_curr}}        {{hint_key_placeholder}} and
+{{indent_curr}}        # True only if this value satisfies this hint.
+{{indent_curr}}        {{hint_value_placeholder}}'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking *only* the first
+key-value pair of the current pith against *only* the key and value child type
+hints subscripting a parent standard mapping type.
+
+This snippet intentionally type-checks both keys and values is thus unsuitable
+for type-checking mappings with ignorable key or value child type hints (e.g.,
+``dict[object, str]``, ``dict[str, object]``).
+'''
+
+# ....................{ HINT ~ pep : (484|585) : sequence  }....................
+CODE_PEP484585_SEQUENCE_ARGS_1 = '''(
+{indent_curr}    # True only if this pith is of this sequence type *AND*...
+{indent_curr}    isinstance({pith_curr_assign_expr}, {hint_curr_expr}) and
+{indent_curr}    # True only if either this sequence is empty *OR* this sequence
+{indent_curr}    # is both non-empty and a random item satisfies this hint.
+{indent_curr}    (not {pith_curr_var_name} or {hint_child_placeholder})
+{indent_curr})'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking the current pith
+against a parent **standard sequence type** (i.e., type hint subscripted by
+exactly one child type hint constraining *all* items of this pith, which
+necessarily satisfies the :class:`collections.abc.Sequence` protocol with
+guaranteed :math:`O(1)` indexation across all sequence items).
+
+Caveats
+-------
+**This snippet cannot contain ternary conditionals.** For unknown reasons
+suggesting a critical defect in the current implementation of Python 3.8's
+assignment expressions, this snippet raises :class:`UnboundLocalError`
+exceptions resembling the following when this snippet contains one or more
+ternary conditionals:
+
+    UnboundLocalError: local variable '__beartype_pith_1' referenced before assignment
+
+In particular, the initial draft of this snippet guarded against empty
+sequences with a seemingly reasonable ternary conditional:
+
+.. code-block:: python
+
+   CODE_PEP484585_SEQUENCE_ARGS_1 = \'\'\'(
+   {indent_curr}    isinstance({pith_curr_assign_expr}, {hint_curr_expr}) and
+   {indent_curr}    {hint_child_placeholder} if {pith_curr_var_name} else True
+   {indent_curr})\'\'\'
+
+That should behave as expected, but doesn't, presumably due to obscure scoping
+rules and a non-intuitive implementation of ternary conditionals in CPython.
+Ergo, the current version of this snippet guards against empty sequences with
+disjunctions and conjunctions (i.e., ``or`` and ``and`` operators) instead.
+Happily, the current version is more efficient than the equivalent approach
+based on ternary conditional (albeit slightly less intuitive).
+'''
+
+
+CODE_PEP484585_SEQUENCE_ARGS_1_PITH_CHILD_EXPR = (
+    f'''{{pith_curr_var_name}}[{VAR_NAME_RANDOM_INT} % len({{pith_curr_var_name}})]''')
+'''
+:pep:`484`- and :pep:`585`-compliant Python expression yielding the value of a
+randomly indexed item of the current sequence pith.
+'''
+
+# ....................{ HINT ~ pep : (484|585) : tuple     }....................
+CODE_PEP484585_TUPLE_FIXED_PREFIX = '''(
+{indent_curr}    # True only if this pith is a tuple.
+{indent_curr}    isinstance({pith_curr_assign_expr}, tuple) and'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet prefixing all code
+type-checking the current pith against each subscripted child hint of an
+itemized :class:`typing.Tuple` type of the form ``typing.Tuple[{typename1},
+{typename2}, ..., {typenameN}]``.
+'''
+
+
+CODE_PEP484585_TUPLE_FIXED_SUFFIX = '''
+{indent_curr})'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet suffixing all code
+type-checking the current pith against each subscripted child hint of an
+itemized :class:`typing.Tuple` type of the form ``typing.Tuple[{typename1},
+{typename2}, ..., {typenameN}]``.
+'''
+
+
+CODE_PEP484585_TUPLE_FIXED_EMPTY = '''
+{{indent_curr}}    # True only if this tuple is empty.
+{{indent_curr}}    not {pith_curr_var_name} and'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet prefixing all code
+type-checking the current pith to be empty against an itemized
+:class:`typing.Tuple` type of the non-standard form ``typing.Tuple[()]``.
+
+See Also
+--------
+:data:`CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD`
+    Further details.
+'''
+
+
+CODE_PEP484585_TUPLE_FIXED_LEN = '''
+{{indent_curr}}    # True only if this tuple is of the expected length.
+{{indent_curr}}    len({pith_curr_var_name}) == {hint_childs_len} and'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet prefixing all code
+type-checking the current pith to be of the expected length against an itemized
+:class:`typing.Tuple` type of the non-standard form ``typing.Tuple[()]``.
+
+See Also
+--------
+:data:`CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD`
+    Further details.
+'''
+
+
+CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD = '''
+{{indent_curr}}    # True only if this item of this non-empty tuple deeply
+{{indent_curr}}    # satisfies this child hint.
+{{indent_curr}}    {hint_child_placeholder} and'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking the current pith
+against the current child hint subscripting an itemized :class:`typing.Tuple`
+type of the form ``typing.Tuple[{typename1}, {typename2}, ..., {typenameN}]``.
+
+Caveats
+-------
+The caller is required to manually slice the trailing suffix ``" and"`` after
+applying this snippet to the last subscripted child hint of an itemized
+:class:`typing.Tuple` type. While there exist alternate and more readable means
+of accomplishing this, this approach is the optimally efficient.
+
+The ``{indent_curr}`` format variable is intentionally brace-protected to
+efficiently defer its interpolation until the complete PEP-compliant code
+snippet type-checking the current pith against *all* subscripted arguments of
+this parent type has been generated.
+'''
+
+
+CODE_PEP484585_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR = (
+    '''{pith_curr_var_name}[{pith_child_index}]''')
+'''
+:pep:`484`- and :pep:`585`-compliant Python expression yielding the value of the
+currently indexed item of the current pith (which, by definition, *must* be a
+tuple).
+'''
+
+# ....................{ HINT ~ pep : (484|585) : subclass  }....................
+CODE_PEP484585_SUBCLASS = '''(
+{indent_curr}    # True only if this pith is a class *AND*...
+{indent_curr}    isinstance({pith_curr_assign_expr}, type) and
+{indent_curr}    # True only if this class subclasses this superclass.
+{indent_curr}    issubclass({pith_curr_var_name}, {hint_curr_expr})
+{indent_curr})'''
+'''
+:pep:`484`- and :pep:`585`-compliant code snippet type-checking the current pith
+to be a subclass of the subscripted child hint of a :pep:`484`- or
+:pep:`585`-compliant **subclass type hint** (e.g., :attr:`typing.Type`,
+:class:`type`).
+'''
+
+# ....................{ HINT ~ pep : 484 : instance        }....................
+CODE_PEP484_INSTANCE = '''isinstance({pith_curr_expr}, {hint_curr_expr})'''
+'''
+:pep:`484`-compliant code snippet type-checking the current pith against the
+current child PEP-compliant type expected to be a trivial non-:mod:`typing`
+type (e.g., :class:`int`, :class:`str`).
+
+Caveats
+-------
+**This snippet is intentionally compact rather than embedding a human-readable
+comment.** For example, this snippet intentionally avoids doing this:
+
+.. code-block:: python
+
+   CODE_PEP484_INSTANCE = '
+   {indent_curr}# True only if this pith is of this type.
+   {indent_curr}isinstance({pith_curr_expr}, {hint_curr_expr})'
+
+Although feasible, doing that would significantly complicate code generation for
+little to *no* tangible gain. Indeed, we actually tried doing that once. We
+failed hard after breaking everything. **Avoid the mistakes of the past.**
+'''
+
+# ....................{ HINT ~ pep : 484 : union           }....................
+CODE_PEP484604_UNION_PREFIX = '''('''
+'''
+:pep:`484`-compliant code snippet prefixing all code type-checking the current
+pith against each subscripted argument of a :class:`typing.Union` type hint.
+'''
+
+
+CODE_PEP484604_UNION_SUFFIX = '''
+{indent_curr})'''
+'''
+:pep:`484`-compliant code snippet suffixing all code type-checking the current
+pith against each subscripted argument of a :class:`typing.Union` type hint.
+'''
+
+
+CODE_PEP484604_UNION_CHILD_NONPEP = '''
+{{indent_curr}}    # True only if this pith is of one of these types.
+{{indent_curr}}    isinstance({pith_curr_expr}, {hint_curr_expr}) or'''
+'''
+:pep:`484`-compliant code snippet type-checking the current pith against the
+current PEP-noncompliant child argument subscripting a parent
+:class:`typing.Union` type hint.
+
+See Also
+--------
+:data:`CODE_PEP484604_UNION_CHILD_PEP`
+    Further details.
+'''
+
+
+CODE_PEP484604_UNION_CHILD_PEP = '''
+{{indent_curr}}    {hint_child_placeholder} or'''
+'''
+:pep:`484`-compliant code snippet type-checking the current pith against the
+current PEP-compliant child argument subscripting a parent :class:`typing.Union`
+type hint.
+
+Caveats
+-------
+The caller is required to manually slice the trailing suffix ``" or"`` after
+applying this snippet to the last subscripted argument of such a hint. While
+there exist alternate and more readable means of accomplishing this, this
+approach is the optimally efficient.
+
+The ``{indent_curr}`` format variable is intentionally brace-protected to
+efficiently defer its interpolation until the complete PEP-compliant code
+snippet type-checking the current pith against *all* subscripted arguments of
+this parent hint has been generated.
+'''
+
+# ....................{ HINT ~ pep : 586                   }....................
+CODE_PEP586_PREFIX = '''(
+{{indent_curr}}    # True only if this pith is of one of these literal types.
+{{indent_curr}}    isinstance({pith_curr_assign_expr}, {hint_child_types_expr}) and ('''
+'''
+:pep:`586`-compliant code snippet prefixing all code type-checking the current
+pith against a :pep:`586`-compliant :class:`typing.Literal` type hint
+subscripted by one or more literal objects.
+'''
+
+
+CODE_PEP586_SUFFIX = '''
+{indent_curr}))'''
+'''
+:pep:`586`-compliant code snippet suffixing all code type-checking the current
+pith against a :pep:`586`-compliant :class:`typing.Literal` type hint
+subscripted by one or more literal objects.
+'''
+
+
+CODE_PEP586_LITERAL = '''
+{{indent_curr}}        # True only if this pith is equal to this literal.
+{{indent_curr}}        {pith_curr_var_name} == {hint_child_expr} or'''
+'''
+:pep:`586`-compliant code snippet type-checking the current pith against the
+current child literal object subscripting a :pep:`586`-compliant
+:class:`typing.Literal` type hint.
+
+Caveats
+-------
+The caller is required to manually slice the trailing suffix ``" and"`` after
+applying this snippet to the last subscripted argument of such a
+:class:`typing.Literal` type. While there exist alternate and more readable
+means of accomplishing this, this approach is the optimally efficient.
+
+The ``{indent_curr}`` format variable is intentionally brace-protected to
+efficiently defer its interpolation until the complete PEP-compliant code
+snippet type-checking the current pith against *all* subscripted arguments of
+this parent hint has been generated.
+'''
+
+# ....................{ HINT ~ pep : 593                   }....................
+CODE_PEP593_VALIDATOR_PREFIX = '''('''
+'''
+:pep:`593`-compliant code snippet prefixing all code type-checking the current
+pith against a :pep:`593`-compliant :obj:`typing.Annotated` type hint
+subscripted by one or more :mod:`beartype.vale` validators.
+'''
+
+
+CODE_PEP593_VALIDATOR_SUFFIX = '''
+{indent_curr})'''
+'''
+:pep:`593`-compliant code snippet suffixing all code type-checking the current
+pith against each a :pep:`593`-compliant :class:`typing.Annotated` type hint
+subscripted by one or more :mod:`beartype.vale` validators.
+'''
+
+
+CODE_PEP593_VALIDATOR_METAHINT = '''
+{indent_curr}    {hint_child_placeholder} and'''
+'''
+:pep:`593`-compliant code snippet type-checking the current pith against the
+**metahint** (i.e., first child type hint) subscripting a obj:`typing.Annotated`
+type hint subscripted by one or more :mod:`beartype.vale` validators.
+'''
+
+
+CODE_PEP593_VALIDATOR_IS = '''
+{indent_curr}    # True only if this pith satisfies this caller-defined
+{indent_curr}    # validator of this annotated metahint.
+{indent_curr}    {hint_child_expr} and'''
+'''
+:pep:`593`-compliant code snippet type-checking the current pith against
+:mod:`beartype`-specific **data validator code** (i.e., caller-defined
+:meth:`beartype.vale.BeartypeValidator._is_valid_code` string) of the current
+child :mod:`beartype.vale` validator subscripting a parent :pep:`593`-compliant
+:class:`typing.Annotated` type hint.
+
+Caveats
+-------
+The caller is required to manually slice the trailing suffix ``" and"`` after
+applying this snippet to the last subscripted argument of such a
+:class:`typing.Annotated` type. While there exist alternate and more readable
+means of accomplishing this, this approach is the optimally efficient.
+'''
+
+# ..................{ FORMATTERS                             }..................
+# str.format() methods, globalized to avoid inefficient dot lookups elsewhere.
+# This is an absurd micro-optimization. *fight me, github developer community*
+CODE_PEP484_INSTANCE_format: Callable = (
+    CODE_PEP484_INSTANCE.format)
+CODE_PEP484585_GENERIC_CHILD_format: Callable = (
+    CODE_PEP484585_GENERIC_CHILD.format)
+CODE_PEP484585_MAPPING_format: Callable = (
+    CODE_PEP484585_MAPPING.format)
+CODE_PEP484585_MAPPING_KEY_ONLY_format: Callable = (
+    CODE_PEP484585_MAPPING_KEY_ONLY.format)
+CODE_PEP484585_MAPPING_KEY_VALUE_format: Callable = (
+    CODE_PEP484585_MAPPING_KEY_VALUE.format)
+CODE_PEP484585_MAPPING_VALUE_ONLY_format: Callable = (
+    CODE_PEP484585_MAPPING_VALUE_ONLY.format)
+CODE_PEP484585_MAPPING_KEY_ONLY_PITH_CHILD_EXPR_format: Callable = (
+    CODE_PEP484585_MAPPING_KEY_ONLY_PITH_CHILD_EXPR.format)
+CODE_PEP484585_MAPPING_VALUE_ONLY_PITH_CHILD_EXPR_format: Callable = (
+    CODE_PEP484585_MAPPING_VALUE_ONLY_PITH_CHILD_EXPR.format)
+CODE_PEP484585_MAPPING_KEY_VALUE_PITH_CHILD_EXPR_format: Callable = (
+    CODE_PEP484585_MAPPING_KEY_VALUE_PITH_CHILD_EXPR.format)
+CODE_PEP484585_SEQUENCE_ARGS_1_format: Callable = (
+    CODE_PEP484585_SEQUENCE_ARGS_1.format)
+CODE_PEP484585_SEQUENCE_ARGS_1_PITH_CHILD_EXPR_format: Callable = (
+    CODE_PEP484585_SEQUENCE_ARGS_1_PITH_CHILD_EXPR.format)
+CODE_PEP484585_SUBCLASS_format: Callable = (
+    CODE_PEP484585_SUBCLASS.format)
+CODE_PEP484585_TUPLE_FIXED_EMPTY_format: Callable = (
+    CODE_PEP484585_TUPLE_FIXED_EMPTY.format)
+CODE_PEP484585_TUPLE_FIXED_LEN_format: Callable = (
+    CODE_PEP484585_TUPLE_FIXED_LEN.format)
+CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD_format: Callable = (
+    CODE_PEP484585_TUPLE_FIXED_NONEMPTY_CHILD.format)
+CODE_PEP484585_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR_format: Callable = (
+    CODE_PEP484585_TUPLE_FIXED_NONEMPTY_PITH_CHILD_EXPR.format)
+CODE_PEP484604_UNION_CHILD_PEP_format: Callable = (
+    CODE_PEP484604_UNION_CHILD_PEP.format)
+CODE_PEP484604_UNION_CHILD_NONPEP_format: Callable = (
+    CODE_PEP484604_UNION_CHILD_NONPEP.format)
+# CODE_PEP572_PITH_ASSIGN_AND_format: Callable = (
+#     CODE_PEP572_PITH_ASSIGN_AND.format)
+CODE_PEP572_PITH_ASSIGN_EXPR_format: Callable = (
+    CODE_PEP572_PITH_ASSIGN_EXPR.format)
+CODE_PEP586_LITERAL_format: Callable = (
+    CODE_PEP586_LITERAL.format)
+CODE_PEP586_PREFIX_format: Callable = (
+    CODE_PEP586_PREFIX.format)
+CODE_PEP593_VALIDATOR_IS_format: Callable = (
+    CODE_PEP593_VALIDATOR_IS.format)
+CODE_PEP593_VALIDATOR_METAHINT_format: Callable = (
+    CODE_PEP593_VALIDATOR_METAHINT.format)
+CODE_PEP593_VALIDATOR_SUFFIX_format: Callable = (
+    CODE_PEP593_VALIDATOR_SUFFIX.format)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/convert/convcoerce.py
@@ -0,0 +1,475 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **PEP-agnostic type hint coercers** (i.e., mid-level callables
+*permanently* converting type hints from one format into another, either
+losslessly or in a lossy manner).
+
+Type hint coercions imposed by this submodule are externalized outside
+:mod:`beartype` as globally scoped changes accessible to other modules. These
+coercions are permanently applied to the ``__annotations__`` dunder dictionaries
+of the classes and callables annotated by these type hints.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: coerce_hint() should also rewrite unhashable hints to be hashable *IF
+#FEASIBLE.* This isn't always feasible, of course (e.g., "Annotated[[]]",
+#"Literal[[]]"). The one notable place where this *IS* feasible is with PEP
+#585-compliant type hints subscripted by unhashable rather than hashable
+#iterables, which can *ALWAYS* be safely rewritten to be hashable (e.g.,
+#coercing "callable[[], None]" to "callable[(), None]").
+
+#FIXME: [PEP 544] coerce_hint() should also coerce PEP 544-compatible protocols
+#*NOT* decorated by @typing.runtime_checkable to be decorated by that decorator,
+#as such protocols are unusable at runtime. Yes, we should always try something
+#*REALLY* sneaky and clever.
+#
+#Specifically, rather than accept "typing" nonsense verbatim, we could instead:
+#* Detect PEP 544-compatible protocol type hints *NOT* decorated by
+#  @typing.runtime_checkable. The existing is_type_isinstanceable() tester now
+#  detects whether arbitrary classes are isinstanceable, so just call that.
+#* Emit a non-fatal warning advising the end user to resolve this on their end.
+#* Meanwhile, beartype can simply:
+#  * Dynamically fabricate a new PEP 544-compatible protocol decorated by
+#    @typing.runtime_checkable using the body of the undecorated user-defined
+#    protocol as its base. Indeed, simply subclassing a new subclass decorated
+#    by @typing.runtime_checkable from the undecorated user-defined protocol as
+#    its base with a noop body of "pass" should suffice.
+#  * Replacing all instances of the undecorated user-defined protocol with that
+#    decorated beartype-defined protocol in annotations. Note this would
+#    strongly benefit from some form of memoization or caching. Since this edge
+#    case should be fairly rare, even a dictionary would probably be overkill.
+#    Just implementing something resembling the following memoized getter
+#    in the "utilpep544" submodule would probably suffice:
+#        @callable_cached
+#        def get_pep544_protocol_checkable_from_protocol_uncheckable(
+#            protocol_uncheckable: object) -> Protocol:
+#            ...
+#
+#Checkmate, "typing". Checkmate.
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    Optional,
+    Union,
+)
+from beartype._cave._cavefast import NotImplementedType
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+from beartype._data.func.datafunc import METHOD_NAMES_DUNDER_BINARY
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.forward.fwdmain import resolve_hint
+from beartype._util.cache.map.utilmapbig import CacheUnboundedStrong
+from beartype._util.hint.utilhinttest import is_hint_uncached
+from beartype._util.hint.pep.proposal.pep484.utilpep484union import (
+    make_hint_pep484_union)
+
+# ....................{ COERCERS ~ root                    }....................
+#FIXME: Document mypy-specific coercion in the docstring as well, please.
+def coerce_func_hint_root(
+    hint: object,
+    pith_name: Optional[str],
+    bear_call: BeartypeCall,
+    exception_prefix: str,
+) -> object:
+    '''
+    PEP-compliant type hint coerced (i.e., converted) from the passed **root
+    type hint** (i.e., possibly PEP-noncompliant type hint annotating the
+    parameter or return with the passed name of the passed callable) if this
+    hint is coercible *or* this hint as is otherwise (i.e., if this hint is
+    *not* coercible).
+
+    This function is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). Since the hint returned by this
+    function conditionally depends upon the passed callable, memoizing this
+    function would consume space needlessly with *no* useful benefit.
+
+    Caveats
+    -------
+    This function *cannot* be meaningfully memoized, since the passed type hint
+    is *not* guaranteed to be cached somewhere. Only functions passed cached
+    type hints can be meaningfully memoized. Since this high-level function
+    internally defers to unmemoized low-level functions that are :math:`O(n)`
+    for :math:``n` the size of the inheritance hierarchy of this hint, this
+    function should be called sparingly. See the
+    :mod:`beartype._decor.cache.cachehint` submodule for further details.
+
+    Parameters
+    ----------
+    hint : object
+        Possibly PEP-noncompliant type hint to be possibly coerced.
+    pith_name : Optional[str]
+        Either:
+
+        * If this hint annotates a parameter of some callable, the name of that
+          parameter.
+        * If this hint annotates the return of some callable, ``"return"``.
+        * Else, :data:`None`.
+    bear_call : BeartypeCall
+        Decorated callable annotated by this hint.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this possibly PEP-noncompliant hint is coercible, a PEP-compliant
+          type hint coerced from this hint.
+        * Else, this hint as is unmodified.
+    '''
+    assert isinstance(pith_name, NoneTypeOr[str]), (
+        f'{repr(pith_name)} neither string nor "None".')
+    assert bear_call.__class__ is BeartypeCall, (
+        f'{repr(bear_call)} not @beartype call.')
+    # print(f'Coercing pith "{pith_name}" annotated by type hint {repr(hint)}...')
+
+    # ..................{ FORWARD REFERENCE                  }..................
+    # If this hint is stringified (e.g., as a PEP 484- or 563-compliant forward
+    # reference), resolve this hint to the non-string hint to which this hint
+    # refers *BEFORE* performing any subsequent logic with this hint -- *ALL* of
+    # which assumes this hint to be a non-string hint.
+    if isinstance(hint, str):
+        hint = resolve_hint(
+            hint=hint,
+            bear_call=bear_call,
+            exception_prefix=exception_prefix,
+        )
+    # Else, this hint is *NOT* stringified.
+    #
+    # In either case, this hint is guaranteed to now be a non-string hint.
+
+    # ..................{ MYPY                               }..................
+    # If...
+    if (
+        # This hint annotates the return for the decorated callable *AND*...
+        pith_name == ARG_NAME_RETURN and
+        # The decorated callable is a binary dunder method (e.g., __eq__())...
+        bear_call.func_wrapper_name in METHOD_NAMES_DUNDER_BINARY
+    ):
+        # Expand this hint to accept both this hint *AND* the "NotImplemented"
+        # singleton as valid returns from this method. Why? Because this
+        # expansion has been codified by mypy and is thus a de-facto typing
+        # standard, albeit one currently lacking formal PEP standardization.
+        #
+        # Consider this representative binary dunder method:
+        #     class MuhClass:
+        #         @beartype
+        #         def __eq__(self, other: object) -> bool:
+        #             if isinstance(other, TheCloud):
+        #                 return self is other
+        #             return NotImplemented
+        #
+        # Technically, that method *COULD* be retyped to return:
+        #         def __eq__(self, other: object) -> Union[
+        #             bool, type(NotImplemented)]:
+        #
+        # Pragmatically, mypy and other static type checkers do *NOT* currently
+        # support the type() builtin in a sane manner and thus raise errors
+        # given the otherwise valid logic above. This means that the following
+        # equivalent approach also yields the same errors:
+        #     NotImplementedType = type(NotImplemented)
+        #     class MuhClass:
+        #         @beartype
+        #         def __eq__(self, other: object) -> Union[
+        #             bool, NotImplementedType]:
+        #             if isinstance(other, TheCloud):
+        #                 return self is other
+        #             return NotImplemented
+        #
+        # Of course, the latter approach can be manually rectified by
+        # explicitly typing that type as "Any": e.g.,
+        #     NotImplementedType: Any = type(NotImplemented)
+        #
+        # Of course, expecting users to be aware of these ludicrous sorts of
+        # mypy idiosyncrasies merely to annotate an otherwise normal binary
+        # dunder method is one expectation too far.
+        #
+        # In theory, official CPython developers have already resolved this
+        # under Python >= 3.10 by defining the "types.NotImplementedType" type.
+        # In practice, that fails to assist older Python versions. Mypy has
+        # thus taken the surprisingly sensible course of silently ignoring this
+        # edge case by effectively performing the same type expansion as
+        # performed here. *applause*
+        return Union[hint, NotImplementedType]  # pyright: ignore[reportGeneralTypeIssues]
+
+    # Defer to the function-agnostic root hint coercer as a generic fallback.
+    return coerce_hint_root(hint=hint, exception_prefix=exception_prefix)
+
+
+def coerce_hint_root(hint: object, exception_prefix: str) -> object:
+    '''
+    PEP-compliant type hint coerced (i.e., converted) from the passed **root
+    type hint** (i.e., possibly PEP-noncompliant type hint that has *no* parent
+    type hint) if this hint is coercible *or* this hint as is otherwise (i.e.,
+    if this hint is *not* coercible).
+
+    Specifically, if the passed hint is:
+
+    * A **PEP-noncompliant tuple union** (i.e., tuple of one or more standard
+      classes and forward references to standard classes), this function:
+
+      * Coerces this tuple union into the equivalent :pep:`484`-compliant
+        union.
+      * Replaces this tuple union in the ``__annotations__`` dunder tuple of
+        this callable with this :pep:`484`-compliant union.
+      * Returns this :pep:`484`-compliant union.
+
+    This function is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). See caveats that follow.
+
+    Caveats
+    -------
+    This function *cannot* be meaningfully memoized, since the passed type hint
+    is *not* guaranteed to be cached somewhere. Only functions passed cached
+    type hints can be meaningfully memoized. Since this high-level function
+    internally defers to unmemoized low-level functions that are ``O(n)`` for
+    ``n`` the size of the inheritance hierarchy of this hint, this function
+    should be called sparingly. See the :mod:`beartype._decor.cache.cachehint`
+    submodule for further details.
+
+    Parameters
+    ----------
+    hint : object
+        Possibly PEP-noncompliant type hint to be possibly coerced.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this possibly PEP-noncompliant hint is coercible, a PEP-compliant
+          type hint coerced from this hint.
+        * Else, this hint as is unmodified.
+    '''
+
+    # ..................{ NON-PEP                            }..................
+    # If this hint is a PEP-noncompliant tuple union, coerce this union into
+    # the equivalent PEP-compliant union subscripted by the same child hints.
+    # By definition, PEP-compliant unions are a superset of PEP-noncompliant
+    # tuple unions and thus accept all child hints accepted by the latter.
+    if isinstance(hint, tuple):
+        return make_hint_pep484_union(hint)
+    # Else, this hint is *NOT* a PEP-noncompliant tuple union.
+
+    # Since none of the above conditions applied, this hint could *NOT* be
+    # specifically coerced as a root type hint. Nonetheless, this hint may
+    # still be generically coercible as a hint irrespective of its contextual
+    # position relative to other type hints.
+    #
+    # Return this hint, possibly coerced as a context-agnostic type hint.
+    return coerce_hint_any(hint)
+
+# ....................{ COERCERS ~ any                     }....................
+def coerce_hint_any(hint: object) -> Any:
+    '''
+    PEP-compliant type hint coerced (i.e., converted) from the passed
+    PEP-compliant type hint if this hint is coercible *or* this hint as is
+    otherwise (i.e., if this hint is *not* coercible).
+
+    Specifically, if the passed hint is:
+
+    * A **PEP-compliant uncached type hint** (i.e., hint *not* already
+      internally cached by its parent class or module), this function:
+
+      * If this hint has already been passed to a prior call of this function,
+        returns the semantically equivalent PEP-compliant type hint having the
+        same machine-readable representation as this hint cached by that call.
+        Doing so deduplicates this hint, which both:
+
+        * Minimizes space complexity across the lifetime of this process.
+        * Minimizes time complexity by enabling beartype-specific memoized
+          callables to efficiently reduce to constant-time lookup operations
+          when repeatedly passed copies of this hint nonetheless sharing the
+          same machine-readable representation.
+
+      * Else, internally caches this hint with a thread-safe global cache and
+        returns this hint as is.
+
+      Uncached hints include:
+
+      * :pep:`484`-compliant subscripted generics under Python >= 3.9 (e.g.,
+        ``from typing import List; class MuhPep484List(List): pass;
+        MuhPep484List[int]``). See below for further commentary.
+      * :pep:`585`-compliant type hints, including both:
+
+        * Builtin :pep:`585`-compliant type hints (e.g., ``list[int]``).
+        * User-defined :pep:`585`-compliant generics (e.g.,
+          ``class MuhPep585List(list): pass; MuhPep585List[int]``).
+
+    * Already cached, this hint is already PEP-compliant by definition. In this
+      case, this function preserves and returns this hint as is.
+
+    This function is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). See caveats that follow.
+
+    Design
+    ------
+    This function does *not* bother caching **self-caching type hints** (i.e.,
+    type hints that externally cache themselves), as these hints are already
+    cached elsewhere. Self-cached type hints include most type hints created by
+    subscripting type hint factories declared by the :mod:`typing` module,
+    which internally cache their resulting type hints: e.g.,
+
+    .. code-block:: python
+
+       >>> import typing
+       >>> typing.List[int] is typing.List[int]
+       True
+
+    Equivalently, this function *only* caches **uncached type hints** (i.e.,
+    type hints that do *not* externally cache themselves), as these hints are
+    *not* already cached elsewhere. Uncached type hints include *all*
+    :pep:`585`-compliant type hints produced by subscripting builtin container
+    types, which fail to internally cache their resulting type hints: e.g.,
+
+    .. code-block:: python
+
+       >>> list[int] is list[int]
+       False
+
+    This function enables callers to coerce uncached type hints into
+    :mod:`beartype`-cached type hints. :mod:`beartype` effectively requires
+    *all* type hints to be cached somewhere! :mod:`beartype` does *not* care
+    who, what, or how is caching those type hints -- only that they are cached
+    before being passed to utility functions in the :mod:`beartype` codebase.
+    Why? Because most such utility functions are memoized for efficiency by the
+    :func:`beartype._util.cache.utilcachecall.callable_cached` decorator, which
+    maps passed parameters (typically including the standard ``hint`` parameter
+    accepting a type hint) based on object identity to previously cached return
+    values. You see the problem, we trust.
+
+    Uncached type hints that are otherwise semantically equal are nonetheless
+    distinct objects and will thus be treated as distinct parameters by
+    memoization decorators. If this function did *not* exist, uncached type
+    hints could *not* be coerced into :mod:`beartype`-cached type hints and
+    thus could *not* be memoized, dramatically reducing the efficiency of
+    :mod:`beartype` for standard type hints.
+
+    Caveats
+    -------
+    This function *cannot* be meaningfully memoized, since the passed type hint
+    is *not* guaranteed to be cached somewhere. Only functions passed cached
+    type hints can be meaningfully memoized. Since this high-level function
+    internally defers to unmemoized low-level functions that are :math:`O(n)`
+    for :math:`n` the size of the inheritance hierarchy of this hint, this
+    function should be called sparingly.
+
+    This function intentionally does *not* cache :pep:`484`-compliant generics
+    subscripted by type variables under Python < 3.9. Those hints are
+    technically uncached but silently treated by this function as self-cached
+    and thus preserved as is. Why? Because correctly detecting those hints as
+    uncached would require an unmemoized :math:`O(n)` search across the
+    inheritance hierarchy of *all* passed objects and thus all type hints
+    annotating callables decorated by :func:`beartype.beartype`. Since this
+    failure only affects obsolete Python versions *and* since the only harms
+    induced by this failure are a slight increase in space and time consumption
+    for edge-case type hints unlikely to actually be used in real-world code,
+    this tradeoff is more than acceptable. We're not the bad guy here. Right?
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be possibly coerced.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this PEP-compliant type hint is coercible, another PEP-compliant
+          type hint coerced from this hint.
+        * Else, this hint as is unmodified.
+    '''
+
+    # ..................{ NON-SELF-CACHING                   }..................
+    # If this hint is *NOT* self-caching, this hint *MUST* thus be explicitly
+    # cached here. Failing to do so would disable subsequent memoization,
+    # reducing decoration- and call-time efficiency when decorating callables
+    # repeatedly annotated by copies of this hint.
+    #
+    # Specifically, deduplicate this hint by either:
+    # * If this is the first copy of this hint passed to this function, cache
+    #   this hint under its machine-readable implementation.
+    # * Else, one or more prior copies of this hint have already been passed to
+    #   this function. In this case, replace this subsequent copy by the first
+    #   copy of this hint originally passed to a prior call of this function.
+    if is_hint_uncached(hint):
+        # print(f'Self-caching type hint {repr(hint)}...')
+        return _hint_repr_to_hint.cache_or_get_cached_value(
+            key=repr(hint), value=hint)
+    # Else, this hint is (hopefully) self-caching.
+
+    # Return this uncoerced hint as is.
+    return hint
+
+# ....................{ PRIVATE ~ mappings                 }....................
+_hint_repr_to_hint = CacheUnboundedStrong()
+'''
+**Type hint cache** (i.e., thread-safe cache mapping from the machine-readable
+representations of all non-self-cached type hints to cached singleton instances
+of those hints).**
+
+This cache caches:
+
+* :pep:`585`-compliant type hints, which do *not* cache themselves.
+* :pep:`604`-compliant unions, which do *not* cache themselves.
+
+This cache does *not* cache:
+
+* Type hints declared by the :mod:`typing` module, which implicitly cache
+  themselves on subscription thanks to inscrutable metaclass magic.
+* :pep:`563`-compliant **deferred type hints** (i.e., type hints persisted as
+  evaluable strings rather than actual type hints). Ideally, this cache would
+  cache the evaluations of *all* deferred type hints. Sadly, doing so is
+  infeasible in the general case due to global and local namespace lookups
+  (e.g., ``Dict[str, int]`` only means what you think it means if an
+  importation resembling ``from typing import Dict`` preceded that type hint).
+
+Design
+------
+**This dictionary is intentionally thread-safe.** Why? Because this dictionary
+is used to modify the ``__attributes__`` dunder variable of arbitrary callables.
+Since most such callables are either module- or class-scoped, that variable is
+effectively global. To prevent race conditions between competing threads
+contending over that variable, this dictionary *must* be thread-safe.
+
+**This dictionary is intentionally designed as a naive dictionary rather than a
+robust LRU cache,** for the same reasons that callables accepting hints are
+memoized by the :func:`beartype._util.cache.utilcachecall.callable_cached`
+rather than the :func:`functools.lru_cache` decorator. Why? Because:
+
+* The number of different type hints instantiated across even worst-case
+  codebases is negligible in comparison to the space consumed by those hints.
+* The :attr:`sys.modules` dictionary persists strong references to all
+  callables declared by previously imported modules. In turn, the
+  ``func.__annotations__`` dunder dictionary of each such callable persists
+  strong references to all type hints annotating that callable. In turn, these
+  two statements imply that type hints are *never* garbage collected but
+  instead persisted for the lifetime of the active Python process. Ergo,
+  temporarily caching hints in an LRU cache is pointless, as there are *no*
+  space savings in dropping stale references to unused hints.
+
+**This dictionary intentionally caches machine-readable representation strings
+hashes rather than alternative keys** (e.g., actual hashes). Why? Disambiguity.
+Although comparatively less efficient in both space and time to construct than
+hashes, the :func:`repr` strings produced for two dissimilar type hints *never*
+ambiguously collide unless an external caller maliciously modified one or more
+identifying dunder attributes of those hints (e.g., the ``__module__``,
+``__qualname__``, and/or ``__name__`` dunder attributes). That should *never*
+occur in production code. Meanwhile, the :func:`hash` values produced for two
+dissimilar type hints *commonly* ambiguously collide. This is why hashable
+containers (e.g., :class:`dict`, :class:`set`) explicitly handle hash table
+collisions and why we are *not* going to do so.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/convert/convreduce.py
@@ -0,0 +1,660 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-agnostic type hint reducers** (i.e., low-level callables
+*temporarily* converting type hints from one format into another, either
+losslessly or in a lossy manner).
+
+Type hint reductions imposed by this submodule are purely internal to
+:mod:`beartype` itself and thus transient in nature. These reductions are *not*
+permanently applied to the ``__annotations__`` dunder dictionaries of the
+classes and callables annotated by these type hints.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    # Callable,
+    Dict,
+    Optional,
+)
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignAbstractSet,
+    HintSignAnnotated,
+    HintSignAsyncContextManager,
+    HintSignAsyncGenerator,
+    HintSignAsyncIterable,
+    HintSignAsyncIterator,
+    HintSignAwaitable,
+    HintSignByteString,
+    HintSignCallable,
+    HintSignChainMap,
+    HintSignCollection,
+    HintSignContainer,
+    HintSignContextManager,
+    HintSignCoroutine,
+    HintSignCounter,
+    HintSignDefaultDict,
+    HintSignDeque,
+    HintSignDict,
+    HintSignFinal,
+    HintSignFrozenSet,
+    HintSignGenerator,
+    HintSignGeneric,
+    HintSignHashable,
+    HintSignItemsView,
+    HintSignIterable,
+    HintSignIterator,
+    HintSignKeysView,
+    HintSignList,
+    HintSignLiteralString,
+    HintSignMappingView,
+    HintSignMapping,
+    HintSignMatch,
+    HintSignMutableMapping,
+    HintSignMutableSequence,
+    HintSignMutableSet,
+    HintSignNewType,
+    HintSignNone,
+    HintSignNumpyArray,
+    HintSignOrderedDict,
+    HintSignPanderaAny,
+    HintSignPattern,
+    HintSignPep557DataclassInitVar,
+    HintSignPep585BuiltinSubscriptedUnknown,
+    HintSignPep695TypeAlias,
+    HintSignReversible,
+    HintSignSelf,
+    HintSignSequence,
+    HintSignSet,
+    HintSignSized,
+    HintSignTuple,
+    HintSignType,
+    HintSignTypeAlias,
+    HintSignTypeGuard,
+    HintSignTypeVar,
+    HintSignTypedDict,
+    HintSignValuesView,
+)
+from beartype._data.hint.datahinttyping import TypeStack
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.hint.nonpep.mod.utilmodnumpy import (
+    reduce_hint_numpy_ndarray)
+from beartype._util.hint.nonpep.mod.utilmodpandera import (
+    reduce_hint_pandera)
+from beartype._util.hint.pep.proposal.pep484.utilpep484 import (
+    reduce_hint_pep484_deprecated,
+    reduce_hint_pep484_none,
+)
+from beartype._util.hint.pep.proposal.pep484.utilpep484generic import (
+    reduce_hint_pep484_generic)
+from beartype._util.hint.pep.proposal.pep484.utilpep484newtype import (
+    reduce_hint_pep484_newtype)
+from beartype._util.hint.pep.proposal.pep484.utilpep484typevar import (
+    reduce_hint_pep484_typevar)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585type import (
+    reduce_hint_pep484585_type)
+from beartype._util.hint.pep.proposal.utilpep557 import (
+    reduce_hint_pep557_initvar)
+from beartype._util.hint.pep.proposal.utilpep585 import (
+    reduce_hint_pep585_builtin_subscripted_unknown)
+from beartype._util.hint.pep.proposal.utilpep589 import reduce_hint_pep589
+from beartype._util.hint.pep.proposal.utilpep591 import reduce_hint_pep591
+from beartype._util.hint.pep.proposal.utilpep593 import reduce_hint_pep593
+from beartype._util.hint.pep.proposal.utilpep613 import reduce_hint_pep613
+from beartype._util.hint.pep.proposal.utilpep647 import reduce_hint_pep647
+from beartype._util.hint.pep.proposal.utilpep673 import reduce_hint_pep673
+from beartype._util.hint.pep.proposal.utilpep675 import reduce_hint_pep675
+from beartype._util.hint.pep.proposal.utilpep695 import reduce_hint_pep695
+from beartype._util.hint.pep.utilpepget import get_hint_pep_sign_or_none
+from beartype._util.hint.pep.utilpepreduce import reduce_hint_pep_unsigned
+from beartype._util.utilobject import SENTINEL
+from collections.abc import Callable
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint(
+    # Mandatory parameters.
+    hint: Any,
+    conf: BeartypeConf,
+
+    # Optional parameters.
+    cls_stack: TypeStack = None,
+    pith_name: Optional[str] = None,
+    exception_prefix: str = '',
+) -> object:
+    '''
+    Lower-level type hint reduced (i.e., converted) from the passed higher-level
+    type hint if this hint is reducible *or* this hint as is otherwise (i.e., if
+    this hint is irreducible).
+
+    This reducer *cannot* be meaningfully memoized, since multiple passed
+    parameters (e.g., ``pith_name``, ``cls_stack``) are typically isolated to a
+    handful of callables across the codebase currently being decorated by
+    :mod:`beartype`. Memoizing this reducer would needlessly consume space and
+    time. To improve efficiency, this reducer is instead implemented in terms of
+    two lower-level private reducers:
+
+    * The memoized :func:`._reduce_hint_cached` reducer, responsible for
+      efficiently reducing *most* (but not all) type hints.
+    * The unmemoized :func:`._reduce_hint_uncached` reducer, responsible for
+      inefficiently reducing the small subset of type hints contextually
+      requiring these problematic parameters.
+
+    Parameters
+    ----------
+    hint : Any
+        Type hint to be possibly reduced.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+    pith_name : Optional[str], optional
+        Either:
+
+        * If this hint annotates a parameter of some callable, the name of that
+          parameter.
+        * If this hint annotates the return of some callable, ``"return"``.
+        * Else, :data:`None`.
+
+        Defaults to :data:`None`.
+    exception_prefix : str, optional
+        Substring prefixing exception messages raised by this function. Defaults
+        to the empty string.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If the passed hint is reducible, another hint reduced from this hint.
+        * Else, this hint as is unmodified.
+    '''
+
+    # Previously reduced instance of this hint, initialized to the sentinel to
+    # guarantee that the passed hint is *NEVER* equal to the previously reduced
+    # instance of this hint unless actually reduced below. This is necessary, as
+    # "None" is a valid type hint reduced to "type(None)" below.
+    hint_prev: object = SENTINEL
+
+    # Repeatedly reduce this hint to increasingly irreducible hints until this
+    # hint is no longer reducible.
+    while True:
+        # This possibly contextual hint inefficiently reduced to another hint.
+        #
+        # Note that we intentionally reduce lower-level contextual hints
+        # *BEFORE* reducing higher-level context-free hints. In theory, order of
+        # reduction *SHOULD* be insignificant; in practice, we suspect
+        # unforeseen and unpredictable interactions between these two
+        # reductions. To reduce the likelihood of fire-breathing dragons here,
+        # we reduce lower-level hints first.
+        hint = _reduce_hint_uncached(
+            hint=hint,
+            conf=conf,
+            pith_name=pith_name,
+            cls_stack=cls_stack,
+            exception_prefix=exception_prefix,
+        )
+
+        # This possibly context-free hint efficiently reduced to another hint.
+        hint = _reduce_hint_cached(hint, conf, exception_prefix)
+
+        # If the current and previously reduced instances of this hint are
+        # identical, the above reductions preserved this hint as is rather than
+        # reducing this hint, implying this hint to irreducible. In this case,
+        # stop reducing.
+        if hint is hint_prev:
+            break
+        # Else, the current and previously reduced instances of this hint
+        # differ, implying this hint to still be reducible. In this case,
+        # continue reducing.
+
+        # Previously reduced instance of this hint.
+        hint_prev = hint
+
+    # Return this possibly reduced hint.
+    return hint
+
+# ....................{ PRIVATE ~ reducers                 }....................
+def _reduce_hint_uncached(
+    hint: Any,
+    conf: BeartypeConf,
+    cls_stack: TypeStack,
+    pith_name: Optional[str],
+    exception_prefix: str,
+) -> object:
+    '''
+    Lower-level **contextual type hint** (i.e., type hint contextually dependent
+    on the kind of class, attribute, callable parameter, or callable return
+    annotated by this hint) inefficiently reduced (i.e., converted) from the
+    passed higher-level context-free type hint if this hint is reducible *or*
+    this hint as is otherwise (i.e., if this hint is irreducible).
+
+    This reducer *cannot* be meaningfully memoized, since multiple passed
+    parameters (e.g., ``pith_name``, ``cls_stack``) are typically isolated to a
+    handful of callables across the codebase currently being decorated by
+    :mod:`beartype`. Thankfully, this reducer is responsible for reducing only a
+    small subset of type hints requiring these problematic parameters.
+
+    Parameters
+    ----------
+    hint : Any
+        Type hint to be possibly reduced.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    cls_stack : TypeStack
+        **Type stack** (i.e., either tuple of zero or more arbitrary types *or*
+        :data:`None`). See also the :func:`.beartype_object` decorator.
+    pith_name : Optional[str]
+        Either:
+
+        * If this hint annotates a parameter of some callable, the name of that
+          parameter.
+        * If this hint annotates the return of some callable, ``"return"``.
+        * Else, :data:`None`.
+    exception_prefix : str
+        Substring prefixing exception messages raised by this function.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If the passed hint is reducible, another hint reduced from this hint.
+        * Else, this hint as is unmodified.
+    '''
+
+    # Sign uniquely identifying this hint if this hint is identifiable *OR*
+    # "None" otherwise (e.g., if this hint is merely an isinstanceable class).
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # Callable reducing this hint if a callable reducing hints of this sign was
+    # previously registered *OR* "None" otherwise (i.e., if *NO* such callable
+    # was registered, in which case this hint is preserved as is).
+    hint_reducer = _HINT_SIGN_TO_REDUCE_HINT_UNCACHED.get(hint_sign)
+
+    # If a callable reducing hints of this sign was previously registered,
+    # reduce this hint to another hint via this callable.
+    if hint_reducer is not None:  # type: ignore[call-arg]
+        # print(f'Reducing hint {repr(hint)} to...')
+        hint = hint_reducer(
+            hint=hint,  # pyright: ignore[reportGeneralTypeIssues]
+            conf=conf,
+            cls_stack=cls_stack,
+            pith_name=pith_name,
+            exception_prefix=exception_prefix,
+        )
+        # print(f'...{repr(hint)}.')
+    # Else, *NO* such callable was registered. Preserve this hint as is, you!
+
+    # Return this possibly reduced hint.
+    return hint
+
+
+@callable_cached
+def _reduce_hint_cached(
+    hint: Any,
+    conf: BeartypeConf,
+    exception_prefix: str,
+) -> object:
+    '''
+    Lower-level **context-free type hint** (i.e., type hint *not* contextually
+    dependent on the kind of class, attribute, callable parameter, or callable
+    return annotated by this hint) efficiently reduced (i.e., converted) from
+    the passed higher-level context-free type hint if this hint is reducible
+    *or* this hint as is otherwise (i.e., if this hint is irreducible).
+
+    This reducer is memoized for efficiency. Thankfully, this reducer is
+    responsible for reducing *most* (but not all) type hints.
+
+    Parameters
+    ----------
+    hint : Any
+        Type hint to be possibly reduced.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_prefix : str
+        Substring prefixing exception messages raised by this function.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If the passed hint is reducible, another hint reduced from this hint.
+        * Else, this hint as is unmodified.
+    '''
+
+    # Attempt to...
+    try:
+        # If this beartype configuration coercively overrides this source hint
+        # with a corresponding target hint, do so now *BEFORE* attempting to
+        # reduce this hint via standard reduction heuristics. User preferences
+        # take preference over standards.
+        #
+        # Note that this one-liner looks ridiculous, but actually works. More
+        # importantly, this is the fastest way to accomplish this. Flex!
+        hint = conf.hint_overrides.get(hint, hint)
+    # If doing so raises a "TypeError", this source hint is unhashable and thus
+    # inapplicable for hint overriding. In this case, silently ignore this hint.
+    except TypeError:
+        pass
+
+    # Sign uniquely identifying this hint if this hint is identifiable *OR*
+    # "None" otherwise (e.g., if this hint is merely an isinstanceable class).
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # Callable reducing this hint if a callable reducing hints of this sign was
+    # previously registered *OR* "None" otherwise (i.e., if *NO* such callable
+    # was registered, in which case this hint is preserved as is).
+    hint_reducer = _HINT_SIGN_TO_REDUCE_HINT_CACHED.get(hint_sign)
+
+    # If a callable reducing hints of this sign was previously registered,
+    # reduce this hint to another hint via this callable.
+    if hint_reducer is not None:
+        hint = hint_reducer(  # type: ignore[call-arg]
+            hint=hint,  # pyright: ignore[reportGeneralTypeIssues]
+            conf=conf,
+            exception_prefix=exception_prefix,
+        )
+    # Else, *NO* such callable was registered. Preserve this hint as is, you!
+
+    # Return this possibly reduced hint.
+    return hint
+
+# ....................{ PRIVATE ~ hints                    }....................
+# Note that these type hints would ideally be defined with the mypy-specific
+# "callback protocol" pseudostandard, documented here:
+#     https://mypy.readthedocs.io/en/stable/protocols.html#callback-protocols
+#
+# Doing so would enable static type-checkers to type-check that the values of
+# these dictionaries are valid reducer functions. Sadly, that pseudostandard is
+# absurdly strict to the point of practical uselessness. Attempting to conform
+# to that pseudostandard would require refactoring *ALL* reducer functions to
+# explicitly define the same signature. However, we have intentionally *NOT*
+# done that. Why? Doing so would substantially increase the fragility of this
+# API by preventing us from readily adding and removing infrequently required
+# parameters (e.g., "cls_stack", "pith_name"). Callback protocols suck, frankly.
+_HintSignToReduceHintCached = Dict[Optional[HintSign], Callable]
+'''
+PEP-compliant type hint matching a **cached reducer dictionary** (i.e.,
+mapping from each sign uniquely identifying various type hints to a memoized
+callable reducing those higher- to lower-level hints).
+'''
+
+
+_HintSignToReduceHintUncached = _HintSignToReduceHintCached
+'''
+PEP-compliant type hint matching an **uncached reducer dictionary** (i.e.,
+mapping from each sign uniquely identifying various type hints to an unmemoized
+callable reducing those higher- to lower-level hints).
+'''
+
+# ....................{ PRIVATE ~ dicts                    }....................
+_HINT_SIGN_TO_REDUCE_HINT_CACHED: _HintSignToReduceHintCached = {
+    # ..................{ NON-PEP                            }..................
+    # If this hint is identified by *NO* sign, this hint is either an
+    # isinstanceable type *OR* a hint unrecognized by beartype. In either case,
+    # apply the following reductions:
+    #
+    # * If this configuration enables support for the PEP 484-compliant implicit
+    #   numeric tower:
+    #   * Expand the "float" type hint to the "float | int" union.
+    #   * Expand the "complex" type hint to the "complex | float | int" union.
+    None: reduce_hint_pep_unsigned,
+
+    # ..................{ PEP 484                            }..................
+    # If this hint is a PEP 484-compliant IO generic base class *AND* the active
+    # Python interpreter targets Python >= 3.8 and thus supports PEP
+    # 544-compliant protocols, reduce this functionally useless hint to the
+    # corresponding functionally useful beartype-specific PEP 544-compliant
+    # protocol implementing this hint.
+    #
+    # Note that PEP 484-compliant IO generic base classes are technically usable
+    # under Python < 3.8 (e.g., by explicitly subclassing those classes from
+    # third-party classes). Ergo, we can neither safely emit warnings nor raise
+    # exceptions on visiting these classes under *ANY* Python version.
+    HintSignGeneric: reduce_hint_pep484_generic,
+
+    # If this hint is a PEP 484-compliant new type, reduce this new type to the
+    # user-defined class aliased by this new type.
+    HintSignNewType: reduce_hint_pep484_newtype,
+
+    # If this is the PEP 484-compliant "None" singleton, reduce this hint to
+    # the type of that singleton. While *NOT* explicitly defined by the
+    # "typing" module, PEP 484 explicitly supports this singleton:
+    #     When used in a type hint, the expression None is considered
+    #     equivalent to type(None).
+    #
+    # The "None" singleton is used to type callables lacking an explicit
+    # "return" statement and thus absurdly common.
+    HintSignNone: reduce_hint_pep484_none,
+
+    #FIXME: Remove this branch *AFTER* deeply type-checking type variables.
+    # If this type variable was parametrized by one or more bounded
+    # constraints, reduce this hint to these constraints.
+    HintSignTypeVar: reduce_hint_pep484_typevar,
+
+    # ..................{ PEP (484|585)                      }..................
+    # If this hint is a PEP 484- or 585-compliant subclass type hint subscripted
+    # by an ignorable child type hint (e.g., "object", "typing.Any"), silently
+    # ignore this argument by reducing this hint to the "type" superclass.
+    #
+    # Note that:
+    # * This reduction could be performed elsewhere, but remains here as doing
+    #   so here dramatically simplifies matters elsewhere.
+    # * This reduction *CANNOT* be performed by the is_hint_ignorable() tester,
+    #   as subclass type hints subscripted by ignorable child type hints are
+    #   *NOT* ignorable; they're reducible to the "type" superclass.
+    HintSignType: reduce_hint_pep484585_type,
+
+    # ..................{ PEP 557                            }..................
+    # If this hint is a dataclass-specific initialization-only instance
+    # variable (i.e., instance of the PEP 557-compliant "dataclasses.InitVar"
+    # class introduced by Python 3.8.0), reduce this functionally useless hint
+    # to the functionally useful child type hint subscripting this parent hint.
+    HintSignPep557DataclassInitVar: reduce_hint_pep557_initvar,
+
+    # ..................{ PEP 585                            }..................
+    # If this hint is a PEP 585-compliant unrecognized subscripted builtin type
+    # hint (i.e., C-based type hint that is *NOT* an isinstanceable type,
+    # instantiated by subscripting a pure-Python origin class subclassing the
+    # C-based "types.GenericAlias" type where that origin class is unrecognized
+    # by :mod:`beartype` and thus PEP-noncompliant), reduce this C-based type
+    # hint (which is *NOT* type-checkable as is) to its unsubscripted
+    # pure-Python origin class (which is type-checkable as is). Examples include
+    # "os.PathLike[...]" and "weakref.weakref[...]" type hints.
+    HintSignPep585BuiltinSubscriptedUnknown: (
+        reduce_hint_pep585_builtin_subscripted_unknown),
+
+    # ..................{ PEP 589                            }..................
+    #FIXME: Remove *AFTER* deeply type-checking typed dictionaries. For now,
+    #shallowly type-checking such hints by reduction to untyped dictionaries
+    #remains the sanest temporary work-around.
+
+    # If this hint is a PEP 589-compliant typed dictionary (i.e.,
+    # "typing.TypedDict" or "typing_extensions.TypedDict" subclass), silently
+    # ignore all child type hints annotating this dictionary by reducing this
+    # hint to the "Mapping" superclass. Yes, "Mapping" rather than "dict". By
+    # PEP 589 edict:
+    #     First, any TypedDict type is consistent with Mapping[str, object].
+    #
+    # Typed dictionaries are largely discouraged in the typing community, due to
+    # their non-standard semantics and syntax.
+    HintSignTypedDict: reduce_hint_pep589,
+
+    # ..................{ PEP 591                            }..................
+    #FIXME: Remove *AFTER* deeply type-checking final type hints.
+
+    # If this hint is a PEP 591-compliant "typing.Final[...]" type hint,
+    # silently reduce this hint to its subscripted argument (e.g., from
+    # "typing.Final[int]" to merely "int").
+    HintSignFinal: reduce_hint_pep591,
+
+    # ..................{ PEP 593                            }..................
+    # If this hint is a PEP 593-compliant beartype-agnostic type metahint,
+    # ignore all annotations on this hint by reducing this hint to the
+    # lower-level hint it annotates.
+    HintSignAnnotated: reduce_hint_pep593,
+
+    # ..................{ PEP 675                            }..................
+    #FIXME: Remove *AFTER* deeply type-checking literal strings. Note that doing
+    #so will prove extremely non-trivial or possibly even infeasible, suggesting
+    #we will probably *NEVER* deeply type-check literal strings. It's *NOT*
+    #simply a matter of efficiently parsing ASTs at runtime; it's that as well
+    #as correctly transitively inferring literal strings across operations and
+    #calls, which effectively requires parsing the entire codebase and
+    #constructing an in-memory graph of all type relations. See also:
+    #    https://peps.python.org/pep-0675/#inferring-literalstring
+
+    # If this hint is a PEP 675-compliant "typing.LiteralString" type hint,
+    # reduce this hint to the standard "str" type.
+    HintSignLiteralString: reduce_hint_pep675,
+
+    # ..................{ PEP 695                            }..................
+    # If this hint is a PEP 695-compliant "type" alias, reduce this alias to the
+    # underlying hint lazily referred to by this alias.
+    HintSignPep695TypeAlias: reduce_hint_pep695,
+
+    # ..................{ NON-PEP ~ numpy                    }..................
+    # If this hint is a PEP-noncompliant typed NumPy array (e.g.,
+    # "numpy.typing.NDArray[np.float64]"), reduce this hint to the equivalent
+    # well-supported beartype validator.
+    HintSignNumpyArray: reduce_hint_numpy_ndarray,
+
+    # ..................{ NON-PEP ~ pandera                  }..................
+    # If this hint is *ANY* PEP-noncompliant Pandera type hint (e.g.,
+    # "pandera.typing.DataFrame[...]"), reduce this hint to an arbitrary
+    # PEP-compliant ignorable type hint. See this reducer for commentary.
+    HintSignPanderaAny: reduce_hint_pandera,
+}
+'''
+Dictionary mapping from each sign uniquely identifying PEP-compliant type hints
+to that sign's **cached reducer** (i.e., low-level function efficiently memoized
+by the :func:`.callable_cached` decorator reducing those higher- to lower-level
+hints).
+
+Each value of this dictionary is expected to have a signature resembling:
+
+.. code-block:: python
+
+   def reduce_hint_pep{pep_number}(
+       hint: object,
+       conf: BeartypeConf,
+       pith_name: Optional[str],
+       exception_prefix: str,
+       *args, **kwargs
+   ) -> object:
+
+Note that:
+
+* Reducers should explicitly accept *only* those parameters they explicitly
+  require. Ergo, a reducer requiring *only* the ``hint`` parameter should omit
+  all of the other parameters referenced above.
+* Reducers do *not* need to validate the passed type hint as being of the
+  expected sign. By design, a reducer is only ever passed a type hint of the
+  expected sign.
+* Reducers should *not* be memoized (e.g., by the
+  ``callable_cached`` decorator). Since the higher-level :func:`.reduce_hint`
+  function that is the sole entry point to calling all lower-level reducers is
+  itself memoized, reducers themselves neither require nor benefit from
+  memoization. Moreover, even if they did either require or benefit from
+  memoization, they couldn't be -- at least, not directly. Why? Because
+  :func:`.reduce_hint` necessarily passes keyword arguments to all reducers. But
+  memoized functions *cannot* receive keyword arguments (without destroying
+  efficiency and thus the entire point of memoization).
+'''
+
+
+_HINT_SIGN_TO_REDUCE_HINT_UNCACHED: _HintSignToReduceHintUncached = {
+    # ..................{ PEP 484                            }..................
+    # Preserve deprecated PEP 484-compliant type hints as is while emitting one
+    # non-fatal deprecation warning for each.
+    #
+    # Note that, to ensure that one such warning is emitted for each such hint,
+    # these reducers are intentionally uncached rather than cached.
+    HintSignAbstractSet: reduce_hint_pep484_deprecated,
+    HintSignAsyncContextManager: reduce_hint_pep484_deprecated,
+    HintSignAsyncGenerator: reduce_hint_pep484_deprecated,
+    HintSignAsyncIterable: reduce_hint_pep484_deprecated,
+    HintSignAsyncIterator: reduce_hint_pep484_deprecated,
+    HintSignAwaitable: reduce_hint_pep484_deprecated,
+    HintSignByteString: reduce_hint_pep484_deprecated,
+    HintSignCallable: reduce_hint_pep484_deprecated,
+    HintSignChainMap: reduce_hint_pep484_deprecated,
+    HintSignCollection: reduce_hint_pep484_deprecated,
+    HintSignContainer: reduce_hint_pep484_deprecated,
+    HintSignContextManager: reduce_hint_pep484_deprecated,
+    HintSignCoroutine: reduce_hint_pep484_deprecated,
+    HintSignCounter: reduce_hint_pep484_deprecated,
+    HintSignDefaultDict: reduce_hint_pep484_deprecated,
+    HintSignDeque: reduce_hint_pep484_deprecated,
+    HintSignDict: reduce_hint_pep484_deprecated,
+    HintSignFrozenSet: reduce_hint_pep484_deprecated,
+    HintSignGenerator: reduce_hint_pep484_deprecated,
+    HintSignHashable: reduce_hint_pep484_deprecated,
+    HintSignItemsView: reduce_hint_pep484_deprecated,
+    HintSignIterable: reduce_hint_pep484_deprecated,
+    HintSignIterator: reduce_hint_pep484_deprecated,
+    HintSignKeysView: reduce_hint_pep484_deprecated,
+    HintSignList: reduce_hint_pep484_deprecated,
+    HintSignMappingView: reduce_hint_pep484_deprecated,
+    HintSignMapping: reduce_hint_pep484_deprecated,
+    HintSignMatch: reduce_hint_pep484_deprecated,
+    HintSignMutableMapping: reduce_hint_pep484_deprecated,
+    HintSignMutableSequence: reduce_hint_pep484_deprecated,
+    HintSignMutableSet: reduce_hint_pep484_deprecated,
+    HintSignOrderedDict: reduce_hint_pep484_deprecated,
+    HintSignPattern: reduce_hint_pep484_deprecated,
+    HintSignReversible: reduce_hint_pep484_deprecated,
+    HintSignSequence: reduce_hint_pep484_deprecated,
+    HintSignSet: reduce_hint_pep484_deprecated,
+    HintSignSized: reduce_hint_pep484_deprecated,
+    HintSignTuple: reduce_hint_pep484_deprecated,
+    HintSignType: reduce_hint_pep484_deprecated,
+    HintSignValuesView: reduce_hint_pep484_deprecated,
+
+    # ..................{ PEP 613                            }..................
+    # Reduce PEP 613-compliant "typing.TypeAlias" type hints to an arbitrary
+    # ignorable type hint *AND* emit a non-fatal deprecation warning.
+    #
+    # Note that, to ensure that one such warning is emitted for each such hint,
+    # this reducer is intentionally uncached rather than cached.
+    HintSignTypeAlias: reduce_hint_pep613,
+
+    # ..................{ PEP 647                            }..................
+    # Reduce PEP 647-compliant "typing.TypeGuard[...]" type hints to either:
+    # * If this hint annotates the return of some callable, the "bool" type.
+    # * Else, raise an exception.
+    HintSignTypeGuard: reduce_hint_pep647,
+
+    # ..................{ PEP 673                            }..................
+    # Reduce PEP 673-compliant "typing.Self" type hints to either:
+    # * If @beartype is currently decorating a class, the most deeply nested
+    #   class on the passed type stack.
+    # * Else, raise an exception.
+    HintSignSelf: reduce_hint_pep673,
+}
+'''
+Dictionary mapping from each sign uniquely identifying various type hints to
+that sign's **uncached reducer** (i.e., low-level function whose reduction
+decision contextually depends on the currently decorated callable and thus
+*cannot* be efficiently memoized by the :func:`.callable_cached` decorator).
+
+See Also
+--------
+:data:`._HINT_SIGN_TO_REDUCE_HINT_CACHED`
+    Further details.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/convert/convsanify.py
@@ -0,0 +1,423 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-agnostic type hint sanitizers** (i.e., high-level callables
+converting type hints from one format into another, either permanently or
+temporarily and either losslessly or in a lossy manner).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    Optional,
+)
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.convert.convcoerce import (
+    coerce_func_hint_root,
+    coerce_hint_any,
+    coerce_hint_root,
+)
+from beartype._check.convert.convreduce import reduce_hint
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+from beartype._data.hint.datahinttyping import TypeStack
+from beartype._util.cache.map.utilmapbig import CacheUnboundedStrong
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585func import (
+    reduce_hint_pep484585_func_return)
+from beartype._util.hint.utilhinttest import is_hint_ignorable
+
+# ....................{ SANIFIERS ~ root                   }....................
+#FIXME: Unit test us up, please.
+def sanify_hint_root_func(
+    # Mandatory parameters.
+    hint: object,
+    pith_name: str,
+    bear_call: BeartypeCall,
+
+    # Optional parameters.
+    exception_prefix: str = EXCEPTION_PLACEHOLDER,
+) -> object:
+    '''
+    PEP-compliant type hint sanified (i.e., sanitized) from the passed **root
+    type hint** (i.e., possibly PEP-noncompliant type hint annotating the
+    parameter or return with the passed name of the passed callable) if this
+    hint is reducible *or* this hint as is otherwise (i.e., if this hint is
+    irreducible).
+
+    Specifically, this function:
+
+    * If this hint is a **PEP-noncompliant tuple union** (i.e., tuple of one or
+      more standard classes and forward references to standard classes):
+
+      * Coerces this tuple union into the equivalent :pep:`484`-compliant
+        union.
+      * Replaces this tuple union in the ``__annotations__`` dunder tuple of
+        this callable with this :pep:`484`-compliant union.
+      * Returns this :pep:`484`-compliant union.
+
+    * Else if this hint is already PEP-compliant, preserves and returns this
+      hint unmodified as is.
+    * Else (i.e., if this hint is neither PEP-compliant nor -noncompliant and
+      thus invalid as a type hint), raise an exception.
+
+    Caveats
+    -------
+    This sanifier *cannot* be meaningfully memoized, since the passed type hint
+    is *not* guaranteed to be cached somewhere. Only functions passed cached
+    type hints can be meaningfully memoized. Even if this function *could* be
+    meaningfully memoized, there would be no benefit; this function is only
+    called once per parameter or return of the currently decorated callable.
+
+    This sanifier is intended to be called *after* all possibly
+    :pep:`563`-compliant **deferred type hints** (i.e., type hints persisted as
+    evaluatable strings rather than actual type hints) annotating this callable
+    if any have been evaluated into actual type hints.
+
+    Parameters
+    ----------
+    hint : object
+        Possibly PEP-noncompliant root type hint to be sanified.
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+    pith_name : str
+        Either:
+
+        * If this hint annotates a parameter, the name of that parameter.
+        * If this hint annotates the return, ``"return"``.
+    bear_call : BeartypeCall
+        Decorated callable directly annotated by this hint.
+    exception_prefix : str, optional
+        Human-readable label prefixing exception messages raised by this
+        function. Defaults to :data:`EXCEPTION_PLACEHOLDER`.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this hint is PEP-noncompliant, a PEP-compliant type hint converted
+          from this hint.
+        * If this hint is PEP-compliant, this hint unmodified as is.
+
+    Raises
+    ------
+    BeartypeDecorHintNonpepException
+        If this object is neither:
+
+        * A PEP-noncompliant type hint.
+        * A supported PEP-compliant type hint.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the sanify_hint_root_statement() sanitizer.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # PEP-compliant type hint coerced (i.e., permanently converted in the
+    # annotations dunder dictionary of the passed callable) from this possibly
+    # PEP-noncompliant type hint if this hint is coercible *OR* this hint as is
+    # otherwise. Since the passed hint is *NOT* necessarily PEP-compliant,
+    # perform this coercion *BEFORE* validating this hint to be PEP-compliant.
+    hint = bear_call.func_wrappee.__annotations__[pith_name] = (
+        coerce_func_hint_root(
+            hint=hint,
+            pith_name=pith_name,
+            bear_call=bear_call,
+            exception_prefix=exception_prefix,
+        )
+    )
+
+    # If this hint annotates the return, reduce this hint to a simpler hint if
+    # this hint is either PEP 484- or 585-compliant *AND* requires reduction
+    # (e.g., from "Coroutine[None, None, str]" to just "str"). Raise an
+    # exception if this hint is contextually invalid for this callable (e.g.,
+    # generator whose return is *NOT* annotated as "Generator[...]").
+    #
+    # Perform this reduction *BEFORE* performing subsequent tests (e.g., to
+    # accept "Coroutine[None, None, typing.NoReturn]" as expected).
+    #
+    # Note that this logic *ONLY* pertains to callables (rather than statements)
+    # and is thus *NOT* performed by the sanify_hint_root_statement() sanitizer.
+    if pith_name == ARG_NAME_RETURN:
+        hint = reduce_hint_pep484585_func_return(
+            func=bear_call.func_wrappee, exception_prefix=exception_prefix)
+    # Else, this hint annotates a parameter.
+
+    # Reduce this hint to a lower-level PEP-compliant type hint if this hint is
+    # reducible *OR* this hint as is otherwise. Reductions simplify subsequent
+    # logic elsewhere by transparently converting non-trivial hints (e.g.,
+    # numpy.typing.NDArray[...]) into semantically equivalent trivial hints
+    # (e.g., beartype validators).
+    #
+    # Whereas the above coercion permanently persists for the duration of the
+    # active Python process (i.e., by replacing the original type hint in the
+    # annotations dunder dictionary of this callable), this reduction only
+    # temporarily persists for the duration of the current call stack. Why?
+    # Because hints explicitly coerced above are assumed to be either:
+    # * PEP-noncompliant and thus harmful (in the general sense).
+    # * PEP-compliant but semantically deficient and thus equally harmful (in
+    #   the general sense).
+    #
+    # In either case, coerced type hints are generally harmful in *ALL* possible
+    # contexts for *ALL* possible consumers (including other competing runtime
+    # type-checkers). Reduced type hints, however, are *NOT* harmful in any
+    # sense whatsoever; they're simply non-trivial for @beartype to support in
+    # their current form and thus temporarily reduced in-memory into a more
+    # convenient form for beartype-specific type-checking purposes elsewhere.
+    #
+    # Note that parameters are intentionally passed positionally to both
+    # optimize memoization efficiency and circumvent memoization warnings.
+    hint = reduce_hint(
+        hint=hint,
+        conf=bear_call.conf,
+        cls_stack=bear_call.cls_stack,
+        pith_name=pith_name,
+        exception_prefix=exception_prefix,
+    )
+
+    # Return this sanified hint.
+    return hint
+
+
+#FIXME: Unit test us up, please.
+def sanify_hint_root_statement(
+    hint: object,
+    conf: BeartypeConf,
+    exception_prefix: str,
+) -> object:
+    '''
+    PEP-compliant type hint sanified (i.e., sanitized) from the passed **root
+    type hint** (i.e., possibly PEP-noncompliant type hint that has *no* parent
+    type hint) if this hint is reducible *or* this hint as is otherwise (i.e.,
+    if this hint is irreducible).
+
+    This sanifier is principally intended to be called by a **statement-level
+    type-checker factory** (i.e., a function creating and returning a runtime
+    type-checker type-checking this hint, outside the context of any standard
+    type hinting annotation like a user-defined class variable, callable
+    parameter or return, or assignment statement). Such factories include:
+
+    * The private :func:`beartype._check.checkmake.make_func_tester` factory,
+      internally called by:
+
+      * The public :func:`beartype.door.is_bearable` function.
+      * The public :meth:`beartype.door.TypeHint.is_bearable` method.
+
+    Parameters
+    ----------
+    hint : object
+        Possibly PEP-noncompliant root type hint to be sanified.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this hint is PEP-noncompliant, a PEP-compliant type hint converted
+          from this hint.
+        * If this hint is PEP-compliant, this hint unmodified as is.
+
+    Raises
+    ------
+    BeartypeDecorHintNonpepException
+        If this object is neither:
+
+        * A PEP-noncompliant type hint.
+        * A supported PEP-compliant type hint.
+
+    See Also
+    --------
+    :func:`.sanify_hint_root_func`
+        Further details.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the sanify_hint_root_func() sanitizer, please.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # PEP-compliant type hint coerced from this possibly PEP-noncompliant type
+    # hint if this hint is coercible *OR* this hint as is otherwise. Since the
+    # passed hint is *NOT* necessarily PEP-compliant, perform this coercion
+    # *BEFORE* validating this hint to be PEP-compliant.
+    hint = coerce_hint_root(hint=hint, exception_prefix=exception_prefix)
+
+    # Reduce this hint to a lower-level PEP-compliant type hint if this hint is
+    # reducible *OR* this hint as is otherwise. See
+    # sanify_hint_root_func() for further commentary.
+    hint = reduce_hint(hint=hint, conf=conf, exception_prefix=exception_prefix)
+
+    # Return this sanified hint.
+    return hint
+
+# ....................{ SANIFIERS ~ any                    }....................
+#FIXME: Unit test us up, please.
+def sanify_hint_child_if_unignorable_or_none(*args, **kwargs) -> Any:
+    '''
+    Type hint sanified (i.e., sanitized) from the passed **possibly insane child
+    type hint** (i.e., hint transitively subscripting the root type hint
+    annotating a parameter or return of the currently decorated callable) if
+    this hint is both reducible and ignorable, this hint unmodified if this hint
+    is both irreducible and ignorable, and :data:`None` otherwise (i.e., if this
+    hint is ignorable).
+
+    This high-level sanifier effectively chains the lower-level
+    :func:`sanify_hilt_child` sanifier and
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester into a
+    single unified function, streamlining sanification and ignorability
+    detection throughout the codebase.
+
+    Note that a :data:`None` return unambiguously implies this hint to be
+    ignorable, even if the passed hint is itself :data:`None`. Why? Because if
+    the passed hint were :data:`None`, then a :pep:`484`-compliant reducer will
+    internally reduce this hint to ``type(None)``. After reduction, *all* hints
+    are guaranteed to be non-:data:`None`.
+
+    Parameters
+    ----------
+    All passed arguments are passed as is to the lower-level
+    :func:`sanify_hilt_child` sanifier.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If the passed possibly insane child type hint is ignorable after
+          reduction to a sane child type hint, :data:`None`.
+        * Else, the sane child type hint to which this hint reduces.
+    '''
+
+    # Sane child hint sanified from this possibly insane child hint if this hint
+    # is reducible *OR* this hint as is otherwise (i.e., if irreducible).
+    hint_child = sanify_hint_child(*args, **kwargs)
+
+    # Return either "None" if this hint is ignorable or this hint otherwise.
+    return None if is_hint_ignorable(hint_child) else hint_child
+
+
+def sanify_hint_child(
+    # Mandatory parameters.
+    hint: object,
+    conf: BeartypeConf,
+    exception_prefix: str,
+
+    # Optional parameters.
+    cls_stack: TypeStack = None,
+    pith_name: Optional[str] = None,
+) -> Any:
+    '''
+    Type hint sanified (i.e., sanitized) from the passed **possibly insane child
+    type hint** (i.e., hint transitively subscripting the root type hint
+    annotating a parameter or return of the currently decorated callable) if
+    this hint is reducible *or* this hint unmodified otherwise (i.e., if this
+    hint is irreducible).
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be sanified.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_prefix : str
+        Substring prefixing exception messages raised by this function.
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+    pith_name : Optional[str], optional
+        Either:
+
+        * If this hint directly annotates a callable parameter (as the root type
+          hint of that parameter), the name of this parameter.
+        * If this hint directly annotates a callable return (as the root type
+          hint of that return), the magic string ``"return"``.
+        * Else, :data:`None`.
+
+        Defaults to :data:`None`.
+
+    Returns
+    -------
+    object
+        Type hint sanified from this possibly insane child type hint.
+    '''
+
+    # This sanifier covers the proper subset of logic performed by the
+    # sanify_hint_root_statement() sanifier applicable to child type hints.
+
+    # PEP-compliant type hint coerced (i.e., permanently converted in the
+    # annotations dunder dictionary of the passed callable) from this possibly
+    # PEP-noncompliant type hint if this hint is coercible *OR* this hint as is
+    # otherwise. Since the passed hint is *NOT* necessarily PEP-compliant,
+    # perform this coercion *BEFORE* validating this hint to be PEP-compliant.
+    hint = coerce_hint_any(hint)
+
+    # Return this hint reduced.
+    return reduce_hint(
+        hint=hint,
+        conf=conf,
+        cls_stack=cls_stack,
+        pith_name=pith_name,
+        exception_prefix=exception_prefix,
+    )
+
+# ....................{ PRIVATE ~ mappings                 }....................
+_HINT_REPR_TO_HINT = CacheUnboundedStrong()
+'''
+**Type hint cache** (i.e., thread-safe cache mapping from the machine-readable
+representations of all non-self-cached type hints to those hints).**
+
+This cache caches:
+
+* :pep:`585`-compliant type hints, which do *not* cache themselves.
+
+This cache does *not* cache:
+
+* Type hints declared by the :mod:`typing` module, which implicitly cache
+  themselves on subscription thanks to inscrutable metaclass magic.
+* :pep:`563`-compliant **deferred type hints** (i.e., type hints persisted as
+  evaluable strings rather than actual type hints). Ideally, this cache would
+  cache the evaluations of *all* deferred type hints. Sadly, doing so is
+  infeasible in the general case due to global and local namespace lookups
+  (e.g., ``Dict[str, int]`` only means what you think it means if an
+  importation resembling ``from typing import Dict`` preceded that type hint).
+
+Design
+------
+**This dictionary is intentionally thread-safe.** Why? Because this dictionary
+is used to modify the ``__attributes__`` dunder variable of arbitrary callables.
+Since most of those callables are either module- or class-scoped, that variable
+is effectively global. To prevent race conditions between competing threads
+contending over that global variable, this dictionary *must* be thread-safe.
+
+This dictionary is intentionally designed as a naive dictionary rather than a
+robust LRU cache, for the same reasons that callables accepting hints are
+memoized by the :func:`beartype._util.cache.utilcachecall.callable_cached`
+rather than the :func:`functools.lru_cache` decorator. Why? Because:
+
+* The number of different type hints instantiated across even worst-case
+  codebases is negligible in comparison to the space consumed by those hints.
+* The :attr:`sys.modules` dictionary persists strong references to all
+  callables declared by previously imported modules. In turn, the
+  ``func.__annotations__`` dunder dictionary of each such callable persists
+  strong references to all type hints annotating that callable. In turn, these
+  two statements imply that type hints are *never* garbage collected but
+  instead persisted for the lifetime of the active Python process. Ergo,
+  temporarily caching hints in an LRU cache is pointless, as there are *no*
+  space savings in dropping stale references to unused hints.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_errorcause.py
@@ -0,0 +1,517 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype type-checking error cause sleuth** (i.e., object recursively
+fabricating the human-readable string describing the failure of the pith
+associated with this object to satisfy this PEP-compliant type hint also
+associated with this object) classes.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: The recursive "ViolationCause" class strongly overlaps with the equally
+#recursive (and substantially superior) "beartype.door.TypeHint" class. Ideally:
+#* Define a new private "beartype.door._doorerror" submodule.
+#* Shift the "ViolationCause" class to
+#  "beartype.door._doorerror._TypeHintUnbearability".
+#* Shift the _TypeHintUnbearability.find_cause() method to a new
+#  *PRIVATE* TypeHint._find_cause() method.
+#* Preserve most of the remainder of the "_TypeHintUnbearability" class as a
+#  dataclass encapsulating metadata describing the current type-checking
+#  violation. That metadata (e.g., "cause_indent") is inappropriate for
+#  general-purpose type hints. Exceptions include:
+#  * "hint", "hint_sign", and "hint_childs" -- all of which are subsumed by the
+#    "TypeHint" dataclass and should thus be excised.
+#* Refactor the TypeHint._find_cause() method to accept an instance of
+#  the "_TypeHintUnbearability" dataclass: e.g.,
+#      class TypeHint(...):
+#          def _get_unbearability_cause_or_none(
+#              self, unbearability: _TypeHintUnbearability) -> Optional[str]:
+#              ...
+#* Refactor existing find_cause_*() getters (e.g.,
+#  find_cause_sequence_args_1(), find_cause_union()) into
+#  _get_unbearability_cause_or_none() methods of the corresponding "TypeHint"
+#  subclasses, please.
+#
+#This all seems quite reasonable. Now, let's see whether it is. *gulp*
+#FIXME: Actually, the above comment now ties directly into feature request #235.
+#Resolving the above comment mostly suffices to resolve #235. That said, the
+#above isn't *QUITE* right. It's pretty nice -- but we can do better. See the
+#following comment at #235 for that better:
+#    https://github.com/beartype/beartype/issues/235#issuecomment-1707127231
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeCallHintPepRaiseException
+from beartype.typing import (
+    Any,
+    Callable,
+    Optional,
+    Tuple,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.hint.datahinttyping import TypeStack
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_SUPPORTED_DEEP,
+    HINT_SIGNS_ORIGIN_ISINSTANCEABLE,
+)
+from beartype._util.hint.pep.utilpepget import (
+    get_hint_pep_args,
+    get_hint_pep_sign,
+)
+from beartype._util.hint.pep.utilpeptest import (
+    is_hint_pep,
+    is_hint_pep_args,
+)
+from beartype._check.convert.convsanify import (
+    sanify_hint_child_if_unignorable_or_none)
+
+# ....................{ CLASSES                            }....................
+class ViolationCause(object):
+    '''
+    **Type-checking error cause sleuth** (i.e., object recursively fabricating
+    the human-readable string describing the failure of the pith associated
+    with this object to satisfy this PEP-compliant type hint also associated
+    with this object).
+
+    Attributes
+    ----------
+    cause_indent : str
+        **Indentation** (i.e., string of zero or more spaces) preceding each
+        line of the string returned by this getter if this string spans
+        multiple lines *or* ignored otherwise (i.e., if this string is instead
+        embedded in the current line).
+    cause_str_or_none : Optional[str]
+        If this pith either:
+
+        * Violates this hint, a human-readable string describing this violation.
+        * Satisfies this hint, :data:`None`.
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all flags, options, settings, and other metadata configuring the
+        current decoration of the decorated callable or class).
+    exception_prefix : str
+        Human-readable label describing the parameter or return value from
+        which this object originates, typically embedded in exceptions raised
+        from this getter in the event of unexpected runtime failure.
+    func : Optional[Callable]
+        Either:
+
+        * If this violation originates from a decorated callable, that
+          callable.
+        * Else, :data:`None`.
+    hint : Any
+        Type hint to validate this object against.
+    hint_sign : Any
+        Either:
+
+        * If this hint is PEP-compliant, the sign identifying this hint.
+        * Else, :data:`None` otherwise.
+    hint_childs : Optional[Tuple]
+        Either:
+
+        * If this hint is PEP-compliant, the possibly empty tuple of all child
+          type hints subscripting (indexing) this hint.
+        * Else, :data:`None`.
+    pith : Any
+        Arbitrary object to be validated.
+    pith_name : Optional[str]
+        Either:
+
+        * If this hint directly annotates a callable parameter (as the root type
+          hint of that parameter), the name of this parameter.
+        * If this hint directly annotates a callable return (as the root type
+          hint of that return), the magic string ``"return"``.
+        * Else, :data:`None`.
+    random_int : Optional[int]
+        **Pseudo-random integer** (i.e., unsigned 32-bit integer
+        pseudo-randomly generated by the parent :func:`beartype.beartype`
+        wrapper function in type-checking randomly indexed container items by
+        the current call to that function) if that function generated such an
+        integer *or* ``None`` otherwise (i.e., if that function generated *no*
+        such integer). See the same parameter accepted by the higher-level
+        :func:`beartype._check.error.errorget.get_func_pith_violation`
+        function for further details.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot *ALL* instance variables defined on this object to both:
+    # * Prevent accidental declaration of erroneous instance variables.
+    # * Minimize space and time complexity.
+    __slots__ = (
+        'cause_indent',
+        'cause_str_or_none',
+        'cls_stack',
+        'conf',
+        'exception_prefix',
+        'func',
+        'hint',
+        'hint_sign',
+        'hint_childs',
+        'pith',
+        'pith_name',
+        'random_int',
+    )
+
+
+    _INIT_PARAM_NAMES = frozenset((
+        'cause_indent',
+        'cause_str_or_none',
+        'cls_stack',
+        'conf',
+        'exception_prefix',
+        'func',
+        'hint',
+        'pith',
+        'pith_name',
+        'random_int',
+    ))
+    '''
+    Frozen set of the names of all parameters accepted by the :meth:`init`
+    method, defined as a set to enable efficient membership testing.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Whenever adding, deleting, or renaming any parameter accepted by
+    # this method, make similar changes to the "_INIT_PARAM_NAMES" set above.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    def __init__(
+        self,
+
+        # Mandatory parameters.
+        cls_stack: TypeStack,
+        cause_indent: str,
+        conf: BeartypeConf,
+        exception_prefix: str,
+        func: Optional[Callable],
+        hint: Any,
+        pith: Any,
+        pith_name: Optional[str],
+        random_int: Optional[int],
+
+        # Optional parameters.
+        cause_str_or_none: Optional[str] = None,
+    ) -> None:
+        '''
+        Initialize this object.
+
+        Parameters
+        ----------
+        See the class docstring for a description of these parameters.
+        '''
+        assert isinstance(cls_stack, NoneTypeOr[tuple]), (
+            f'{repr(cls_stack)} neither tuple nor "None".')
+        assert isinstance(conf, BeartypeConf), (
+            f'{repr(conf)} not configuration.')
+        assert func is None or callable(func), (
+            f'{repr(func)} neither callable nor "None".')
+        assert isinstance(pith_name, NoneTypeOr[str]), (
+            f'{repr(pith_name)} not string or "None".')
+        assert isinstance(cause_indent, str), (
+            f'{repr(cause_indent)} not string.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+        assert isinstance(random_int, NoneTypeOr[int]), (
+            f'{repr(random_int)} not integer or "None".')
+        assert isinstance(cause_str_or_none, NoneTypeOr[str]), (
+            f'{repr(cause_str_or_none)} not string or "None".')
+
+        # Classify all passed parameters.
+        self.func = func
+        self.cls_stack = cls_stack
+        self.conf = conf
+        # self.hint = hint
+        self.pith = pith
+        self.pith_name = pith_name
+        self.cause_indent = cause_indent
+        self.exception_prefix = exception_prefix
+        self.random_int = random_int
+        self.cause_str_or_none = cause_str_or_none
+
+        # Nullify all remaining parameters for safety.
+        self.hint_sign: Any = None
+        self.hint_childs: Tuple = None  # type: ignore[assignment]
+
+        # Unignorable sane hint sanified from this possibly ignorable insane
+        # hint *OR* "None" otherwise (i.e., if this hint is ignorable).
+        #
+        # Note that this is a bit inefficient. Since child hints are already
+        # sanitized below, the sanitization performed by this assignment
+        # effectively reduces to a noop for all type hints *EXCEPT* the root
+        # type hint. Technically, this means this could be marginally optimized
+        # by externally sanitizing the root type hint in the "errorget"
+        # submodule. Pragmatically, doing so would only complicate an already
+        # overly complex workflow for little to no tangible gain.
+        self.hint = sanify_hint_child_if_unignorable_or_none(
+            hint=hint,
+            conf=self.conf,
+            cls_stack=self.cls_stack,
+            pith_name=self.pith_name,
+            exception_prefix=self.exception_prefix,
+        )
+
+        # If this hint is both...
+        if (
+            # Unignorable *AND*...
+            self.hint is not None and
+            # PEP-compliant...
+            is_hint_pep(self.hint)
+        ):
+            # Arbitrary object uniquely identifying this hint.
+            self.hint_sign = get_hint_pep_sign(self.hint)
+
+            # Tuple of the zero or more arguments subscripting this hint.
+            hint_childs_insane = get_hint_pep_args(self.hint)
+
+            # List of the zero or more possibly ignorable sane child hints
+            # subscripting this parent hint, initialized to the empty list.
+            hint_childs_sane = []
+
+            # For each possibly ignorable insane child hints subscripting this
+            # parent hint...
+            for hint_child_insane in hint_childs_insane:
+                # If this child hint is PEP-compliant...
+                #
+                # Note that arbitrary PEP-noncompliant arguments *CANNOT* be
+                # safely sanitized. Why? Because arbitrary arguments are *NOT*
+                # necessarily valid type hints. Consider the type hint
+                # "tuple[()]", where the argument "()" is invalid as a type hint
+                # but valid an argument to that type hint.
+                if is_hint_pep(hint_child_insane):
+                    # Unignorable sane child hint sanified from this possibly
+                    # ignorable insane child hint *OR* "None" otherwise (i.e.,
+                    # if this child hint is ignorable).
+                    hint_child_sane = sanify_hint_child_if_unignorable_or_none(
+                        hint=hint_child_insane,
+                        conf=self.conf,
+                        cls_stack=self.cls_stack,
+                        pith_name=self.pith_name,
+                        exception_prefix=self.exception_prefix,
+                    )
+                # Else, this child hint is PEP-noncompliant. In this case,
+                # preserve this child hint as is.
+                else:
+                    hint_child_sane = hint_child_insane
+
+                # Append this possibly ignorable sane child hint to this list.
+                hint_childs_sane.append(hint_child_sane)
+
+            # Tuple of the zero or more possibly ignorable sane child hints
+            # subscripting this parent hint, coerced from this list.
+            self.hint_childs = tuple(hint_childs_sane)
+        # Else, this hint is PEP-noncompliant (e.g., isinstanceable class).
+
+    # ..................{ GETTERS                            }..................
+    def find_cause(self) -> 'ViolationCause':
+        '''
+        Output cause describing whether the pith of this input cause either
+        satisfies or violates the type hint of this input cause.
+
+        Design
+        ------
+        This method is intentionally generalized to support objects both
+        satisfying and *not* satisfying hints as equally valid use cases. While
+        the parent
+        :func:`beartype._check.error.errorget.get_func_pith_violation` function
+        calling this method is *always* passed an object *not* satisfying the
+        passed hint, this method is under no such constraints. Why? Because this
+        method is also called to find which of an arbitrary number of objects
+        transitively nested in the object passed to
+        :func:`beartype._check.error.errorget.get_func_pith_violation` fails to
+        satisfy the corresponding hint transitively nested in the hint passed to
+        that function.
+
+        For example, consider the PEP-compliant type hint ``List[Union[int,
+        str]]`` describing a list whose items are either integers or strings
+        and the list ``list(range(256)) + [False,]`` consisting of the integers
+        0 through 255 followed by boolean :data:`False`. Since that list is a
+        standard sequence, the
+        :func:`._peperrorsequence.find_cause_sequence_args_1`
+        function must decide the cause of this list's failure to comply with
+        this hint by finding the list item that is neither an integer nor a
+        string, implemented by by iteratively passing each list item to the
+        :func:`._peperrorunion.find_cause_union` function. Since
+        the first 256 items of this list are integers satisfying this hint,
+        :func:`._peperrorunion.find_cause_union` returns a dataclass instance
+        whose :attr:`cause` field is :data:`None` up to
+        :func:`._peperrorsequence.find_cause_sequence_args_1`
+        before finally finding the non-compliant boolean item and returning the
+        human-readable cause.
+
+        Returns
+        -------
+        ViolationCause
+            Output cause type-checking this pith against this type hint.
+
+        Raises
+        ------
+        _BeartypeCallHintPepRaiseException
+            If this type hint is either:
+
+            * PEP-noncompliant (e.g., tuple union).
+            * PEP-compliant but no getter function has been implemented to
+              handle this category of PEP-compliant type hint yet.
+        '''
+
+        # If this hint is ignorable, all possible objects satisfy this hint.
+        # Since this hint *CANNOT* (by definition) be the cause of this failure,
+        # return the same cause as is.
+        if self.hint is None:
+            return self
+        # Else, this hint is unignorable.
+
+        # Getter function returning the desired string.
+        cause_finder: Callable[[ViolationCause], ViolationCause] = None  # type: ignore[assignment]
+
+        #FIXME: Trivially simplify this method by:
+        #* Define a new find_cause_nonpep() function elsewhere whose body is
+        #  the body of this "if" conditional branch.
+        #* Register this function with HINT_SIGN_TO_GET_CAUSE_FUNC: e.g.,
+        #  HINT_SIGN_TO_GET_CAUSE_FUNC = {
+        #      ...,
+        #      None: find_cause_nonpep,
+        #  }
+        #* Remove this "if" conditional branch.
+
+        # If *NO* sign uniquely identifies this hint, this hint is either
+        # PEP-noncompliant *OR* only contextually PEP-compliant in certain
+        # specific use cases. In either case...
+        if self.hint_sign is None:
+            # If this hint is a tuple union...
+            if isinstance(self.hint, tuple):
+                # Avoid circular import dependencies.
+                from beartype._check.error._errortype import (
+                    find_cause_instance_types_tuple)
+
+                # Defer to the getter function specific to tuple unions.
+                cause_finder = find_cause_instance_types_tuple
+            # Else, this hint is *NOT* a tuple union. In this case, assume this
+            # hint to be an isinstanceable class. If this is *NOT* the case, the
+            # getter deferred to below raises a human-readable exception.
+            else:
+                # Avoid circular import dependencies.
+                from beartype._check.error._errortype import (
+                    find_cause_instance_type)
+
+                # Defer to the getter function specific to classes.
+                cause_finder = find_cause_instance_type
+        # Else, this hint is PEP-compliant.
+        #
+        # If this hint...
+        elif (
+            # Originates from an origin type and may thus be shallowly
+            # type-checked against that type *AND is either...
+            self.hint_sign in HINT_SIGNS_ORIGIN_ISINSTANCEABLE and (
+                # Unsubscripted *OR*...
+                not is_hint_pep_args(self.hint) or
+                #FIXME: Remove this branch *AFTER* deeply supporting all hints.
+                # Currently unsupported with deep type-checking...
+                self.hint_sign not in HINT_SIGNS_SUPPORTED_DEEP
+            )
+        # Then this hint is both unsubscripted and originating from a standard
+        # type origin. In this case, this hint was type-checked shallowly.
+        ):
+            # Avoid circular import dependencies.
+            from beartype._check.error._errortype import (
+                find_cause_type_instance_origin)
+
+            # Defer to the getter function supporting hints originating from
+            # origin types.
+            cause_finder = find_cause_type_instance_origin
+        # Else, this hint is either subscripted *OR* unsubscripted but not
+        # originating from a standard type origin. In either case, this hint was
+        # type-checked deeply.
+        else:
+            # Avoid circular import dependencies.
+            from beartype._check.error._errordata import (
+                HINT_SIGN_TO_GET_CAUSE_FUNC)
+
+            # Getter function returning the desired string for this attribute if
+            # any *OR* "None" otherwise.
+            cause_finder = HINT_SIGN_TO_GET_CAUSE_FUNC.get(
+                self.hint_sign, None)  # type: ignore[arg-type]
+
+            # If no such function has been implemented to handle this attribute
+            # yet, raise an exception.
+            if cause_finder is None:
+                raise _BeartypeCallHintPepRaiseException(
+                    f'{self.exception_prefix} type hint '
+                    f'{repr(self.hint)} unsupported (i.e., no '
+                    f'"find_cause_"-prefixed getter function defined '
+                    f'for this category of hint).'
+                )
+            # Else, a getter function has been implemented to handle this
+            # attribute.
+
+        # Call this getter function with ourselves and return the string
+        # returned by this getter.
+        return cause_finder(self)
+
+    # ..................{ PERMUTERS                          }..................
+    def permute(self, **kwargs) -> 'ViolationCause':
+        '''
+        Shallow copy of this object such that each the passed keyword argument
+        overwrites the instance variable of the same name in this copy.
+
+        Parameters
+        ----------
+        Keyword arguments of the same name and type as instance variables of
+        this object (e.g., ``hint``, ``pith``).
+
+        Returns
+        -------
+        ViolationCause
+            Shallow copy of this object such that each keyword argument
+            overwrites the instance variable of the same name in this copy.
+
+        Raises
+        ------
+        _BeartypeCallHintPepRaiseException
+            If the name of any passed keyword argument is *not* the name of an
+            existing instance variable of this object.
+
+        Examples
+        --------
+        .. code-block:: pycon
+
+           >>> sleuth = ViolationCause(
+           ...     pith=[42,]
+           ...     hint=typing.List[int],
+           ...     cause_indent='',
+           ...     exception_prefix='List of integers',
+           ... )
+           >>> sleuth_copy = sleuth.permute(pith=[24,])
+           >>> sleuth_copy.pith
+           [24,]
+           >>> sleuth_copy.hint
+           typing.List[int]
+        '''
+
+        # For the name of each passed keyword argument...
+        for arg_name in kwargs.keys():
+            # If this name is *NOT* that of a parameter accepted by the
+            # __init__() method, raise an exception.
+            if arg_name not in self._INIT_PARAM_NAMES:
+                raise _BeartypeCallHintPepRaiseException(
+                    f'{self.__class__}.__init__() parameter '
+                    f'{arg_name} unrecognized.'
+                )
+
+        # For the name of each parameter accepted by the __init__() method...
+        for arg_name in self._INIT_PARAM_NAMES:
+            # If this parameter was *NOT* explicitly passed by the caller,
+            # default this parameter to its current value from this object.
+            if arg_name not in kwargs:
+                kwargs[arg_name] = getattr(self, arg_name)
+
+        # Return a new instance of this class initialized with these arguments.
+        return ViolationCause(**kwargs)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_errordata.py
@@ -0,0 +1,112 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype exception data** (i.e., high-level globals and constants leveraged
+throughout the :mod:`beartype._check.error` subpackage).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Callable,
+    Dict,
+)
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._check.error._errorcause import ViolationCause
+
+# ....................{ GLOBALS                            }....................
+# Initialized with automated inspection below in the _init() function.
+HINT_SIGN_TO_GET_CAUSE_FUNC: Dict[
+    HintSign, Callable[[ViolationCause], ViolationCause]] = {}
+'''
+Dictionary mapping each **sign** (i.e., arbitrary object uniquely identifying a
+category of type hints) to a private getter function defined by this submodule
+whose signature matches that of the :func:`._find_cause` function and
+which is dynamically dispatched by that function to describe type-checking
+failures specific to that unsubscripted :mod:`typing` attribute.
+'''
+
+# ....................{ PRIVATE ~ initializers             }....................
+def _init() -> None:
+    '''
+    Initialize this submodule.
+    '''
+
+    # Defer heavyweight imports.
+    from beartype._data.hint.pep.sign.datapepsigns import (
+        HintSignAnnotated,
+        HintSignForwardRef,
+        HintSignGeneric,
+        HintSignLiteral,
+        HintSignNoReturn,
+        HintSignTuple,
+        HintSignType,
+    )
+    from beartype._data.hint.pep.sign.datapepsignset import (
+        HINT_SIGNS_MAPPING,
+        HINT_SIGNS_ORIGIN_ISINSTANCEABLE,
+        HINT_SIGNS_SEQUENCE_ARGS_1,
+        HINT_SIGNS_UNION,
+    )
+    from beartype._check.error._errortype import (
+        find_cause_instance_type_forwardref,
+        find_cause_subclass_type,
+        find_cause_type_instance_origin,
+    )
+    from beartype._check.error._pep.errorpep484604union import (
+        find_cause_union)
+    from beartype._check.error._pep.errorpep586 import (
+        find_cause_literal)
+    from beartype._check.error._pep.errorpep593 import (
+        find_cause_annotated)
+    from beartype._check.error._pep.pep484.errornoreturn import (
+        find_cause_noreturn)
+    from beartype._check.error._pep.pep484585.errorgeneric import (
+        find_cause_generic)
+    from beartype._check.error._pep.pep484585.errormapping import (
+        find_cause_mapping)
+    from beartype._check.error._pep.pep484585.errorsequence import (
+        find_cause_sequence_args_1,
+        find_cause_tuple,
+    )
+
+    # Map each originative sign to the appropriate getter *BEFORE* any other
+    # mappings. This is merely a generalized fallback subsequently replaced by
+    # sign-specific getters below.
+    for pep_sign_origin_isinstanceable in HINT_SIGNS_ORIGIN_ISINSTANCEABLE:
+        HINT_SIGN_TO_GET_CAUSE_FUNC[pep_sign_origin_isinstanceable] = (
+            find_cause_type_instance_origin)
+
+    # Map each mapping sign to its corresponding getter.
+    for pep_sign_mapping in HINT_SIGNS_MAPPING:
+        HINT_SIGN_TO_GET_CAUSE_FUNC[pep_sign_mapping] = find_cause_mapping
+
+    # Map each 1-argument sequence sign to its corresponding getter.
+    for pep_sign_sequence_args_1 in HINT_SIGNS_SEQUENCE_ARGS_1:
+        HINT_SIGN_TO_GET_CAUSE_FUNC[pep_sign_sequence_args_1] = (
+            find_cause_sequence_args_1)
+
+    # Map each union-specific sign to its corresponding getter.
+    for pep_sign_type_union in HINT_SIGNS_UNION:
+        HINT_SIGN_TO_GET_CAUSE_FUNC[pep_sign_type_union] = find_cause_union
+
+    # Map each sign validated by a unique getter to that getter *AFTER* all
+    # other mappings. These sign-specific getters are intended to replace all
+    # other automated mappings above.
+    HINT_SIGN_TO_GET_CAUSE_FUNC.update({
+        HintSignAnnotated: find_cause_annotated,
+        HintSignForwardRef: find_cause_instance_type_forwardref,
+        HintSignGeneric: find_cause_generic,
+        HintSignLiteral: find_cause_literal,
+        HintSignNoReturn: find_cause_noreturn,
+        HintSignTuple: find_cause_tuple,
+        HintSignType: find_cause_subclass_type,
+    })
+
+
+# Initialize this submodule.
+_init()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_errortype.py
@@ -0,0 +1,362 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype class type hint violation describers** (i.e., functions returning
+human-readable strings explaining violations of type hints that are standard
+isinstanceable classes rather than PEP-specific objects).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeCallHintForwardRefException,
+    BeartypePlugInstancecheckStrException,
+)
+from beartype.roar._roarexc import _BeartypeCallHintPepRaiseException
+from beartype.typing import Optional
+from beartype._cave._cavefast import TestableTypes
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignForwardRef,
+    HintSignType,
+)
+from beartype._check.error._errorcause import ViolationCause
+from beartype._util.cls.utilclstest import is_type_subclass
+from beartype._util.cls.pep.utilpep3119 import (
+    die_unless_type_isinstanceable,
+    die_unless_type_issubclassable,
+)
+from beartype._util.func.arg.utilfuncargtest import (
+    die_unless_func_args_len_flexible_equal)
+from beartype._util.hint.nonpep.utilnonpeptest import (
+    die_unless_hint_nonpep_tuple)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585ref import (
+    import_pep484585_ref_type)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585type import (
+    get_hint_pep484585_type_superclass)
+from beartype._util.hint.pep.utilpepget import (
+    get_hint_pep_origin_type_isinstanceable_or_none)
+from beartype._util.text.utiltextansi import color_hint
+from beartype._util.text.utiltextjoin import join_delimited_disjunction_types
+from beartype._util.text.utiltextlabel import label_type
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ GETTERS ~ instance : type          }....................
+def find_cause_instance_type(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either is
+    or is not an instance of the isinstanceable class of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    BeartypePlugInstancecheckStrException
+        If the metaclass of this isinstanceable class defines the
+        :mod:`beartype`-specific ``__instancecheck_str__()`` dunder method but
+        either:
+
+        * This method is *not* a pure-Python callable.
+        * This method is a pure-Python callable with an unexpected signature
+          that differs from the expected API:
+
+          .. code-block:: python
+
+             def __instancecheck_str__(cls, obj: typing.Any) -> str:
+
+        * This method is a pure-Python callable with the expected signature that
+          returns either:
+
+          * An object that is *not* a string.
+          * The empty string.
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+
+    # Isinstanceable class against which this pith was type-checked.
+    hint = cause.hint
+
+    # Pith type-checked against this isinstanceable class.
+    pith = cause.pith
+
+    # If this hint is *NOT* an isinstanceable class, raise an exception.
+    die_unless_type_isinstanceable(
+        cls=hint,
+        exception_cls=_BeartypeCallHintPepRaiseException,
+        exception_prefix=cause.exception_prefix,
+    )
+    # Else, this hint is an isinstanceable class.
+
+    # Output cause justification. If this pith either:
+    # * Violates this hint, this is a human-readable substring describing this
+    #   violation.
+    # * Satisfies this hint, "None".
+    cause_str_or_none: Optional[str] = None
+
+    # If this pith is *NOT* an instance of this class...
+    if not isinstance(pith, hint):
+        # Metaclass-specific __instancecheck_str__() dunder method if the
+        # metaclass of this class defines this method *OR* "None" otherwise
+        # (i.e., if that metaclass does *NOT* define this method).
+        #
+        # Note that this constitutes a plugin API. Although currently
+        # beartype-specific, this API is intended to receive widespread adoption
+        # as a pseudo-standard throughout the runtime type-checking community
+        # (e.g., by typeguard and possibly Pydantic). Various third-party
+        # packages that publish custom type hint factories currently leverage
+        # this API to generate package-specific violation messages, including:
+        # * @patrick-kidger's "jaxtyping" package. For the good of Google!
+        get_hint_violation_str = getattr(hint, '__instancecheck_str__', None)
+
+        # If the metaclass of this class defines this dunder method...
+        if get_hint_violation_str:
+            # Human-readable substring prefixing *ALL* exceptions raised below.
+            EXCEPTION_PREFIX = (
+                f'{cause.exception_prefix}{repr(hint)} '
+                f'beartype-specific dunder method __instancecheck_str__() '
+            )
+
+            # If this method is *NOT* a pure-Python callable accepting exactly
+            # two parameters, this method does *NOT* satisfy the expected API:
+            #      def __instancecheck_str__(cls, obj: typing.Any) -> str:
+            #
+            # In this case, raise an exception.
+            die_unless_func_args_len_flexible_equal(
+                func=get_hint_violation_str,
+                func_args_len_flexible=2,
+                exception_cls=BeartypePlugInstancecheckStrException,
+                exception_prefix=EXCEPTION_PREFIX,
+            )
+            # Else, this method satisfies the expected API.
+
+            # Human-readable substring describing this violation generated by
+            # the metaclass of this class.
+            cause_str_or_none = get_hint_violation_str(pith)
+
+            # If this string is *NOT* actually a string, raise an exception.
+            if not isinstance(cause_str_or_none, str):
+                raise BeartypePlugInstancecheckStrException(
+                    f'{EXCEPTION_PREFIX}return {cause_str_or_none} not string.')
+            # Else, this string is actually a string.
+            #
+            # If this string is empty, raise an exception.
+            elif not cause_str_or_none:
+                raise BeartypePlugInstancecheckStrException(
+                    f'{EXCEPTION_PREFIX}return string empty.')
+            # Else, this string is non-empty.
+        # Else, the metaclass of this class does *NOT* define this method. In
+        # this case, fallback to a standard substring describing this violation.
+        else:
+            cause_str_or_none = (
+                f'{represent_pith(pith)} not instance of '
+                f'{color_hint(text=label_type(hint), is_color=cause.conf.is_color)}'
+            )
+    # Else, this pith is an instance of this class.
+
+    # Output cause to be returned, permuted from this input cause with this
+    # output cause justification.
+    cause_return = cause.permute(cause_str_or_none=cause_str_or_none)
+
+    # Return this output cause.
+    return cause_return
+
+
+def find_cause_instance_type_forwardref(
+    cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either is
+    or is not an instance of the class referred to by the **forward reference
+    type hint** (i.e., string whose value is the either absolute *or* relative
+    name of a user-defined type which has yet to be defined) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignForwardRef, (
+        f'{cause.hint_sign} not forward reference.')
+
+    # Class referred to by this absolute or relative forward reference.
+    hint_ref_type = import_pep484585_ref_type(
+        hint=cause.hint,
+        cls_stack=cause.cls_stack,
+        func=cause.func,
+        exception_cls=BeartypeCallHintForwardRefException,
+        exception_prefix=cause.exception_prefix,
+    )
+
+    # Defer to the function handling isinstanceable classes. Neato!
+    return find_cause_instance_type(cause.permute(hint=hint_ref_type))
+
+
+def find_cause_type_instance_origin(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either is
+    or is not an instance of the isinstanceable type underlying the
+    **originative type hint** (i.e., PEP-compliant type hint originating from a
+    non-:mod:`typing` class, typically due to being either a
+    :pep:`585`-compliant type hint *or* a third-party type hint subclassing the
+    :class:`types.GenericAlias` superclass defined by :pep:`585`) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+
+    # Isinstanceable origin type originating this hint if any *OR* "None".
+    hint_type = get_hint_pep_origin_type_isinstanceable_or_none(cause.hint)
+
+    # If this hint does *NOT* originate from such a type, raise an exception.
+    if hint_type is None:
+        raise _BeartypeCallHintPepRaiseException(
+            f'{cause.exception_prefix}type hint '
+            f'{repr(cause.hint)} not originated from '
+            f'isinstanceable origin type.'
+        )
+    # Else, this hint originates from such a type.
+
+    # Defer to the getter function handling non-"typing" classes. Presto!
+    return find_cause_instance_type(cause.permute(hint=hint_type))
+
+# ....................{ GETTERS ~ instance : types         }....................
+def find_cause_instance_types_tuple(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either is
+    or is not an instance of one or more isinstanceable types in the tuple of
+    these types of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+
+    # If this hint is *NOT* a tuple union, raise an exception.
+    die_unless_hint_nonpep_tuple(
+        hint=cause.hint,
+        exception_prefix=cause.exception_prefix,
+        exception_cls=_BeartypeCallHintPepRaiseException,
+    )
+    # Else, this hint is a tuple union.
+
+    # Output cause to be returned, permuted from this input cause such that the
+    # output cause justification is either...
+    cause_return = cause.permute(cause_str_or_none=(
+        # If this pith is an instance of one or more types in this tuple union,
+        # "None";
+        None
+        if isinstance(cause.pith, cause.hint) else
+        # Else, this pith is an instance of *NO* types in this tuple union. In
+        # this case, a substring describing this failure to be embedded in a
+        # longer string.
+        (
+            f'{represent_pith(cause.pith)} not instance of '
+            f'{color_hint(text=join_delimited_disjunction_types(cause.hint), is_color=cause.conf.is_color)}'
+        )
+    ))
+
+    # Return this cause.
+    return cause_return
+
+# ....................{ GETTERS ~ subclass : type          }....................
+def find_cause_subclass_type(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either is
+    or is not a subclass of the issubclassable type of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignType, (
+        f'{cause.hint_sign} not HintSignType.')
+
+    # Superclass this pith is required to be a subclass of.
+    hint_superclass = get_hint_pep484585_type_superclass(
+        hint=cause.hint, exception_prefix=cause.exception_prefix)
+
+    # If this superclass is neither a class nor tuple of classes, this
+    # superclass *MUST* by process of elimination and the validation already
+    # performed above by the get_hint_pep484585_type_superclass() getter be a
+    # forward reference to a class. In this case...
+    if not isinstance(hint_superclass, TestableTypes):
+        # Reduce this superclass to the class referred to by this absolute or
+        # relative forward reference.
+        hint_superclass = import_pep484585_ref_type(
+            hint=hint_superclass,  # type: ignore[arg-type]
+            cls_stack=cause.cls_stack,
+            func=cause.func,
+            exception_cls=BeartypeCallHintForwardRefException,
+            exception_prefix=cause.exception_prefix,
+        )
+
+        # If this superclass is *NOT* issubclassable, raise an exception.
+        die_unless_type_issubclassable(
+            cls=hint_superclass,
+            exception_cls=_BeartypeCallHintPepRaiseException,
+            exception_prefix=cause.exception_prefix,
+        )
+        # Else, this superclass is issubclassable.
+    # In either case, this superclass is now issubclassable.
+
+    # Output cause to be returned, permuted from this input cause.
+    cause_return = cause.permute()
+
+    # If this pith subclasses this superclass, set the output cause
+    # justification to "None".
+    if is_type_subclass(cause_return.pith, hint_superclass):
+        cause_return.cause_str_or_none = None
+    # Else, this pith does *NOT* subclass this superclass. In this case...
+    else:
+        # Description of this superclasses, defined as either...
+        hint_superclass_label = (
+            # If this superclass is a class, a description of this class;
+            label_type(hint_superclass)
+            if isinstance(hint_superclass, type) else
+            # Else, this superclass is a tuple of classes. In this case, a
+            # description of these classes...
+            join_delimited_disjunction_types(hint_superclass)
+        )
+
+        # Human-readable string describing this failure.
+        cause_return.cause_str_or_none = (
+            f'{represent_pith(cause_return.pith)} not subclass of '
+            f'{hint_superclass_label}'
+        )
+
+    # Return this cause.
+    return cause_return
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/errorpep484604union.py
@@ -0,0 +1,238 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype** :pep:`484`-compliant **union type hint violation describers**
+(i.e., functions returning human-readable strings explaining violations of
+:pep:`484`-compliant union type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeCallHintPepRaiseException
+from beartype._data.hint.pep.sign.datapepsignset import HINT_SIGNS_UNION
+from beartype._check.error._errorcause import ViolationCause
+from beartype._util.hint.pep.utilpepget import (
+    get_hint_pep_origin_type_isinstanceable_or_none)
+from beartype._util.hint.pep.utilpeptest import is_hint_pep
+from beartype._util.text.utiltextansi import color_hint
+from beartype._util.text.utiltextjoin import join_delimited_disjunction_types
+from beartype._util.text.utiltextmunge import (
+    suffix_str_unless_suffixed,
+    uppercase_str_char_first,
+)
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ GETTERS                            }....................
+def find_cause_union(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the PEP-compliant union type hint of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign in HINT_SIGNS_UNION, (
+        f'{repr(cause.hint)} not union sign.')
+
+    # Indentation preceding each line of the strings returned by child getter
+    # functions called by this parent getter function, offset to visually
+    # demarcate child from parent causes in multiline strings.
+    CAUSE_INDENT_CHILD = cause.cause_indent + '  '
+
+    # List of all human-readable strings describing the failure of this pith to
+    # satisfy each of these child hints.
+    cause_strs = []
+
+    # Subset of all classes shallowly associated with these child hints (i.e.,
+    # by being either these child hints in the case of non-"typing" classes
+    # *OR* the classes originating these child hints in the case of
+    # PEP-compliant type hints) that this pith fails to shallowly satisfy.
+    hint_types_violated = set()
+
+    # Truncated object representation of this pith.
+    pith_repr = represent_pith(cause.pith)
+
+    # 0-based index of the first non-whitespace character following this
+    # representation in violation causes collected below. Look. Just accept it.
+    PITH_REPR_INDEX = len(pith_repr) + 1
+
+    # For each subscripted argument of this union...
+    for hint_child in cause.hint_childs:
+        # If this child hint is ignorable, continue to the next.
+        if hint_child is None:
+            continue
+        # Else, this child hint is unignorable.
+
+        # If this child hint is PEP-compliant...
+        if is_hint_pep(hint_child):
+            # Non-"typing" class originating this child hint if any *OR* "None"
+            # otherwise.
+            hint_child_origin_type = (
+                get_hint_pep_origin_type_isinstanceable_or_none(hint_child))
+
+            # If...
+            if (
+                # This child hint originates from a non-"typing" class *AND*...
+                hint_child_origin_type is not None and
+                # This pith is *NOT* an instance of this class...
+                not isinstance(cause.pith, hint_child_origin_type)
+            # Then this pith fails to satisfy this child hint. In this case...
+            ):
+                # Add this class to the subset of all classes this pith does
+                # *NOT* satisfy.
+                hint_types_violated.add(hint_child_origin_type)
+
+                # Continue to the next child hint.
+                continue
+            # Else, this pith is an instance of this class and thus shallowly
+            # (but *NOT* necessarily deeply) satisfies this child hint.
+
+            # Child hint output cause to be returned, type-checking only whether
+            # this pith deeply satisfies this child hint.
+            cause_child = cause.permute(
+                hint=hint_child, cause_indent=CAUSE_INDENT_CHILD,
+            ).find_cause()
+
+            # If this pith deeply satisfies this child hint, return this cause
+            # as is.
+            if cause_child.cause_str_or_none is None:
+                # print('Union child {!r} pith {!r} deeply satisfied!'.format(hint_child, pith))
+                return cause
+            # Else, this pith deeply violates this child hint.
+
+            # Cause of this violation.
+            cause_str = cause_child.cause_str_or_none
+
+            # If this cause is prefixed by the truncated object representation
+            # of this pith...
+            #
+            # Note that this should *ALWAYS* be the case. Nonetheless, let's
+            # *NOT* assume anything to avoid exploding everything.
+            if cause_str.startswith(pith_repr):
+                # Strip the prefixing
+                # representation of this pith from this cause (e.g., the prefix
+                # "MuhClass <object MuhClass at 0x7fbc277a2cf0>" from the cause
+                # 'MuhClass <object MuhClass at 0x7fbc277a2cf0> not instance of
+                # <protocol "muh_package.MuhProtocol">'). Why? Because the block
+                # of text preceding the bulleted list containing this cause is
+                # already redundantly prefixed by this representation.
+                cause_str = cause_str[PITH_REPR_INDEX:]
+            # Else, this cause is *NOT* prefixed by the truncated object
+            # representation of this pith. In this case, silently accept that
+            # Bad Things have happened and that we should move to a Bad Future.
+
+            # Append the cause of this violation as a bullet-prefixed line to
+            # the running list of these lines.
+            cause_strs.append(cause_str)
+        # Else, this child hint is PEP-noncompliant. In this case...
+        else:
+            # Assert this child hint to be a non-"typing" class. Note that
+            # the "typing" module should have already guaranteed that all
+            # subscripted arguments of unions are either PEP-compliant type
+            # hints or non-"typing" classes.
+            assert isinstance(hint_child, type), (
+                f'{cause.exception_prefix}union type hint '
+                f'{repr(cause.hint)} child hint {repr(hint_child)} invalid '
+                f'(i.e., neither type hint nor non-"typing" class).')
+            # Else, this child hint is a non-"typing" type.
+
+            # If this pith is an instance of this class, this pith satisfies
+            # this hint. In this case, return this cause as is.
+            if isinstance(cause.pith, hint_child):
+                return cause
+
+            # Else, this pith is *NOT* an instance of this class, implying this
+            # pith to *NOT* satisfy this hint. In this case, add this class to
+            # the subset of all classes this pith does *NOT* satisfy.
+            hint_types_violated.add(hint_child)
+
+    # If this pith fails to shallowly satisfy one or more of the types of this
+    # union, concatenate these failures onto one discrete bullet-prefixed line.
+    if hint_types_violated:
+        # Human-readable comma-delimited disjunction of the names of these
+        # classes (e.g., "bool, float, int, or str").
+        cause_types_unsatisfied = join_delimited_disjunction_types(
+            hint_types_violated)
+
+        # Prepend this cause as a discrete bullet-prefixed line.
+        #
+        # Note that this cause is intentionally prependend rather than appended
+        # to this list. Since this cause applies *ONLY* to the shallow type of
+        # the current pith rather than any items contained in this pith,
+        # listing this shallow cause *BEFORE* other deeper causes typically
+        # applying to items contained in this pith produces substantially more
+        # human-readable exception messages: e.g.,
+        #     # This reads well.
+        #     @beartyped pep_hinted() parameter pep_hinted_param=(1,) violates
+        #     PEP type hint typing.Union[int, typing.Sequence[str]], as (1,):
+        #     * Not int.
+        #     * Tuple item 0 value "1" not str.
+        #
+        #     # This does not.
+        #     @beartyped pep_hinted() parameter pep_hinted_param=(1,) violates
+        #     PEP type hint typing.Union[int, typing.Sequence[str]], as (1,):
+        #     * Tuple item 0 value "1" not str.
+        #     * Not int.
+        #
+        # Note that prepending to lists is an O(n) operation, but that this
+        # cost is negligible in this case both due to the negligible number of
+        # child hints of the average "typing.Union" in general *AND* due to the
+        # fact that this function is only called when a catastrophic type-check
+        # failure has already occurred.
+        cause_strs.insert(0, (
+            f'not {color_hint(text=cause_types_unsatisfied, is_color=cause.conf.is_color)}'
+        ))
+    # Else, this pith shallowly satisfies *ALL* the types of this union.
+
+    # If prior logic appended *NO* causes, raise an exception.
+    if not cause_strs:
+        raise _BeartypeCallHintPepRaiseException(
+            f'{cause.exception_prefix}type hint '
+            f'{repr(cause.hint)} failure causes unknown.'
+        )
+    # Else, prior logic appended one or more strings describing these failures.
+
+    # Output cause to be returned, permuted from this input cause such that the
+    # output cause justification is either...
+    cause_return = cause.permute(cause_str_or_none=(
+        # If prior logic appended one cause, a single-line
+        # substring intended to be embedded in a longer string;
+        f'{pith_repr} {cause_strs[0]}'
+        if len(cause_strs) == 1 else
+        # Else, prior logic appended two or more causes. In this case, a
+        # multiline string comprised of...
+        '{}:\n{}'.format(
+            # This truncated object representation followed by...
+            pith_repr,
+            # The newline-delimited concatenation of each cause as a discrete
+            # bullet-prefixed line...
+            '\n'.join(
+                '{}* {}'.format(
+                    # Indented by the current indent...
+                    cause.cause_indent,
+                    # Whose first character is uppercased...
+                    uppercase_str_char_first(
+                        # Suffixed by a period if not yet suffixed by a period.
+                        suffix_str_unless_suffixed(text=cause_str, suffix='.')
+                    )
+                )
+                # '{}* {}.'.format(cause_indent, uppercase_str_char_first(cause_union))
+                for cause_str in cause_strs
+            )
+        )
+    ))
+
+    # Return this cause.
+    return cause_return
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/errorpep586.py
@@ -0,0 +1,98 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype** :pep:`586`-compliant **type hint violation describers** (i.e.,
+functions returning human-readable strings explaining violations of
+:pep:`586`-compliant :attr:`typing.Literal` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.error._errorcause import ViolationCause
+from beartype._data.hint.pep.sign.datapepsigns import HintSignLiteral
+from beartype._util.hint.pep.proposal.utilpep586 import (
+    get_hint_pep586_literals)
+from beartype._util.text.utiltextjoin import join_delimited_disjunction
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ GETTERS                            }....................
+def find_cause_literal(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the :pep:`586`-compliant :mod:`beartype`-specific
+    **literal** (i.e., :attr:`typing.Literal` type hint) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    ----------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignLiteral, (
+        f'{repr(cause.hint_sign)} not "HintSignLiteral".')
+
+    # Tuple of zero or more literal objects subscripting this hint,
+    # intentionally replacing the current such tuple due to the non-standard
+    # implementation of the third-party "typing_extensions.Literal" factory.
+    hint_childs = get_hint_pep586_literals(
+        hint=cause.hint, exception_prefix=cause.exception_prefix)
+
+    # If this pith is equal to any literal object subscripting this hint, this
+    # pith satisfies this hint. Specifically, if there exists at least one...
+    if any(
+        # Literal object subscripting this hint such that...
+        (
+            # This pith is of the same type as that of this literal *AND*...
+            #
+            # Note that PEP 586 explicitly requires this pith to be validated
+            # to be an instance of the same type as this literal *BEFORE*
+            # validated as equal to this literal, due to subtle edge cases in
+            # equality comparison that could yield false positives.
+            isinstance(cause.pith, type(hint_literal)) and
+            # This pith is equal to this literal.
+            cause.pith == hint_literal
+        )
+        # For each literal object subscripting this hint...
+        for hint_literal in hint_childs
+    ):
+        # Then return this cause unmodified, as this pith deeply satisfies this
+        # hint.
+        return cause
+    # Else, this pith fails to satisfy this hint.
+
+    # Tuple union of the types of all literals subscripting this hint.
+    hint_literal_types = tuple(
+        type(hint_literal) for hint_literal in hint_childs)
+
+    # Shallow output cause to be returned, type-checking only whether this pith
+    # is an instance of one or more of these types.
+    cause_shallow = cause.permute(hint=hint_literal_types).find_cause()
+
+    # If this pith is *NOT* such an instance, return this string.
+    if cause_shallow.cause_str_or_none is not None:
+        return cause_shallow
+    # Else, this pith is such an instance and thus shallowly satisfies this
+    # hint. Since this pith fails to satisfy this hint, this pith must by
+    # deduction be unequal to all literals subscripting this hint.
+
+    # Human-readable comma-delimited disjunction of the machine-readable
+    # representations of all literal objects subscripting this hint.
+    cause_literals_unsatisfied = join_delimited_disjunction(
+        repr(hint_literal) for hint_literal in hint_childs)
+
+    # Deep output cause to be returned, permuted from this input cause such that
+    # the justification is a human-readable string describing this failure.
+    cause_deep = cause.permute(cause_str_or_none=(
+        f'{represent_pith(cause.pith)} != {cause_literals_unsatisfied}.'))
+
+    # Return this cause.
+    return cause_deep
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/errorpep593.py
@@ -0,0 +1,109 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype :pep:`593`-compliant **type hint violation describers** (i.e.,
+functions returning human-readable strings explaining violations of
+:pep:`593`-compliant :attr:`typing.Annotated` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeCallHintPepRaiseException
+from beartype._check.error._errorcause import ViolationCause
+from beartype._data.hint.pep.sign.datapepsigns import HintSignAnnotated
+from beartype._util.hint.pep.proposal.utilpep593 import (
+    get_hint_pep593_metadata,
+    get_hint_pep593_metahint,
+)
+from beartype._data.code.datacodeindent import CODE_INDENT_1
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ GETTERS                            }....................
+def find_cause_annotated(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the :pep:`593`-compliant :mod:`beartype`-specific
+    **metahint** (i.e., type hint annotating a standard class with one or more
+    :class:`beartype.vale._core._valecore.BeartypeValidator` objects, each
+    produced by subscripting the :class:`beartype.vale.Is` class or a subclass
+    of that class) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignAnnotated, (
+        f'{cause.hint_sign} not "HintSignAnnotated".')
+
+    # Defer heavyweight imports.
+    from beartype.vale._core._valecore import BeartypeValidator
+
+    # Type hint annotated by this metahint.
+    metahint = get_hint_pep593_metahint(cause.hint)
+
+    # Tuple of zero or more arbitrary objects annotating this metahint.
+    hint_validators = get_hint_pep593_metadata(cause.hint)
+
+    # Shallow output cause to be returned, type-checking only whether this pith
+    # satisfies this metahint.
+    cause_shallow = cause.permute(hint=metahint).find_cause()
+
+    # If this pith fails to satisfy this metahint, return this cause as is.
+    if cause_shallow.cause_str_or_none is not None:
+        return cause_shallow
+    # Else, this pith satisfies this metahint.
+
+    # Deep output cause to be returned, permuted from this input cause.
+    cause_deep = cause.permute()
+
+    # For each beartype validator annotating this metahint...
+    for hint_validator in hint_validators:
+        # If this is *NOT* a beartype validator, raise an exception.
+        #
+        # Note that this object should already be a beartype validator, as the
+        # @beartype decorator enforces this constraint at decoration time.
+        if not isinstance(hint_validator, BeartypeValidator):
+            raise _BeartypeCallHintPepRaiseException(
+                f'{cause_deep.exception_prefix}PEP 593 type hint '
+                f'{repr(cause_deep.hint)} argument {repr(hint_validator)} '
+                f'not beartype validator '
+                f'(i.e., "beartype.vale.Is*[...]" object).'
+            )
+        # Else, this is a beartype validator.
+        #
+        # If this pith fails to satisfy this validator and is thus the cause of
+        # this failure...
+        elif not hint_validator.is_valid(cause_deep.pith):
+            #FIXME: Unit test this up, please.
+            # Human-readable string diagnosing this failure.
+            hint_diagnosis = hint_validator.get_diagnosis(
+                obj=cause_deep.pith,
+                indent_level_outer=CODE_INDENT_1,
+                indent_level_inner='',
+            )
+
+            # Human-readable string describing this failure.
+            cause_deep.cause_str_or_none = (
+                f'{represent_pith(cause_deep.pith)} violates validator '
+                f'{repr(hint_validator)}:\n'
+                f'{hint_diagnosis}'
+            )
+
+            # Immediately halt iteration.
+            break
+        # Else, this pith satisfies this validator. Ergo, this validator is
+        # *NOT* the cause of this failure. Silently continue to the next.
+
+    # Return this output cause.
+    return cause_deep
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/pep484/errornoreturn.py
@@ -0,0 +1,53 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype** :pep:`484`-compliant :attr:`typing.NoReturn` **type hint violation
+describers** (i.e., functions returning human-readable strings explaining
+violations of :pep:`484`-compliant :attr:`typing.NoReturn` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Callable
+from beartype._data.hint.pep.sign.datapepsigns import HintSignNoReturn
+from beartype._check.error._errorcause import ViolationCause
+from beartype._util.text.utiltextlabel import label_callable
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ GETTERS                            }....................
+def find_cause_noreturn(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing describing the failure of the decorated callable to
+    *not* return a value in violation of the :pep:`484`-compliant
+    :attr:`typing.NoReturn` type hint.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignNoReturn, (
+        f'{repr(cause.hint)} not "HintSignNoReturn".')
+
+    # Decorated callable originating this violation.
+    func: Callable = cause.func  # type: ignore[assignment]
+
+    # Output cause to be returned, permuted from this input cause such that the
+    # justification is a human-readable string describing this failure.
+    cause_return = cause.permute(cause_str_or_none=(
+        f'{label_callable(func)} annotated by PEP 484 return type hint '
+        f'"typing.NoReturn" returned {represent_pith(cause.pith)}'
+    ))
+
+    # Return this cause.
+    return cause_return
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/pep484585/errorgeneric.py
@@ -0,0 +1,94 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype PEP-compliant generic type hint exception raisers** (i.e., functions
+raising human-readable exceptions called by :mod:`beartype`-decorated callables
+on the first invalid parameter or return value failing a type-check against the
+PEP-compliant generic type hint annotating that parameter or return).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.pep.sign.datapepsigns import HintSignGeneric
+from beartype._check.error._errorcause import ViolationCause
+from beartype._check.error._errortype import find_cause_instance_type
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+    get_hint_pep484585_generic_type,
+    iter_hint_pep484585_generic_bases_unerased_tree,
+)
+
+# ....................{ GETTERS                            }....................
+def find_cause_generic(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the :pep:`484`- or :pep:`585`-compliant **generic**
+    (i.e., type hint subclassing a combination of one or more of the
+    :mod:`typing.Generic` superclass, the :mod:`typing.Protocol` superclass,
+    and/or other :mod:`typing` non-class pseudo-superclasses) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    ----------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignGeneric, (
+        f'{repr(cause.hint_sign)} not generic.')
+    # print(f'[find_cause_generic] cause.pith: {cause.pith}')
+    # print(f'[find_cause_generic] cause.hint [pre-reduction]: {cause.hint}')
+
+    # Origin type originating this generic, deduced by stripping all child type
+    # hints subscripting this hint from this hint.
+    hint_type = get_hint_pep484585_generic_type(
+        hint=cause.hint, exception_prefix=cause.exception_prefix)
+
+    # Shallow output cause to be returned, type-checking only whether this pith
+    # is instance of this origin type.
+    cause_shallow = cause.permute(hint=hint_type)
+    cause_shallow = find_cause_instance_type(cause_shallow)
+    # print(f'[find_cause_generic] cause.hint [post-reduction]: {cause.hint}')
+
+    # If this pith is *NOT* an instance of this type, return this cause.
+    if cause_shallow.cause_str_or_none is not None:
+        return cause_shallow
+    # Else, this pith is an instance of this type.
+
+    # For each unignorable unerased transitive pseudo-superclass originally
+    # declared as an erased superclass of this generic...
+    for hint_child in iter_hint_pep484585_generic_bases_unerased_tree(
+        hint=cause.hint,
+        conf=cause.conf,
+        exception_prefix=cause.exception_prefix,
+    ):
+        # Deep output cause to be returned, permuted from this input cause.
+        cause_deep = cause.permute(hint=hint_child).find_cause()
+        # print(f'tuple pith: {pith_item}\ntuple hint child: {hint_child}')
+
+        # If this pseudo-superclass is the cause of this failure...
+        if cause_deep.cause_str_or_none is not None:
+            # Human-readable string prefixing this failure with additional
+            # metadata describing this pseudo-superclass.
+            cause_deep.cause_str_or_none = (
+                f'generic base {repr(hint_child)} '
+                f'{cause_deep.cause_str_or_none}'
+            )
+
+            # Return this cause.
+            return cause_deep
+        # Else, this pseudo-superclass is *NOT* the cause of this failure.
+        # Silently continue to the next.
+        # print(f'[find_cause_generic] Ignoring satisfied base {hint_child}...')
+
+    # Return this cause as is. This pith satisfies both this generic itself
+    # *AND* all pseudo-superclasses subclassed by this generic, implying this
+    # pith to deeply satisfy this hint.
+    return cause
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/pep484585/errormapping.py
@@ -0,0 +1,155 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype :pep:`484`- and :pep:`585`-compliant **mapping type hint violation
+describers** (i.e., functions returning human-readable strings explaining
+violations of :pep:`484`- and :pep:`585`-compliant mapping type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype import BeartypeStrategy
+from beartype.typing import (
+    Iterable,
+    Tuple,
+    Hashable,
+)
+from beartype._data.hint.pep.sign.datapepsignset import HINT_SIGNS_MAPPING
+from beartype._check.error._errorcause import ViolationCause
+from beartype._check.error._errortype import find_cause_type_instance_origin
+from beartype._util.text.utiltextprefix import prefix_pith_type
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ FINDERS                            }....................
+def find_cause_mapping(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the **mapping type hint** (i.e., PEP-compliant type
+    hint accepting exactly two subscripted arguments constraining *all*
+    key-value pairs of this pith, which necessarily satisfies the
+    :class:`collections.abc.Mapping` protocol) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign in HINT_SIGNS_MAPPING, (
+        f'{repr(cause.hint)} not mapping hint.')
+
+    # Assert this mapping was subscripted by exactly two arguments. Note that
+    # the "typing" module should have already guaranteed this on our behalf.
+    assert len(cause.hint_childs) == 2, (
+        f'Mapping hint {repr(cause.hint)} subscripted by '
+        f'{len(cause.hint_childs)} != 2.')
+    # print(f'Validating mapping {repr(cause.pith)}...')
+
+    # Shallow output cause to be returned, type-checking only whether this path
+    # is an instance of the type originating this hint (e.g., "list" for
+    # "list[str]").
+    cause_shallow = find_cause_type_instance_origin(cause)
+
+    # If this pith is *NOT* an instance of this type, return this shallow cause.
+    if cause_shallow.cause_str_or_none is not None:
+        return cause_shallow
+    # Else, this pith is an instance of this type and is thus a mapping.
+    #
+    # If this mapping is empty, all items of this mapping (of which there are
+    # none) are valid. This mapping satisfies this hint. Just go with it!
+    elif not cause.pith:
+        return cause
+    # Else, this mapping is non-empty.
+
+    # Child key and value hints subscripting this mapping hint.
+    hint_key = cause.hint_childs[0]
+    hint_value = cause.hint_childs[1]
+
+    # True only if these hints are unignorable.
+    hint_key_unignorable = hint_key is not None
+    hint_value_unignorable = hint_value is not None
+
+    # Arbitrary iterator vaguely satisfying the dict.items() protocol,
+    # yielding zero or more 2-tuples of the form "(key, value)", where:
+    # * "key" is the key of the current key-value pair.
+    # * "value" is the value of the current key-value pair.
+    pith_items: Iterable[Tuple[Hashable, object]] = None  # type: ignore[assignment]
+
+    # If the only the first key-value pair of this mapping was
+    # type-checked by the the parent @beartype-generated wrapper
+    # function in O(1) time, type-check only this key-value pair of this
+    # mapping in O(1) time as well.
+    if cause.conf.strategy is BeartypeStrategy.O1:
+        # First key-value pair of this mapping.
+        pith_item = next(iter(cause.pith.items()))
+
+        # Tuple containing only this pair.
+        pith_items = (pith_item,)
+        # print(f'Checking item {pith_item_index} in O(1) time!')
+    # Else, all keys of this mapping were type-checked by the parent
+    # @beartype-generated wrapper function in O(n) time. In this case,
+    # type-check *ALL* indices of this mapping in O(n) time as well.
+    else:
+        # Iterator yielding all key-value pairs of this mapping.
+        pith_items = cause.pith.items()
+        # print('Checking mapping in O(n) time!')
+
+    # For each key-value pair of this mapping...
+    for pith_key, pith_value in pith_items:
+        # If this child key hint is unignorable...
+        if hint_key_unignorable:
+            # Deep output cause, type-checking whether this key satisfies
+            # this child key hint.
+            cause_deep = cause.permute(
+                pith=pith_key, hint=hint_key).find_cause()
+
+            # If this key is the cause of this failure...
+            if cause_deep.cause_str_or_none is not None:
+                # Human-readable substring prefixing this failure with
+                # metadata describing this key.
+                cause_deep.cause_str_or_none = (
+                    f'{prefix_pith_type(pith=cause.pith, is_color=True)}'
+                    f'key {cause_deep.cause_str_or_none}'
+                )
+
+                # Return this cause.
+                return cause_deep
+            # Else, this key is *NOT* the cause of this failure. Silently
+            # continue to this value.
+        # Else, this child key hint is ignorable.
+
+        # If this child value hint is unignorable...
+        if hint_value_unignorable:
+            # Deep output cause, type-checking whether this value satisfies
+            # this child value hint.
+            cause_deep = cause.permute(
+                pith=pith_value, hint=hint_value).find_cause()
+
+            # If this value is the cause of this failure...
+            if cause_deep.cause_str_or_none is not None:
+                # Human-readable substring prefixing this failure with
+                # metadata describing this value.
+                cause_deep.cause_str_or_none = (
+                    f'{prefix_pith_type(pith=cause.pith, is_color=True)}'
+                    f'key {represent_pith(pith_key)} '
+                    f'value {cause_deep.cause_str_or_none}'
+                )
+
+                # Return this cause.
+                return cause_deep
+            # Else, this value is *NOT* the cause of this failure. Silently
+            # continue to the key-value pair.
+        # Else, this child value hint is ignorable.
+
+    # Return this cause as is; all items of this mapping are valid, implying
+    # this mapping to deeply satisfy this hint.
+    return cause
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/_pep/pep484585/errorsequence.py
@@ -0,0 +1,307 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype :pep:`484`- and :pep:`585`-compliant **sequence type hint violation
+describers** (i.e., functions returning human-readable strings explaining
+violations of :pep:`484`- and :pep:`585`-compliant sequence type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.pep.sign.datapepsigns import HintSignTuple
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_SEQUENCE_ARGS_1)
+from beartype._check.error._errorcause import ViolationCause
+from beartype._check.error._errortype import find_cause_type_instance_origin
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585 import (
+    is_hint_pep484585_tuple_empty)
+from beartype._util.text.utiltextansi import color_type
+from beartype._util.text.utiltextprefix import prefix_pith_type
+from beartype._util.text.utiltextrepr import represent_pith
+
+# ....................{ FINDERS                            }....................
+def find_cause_sequence_args_1(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the **single-argument variadic sequence type hint**
+    (i.e., PEP-compliant type hint accepting exactly one subscripted argument
+    constraining *all* items of this pith, which necessarily satisfies the
+    :class:`collections.abc.Sequence` protocol with guaranteed :math:`O(1)`
+    indexation across all sequence items) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign in HINT_SIGNS_SEQUENCE_ARGS_1, (
+        f'{repr(cause.hint)} not 1-argument sequence hint.')
+
+    # Assert this sequence was subscripted by exactly one argument. Note that
+    # the "typing" module should have already guaranteed this on our behalf.
+    assert len(cause.hint_childs) == 1, (
+        f'1-argument sequence hint {repr(cause.hint)} subscripted by '
+        f'{len(cause.hint_childs)} != 1.')
+
+    # Shallow output cause to be returned, type-checking only whether this path
+    # is an instance of the type originating this hint (e.g., "list" for
+    # "list[str]").
+    cause_shallow = find_cause_type_instance_origin(cause)
+
+    # Return either...
+    return (
+        # If this pith is *NOT* an instance of this type, this shallow cause;
+        cause_shallow
+        if cause_shallow.cause_str_or_none is not None else
+        # Else, this pith is an instance of this type and is thus a sequence.
+        # In this case, defer to this function supporting arbitrary sequences.
+        _find_cause_sequence(cause)
+    )
+
+
+def find_cause_tuple(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the **tuple type hint** (i.e., PEP-compliant type hint
+    accepting either zero or more subscripted arguments iteratively constraining
+    each item of this fixed-length tuple *or* exactly one subscripted arguments
+    constraining *all* items of this variadic tuple) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert cause.hint_sign is HintSignTuple, (
+        f'{repr(cause.hint_sign)} not "HintSignTuple".')
+
+    # Shallow output cause to be returned, type-checking only whether this path
+    # is an instance of the type originating this hint (e.g., "list" for
+    # "list[str]").
+    cause_shallow = find_cause_type_instance_origin(cause)
+
+    # If this pith is *NOT* a tuple, return this shallow cause.
+    if cause_shallow.cause_str_or_none is not None:
+        return cause_shallow
+    # Else, this pith is a tuple.
+    #
+    # If this hint is a tuple...
+    elif (
+        # Subscripted by exactly two child hints *AND*...
+        len(cause.hint_childs) == 2 and
+        # The second child hint is just an unquoted ellipsis...
+        cause.hint_childs[1] is Ellipsis
+    ):
+    # Then this hint is of the variadic form "Tuple[{typename}, ...]", typing a
+    # tuple accepting a variadic number of items all satisfying the
+    # child hint "{typename}". Since this case semantically reduces to a simple
+    # sequence, defer to this function supporting arbitrary sequences.
+        return _find_cause_sequence(cause)
+    # Else, this hint is of the fixed-length form "Tuple[{typename1}, ...,
+    # {typenameN}]", typing a tuple accepting a fixed number of items each
+    # satisfying a unique child hint.
+    #
+    # If this hint is the empty fixed-length tuple, validate this pith to be
+    # the empty tuple.
+    elif is_hint_pep484585_tuple_empty(cause.hint):
+        # If this pith is the empty tuple, this path satisfies this hint.
+        if not cause.pith:
+            return cause
+        # Else, this tuple is non-empty and thus fails to satisfy this hint.
+
+        # Deep output cause to be returned, permuted from this input cause
+        # with a human-readable string describing this failure.
+        cause_deep = cause.permute(cause_str_or_none=(
+            f'tuple {represent_pith(cause.pith)} non-empty'))
+
+        # Return this cause.
+        return cause_deep
+    # Else, this hint is a standard fixed-length tuple.
+
+    # If this pith and hint are of differing lengths, this tuple fails to
+    # satisfy this hint. In this case...
+    if len(cause.pith) != len(cause.hint_childs):
+        # Deep output cause to be returned, permuted from this input cause
+        # with a human-readable string describing this failure.
+        cause_deep = cause.permute(cause_str_or_none=(
+            f'tuple {represent_pith(cause.pith)} length '
+            f'{len(cause.pith)} != {len(cause.hint_childs)}'
+        ))
+
+        # Return this cause.
+        return cause_deep
+    # Else, this pith and hint are of the same length.
+
+    # For each enumerated item of this tuple...
+    for pith_item_index, pith_item in enumerate(cause.pith):
+        # Child hint corresponding to this tuple item. Since this pith and
+        # hint are of the same length, this child hint exists.
+        hint_child = cause.hint_childs[pith_item_index]
+        # print(f'tuple pith: {repr(pith_item)}\ntuple hint child: {repr(hint_child)}')
+
+        # If this child hint is ignorable, continue to the next.
+        if hint_child is None:
+            continue
+        # Else, this child hint is unignorable.
+
+        # Deep output cause to be returned, type-checking whether this tuple
+        # item satisfies this child hint.
+        # sleuth_copy = cause.permute(pith=pith_item, hint=hint_child)
+        # pith_item_cause = sleuth_copy.find_cause()
+        cause_deep = cause.permute(
+            pith=pith_item, hint=hint_child).find_cause()
+
+        # If this item is the cause of this failure...
+        if cause_deep.cause_str_or_none is not None:
+            # print(f'tuple pith: {sleuth_copy.pith}\ntuple hint child: {sleuth_copy.hint}\ncause: {pith_item_cause}')
+
+            # Human-readable substring prefixing this failure with metadata
+            # describing this item.
+            cause_deep.cause_str_or_none = (
+                f'{prefix_pith_type(pith=cause.pith, is_color=cause.conf.is_color)}'
+                f'index {color_type(text=str(pith_item_index), is_color=cause.conf.is_color)} '
+                f'item {cause_deep.cause_str_or_none}'
+            )
+
+            # Return this cause.
+            return cause_deep
+        # Else, this item is *NOT* the cause of this failure. Silently
+        # continue to the next.
+
+    # Return this cause as is; all items of this fixed-length tuple are valid,
+    # implying this pith to deeply satisfy this hint.
+    return cause
+
+# ....................{ PRIVATE ~ finders                  }....................
+def _find_cause_sequence(cause: ViolationCause) -> ViolationCause:
+    '''
+    Output cause describing whether the pith of the passed input cause either
+    satisfies or violates the **variadic sequence type hint** (i.e.,
+    PEP-compliant type hint accepting one or more subscripted arguments
+    constraining *all* items of this object, which necessarily satisfies the
+    :class:`collections.abc.Sequence` protocol with guaranteed ``O(1)``
+    indexation across all sequence items) of that cause.
+
+    Parameters
+    ----------
+    cause : ViolationCause
+        Input cause providing this data.
+
+    Returns
+    -------
+    ViolationCause
+        Output cause type-checking this data.
+    '''
+    # Assert this type hint to describe a variadic sequence. See the parent
+    # find_cause_sequence_args_1() and find_cause_tuple()
+    # functions for derivative logic.
+    #
+    # Note that this pith need *NOT* be validated to be an instance of the
+    # expected variadic sequence, as the caller guarantees this to be the case.
+    assert isinstance(cause, ViolationCause), f'{repr(cause)} not cause.'
+    assert (
+        cause.hint_sign in HINT_SIGNS_SEQUENCE_ARGS_1 or (
+            cause.hint_sign is HintSignTuple and
+            len(cause.hint_childs) == 2 and
+            cause.hint_childs[1] is Ellipsis
+        )
+    ), (f'{repr(cause.hint)} neither '
+        f'standard sequence nor variadic tuple hint.')
+
+    # If this sequence is empty, all items of this sequence (of which there are
+    # none) are valid. This sequence satisfies this hint. Just go with it!
+    if not cause.pith:
+        return cause
+    # Else, this sequence is non-empty.
+
+    # First child hint subscripting this sequence hint. All remaining child
+    # hints if any are ignorable. Specifically, if this hint is:
+    # * A standard sequence (e.g., "typing.List[str]"), this hint is
+    #   subscripted by only one child hint.
+    # * A variadic tuple (e.g., "typing.Tuple[str, ...]"), this hint is
+    #   subscripted by only two child hints the latter of which is
+    #   ignorable syntactic chuff.
+    hint_child = cause.hint_childs[0]
+
+    # If this child hint is ignorable, this sequence satisfies this hint.
+    if hint_child is None:
+        return cause
+    # Else, this child hint is unignorable.
+
+    # Arbitrary iterator satisfying the enumerate() protocol, yielding zero or
+    # more 2-tuples of the form "(item_index, item)", where:
+    # * "item_index" is the 0-based index of this item.
+    # * "item" is an arbitrary item of this sequence.
+    pith_enumerator = None
+
+    # If this sequence was indexed by the parent @beartype-generated wrapper
+    # function by a pseudo-random integer in O(1) time, type-check *ONLY* the
+    # same index of this sequence also in O(1) time. Since the current call to
+    # that function failed a type-check, either this index is the index
+    # responsible for that failure *OR* this sequence is valid and another
+    # container is responsible for that failure. In either case, no other
+    # indices of this sequence need be checked.
+    if cause.random_int is not None:
+        # 0-based index of this item calculated from this random integer in the
+        # *SAME EXACT WAY* as in the parent @beartype-generated wrapper.
+        pith_item_index = cause.random_int % len(cause.pith)
+
+        # Pseudo-random item with this index in this sequence.
+        pith_item = cause.pith[pith_item_index]
+
+        # 2-tuple of this index and item in the same order as the 2-tuples
+        # returned by the enumerate() builtin.
+        pith_enumeratable = (pith_item_index, pith_item)
+
+        # Iterator yielding only this 2-tuple.
+        pith_enumerator = iter((pith_enumeratable,))
+        # print(f'Checking item {pith_item_index} in O(1) time!')
+    # Else, this sequence was iterated by the parent @beartype-generated wrapper
+    # function in O(n) time. In this case, type-check *ALL* indices of this
+    # sequence in O(n) time as well.
+    else:
+        # Iterator yielding all indices and items of this sequence.
+        pith_enumerator = enumerate(cause.pith)
+        # print('Checking sequence in O(n) time!')
+
+    # For each enumerated item of this sequence...
+    for pith_item_index, pith_item in pith_enumerator:
+        # Deep output cause, type-checking whether this item satisfies this
+        # child hint.
+        cause_deep = cause.permute(
+            pith=pith_item, hint=hint_child).find_cause()
+
+        # If this item is the cause of this failure...
+        if cause_deep.cause_str_or_none is not None:
+            # Human-readable substring prefixing this failure with metadata
+            # describing this item.
+            cause_deep.cause_str_or_none = (
+                f'{prefix_pith_type(pith=cause.pith, is_color=cause.conf.is_color)}'
+                f'index {color_type(text=str(pith_item_index), is_color=cause.conf.is_color)} '
+                f'item {cause_deep.cause_str_or_none}'
+            )
+
+            # Return this cause.
+            return cause_deep
+        # Else, this item is *NOT* the cause of this failure. Silently continue
+        # to the next.
+
+    # Return this cause as is; all items of this sequence are valid, implying
+    # this sequence to deeply satisfy this hint.
+    return cause
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/error/errorget.py
@@ -0,0 +1,597 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype exception getters** (i.e., high-level callables creating and
+returning human-readable exceptions, called by various runtime type-checkers
+published by :mod:`beartype` when an arbitrary object violates a type hint).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: [ACCESS] Generalizing the "random_int" concept (i.e., the optional
+#"random_int" parameter accepted by the get_func_pith_violation() function) that
+#enables O(1) exception handling to containers that do *NOT* provide efficient
+#random access like mappings and sets will be highly non-trivial. While there
+#exist a number of alternative means of implementing that generalization, the
+#most reasonable *BY FAR* is probably to:
+#
+#* Embed additional assignment expressions in the type-checking tests generated
+#  by the make_func_pith_code() function that uniquely store the value of
+#  each item, key, or value returned by each access of a non-indexable container
+#  iterator into a new unique local variable. Note this unavoidably requires:
+#  * Adding a new index to the "hint_curr_meta" tuples internally created by
+#    that function -- named, say, "_HINT_META_INDEX_ITERATOR_NAME". The value
+#    of the tuple item at this index should either be:
+#    * If the currently iterated type hint is a non-indexable container, the
+#      name of the new unique local variable assigned to by this assignment
+#      expression whose value is obtained from the iterator cached for that
+#      container.
+#    * Else, "None".
+#    Actually... hmm. Perhaps we only need a new local variable
+#    "iterator_nonsequence_names" whose value is a cached "FixedList" of
+#    sufficiently large size (so, "FIXED_LIST_SIZE_MEDIUM"?). We could then simply
+#    iteratively insert the names of the wrapper-specific new unique local
+#    variables into this list.
+#    Actually... *WAIT.* Is all we need a single counter initialized to, say:
+#        iterators_nonsequence_len = 0
+#    We then both use that counter to:
+#    * Uniquify the names of these wrapper-specific new unique local variables
+#      during iteration over type hints.
+#    * Trivially generate a code snippet passing a list of these names to the
+#      "iterators_nonsequence" parameter of get_func_pith_violation() function
+#      after iteration over type hints.
+#    Right. That looks like The Way, doesn't it? This would seem to be quite a
+#    bit easier than we'd initially thought, which is always nice. Oi!
+#  * Python >= 3.8, but that's largely fine. Python 3.6 and 3.7 are
+#    increasingly obsolete in 2021.
+#* Add a new optional "iterators_nonsequence" parameter to the
+#  get_func_pith_violation() function, accepting either:
+#  * If the current parameter or return of the parent wrapper function was
+#    annotated with one or more non-indexable container type hints, a *LIST* of
+#    the *VALUES* of all unique local variables assigned to by assignment
+#    expressions in that parent wrapper function. These values were obtained
+#    from the iterators cached for those containers. To enable these exception
+#    handlers to efficiently treat this list like a FIFO stack (e.g., with the
+#    list.pop() method), this list should be sorted in the reverse order that
+#    these assignment expressions are defined in.
+#* Refactor exception handlers to then preferentially retrieve non-indexable
+#  container items in O(1) time from this stack rather than simply iterating
+#  over all container items in O(n) brute-force time. Obviously, extreme care
+#  must be taken here to ensure that this exception handling algorithm visits
+#  containers in the exact same order as visited by our testing algorithm.
+
+#FIXME: [COLOR] The call to the strip_text_ansi() function below is inefficient
+#and thus non-ideal. Since efficiency isn't a pressing concern in an exception
+#raiser, this is more a matter of design purity than anything. Still, it would
+#be preferable to avoid embedding ANSI escape sequences when the user requests
+#that rather than forcibly stripping those sequences out after the fact via an
+#inefficient regex. To do so, we'll want to:
+#* Augment the color_*() family of functions with a mandatory "conf:
+#  BeartypeConf" parameter.
+#* Pass that parameter to *EVERY* call to one of those functions.
+#* Refactor those functions to respect that parameter. The ideal means of
+#  doing so would probably be define in the
+#  "beartype._util.text.utiltextansi" submodule:
+#  * A new "_BeartypeTheme" dataclass mapping from style names to format
+#    strings embedding the ANSI escape sequences styling those styles.
+#  * A new pair of private "_THEME_MONOCHROME" and "_THEME_PRISMATIC"
+#    instances of that dataclass. The values of the "_THEME_MONOCHROME"
+#    dictionary should all just be the default format string: e.g.,
+#    _THEME_MONOCHROME = _BeartypeTheme(
+#        format_error='{text}',
+#        ...
+#    )
+#
+#    _THEME_PRISMATIC = _BeartypeTheme(
+#        format_error=f'{_STYLE_BOLD}{_COLOUR_RED}{{text}}{_COLOUR_RESET}',
+#        ...
+#    )
+#  * A new "_THEME_DEFAULT" instance of that dataclass conditionally defined
+#    as either "_THEME_MONOCHROME" or "_THEME_PRISMATIC" depending on
+#    whether stdout is attached to a TTY or not. Alternately, to avoid
+#    performing that somewhat expensive logic at module scope (and thus on
+#    initial beartype importation), it might be preferable to instead define
+#    a new cached private getter resembling:
+#
+#    @callable_cached
+#    def _get_theme_default() -> _BeartypeTheme:
+#        return (
+#            _THEME_PRISMATIC
+#            if is_stdout_terminal() else
+#            _THEME_MONOCHROME
+#        )
+
+# ....................{ IMPORTS                            }....................
+from beartype.meta import URL_ISSUES
+from beartype.roar._roarexc import (
+    _BeartypeCallHintPepRaiseDesynchronizationException,
+    _BeartypeCallHintPepRaiseException,
+)
+from beartype.typing import Optional
+from beartype._check.error._errorcause import ViolationCause
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._conf.confenum import BeartypeViolationVerbosity
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+from beartype._data.hint.datahinttyping import (
+    TypeException,
+    TypeStack,
+)
+from beartype._util.text.utiltextansi import (
+    color_hint,
+    strip_str_ansi,
+)
+from beartype._util.text.utiltextmunge import (
+    suffix_str_unless_suffixed,
+    uppercase_str_char_first,
+)
+from beartype._util.text.utiltextprefix import (
+    prefix_callable_return_value,
+    prefix_callable_arg_value,
+    prefix_pith_value,
+)
+from beartype._util.text.utiltextrepr import represent_object
+from collections.abc import Callable as CallableABC
+
+# ....................{ GETTERS                            }....................
+def get_func_pith_violation(
+    # Mandatory parameters.
+    func: CallableABC,
+    conf: BeartypeConf,
+    pith_name: str,
+    pith_value: object,
+
+    # Optional keyword parameters.
+    **kwargs
+) -> Exception:
+    '''
+    Human-readable exception detailing the failure of the parameter with the
+    passed name *or* return if this name is the magic string ``return`` of the
+    passed decorated function fails to satisfy the type hint annotating this
+    parameter or return.
+
+    Parameters
+    ----------
+    func : CallableTypes
+        Decorated callable to raise this exception from.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all flags, options, settings, and other metadata configuring the
+        current decoration of the decorated callable or class).
+    pith_name : str
+        Either:
+
+        * If the object failing to satisfy this hint is a passed parameter, the
+          name of this parameter.
+        * Else, the magic string ``"return"`` implying this object to be the
+          value returned from this callable.
+    pith_value : object
+        Passed parameter or returned value violating this hint.
+
+    All remaining keyword parameters are passed as is to the
+    :func:`.get_hint_object_violation` getter.
+
+    Returns
+    -------
+    Exception
+        Human-readable exception detailing the failure of this parameter or
+        return to satisfy the type hint annotating this parameter or return.
+        This is guaranteed to be an instance of either:
+
+        * If this is a parameter, :attr:`.BeartypeConf.violation_param_type`.
+        * If this is a return, :attr:`.BeartypeConf.violation_return_type`.
+
+    Raises
+    ------
+    All exceptions raised by the lower-level :func:`.get_hint_object_violation`
+    getter as well as:
+
+    _BeartypeCallHintPepRaiseException
+        If the parameter or return with the passed name is unannotated.
+
+    See Also
+    --------
+    :func:`.get_hint_object_violation`
+        Further details.
+    '''
+    assert callable(func), f'{repr(func)} uncallable.'
+    assert isinstance(pith_name, str), f'{repr(pith_name)} not string.'
+
+    # If this parameter or return value is unannotated, raise an exception.
+    #
+    # Note that this should *NEVER* occur, as the caller guarantees this
+    # parameter or return to be annotated. However, since malicious callers
+    # *COULD* deface the "__annotations__" dunder dictionary without our
+    # knowledge or permission, precautions are warranted.
+    if pith_name not in func.__annotations__:
+        raise _BeartypeCallHintPepRaiseException(f'{repr(func)} unannotated.')
+    # Else, this parameter or return value is annotated.
+
+    # Type hint annotating this parameter or return value.
+    #
+    # Note that we intentionally avoid calling the __annotations__.get() method
+    # to obtain this hint. Since "None" is a valid type hint, calling that
+    # method gains us nothing over the current approach.
+    hint = func.__annotations__[pith_name]
+
+    # Defer to this lower-level violation factory.
+    return get_hint_object_violation(
+        obj=pith_value,
+        hint=hint,
+        conf=conf,
+        func=func,
+        pith_name=pith_name,
+        **kwargs
+    )
+
+
+def get_hint_object_violation(
+    # Mandatory parameters.
+    obj: object,
+    hint: object,
+    conf: BeartypeConf,
+
+    # Optional parameters.
+    func: Optional[CallableABC] = None,
+    cls_stack: TypeStack = None,
+    exception_prefix: Optional[str] = None,
+    pith_name: Optional[str] = None,
+    random_int: Optional[int] = None,
+) -> Exception:
+    '''
+    Human-readable exception detailing the failure of the passed object to
+    satisfy the passed type hint under the passed beartype configuration.
+
+    This function intentionally returns rather than raises this exception. Why?
+    Because the ignorable stack frame encapsulating the call of the parent
+    type-checking wrapper function generated by the :mod:`beartype.beartype`
+    decorator complicates inspection of type-checking violations in tracebacks
+    (especially from :mod:`pytest`, which unhelpfully recapitulates the full
+    definition of this function including this docstring in those tracebacks).
+    Instead, that wrapper function raises this exception directly from itself.
+
+    Design
+    ------
+    The :mod:`beartype` package actually implements two parallel PEP-compliant
+    runtime type-checkers, each complementing the other by providing
+    functionality unsuited for the other. These are:
+
+    * The :mod:`beartype._check.code` submodule, dynamically generating
+      optimized PEP-compliant runtime type-checking code embedded in the body
+      of the wrapper function wrapping the decorated callable. For both
+      efficiency and maintainability, that code only tests whether or not a
+      parameter passed to that callable or value returned from that callable
+      satisfies a PEP-compliant annotation on that callable; that code does
+      *not* raise human-readable exceptions in the event that value fails to
+      satisfy that annotation. Instead, that code defers to...
+    * This function, performing unoptimized PEP-compliant runtime type-checking
+      generically applicable to all wrapper functions. The aforementioned
+      code calls this function only in the event that value fails to satisfy
+      that annotation, in which case this function then returns a human-readable
+      exception after discovering the underlying cause of this type failure by
+      recursively traversing that value and annotation. While efficiency is the
+      foremost focus of this package, efficiency is irrelevant during exception
+      handling -- which typically only occurs under infrequent edge cases.
+      Likewise, while raising this exception *would* technically be feasible
+      from the aforementioned code, doing so proved sufficiently non-trivial,
+      fragile, and ultimately unmaintainable to warrant offloading to this
+      function universally callable from all wrapper functions.
+
+    Parameters
+    ----------
+    obj : object
+        Arbitrary object to be type-checked against this type hint.
+    hint : object
+        Type hint against which to type-check this object.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all flags, options, settings, and other metadata configuring the
+        validation of this object against this type hint).
+    func : Optional[CallableABC]
+        Either:
+
+        * If this violation originates from a decorated callable, that
+          callable.
+        * Else, :data:`None`.
+
+        Defaults to :data:`None`.
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+    exception_prefix : Optional[str]
+        Either:
+
+        * If the caller prefers specifying an explicit human-readable label
+          prefixing the representation of this object in the exception message,
+          that labal.
+        * Else, :data:`None`. In this case, this getter automatically
+          synthesizes this label from the other passed parameters that are
+          required to be non-:data:`None`. If any such parameter is
+          :data:`None`, an exception is raised. These parameters include:
+
+          * The passed ``func`` parameter, required to be non-:data:`None`.
+          * The passed ``pith_name`` parameter, required to be non-:data:`None`.
+    pith_name : Optional[str]
+        Either:
+
+        * If this hint annotates a parameter of some callable, the name of that
+          parameter.
+        * If this hint annotates the return of some callable, ``"return"``.
+        * Else, :data:`None`.
+
+        Defaults to :data:`None`.
+    random_int: Optional[int], optional
+        **Pseudo-random integer** (i.e., unsigned 32-bit integer
+        pseudo-randomly generated by the parent :func:`beartype.beartype`
+        wrapper function in type-checking randomly indexed container items by
+        the current call to that function) if that function generated such an
+        integer *or* :data:`None` otherwise (i.e., if that function generated
+        *no* such integer). Note that this parameter critically governs whether
+        this exception handler runs in constant or linear time. Specifically, if
+        this parameter is:
+
+        * An integer, this handler runs in **constant time.** Since there exists
+          a one-to-one relation between this integer and the random container
+          item(s) type-checked by the parent :func:`beartype.beartype` wrapper
+          function, receiving this integer enables this handler to efficiently
+          re-type-check the same random container item(s) type-checked by the
+          parent in constant time rather type-checking all container items in
+          linear time.
+        * :data:`None`, this handler runs in **linear time.**
+
+        Defaults to :data:`None`, implying this exception handler runs in linear
+        time by default.
+
+    Returns
+    -------
+    Exception
+        Human-readable exception detailing the failure of this object to satisfy
+        the type hint. This is guaranteed to be an instance of either:
+
+        * If this is a parameter, :attr:`.BeartypeConf.violation_param_type`.
+        * If this is a return, :attr:`.BeartypeConf.violation_return_type`.
+        * Else, :attr:`.BeartypeConf.violation_door_type`.
+
+    Raises
+    ------
+    BeartypeDecorHintPepException
+        If the type hint annotating this object is *not* PEP-compliant.
+    _BeartypeCallHintPepRaiseException
+        If all three of the ``exception_prefix``,``func``, and ``pith_name``
+        parameters are :data:`None`.
+    _BeartypeCallHintPepRaiseDesynchronizationException
+        If this pith actually satisfies this hint, implying either:
+
+        * The parent wrapper function generated by the :mod:`beartype.beartype`
+          decorator type-checking this pith triggered a false negative by
+          erroneously misdetecting this pith as failing this type check.
+        * This child helper function re-type-checking this pith triggered a
+          false positive by erroneously misdetecting this pith as satisfying
+          this type check when in fact this pith fails to do so.
+    '''
+    # print('''get_hint_object_violation(
+    #     func={!r},
+    #     hint={!r},
+    #     conf={!r},
+    #     pith_name={!r},
+    #     pith_value={!r}',
+    # )'''.format(func, hint, conf, pith_name, pith_value))
+
+    # ....................{ LOCALS                         }....................
+    # Type of violation to be raised.
+    exception_cls: TypeException = None  # type: ignore[assignment]
+
+    # If the caller passed *NO* parameter name, the passed object is neither a
+    # parameter nor return of a decorated callable. By elimination, this object
+    # *MUST* have been directly passed to the beartype.door.die_if_unbearable()
+    # type-checker. In this case...
+    if pith_name is None:
+        # If the caller also passed *NO* exception prefix, raise an exception.
+        if exception_prefix is None:
+            raise _BeartypeCallHintPepRaiseException(
+                'get_hint_object_violation() passed neither '
+                '"exception_prefix" nor "pith_name" parameters.'
+            )
+        # Else, the caller passed an exception prefix.
+
+        # Default the exception class appropriately.
+        exception_cls = conf.violation_door_type
+
+        # Suffix this exception prefix with an additional noun for disambiguity.
+        exception_prefix = (
+            f'{exception_prefix}value '
+            f'{prefix_pith_value(pith=obj, is_color=conf.is_color)}'
+        )
+    # Else, the caller passed a parameter name. In this case...
+    else:
+        # If the caller also passed an exception prefix, raise an exception.
+        if exception_prefix is not None:
+            raise _BeartypeCallHintPepRaiseException(
+                'get_hint_object_violation() passed both '
+                '"exception_prefix" and "pith_name" parameters.'
+            )
+        # Else, the caller passed *NO* exception prefix.
+
+        # If the name of this parameter is the magic string implying the passed
+        # object to be a return value...
+        if pith_name == ARG_NAME_RETURN:
+            # Default these exception locals appropriately
+            exception_cls = conf.violation_return_type
+            exception_prefix = prefix_callable_return_value(
+                func=func,  # type: ignore[arg-type]
+                return_value=obj,
+                is_color=conf.is_color,
+            )
+        # Else, the passed object is a parameter. In this case...
+        else:
+            # Default these exception locals appropriately
+            exception_cls = conf.violation_param_type
+            exception_prefix = prefix_callable_arg_value(
+                func=func,  # type: ignore[arg-type]
+                arg_name=pith_name,
+                arg_value=obj,
+                is_color=conf.is_color,
+            )
+
+    # Uppercase the first character of this violation prefix for readability.
+    exception_prefix = uppercase_str_char_first(exception_prefix)
+
+    # ....................{ CAUSE                          }....................
+    # Cause describing the failure of this pith to satisfy this hint.
+    violation_cause = ViolationCause(
+        cause_indent='',
+        cls_stack=cls_stack,
+        conf=conf,
+        exception_prefix=exception_prefix,
+        func=func,
+        hint=hint,
+        pith=obj,
+        pith_name=pith_name,
+        random_int=random_int,
+    ).find_cause()
+
+    # If this pith satisfies this hint, *SOMETHING HAS GONE TERRIBLY AWRY.*
+    #
+    # In theory, this should never happen, as the parent wrapper function
+    # performing type checking should *ONLY* call this child helper function
+    # when this pith does *NOT* satisfy this hint. In this case, raise an
+    # exception encouraging the end user to submit an upstream issue with us.
+    if not violation_cause.cause_str_or_none:
+        pith_value_repr = represent_object(
+            obj=obj, max_len=_CAUSE_TRIM_OBJECT_REPR_MAX_LEN)
+        raise _BeartypeCallHintPepRaiseDesynchronizationException(
+            f'{exception_prefix}violates type hint {repr(hint)}, '
+            f'but violation factory get_hint_object_violation() '
+            f'erroneously suggests this object satisfies this hint. '
+            f'Please report this desynchronization failure to '
+            f'the beartype issue tracker ({URL_ISSUES}) with '
+            f'the accompanying exception traceback and '
+            f'the representation of this object:\n'
+            f'    {pith_value_repr}\n'
+            f'The bear groans in disappointment. If you feel similarly, '
+            f'know that you are not alone.'
+        )
+    # Else, this pith violates this hint as expected and as required for sanity.
+
+    # This failure suffixed by a period if *NOT* yet suffixed by a period.
+    violation_cause_suffixed = suffix_str_unless_suffixed(
+        text=violation_cause.cause_str_or_none, suffix='.')
+
+    # List of the one or more culprits responsible for this violation,
+    # initialized to the passed parameter or returned value violating this hint.
+    violation_culprits = [obj,]
+
+    # If the actual object directly responsible for this violation is *NOT* the
+    # passed parameter or returned value indirectly violating this hint, then
+    # the latter is almost certainly a container transitively containing the
+    # former as an item. In this case, add this item to this list as well.
+    if obj is not violation_cause.pith:
+        violation_culprits.append(violation_cause.pith)
+    # Else, the actual object directly responsible for this violation is the
+    # passed parameter or returned value indirectly violating this hint. In this
+    # case, avoid adding duplicate items to this list.
+
+    # ....................{ VERBOSITY                      }....................
+    # Violation verbosity, localized for negligible efficiency. *vomits*
+    violation_verbosity = conf.violation_verbosity
+
+    # Machine-readable representation of this hint embellished with colour.
+    hint_repr = f'{color_hint(text=repr(hint), is_color=conf.is_color)}'
+
+    # Dictionary mapping from each possibly violation verbosity to a
+    # corresponding substring prepending this exception message.
+    VIOLATION_VERBOSITY_TO_PREFIX = {
+        BeartypeViolationVerbosity.MINIMAL: (
+            f'{exception_prefix}was expected to be of type {hint_repr}'),
+        BeartypeViolationVerbosity.DEFAULT: (
+            f'{exception_prefix}violates type hint {hint_repr}'),
+    }
+    VIOLATION_VERBOSITY_TO_PREFIX[BeartypeViolationVerbosity.MAXIMAL] = (  # <-- alias!
+        VIOLATION_VERBOSITY_TO_PREFIX[BeartypeViolationVerbosity.DEFAULT])
+
+    # Dictionary mapping from each possibly violation verbosity to a
+    # corresponding substring embedded in the middle of this exception message.
+    VIOLATION_VERBOSITY_TO_INFIX = {
+        BeartypeViolationVerbosity.MINIMAL: '',
+        BeartypeViolationVerbosity.DEFAULT: '',
+        BeartypeViolationVerbosity.MAXIMAL: (
+            # If this configuration is the default configuration, avoid
+            # needlessly representing this default configuration.
+            ''
+            if conf == BEARTYPE_CONF_DEFAULT else
+            # Else, this configuration is *NOT* the default configuration. In
+            # this case, append the machine-readable representation of this
+            # non-default configuration to this exception message for
+            # disambiguity and clarity.
+            f' under non-default configuration {repr(conf)}'
+        ),
+    }
+
+    # Dictionary mapping from each possibly violation verbosity to a
+    # corresponding substring appending this exception message.
+    VIOLATION_VERBOSITY_TO_SUFFIX = {
+        BeartypeViolationVerbosity.MINIMAL: '.',
+        BeartypeViolationVerbosity.DEFAULT: f', as {violation_cause_suffixed}',
+    }
+    VIOLATION_VERBOSITY_TO_SUFFIX[BeartypeViolationVerbosity.MAXIMAL] = (  # <-- alias!
+        VIOLATION_VERBOSITY_TO_SUFFIX[BeartypeViolationVerbosity.DEFAULT])
+
+    # ....................{ EXCEPTION                      }....................
+    # Human-readable violation message to be raised.
+    exception_message = (
+        f'{VIOLATION_VERBOSITY_TO_PREFIX[violation_verbosity]}'
+        f'{VIOLATION_VERBOSITY_TO_INFIX[violation_verbosity]}'
+        f'{VIOLATION_VERBOSITY_TO_SUFFIX[violation_verbosity]}'
+    )
+
+    #FIXME: In theory, this should no longer be needed. Consider:
+    #* Refactoring all instances of "is_color=True" throughout this subpackage
+    #  to instead read "is_color=cause.conf.is_color".
+    #* Refactoring all calls to the represent_pith() function throughout this
+    #  subpackage to additionally pass a new optional
+    #  "is_color=cause.conf.is_color" parameter.
+    #* Refactoring this call away.
+    #* Validating with unit tests that violation messages contain *NO* ANSI when
+    #  configured such that "BeartypeConf(is_color=False)".
+    # Strip all ANSI escape sequences from this message if requested by this
+    # external user-defined configuration.
+    exception_message = strip_str_ansi(
+        text=exception_message, is_color=conf.is_color)
+
+    # Exception of the desired class embedding this cause. By default, attempt
+    # to pass @beartype-specific parameters to this exception subclass.
+    try:
+        exception = exception_cls(  # type: ignore[call-arg]
+            message=exception_message,  # pyright: ignore
+            culprits=tuple(violation_culprits),  # pyright: ignore
+        )
+    # If this exception subclass fails to support @beartype-specific parameters,
+    # fallback to the standard exception idiom of a positionally passed message.
+    except TypeError:
+        exception = exception_cls(exception_message)
+
+    # Return this exception to the @beartype-generated type-checking wrapper
+    # (which directly calls this function), which will then squelch the
+    # ignorable stack frame encapsulating that call to this function by raising
+    # this exception directly from that wrapper.
+    return exception
+
+# ....................{ PRIVATE ~ constants                }....................
+# Assuming a line length of 80 characters, this magic number truncates
+# arbitrary object representations to 100 lines (i.e., 8000/80), which seems
+# more than reasonable and (possibly) not overly excessive.
+_CAUSE_TRIM_OBJECT_REPR_MAX_LEN = 8000
+'''
+Maximum length of arbitrary object representations suffixing human-readable
+strings returned by the :func:`_find_cause` getter function, intended to
+be sufficiently long to assist in identifying type-check failures but not so
+excessively long as to prevent human-readability.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/forward/fwdmain.py
@@ -0,0 +1,609 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **stringified type hint utilities** (i.e., low-level callables handling
+**stringified type hints** (i.e., declared as :pep:`484`- or
+:pep:`563`-compliant forward references referring to actual type hints that have
+yet to be declared in the local and global scopes declaring a callable or
+class)).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from __future__ import annotations
+from beartype.roar import (
+    BeartypeDecorHintForwardRefException,
+    BeartypeDecorHintPep604Exception,
+)
+from beartype.roar._roarexc import _BeartypeUtilCallableScopeNotFoundException
+from beartype.typing import Optional
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.forward.fwdscope import BeartypeForwardScope
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.kind.datakinddict import DICT_EMPTY
+from beartype._data.kind.datakindset import FROZENSET_EMPTY
+from beartype._util.cls.utilclsget import get_type_locals
+from beartype._util.func.utilfuncscope import (
+    get_func_globals,
+    get_func_locals,
+)
+from beartype._util.module.utilmodget import get_object_module_name
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_MOST_3_9
+from builtins import __dict__ as func_builtins  # type: ignore[attr-defined]
+
+# ....................{ RESOLVERS                          }....................
+#FIXME: Unit test us up, please.
+def resolve_hint(
+    # Mandatory parameters.
+    hint: str,
+    bear_call: BeartypeCall,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintForwardRefException,
+    exception_prefix: str = '',
+) -> object:
+    '''
+    Resolve the passed **stringified type hint** (i.e., declared as a
+    :pep:`484`- or :pep:`563`-compliant forward reference referring to an actual
+    type hint that has yet to be declared in the local and global scopes
+    declaring the currently decorated class or callable) to the non-string type
+    hint to which this stringified type hint refers.
+
+    This resolver is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). Resolving both absolute *and* relative
+    forward references assumes contextual context (e.g., the fully-qualified
+    name of the object to which relative forward references are relative to)
+    that *cannot* be safely and context-freely memoized away.
+
+    Parameters
+    ----------
+    hint : str
+        Stringified type hint to be resolved.
+    bear_call : BeartypeCall
+        Decorated callable annotated by this hint.
+    exception_cls : Type[Exception], optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintForwardRefException`.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this possibly PEP-noncompliant hint is coercible, a PEP-compliant
+          type hint coerced from this hint.
+        * Else, this hint as is unmodified.
+
+    Raises
+    ------
+    exception_cls
+        If attempting to dynamically evaluate this stringified type hint into a
+        non-string type hint against both the global and local scopes of the
+        decorated callable raises an exception, typically due to this
+        stringified type hint being syntactically invalid.
+    BeartypeDecorHintPep604Exception
+        If the active Python interpreter is Python <= 3.9 and this stringified
+        type hint is a :pep:`604`-compliant new-style union, which requires
+        Python >= 3.10.
+    '''
+    assert isinstance(hint, str), f'{repr(hint)} not stringified type hint.'
+    assert isinstance(bear_call, BeartypeCall), (
+        f'{repr(bear_call)} not @beartype call.')
+    # print(f'Resolving stringified type hint {repr(hint)}...')
+
+    # ..................{ LOCALS                             }..................
+    # Decorated callable and metadata associated with that callable, localized
+    # to improve both readability and negligible efficiency when accessed below.
+    func = bear_call.func_wrappee_wrappee
+
+    # If the frozen set of the unqualified names of all parent callables
+    # lexically containing this decorated callable has yet to be decided...
+    if bear_call.func_wrappee_scope_nested_names is None:
+        # Decide this frozen set as either...
+        bear_call.func_wrappee_scope_nested_names = (
+            # If the decorated callable is nested, the non-empty frozen set of
+            # the unqualified names of all parent callables lexically containing
+            # this nested decorated callable (including this nested decorated
+            # callable itself);
+            frozenset(func.__qualname__.rsplit(sep='.'))
+            if bear_call.func_wrappee_is_nested else
+            # Else, the decorated callable is a global function. In this
+            # case, the empty frozen set.
+            FROZENSET_EMPTY
+        )
+    # Else, this frozen set has already been decided.
+    #
+    # In either case, this frozen set is now decided. I choose you!
+
+    # If this hint is the unqualified name of a parent callable or class of the
+    # decorated callable, then this hint is a relative forward reference to a
+    # parent callable or class of the decorated callable that is currently being
+    # defined but has yet to be defined in full. If PEP 563 postponed this type
+    # hint under "from __future__ import annotations", this hint *MUST* have
+    # been a locally or globally scoped attribute of the decorated callable
+    # before being postponed by PEP 563 into a relative forward reference to
+    # that attribute: e.g.,
+    #     from __future__ import annotations
+    #
+    #     # If this is a PEP 563-postponed type hint...
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> 'MuhClass': ...
+    #
+    #     # ...then the original type hints prior to being postponed *MUST*
+    #     # have annotated this pre-PEP 563 method signature.
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> MuhClass: ...
+    #
+    # In this case, avoid attempting to resolve this forward reference. Why?
+    # Disambiguity. Although the "MuhClass" class has yet to be defined at the
+    # time @beartype decorates the muh_method() method, an attribute of the same
+    # name may already have been defined at that time: e.g.,
+    #     # While bad form, PEP 563 postpones this valid logic...
+    #     MuhClass = "Just kidding! Had you going there, didn't I?"
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> MuhClass: ...
+    #
+    #     # ...into this relative forward reference.
+    #     MuhClass = "Just kidding! Had you going there, didn't I?"
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> 'MuhClass': ...
+    #
+    # Naively resolving this forward reference would erroneously replace this
+    # hint with the previously declared attribute rather than the class
+    # currently being declared: e.g.,
+    #     # Naive PEP 563 resolution would replace the above by this!
+    #     MuhClass = "Just kidding! Had you going there, didn't I?"
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> (
+    #             "Just kidding! Had you going there, didn't I?"): ...
+    #
+    # This isn't just an edge-case disambiguity, however. This situation
+    # commonly arises when reloading modules containing @beartype-decorated
+    # callables annotated with self-references (e.g., by passing those modules
+    # to the standard importlib.reload() function). Why? Because module
+    # reloading is ill-defined and mostly broken under Python. Since the
+    # importlib.reload() function fails to delete any of the attributes of the
+    # module to be reloaded before reloading that module, the parent callable or
+    # class referred to by this hint will be briefly defined for the duration of
+    # @beartype's decoration of the decorated callable as the prior version of
+    # that parent callable or class!
+    #
+    # Resolving this hint would thus superficially succeed, while actually
+    # erroneously replacing this hint with the prior rather than current version
+    # of that parent callable or class. @beartype would then wrap the decorated
+    # callable with a wrapper expecting the prior rather than current version of
+    # that parent callable or class. All subsequent calls to that wrapper would
+    # then fail. Since this actually happened, we ensure it never does again.
+    #
+    # Lastly, note that this edge case *ONLY* supports top-level relative
+    # forward references (i.e., syntactically valid Python identifier names
+    # subscripting *NO* parent type hints). Child relative forward references
+    # will continue to raise exceptions. As resolving PEP 563-postponed type
+    # hints effectively reduces to a single "all or nothing" call of the
+    # low-level eval() builtin accepting *NO* meaningful configuration, there
+    # exists *NO* means of only partially resolving parent type hints while
+    # preserving relative forward references subscripting those hints. The
+    # solution in those cases is for end users to either:
+    #
+    # * Decorate classes rather than methods: e.g.,
+    #     # Users should replace this method decoration, which will fail at
+    #     # runtime...
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> list[MuhClass]: ...
+    #
+    #     # ...with this class decoration, which will work.
+    #     @beartype
+    #     class MuhClass:
+    #         def muh_method(self) -> list[MuhClass]: ...
+    # * Replace implicit with explicit forward references: e.g.,
+    #     # Users should replace this implicit forward reference, which will
+    #     # fail at runtime...
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> list[MuhClass]: ...
+    #
+    #     # ...with this explicit forward reference, which will work.
+    #     class MuhClass:
+    #         @beartype
+    #         def muh_method(self) -> list['MuhClass']: ...
+    #
+    # Indeed, the *ONLY* reasons we support this common edge case are:
+    # * This edge case is indeed common.
+    # * This edge case is both trivial and efficient to support.
+    #
+    # tl;dr: Preserve this hint for disambiguity by reducing to a noop.
+    if hint in bear_call.func_wrappee_scope_nested_names:  # type: ignore[operator]
+        return hint
+    # Else, this hint is *NOT* the unqualified name of a parent callable or
+    # class of the decorated callable. In this case, this hint *COULD* require
+    # dynamic evaluation under the eval() builtin. Why? Because this hint could
+    # simply be the stringified name of a PEP 563-postponed unsubscripted
+    # "typing" non-class attribute imported at module scope. While valid as a
+    # type hint, this attribute is *NOT* a class. Returning this stringified
+    # hint as is would erroneously instruct our code generation algorithm to
+    # treat this stringified hint as a relative forward reference to a class.
+    # Instead, evaluate this stringified hint into its referent below: e.g.,
+    #     from __future__ import annotations
+    #     from typing import Hashable
+    #
+    #     # PEP 563 postpones this into:
+    #     #     def muh_func() -> 'Hashable':
+    #     def muh_func() -> Hashable:
+    #         return 'This is hashable, yo.'
+
+    # If the forward scope of the decorated callable has yet to be decided...
+    if bear_call.func_wrappee_scope_forward is None:
+        # Localize metadata for readability and efficiency. Look. Just do it.
+        cls_stack = bear_call.cls_stack
+
+        # Fully-qualified name of the module declaring the decorated callable,
+        # which also serves as the name of this module and thus global scope.
+        func_module_name = get_object_module_name(func)  # type: ignore[operator]
+
+        # Global scope of the decorated callable.
+        func_globals = get_func_globals(func=func, exception_cls=exception_cls)
+
+        # If the decorated callable is nested (rather than global) and thus
+        # *MAY* have a non-empty local nested scope...
+        if bear_call.func_wrappee_is_nested:
+            # Attempt to...
+            try:
+                # Local scope of the decorated callable, localized to improve
+                # readability and negligible efficiency when accessed below.
+                func_locals = get_func_locals(
+                    func=func,
+
+                    # Ignore all lexical scopes in the fully-qualified name of
+                    # the decorated callable corresponding to parent classes
+                    # lexically nesting the current decorated class containing
+                    # that callable (including that class). Why? Because these
+                    # classes are *ALL* currently being decorated and thus have
+                    # yet to be encapsulated by new stack frames on the call
+                    # stack. If these lexical scopes are *NOT* ignored, this
+                    # call to get_func_locals() will fail to find the parent
+                    # lexical scope of the decorated callable and then raise an
+                    # unexpected exception.
+                    #
+                    # Consider, for example, this nested class decoration of a
+                    # fully-qualified "muh_package.Outer" class:
+                    #     @beartype
+                    #     class Outer(object):
+                    #         class Middle(object):
+                    #             class Inner(object):
+                    #                 def muh_method(self) -> str:
+                    #                     return 'Painful API is painful.'
+                    #
+                    # When @beartype finally recurses into decorating the nested
+                    # muh_package.Outer.Middle.Inner.muh_method() method, this
+                    # call to get_func_locals() if *NOT* passed this parameter
+                    # would naively assume that the parent lexical scope of the
+                    # current muh_method() method on the call stack is named
+                    # "Inner". Instead, the parent lexical scope of that method
+                    # on the call stack is named "muh_package" -- the first
+                    # lexical scope enclosing that method that exists on the
+                    # call stack. The non-existent "Outer", "Middle", and
+                    # "Inner" lexical scopes must *ALL* be silently ignored.
+                    func_scope_names_ignore=(
+                        0 if cls_stack is None else len(cls_stack)),
+
+                    #FIXME: Consider dynamically calculating exactly how many
+                    #additional @beartype-specific frames are ignorable on the
+                    #first call to this function, caching that number, and then
+                    #reusing that cached number on all subsequent calls to this
+                    #function. The current approach employed below of naively
+                    #hard-coding a number of frames to ignore was incredibly
+                    #fragile and had to be effectively disabled, which hampers
+                    #runtime efficiency.
+
+                    # Ignore additional frames on the call stack embodying:
+                    # * The current call to this function.
+                    #
+                    # Note that, for safety, we currently avoid ignoring
+                    # additional frames that we could technically ignore. These
+                    # include:
+                    # * The call to the parent
+                    #   beartype._check.checkcall.BeartypeCall.reinit() method.
+                    # * The call to the parent @beartype.beartype() decorator.
+                    #
+                    # Why? Because the @beartype codebase has been sufficiently
+                    # refactored so as to render any such attempts non-trivial,
+                    # fragile, and frankly dangerous.
+                    func_stack_frames_ignore=1,
+                    exception_cls=exception_cls,
+                )
+            # If this local scope cannot be found (i.e., if this getter found
+            # the lexical scope of the module declaring the decorated callable
+            # *BEFORE* that of the parent callable or class declaring that
+            # callable), then this resolve_hint() function was called *AFTER*
+            # rather than *DURING* the declaration of the decorated callable.
+            # This implies that that callable is not, in fact, currently being
+            # decorated. Instead, that callable was *NEVER* decorated by
+            # @beartype but has instead subsequently been passed to this
+            # resolve_hint() function after its initial declaration -- typically
+            # due to an external caller passing that callable to our public
+            # beartype.peps.resolve_pep563() function.
+            #
+            # In this case, the call stack frame providing this local scope has
+            # (almost certainly) already been deleted and is no longer
+            # accessible. We have no recourse but to default this local scope to
+            # the empty dictionary -- which might be subsequently modified and
+            # *CANNOT* thus default to the singleton empty dictionary
+            # "DICT_EMPTY" (unlike below).
+            except _BeartypeUtilCallableScopeNotFoundException:
+                func_locals = {}
+
+            # If the decorated callable is a method transitively defined by a
+            # root decorated class, add a pair of local attributes exposing:
+            #
+            # * The unqualified basename of the root decorated class. Why?
+            #   Because this class may be recursively referenced in postponed
+            #   type hints and *MUST* thus be exposed to *ALL* postponed type
+            #   hints. However, this class is currently being decorated and thus
+            #   has yet to be defined in either:
+            #   * If this class is module-scoped, the global attribute
+            #     dictionary of that module and thus the "func_globals"
+            #     dictionary.
+            #   * If this class is closure-scoped, the local attribute
+            #     dictionary of that closure and thus the "func_locals"
+            #     dictionary.
+            # * The unqualified basename of the current decorated class. Why?
+            #   For similar reasons. Since the current decorated class may be
+            #   lexically nested in the root decorated class, the current
+            #   decorated class is *NOT* already accessible as either a global
+            #   or local. Exposing the current decorated class to a stringified
+            #   type hint referencing that class thus requires adding a local
+            #   attribute exposing that class.
+            #
+            # Note that:
+            # * *ALL* intermediary classes (i.e., excluding the root decorated
+            #   class) lexically nesting the current decorated class are
+            #   irrelevant. Intermediary classes are neither module-scoped nor
+            #   closure-scoped and thus inaccessible as either globals or locals
+            #   in the nested lexical scope of the current decorated class:
+            #   e.g.,
+            #     # This raises a parser error and is thus *NOT* fine:
+            #     #     NameError: name 'muh_type' is not defined
+            #     class Outer(object):
+            #         class Middle(object):
+            #             muh_type = str
+            #
+            #             class Inner(object):
+            #                 def muh_method(self) -> muh_type:
+            #                     return 'Dumpster fires are all I see.'
+            # * This implicitly overrides any previously declared locals of the
+            #   same name. Although non-ideal, this constitutes syntactically
+            #   valid Python and is thus *NOT* worth emitting even a non-fatal
+            #   warning over: e.g.,
+            #     # This is fine... technically.
+            #     from beartype import beartype
+            #     def muh_closure() -> None:
+            #         MuhClass = 'This is horrible, yet fine.'
+            #
+            #         @beartype
+            #         class MuhClass(object):
+            #             def muh_method(self) -> str:
+            #                 return 'Look away and cringe, everyone!'
+            if cls_stack:
+                # Root and current decorated classes.
+                cls_root = cls_stack[0]
+                cls_curr = cls_stack[-1]
+
+                # Add new locals exposing these classes to type hints,
+                # overwriting any locals of the same names in the higher-level
+                # local scope for any closure declaring this class if any. These
+                # classes are currently being decorated and thus guaranteed to
+                # be the most recent declarations of these attributes.
+                #
+                # Note that the current class assumes lexical precedence over
+                # the root class and is thus added *AFTER* the latter.
+                func_locals[cls_root.__name__] = cls_root
+                func_locals[cls_curr.__name__] = cls_curr
+
+                # Local scope for the class directly defining this method.
+                #
+                # Note that callables *ONLY* have direct access to attributes
+                # declared by the classes directly defining those callables.
+                # Ergo, the local scopes for parent classes of this class
+                # (including the root decorated class) are irrelevant.
+                cls_curr_locals = get_type_locals(
+                    cls=cls_curr,
+                    exception_cls=exception_cls,
+                )
+
+                # Forcefully merge this local scope into the current
+                # local scope, implicitly overwriting any locals of the
+                # same name. Class locals necessarily assume lexical
+                # precedence over:
+                # * These classes themselves.
+                # * Locals defined by higher-level parent classes.
+                # * Locals defined by closures defining these classes.
+                func_locals.update(cls_curr_locals)
+            # Else, the decorated callable is *NOT* a method transitively
+            # declared by a root decorated class.
+        # Else, the decorated callable is global and thus guaranteed to have an
+        # empty local scope. In this case, default to the empty dictionary.
+        else:
+            func_locals = DICT_EMPTY
+
+        # Forward scope compositing this global and local scope of the decorated
+        # callable as well as dynamically replacing each unresolved attribute of
+        # this stringified type hint with a forward reference proxy resolving
+        # this attribute on the first attempt to pass this attribute as the
+        # second parameter to an isinstance()-based runtime type-check: e.g.,
+        #     from beartype import beartype
+        #     from beartype.typing import Dict, Generic, TypeVar
+        #
+        #     T = TypeVar('T')
+        #
+        #     # @beartype resolves this stringified type hint as follows:
+        #     # * The "Dict", "str", and "int" attributes are globals and thus
+        #     #   trivially resolved to those objects via the "func_globals"
+        #     #   scope decided above.
+        #     # * The "MuhGeneric" attribute is neither a global nor local and
+        #     #   thus remains unresolved. This forward scope replaces this
+        #     #   unresolved attribute with a forward reference proxy.
+        #     @beartype
+        #     def muh_func(muh_arg: 'Dict[str, MuhGeneric[int]]') -> None: ...
+        #
+        #     class MuhGeneric(Generic[T]): ...
+        #
+        # Initialize this forward scope to the set of all builtin attributes
+        # (e.g., "str", "Exception"). Although the eval() builtin does, of
+        # course, implicitly evaluate this stringified type hint against all
+        # builtin attributes, it does so only *AFTER* invoking the
+        # BeartypeForwardScope.__missing__() dunder method with each such
+        # builtin attribute referenced in this hint. Since handling that
+        # eccentricity would be less efficient and trivial than simply
+        # initializing this forward scope with all builtin attributes, we prefer
+        # the current (admittedly sus af) approach. Do not squint at this.
+        bear_call.func_wrappee_scope_forward = BeartypeForwardScope(
+            scope_dict=func_builtins, scope_name=func_module_name)
+
+        # Composite this global and local scope into this forward scope (in that
+        # order), implicitly overwriting first each builtin attribute and then
+        # each global attribute previously copied into this forward scope with
+        # each global and then local attribute of the same name. Since locals
+        # *ALWAYS* assume precedence over globals *ALWAYS* assume precedence
+        # over builtins, order of operations is *EXTREMELY* significant here.
+        bear_call.func_wrappee_scope_forward.update(func_globals)
+        bear_call.func_wrappee_scope_forward.update(func_locals)
+        # print(f'Forward scope: {bear_call.func_wrappee_scope_forward}')
+    # Else, this forward scope has already been decided.
+    #
+    # In either case, this forward scope should now all have been decided.
+
+    # ..................{ RESOLVE                            }..................
+    # Attempt to resolve this stringified type hint into a non-string type hint
+    # against both the global and local scopes of the decorated callable.
+    try:
+        hint_resolved = eval(hint, bear_call.func_wrappee_scope_forward)
+        # print(f'Resolved stringified type hint {repr(hint)} to {repr(hint_resolved)}...')
+    # If doing so failed for *ANY* reason whatsoever...
+    except Exception as exception:
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not exception class.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Human-readable message to be raised if this message has been defined
+        # *OR* "None" otherwise (i.e., if this message has yet to be defined).
+        exception_message: Optional[str] = None
+
+        # If the following conditions all hold:
+        # * The active Python interpreter targets Python < 3.10 *AND*...
+        # * The external module defining this stringified type hint was prefixed
+        #   by the "from __future__ import annotations" pragma enabling PEP 563
+        #   *AND*...
+        # * This hint contains one or more PEP 604-compliant new unions (e.g.,
+        #   "int | str")...
+        #
+        # ...then this interpreter fails to syntactically support this hint at
+        # runtime (because only Python >= 3.10 supports PEP 604) but nonetheless
+        # superficially appears to do so under PEP 563 by simply stringifying
+        # this otherwise unsupported hint into a string. Indeed, PEP 563
+        # superficially appears to support a countably infinite set of
+        # syntactically and semantically invalid type hints -- including but
+        # certainly not limited to PEP 604 under Python < 3.10: e.g.,
+        #     from __future__ import annotations  # <-- enable PEP 563
+        #     def bad() -> int | str: # <-- invalid under Python < 3.10, but
+        #         pass                #     silently ignored by PEP 563
+        #     def BAD() -> int ** str:  # <-- invalid under all Python versions,
+        #         pass                  #     but silently ignored by PEP 563
+        #
+        # Clearly, exponentiating one type by another is both syntactically and
+        # semantically invalid -- but PEP 563 blindly accepts and stringifies
+        # that invalid type hint into the string "int ** str". This is nonsense.
+        #
+        # This branch detects this discrepancy between PEP 563 and 604 and, when
+        # detected, raises a human-readable exception advising the caller with
+        # recommendations of how to resolve this. Although we could also simply
+        # do nothing, doing nothing results in non-human-readable exceptions
+        # resembling the following, which only generates confusion: e.g.,
+        #     $ python3.9
+        #     >>> int | str
+        #     Traceback (most recent call last):
+        #       File "<stdin>", line 1, in <module>
+        #     TypeError: unsupported operand type(s) for |: 'type' and 'type'
+        #
+        # Specifically, if...
+        if (
+            # The active Python interpreter targets Python <= 3.9 *AND*...
+            IS_PYTHON_AT_MOST_3_9 and
+            # Evaluating this stringified type hint raised a "TypeError"...
+            isinstance(exception, TypeError)
+        ):
+            # If the exception message raised by this "TypeError" is prefixed by
+            # a well-known substring implying this exception to have been
+            # produced by a discrepancy between PEP 563 and 604...
+            if str(exception).startswith(
+                'unsupported operand type(s) for |: '):
+                # PEP 604-specific exception type, forcefully overriding the
+                # passed exception type (for disambiguity).
+                exception_cls = BeartypeDecorHintPep604Exception
+
+                # Human-readable message providing various recommendations.
+                exception_message = (
+                    f'{exception_prefix}stringified PEP 604 type hint '
+                    f'{repr(hint)} syntactically invalid under Python < 3.10 '
+                    f'(i.e., {repr(exception)}). Consider either:\n'
+                    f'* Requiring Python >= 3.10. Abandon Python < 3.10 all '
+                    f'ye who code here.\n'
+                    f'* Refactoring PEP 604 type hints into '
+                    f'equivalent PEP 484 type hints: e.g.,\n'
+                    f'    # Instead of this...\n'
+                    f'    from __future__ import annotations\n'
+                    f'    def bad_func() -> int | str: ...\n'
+                    f'\n'
+                    f'    # Do this. Ugly, yet it works. Worky >>>> pretty.\n'
+                    f'    from typing import Union\n'
+                    f'    def bad_func() -> Union[int, str]: ...'
+                )
+            # Else, this another kind of "TypeError" entirely. In this case,
+            # defer to the default message defined below.
+        # Else, either the active Python interpreter targets Python >= 3.10 *OR*
+        # another type of exception was raised. In either case, defer to the
+        # default message defined below.
+
+        # If a human-readable message has yet to be defined, fallback to a
+        # default message generically applicable to *ALL* stringified hints.
+        if exception_message is None:
+            # Human-readable message to be raised.
+            exception_message = (
+                f'{exception_prefix}stringified type hint '
+                f'{repr(hint)} syntactically invalid '
+                f'(i.e., {repr(exception)}).'
+            )
+
+            # If the beartype configuration associated with the decorated
+            # callable enabled debugging, append debug-specific metadata to this
+            # message.
+            if bear_call.conf.is_debug:
+                exception_message += (
+                    f' Composite global and local scope enclosing this hint:\n\n'
+                    f'{repr(bear_call.func_wrappee_scope_forward)}'
+                )
+            # Else, the beartype configuration associated with the decorated
+            # callable disabled debugging. In this case, avoid appending
+            # debug-specific metadata to this message.
+        # Else, a human-readable message has already been defined.
+
+        # Raise a human-readable exception wrapping the typically
+        # non-human-readable exception raised above.
+        raise exception_cls(exception_message) from exception
+
+    # ..................{ RETURN                             }..................
+    # Return this resolved hint.
+    return hint_resolved
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/forward/fwdscope.py
@@ -0,0 +1,192 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **forward scope classes** (i.e., dictionary subclasses deferring the
+resolutions of local and global scopes of classes and callables decorated by the
+:func:`beartype.beartype` decorator when dynamically evaluating stringified type
+hints for those classes and callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintForwardRefException
+from beartype.typing import Type
+from beartype._data.hint.datahinttyping import LexicalScope
+from beartype._check.forward.reference.fwdrefabc import (
+    _BeartypeForwardRefIndexableABC)
+from beartype._check.forward.reference.fwdrefmake import (
+    make_forwardref_indexable_subtype)
+from beartype._util.text.utiltextidentifier import die_unless_identifier
+
+# ....................{ SUBCLASSES                         }....................
+#FIXME: Unit test us up, please.
+class BeartypeForwardScope(LexicalScope):
+    '''
+    **Forward scope** (i.e., dictionary mapping from the name to value of each
+    locally and globally accessible attribute in the local and global scope of a
+    class or callable as well as deferring the resolution of each currently
+    undeclared attribute in that scope by replacing that attribute with a
+    forward reference proxy resolved only when that attribute is passed as the
+    second parameter to an :func:`isinstance`-based runtime type-check).
+
+    This dictionary is principally employed to dynamically evaluate stringified
+    type hints, including:
+
+    * :pep:`484`-compliant forward references.
+    * :pep:`563`-postponed type hints.
+
+    Attributes
+    ----------
+    _scope_dict : LexicalScope
+        **Composite local and global scope** (i.e., dictionary mapping from
+        the name to value of each locally and globally accessible attribute
+        in the local and global scope of some class or callable) underlying
+        this forward scope. See the :meth:`__init__` method for details.
+    _scope_name : str
+        Fully-qualified name of this forward scope. See the :meth:`__init__`
+        method for details.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently
+    # called @beartype decorations. Slotting has been shown to reduce read and
+    # write costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_scope_dict',
+        '_scope_name',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, scope_dict: LexicalScope, scope_name: str) -> None:
+        '''
+        Initialize this forward scope.
+
+        Attributes
+        ----------
+        scope_dict : LexicalScope
+            **Composite local and global scope** (i.e., dictionary mapping from
+            the name to value of each locally and globally accessible attribute
+            in the local and global scope of some class or callable) underlying
+            this forward scope.
+
+            Crucially, **this dictionary must composite both the local and
+            global scopes for that class or callable.** This dictionary must
+            *not* provide only the local or global scope; this dictionary must
+            provide both. Why? Because this forward scope is principally
+            intended to be passed as the second and last parameter to the
+            :func:`eval` builtin, called by the
+            :func:`beartype._check.forward.fwdmain.resolve_hint` function. For
+            unknown reasons, :func:`eval` only calls the :meth:`__missing__`
+            dunder method of this forward scope when passed only two parameters
+            (i.e., when passed only a global scope); :func:`eval` does *not*
+            call the :meth:`__missing__` dunder method of this forward scope
+            when passed three parameters (i.e., when passed both a global and
+            local scope). Presumably, this edge case pertains to the official
+            :func:`eval` docstring -- which reads:
+
+                The globals must be a dictionary and locals can be any mapping,
+                defaulting to the current globals and locals.
+                If only globals is given, locals defaults to it.
+
+            Clearly, :func:`eval` treats globals and locals fundamentally
+            differently (probably for efficiency or obscure C implementation
+            details). Since :func:`eval` only supports a single unified globals
+            dictionary for our use case, the caller *must* composite together
+            the global and local scopes into this dictionary. Praise to Guido.
+        scope_name : str
+            Fully-qualified name of this forward scope. For example:
+
+            * ``"some_package.some_module"`` for a module scope (e.g., to
+              resolve a global class or callable against this scope).
+            * ``"some_package.some_module.SomeClass"`` for a class scope (e.g.,
+              to resolve a nested class or callable against this scope).
+
+        Raises
+        ------
+        BeartypeDecorHintForwardRefException
+            If this scope name is *not* a valid Python attribute name.
+        '''
+        assert isinstance(scope_dict, dict), (
+            f'{repr(scope_dict)} not dictionary.')
+
+        # Initialize our superclass with this lexical scope, efficiently
+        # pre-populating this dictionary with all previously declared attributes
+        # underlying this forward scope.
+        super().__init__(scope_dict)
+
+        # If this scope name is syntactically invalid, raise an exception.
+        die_unless_identifier(
+            text=scope_name,
+            exception_cls=BeartypeDecorHintForwardRefException,
+            exception_prefix='Forward scope name ',
+        )
+        # Else, this scope name is syntactically valid.
+
+        # Classify all passed parameters.
+        self._scope_dict = scope_dict
+        self._scope_name = scope_name
+
+    # ..................{ DUNDERS                            }..................
+    def __missing__(self, hint_name: str) -> Type[
+        _BeartypeForwardRefIndexableABC]:
+        '''
+        Dunder method explicitly called by the superclass
+        :meth:`dict.__getitem__` method implicitly called on each ``[``- and
+        ``]``-delimited attempt to access an **unresolved type hint** (i.e.,
+        *not* currently defined in this scope) with the passed name.
+
+        This method transparently replaces this unresolved type hint with a
+        **forward reference proxy** (i.e., concrete subclass of the private
+        :class:`beartype._check.forward.reference.fwdrefabc.BeartypeForwardRefABC`
+        abstract base class (ABC), which resolves this type hint on the first
+        call to the :func:`isinstance` builtin whose second argument is that
+        subclass).
+
+        This method assumes that:
+
+        * This scope is only partially initialized.
+        * This type hint has yet to be declared in this scope.
+        * This type hint will be declared in this scope by the later time that
+          this method is called.
+
+        Parameters
+        ----------
+        hint_name : str
+            Relative (i.e., unqualified) or absolute (i.e., fully-qualified)
+            name of this unresolved type hint.
+
+        Returns
+        -------
+        Type[_BeartypeForwardRefIndexableABC]
+            Forward reference proxy deferring the resolution of this unresolved
+            type hint.
+
+        Raises
+        ------
+        BeartypeDecorHintForwardRefException
+            If this type hint name is *not* a valid Python attribute name.
+        '''
+        # print(f'Missing type hint: {repr(hint_name)}')
+
+        # If this type hint name is syntactically invalid, raise an exception.
+        die_unless_identifier(
+            text=hint_name,
+            exception_cls=BeartypeDecorHintForwardRefException,
+            exception_prefix='Forward reference ',
+        )
+        # Else, this type hint name is syntactically valid.
+
+        # Forward reference proxy to be returned.
+        forwardref_subtype = make_forwardref_indexable_subtype(
+            self._scope_name, hint_name)
+
+        # Cache this proxy.
+        self[hint_name] = forwardref_subtype
+
+        # Return this proxy.
+        return forwardref_subtype
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/forward/reference/fwdrefabc.py
@@ -0,0 +1,242 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **forward reference abstract base classes (ABCs)** (i.e., low-level
+class hierarchy deferring the resolution of a stringified type hint referencing
+an attribute that has yet to be defined and annotating a class or callable
+decorated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintForwardRefException
+from beartype.typing import (
+    NoReturn,
+    Optional,
+    Type,
+)
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+)
+from beartype._check.forward.reference.fwdrefmeta import BeartypeForwardRefMeta
+
+# ....................{ SUPERCLASSES                       }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: The names of *ALL* class variables declared below *MUST* be both:
+# * Prefixed by "__beartype_".
+# * Suffixed by "__".
+# If this is *NOT* done, these variables could induce a namespace conflict with
+# user-defined subpackages, submodules, and classes of the same names
+# concatenated via the BeartypeForwardRefMeta.__getattr__() dunder method.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+#FIXME: Unit test us up, please.
+class BeartypeForwardRefABC(object, metaclass=BeartypeForwardRefMeta):
+    '''
+    Abstract base class (ABC) of all **forward reference subclasses** (i.e.,
+    classes whose :class:`.BeartypeForwardRefMeta` metaclass defers the
+    resolution of stringified type hints referencing actual type hints that have
+    yet to be defined).
+
+    Caveats
+    -------
+    **This ABC prohibits instantiation.** This ABC *only* exists to sanitize,
+    simplify, and streamline the definition of subclasses passed as the second
+    parameter to the :func:`isinstance` builtin, whose
+    :class:`.BeartypeForwardRefMeta.__instancecheck__` dunder method then
+    implicitly resolves the forward references encapsulated by those subclasses.
+    The :func:`.make_forwardref_subtype` function dynamically creates and
+    returns one concrete subclass of this ABC for each unique forward reference
+    required by the :func:`beartype.beartype` decorator, whose :attr:`hint_name`
+    class variable is the name of the attribute referenced by that reference.
+    '''
+
+    # ....................{ PRIVATE ~ class vars           }....................
+    __name_beartype__: str = None  # type: ignore[assignment]
+    '''
+    Absolute (i.e., fully-qualified) or relative (i.e., unqualified) name of the
+    type hint referenced by this forward reference subclass.
+    '''
+
+
+    __scope_name_beartype__: Optional[str] = None
+    '''
+    Fully-qualified name of the lexical scope to which the type hint referenced
+    by this forward reference subclass is relative if that type hint is relative
+    (i.e., if :attr:`__name_beartype__` is relative) *or* ignored otherwise
+    (i.e., if :attr:`__name_beartype__` is absolute).
+    '''
+
+    # ....................{ INITIALIZERS                   }....................
+    def __new__(cls, *args, **kwargs) -> NoReturn:
+        '''
+        Prohibit instantiation by unconditionally raising an exception.
+        '''
+
+        # Instantiatable. It's a word or my username isn't @UncleBobOnAStick.
+        raise BeartypeDecorHintForwardRefException(
+            f'{repr(BeartypeForwardRefABC)} subclass '
+            f'{repr(cls)} not instantiatable.'
+        )
+
+    # ....................{ PRIVATE ~ testers              }....................
+    @classmethod
+    def __is_instance_beartype__(cls, obj: object) -> bool:
+        '''
+        :data:`True` only if the passed object is an instance of the external
+        class referred to by this forward reference.
+
+        Parameters
+        ----------
+        obj : object
+            Arbitrary object to be tested.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this object is an instance of the external
+            class referred to by this forward reference subclass.
+        '''
+
+        # # Resolve the external class referred to by this forward reference and
+        # # permanently store that class in the "__type_beartype__" variable.
+        # cls.__beartype_resolve_type__()
+
+        # Return true only if this object is an instance of the external class
+        # referenced by this forward reference.
+        return isinstance(obj, cls.__type_beartype__)  # type: ignore[arg-type]
+
+
+    @classmethod
+    def __is_subclass_beartype__(cls, obj: object) -> bool:
+        '''
+        :data:`True` only if the passed object is a subclass of the external
+        class referred to by this forward reference.
+
+        Parameters
+        ----------
+        obj : object
+            Arbitrary object to be tested.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this object is a subclass of the external class
+            referred to by this forward reference subclass.
+        '''
+
+        # # Resolve the external class referred to by this forward reference and
+        # # permanently store that class in the "__type_beartype__" variable.
+        # cls.__beartype_resolve_type__()
+
+        # Return true only if this object is a subclass of the external class
+        # referenced by this forward reference.
+        return issubclass(obj, cls.__type_beartype__)  # type: ignore[arg-type]
+
+# ....................{ SUPERCLASSES ~ index               }....................
+#FIXME: Unit test us up, please.
+class _BeartypeForwardRefIndexedABC(BeartypeForwardRefABC):
+    '''
+    Abstract base class (ABC) of all **subscripted forward reference
+    subclasses** (i.e., classes whose :class:`.BeartypeForwardRefMeta`
+    metaclass defers the resolution of stringified type hints referencing actual
+    type hints that have yet to be defined, subscripted by any arbitrary
+    positional and keyword parameters).
+
+    Subclasses of this ABC typically encapsulate user-defined generics that have
+    yet to be declared (e.g., ``"MuhGeneric[int]"``).
+
+    Caveats
+    -------
+    **This ABC currently ignores subscription.** Technically, this ABC *does*
+    store all positional and keyword parameters subscripting this forward
+    reference. Pragmatically, this ABC otherwise silently ignores these
+    parameters by deferring to the superclass :meth:`.is_instance` method (which
+    reduces to the trivial :func:`isinstance` call). Why? Because **generics**
+    (i.e., :class:`typing.Generic` subclasses) themselves behave in the exact
+    same way at runtime.
+    '''
+
+    # ....................{ PRIVATE ~ class vars           }....................
+    __args_beartype__: tuple = None  # type: ignore[assignment]
+    '''
+    Tuple of all positional arguments subscripting this forward reference.
+    '''
+
+
+    __kwargs_beartype__: LexicalScope = None  # type: ignore[assignment]
+    '''
+    Dictionary of all keyword arguments subscripting this forward reference.
+    '''
+
+
+#FIXME: Unit test us up, please.
+class _BeartypeForwardRefIndexableABC(BeartypeForwardRefABC):
+    '''
+    Abstract base class (ABC) of all **subscriptable forward reference
+    subclasses** (i.e., classes whose :class:`.BeartypeForwardRefMeta`
+    metaclass defers the resolution of stringified type hints referencing actual
+    type hints that have yet to be defined, transparently permitting these type
+    hints to be subscripted by any arbitrary positional and keyword parameters).
+    '''
+
+    # ....................{ DUNDERS                        }....................
+    @classmethod
+    def __class_getitem__(cls, *args, **kwargs) -> (
+        Type[_BeartypeForwardRefIndexedABC]):
+        '''
+        Create and return a new **subscripted forward reference subclass**
+        (i.e., concrete subclass of the :class:`._BeartypeForwardRefIndexedABC`
+        abstract base class (ABC) deferring the resolution of the type hint with
+        the passed name, subscripted by the passed positional and keyword
+        arguments).
+
+        This dunder method enables this forward reference subclass to
+        transparently masquerade as any subscriptable type hint factory,
+        including subscriptable user-defined generics that have yet to be
+        declared (e.g., ``"MuhGeneric[int]"``).
+
+        This dunder method is intentionally *not* memoized (e.g., by the
+        :func:`callable_cached` decorator). Ideally, this dunder method *would*
+        be memoized. Sadly, there exists no means of efficiently caching either
+        non-variadic or variadic keyword arguments. Although technically
+        feasible, doing so imposes practical costs defeating the entire point of
+        memoization.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype._check.forward.reference.fwdrefmake import (
+            _make_forwardref_subtype)
+
+        # Subscripted forward reference to be returned.
+        forwardref_indexed_subtype: Type[_BeartypeForwardRefIndexedABC] = (
+            _make_forwardref_subtype(  # type: ignore[assignment]
+                hint_name=cls.__name_beartype__,
+                scope_name=cls.__scope_name_beartype__,
+                type_bases=_BeartypeForwardRefIndexedABC_BASES,
+            ))
+
+        # Classify the arguments subscripting this forward reference.
+        forwardref_indexed_subtype.__args_beartype__ = args  # pyright: ignore[reportGeneralTypeIssues]
+        forwardref_indexed_subtype.__kwargs_beartype__ = kwargs  # pyright: ignore[reportGeneralTypeIssues]
+
+        # Return this subscripted forward reference.
+        return forwardref_indexed_subtype
+
+# ....................{ PRIVATE ~ tuples                   }....................
+_BeartypeForwardRefIndexableABC_BASES = (_BeartypeForwardRefIndexableABC,)
+'''
+1-tuple containing *only* the :class:`._BeartypeForwardRefIndexableABC`
+superclass to reduce space and time consumption.
+'''
+
+
+_BeartypeForwardRefIndexedABC_BASES = (_BeartypeForwardRefIndexedABC,)
+'''
+1-tuple containing *only* the :class:`._BeartypeForwardRefIndexedABC`
+superclass to reduce space and time consumption.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/forward/reference/fwdrefmake.py
@@ -0,0 +1,222 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **forward reference factories** (i.e.,  low-level callables creating
+and returning forward reference proxy subclasses deferring the resolution of a
+stringified type hint referencing an attribute that has yet to be defined and
+annotating a class or callable decorated by the :func:`beartype.beartype`
+decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintForwardRefException
+from beartype.typing import (
+    Dict,
+    Optional,
+    Type,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.hint.datahinttyping import (
+    BeartypeForwardRef,
+    BeartypeForwardRefArgs,
+    TupleTypes,
+)
+from beartype._check.forward.reference.fwdrefabc import (
+    _BeartypeForwardRefIndexableABC,
+    _BeartypeForwardRefIndexableABC_BASES,
+)
+from beartype._util.cls.utilclsmake import make_type
+from beartype._util.text.utiltextidentifier import die_unless_identifier
+
+# ....................{ FACTORIES                          }....................
+def make_forwardref_indexable_subtype(
+    scope_name: Optional[str],
+    hint_name: str,
+) -> Type[_BeartypeForwardRefIndexableABC]:
+    '''
+    Create and return a new **subscriptable forward reference subclass** (i.e.,
+    concrete subclass of the :class:`._BeartypeForwardRefIndexableABC` abstract
+    base class (ABC) deferring the resolution of the unresolved type hint with
+    the passed name, transparently permitting this type hint to be subscripted
+    by any arbitrary positional and keyword parameters).
+
+    This factory is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the lower-level private
+    :func:`._make_forwardref_subtype` factory called by this higher-level public
+    factory is itself memoized.
+
+    Parameters
+    ----------
+    scope_name : Optional[str]
+        Possibly ignored lexical scope name. Specifically:
+
+        * If ``hint_name`` is absolute (i.e., contains one or more ``.``
+          delimiters), this parameter is silently ignored in favour of the
+          fully-qualified name of the module prefixing ``hint_name``.
+        * If ``hint_name`` is relative (i.e., contains *no* ``.`` delimiters),
+          this parameter declares the absolute (i.e., fully-qualified) name of
+          the lexical scope to which this unresolved type hint is relative.
+
+        The fully-qualified name of the module prefixing ``hint_name`` (if any)
+        thus *always* takes precedence over this lexical scope name, which only
+        provides a fallback to resolve relative forward references. While
+        unintuitive, this is needed to resolve absolute forward references.
+    hint_name : str
+        Relative (i.e., unqualified) or absolute (i.e., fully-qualified) name of
+        this unresolved type hint to be referenced.
+
+    Returns
+    -------
+    Type[_BeartypeForwardRefIndexableABC]
+        Subscriptable forward reference subclass referencing this type hint.
+
+    Raises
+    ------
+    BeartypeDecorHintForwardRefException
+        If either:
+
+        * ``hint_name`` is *not* a syntactically valid Python identifier.
+        * ``scope_name`` is neither:
+
+          * A syntactically valid Python identifier.
+          * :data:`None`.
+    '''
+
+    # Subscriptable forward reference to be returned.
+    return _make_forwardref_subtype(  # type: ignore[return-value]
+        scope_name=scope_name,
+        hint_name=hint_name,
+        type_bases=_BeartypeForwardRefIndexableABC_BASES,
+    )
+
+# ....................{ PRIVATE ~ factories                }....................
+def _make_forwardref_subtype(
+    scope_name: Optional[str],
+    hint_name: str,
+    type_bases: TupleTypes,
+) -> BeartypeForwardRef:
+    '''
+    Create and return a new **forward reference subclass** (i.e., concrete
+    subclass of the passed abstract base class (ABC) deferring the resolution of
+    the type hint with the passed name transparently).
+
+    This factory is internally memoized for efficiency.
+
+    Parameters
+    ----------
+    scope_name : Optional[str]
+        Possibly ignored lexical scope name. See
+        :func:`.make_forwardref_indexable_subtype` for further details.
+    hint_name : str
+        Absolute (i.e., fully-qualified) or relative (i.e., unqualified) name of
+        the type hint referenced by this forward reference subclass.
+    type_bases : Tuple[type, ...]
+        Tuple of all base classes to be inherited by this forward reference
+        subclass. For simplicity, this *must* be a 1-tuple ``(type_base,)``
+        where ``type_base`` is a :class:`._BeartypeForwardRefIndexableABC`
+        subclass.
+
+    Returns
+    -------
+    BeartypeForwardRef
+        Forward reference subclass referencing this type hint.
+
+    Raises
+    ------
+    BeartypeDecorHintForwardRefException
+        If either:
+
+        * ``hint_name`` is *not* a syntactically valid Python identifier.
+        * ``scope_name`` is neither:
+
+          * A syntactically valid Python identifier.
+          * :data:`None`.
+    '''
+
+    # Tuple of all passed parameters (in arbitrary order).
+    args: BeartypeForwardRefArgs = (scope_name, hint_name, type_bases)
+
+    # Forward reference proxy previously created and returned by a prior call to
+    # this function passed these parameters if any *OR* "None" otherwise (i.e.,
+    # if this is the first call to this function passed these parameters).
+    # forwardref_subtype: Optional[BeartypeForwardRef] = (
+    forwardref_subtype = _forwardref_args_to_forwardref.get(args, None)
+
+    # If this proxy has already been created, reuse and return this proxy as is.
+    if forwardref_subtype is not None:
+        return forwardref_subtype
+    # Else, this proxy has yet to be created.
+
+    assert isinstance(scope_name, NoneTypeOr[str]), (
+        f'{repr(scope_name)} neither string nor "None".')
+    assert isinstance(hint_name, str), f'{repr(hint_name)} not string.'
+    assert len(type_bases) == 1, (
+        f'{repr(type_bases)} not 1-tuple of a single superclass.')
+
+    # If this attribute name is *NOT* a syntactically valid Python identifier,
+    # raise an exception.
+    die_unless_identifier(
+        text=hint_name,
+        exception_cls=BeartypeDecorHintForwardRefException,
+        exception_prefix='Forward reference ',
+    )
+    # Else, this attribute name is a syntactically valid Python identifier.
+
+    # Possibly empty fully-qualified module name and unqualified basename of the
+    # type referred to by this forward reference.
+    type_module_name, _, type_name = hint_name.rpartition('.')
+
+    # If this module name is empty, fallback to the passed module name if any.
+    #
+    # Note that we intentionally perform *NO* additional validation. Why?
+    # Builtin types. Notably, it is valid to pass an unqualified "hint_name"
+    # and a "scope_name" that is "None" only if "hint_name" is the name of a
+    # builtin type (e.g., "int", "str"). Since validating this edge case is
+    # non-trivial, we defer this validation to subsequent importation logic.
+    if not type_module_name:
+        type_module_name = scope_name
+    # Else, this module name is non-empty.
+
+    # Forward reference proxy to be returned.
+    forwardref_subtype = make_type(
+        type_name=type_name,
+        type_module_name=type_module_name,
+        type_bases=type_bases,
+        exception_cls=BeartypeDecorHintForwardRefException,
+        exception_prefix='Forward reference ',
+    )
+
+    # Classify passed parameters with this proxy.
+    forwardref_subtype.__name_beartype__ = hint_name  # pyright: ignore
+    forwardref_subtype.__scope_name_beartype__ = scope_name  # pyright: ignore
+
+    # Cache this proxy for reuse by subsequent calls to this factory function
+    # passed the same parameters.
+    _forwardref_args_to_forwardref[args] = forwardref_subtype
+
+    # Return this proxy.
+    return forwardref_subtype
+
+# ....................{ PRIVATE ~ globals                  }....................
+_forwardref_args_to_forwardref: Dict[
+    BeartypeForwardRefArgs, BeartypeForwardRef] = {}
+'''
+**Forward reference proxy cache** (i.e., dictionary mapping from the tuple of
+all parameters passed to each prior call of the
+:func:`._make_forwardref_subtype` factory function to the forward reference
+proxy dynamically created and returned by that call).
+
+This cache serves a dual purpose. Notably, this cache both enables:
+
+* External callers to iterate over all previously instantiated forward reference
+  proxies. This is particularly useful when responding to module reloading,
+  which requires that *all* previously cached types be uncached.
+* :func:`._make_forwardref_subtype` to internally memoize itself over its
+  passed parameters. Since the existing ``callable_cached`` decorator could
+  trivially do so as well, however, this is only a negligible side effect.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/forward/reference/fwdrefmeta.py
@@ -0,0 +1,342 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **forward reference metaclasses** (i.e., low-level metaclasses of
+classes deferring the resolution of a stringified type hint referencing an
+attribute that has yet to be defined and annotating a class or callable
+decorated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeCallHintForwardRefException
+from beartype.typing import Dict
+from beartype._data.hint.datahinttyping import BeartypeForwardRef
+from beartype._util.cls.pep.utilpep3119 import (
+    die_unless_object_isinstanceable)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+    is_hint_pep484585_generic,
+    get_hint_pep484585_generic_type,
+)
+from beartype._util.module.utilmodimport import import_module_attr
+from beartype._util.text.utiltextidentifier import is_dunder
+
+# ....................{ METACLASSES                        }....................
+class BeartypeForwardRefMeta(type):
+    '''
+    **Forward reference metaclass** (i.e., metaclass of the
+    :class:`.BeartypeForwardRefABC` superclass deferring the resolution of a
+    stringified type hint referencing an attribute that has yet to be defined
+    and annotating a class or callable decorated by the
+    :func:`beartype.beartype` decorator).
+
+    This metaclass memoizes each **forward reference** (i.e.,
+    :class:`.BeartypeForwardRefABC` instance) according to the fully-qualified
+    name of the attribute referenced by that forward reference. Doing so ensures
+    that only the first :class:`.BeartypeForwardRefABC` instance referring to a
+    unique attribute is required to dynamically resolve that attribute at
+    runtime; all subsequent :class:`.BeartypeForwardRefABC` instances referring
+    to the same attribute transparently reuse the attribute previously resolved
+    by the first such instance, effectively reducing the time cost of resolving
+    forward references to a constant-time operation with negligible constants.
+
+    This metaclass dynamically and efficiently resolves each forward reference
+    in a just-in-time (JIT) manner on the first :func:`isinstance` call whose
+    second argument is that forward reference. Forward references *never* passed
+    to the :func:`isinstance` builtin are *never* resolved, which is good.
+    '''
+
+    # ....................{ DUNDERS                        }....................
+    def __getattr__(cls: BeartypeForwardRef, hint_name: str) -> (  # type: ignore[misc]
+        BeartypeForwardRef):
+        '''
+        **Fully-qualified forward reference subclass** (i.e.,
+        :class:`.BeartypeForwardRefABC` subclass whose metaclass is this
+        metaclass and whose :attr:`.BeartypeForwardRefABC.__name_beartype__`
+        class variable is the fully-qualified name of an external class).
+
+        This dunder method creates and returns a new forward reference subclass
+        referring to an external class whose name is concatenated from (in
+        order):
+
+        #. The fully-qualified name of the external package or module referred
+           to by the passed forward reference subclass.
+        #. The passed unqualified basename, presumably referring to a
+           subpackage, submodule, or class of that external package or module.
+
+        Parameters
+        ----------
+        cls : Type[BeartypeForwardRefABC]
+            Forward reference subclass to concatenate this basename against.
+        hint_name : str
+            Unqualified basename to be concatenated against this forward
+            reference subclass.
+
+        Returns
+        -------
+        Type['_BeartypeForwardRefIndexableABC']
+            Fully-qualified forward reference subclass concatenated as described
+            above.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype._check.forward.reference.fwdrefmake import (
+            make_forwardref_indexable_subtype)
+
+        # If this unqualified basename is that of a non-existent dunder
+        # attribute, raise the standard "AttributeError" exception.
+        #
+        # Note that we intentionally avoid suffixing the exception message by a
+        # "." character here. Why? Because Python treats "AttributeError"
+        # exceptions as special. Notably, Python appears to actually:
+        # 1. Parse apart the messages of these exceptions for the double-quoted
+        #    attribute name embedded in these messages.
+        # 2. Suffix these messages by a "." character followed by a sentence
+        #    suggesting an existing attribute with a similar name to that of the
+        #    attribute name previously parsed from these messages.
+        #
+        # For example, given an erroneous lookup of a non-existent dunder
+        # attribute "__nomnom_beartype__", Python expands the exception message
+        # raised below into:
+        #     AttributeError: Forward reference proxy "MuhRef" dunder attribute
+        #     "__nomnom_beartype__" not found. Did you mean:
+        #     '__name_beartype__'?
+        if is_dunder(hint_name):
+            raise AttributeError(
+                f'Forward reference proxy "{cls.__name__}" dunder attribute '
+                f'"{hint_name}" not found'
+            )
+        # Else, this unqualified basename is *NOT* that of a non-existent dunder
+        # attribute.
+
+        # Return a new fully-qualified forward reference subclass concatenated
+        # as described above.
+        return make_forwardref_indexable_subtype(
+            cls.__scope_name_beartype__,  # type: ignore[arg-type]
+            f'{cls.__name_beartype__}.{hint_name}',
+        )
+
+
+    def __instancecheck__(cls: BeartypeForwardRef, obj: object) -> bool:  # type: ignore[misc]
+        '''
+        :data:`True` only if the passed object is an instance of the external
+        class referenced by the passed **forward reference subclass** (i.e.,
+        :class:`.BeartypeForwardRefABC` subclass whose metaclass is this
+        metaclass and whose :attr:`.BeartypeForwardRefABC.__name_beartype__`
+        class variable is the fully-qualified name of that external class).
+
+        Parameters
+        ----------
+        cls : Type[BeartypeForwardRefABC]
+            Forward reference subclass to test this object against.
+        obj : object
+            Arbitrary object to be tested as an instance of the external class
+            referenced by this forward reference subclass.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this object is an instance of the external
+            class referenced by this forward reference subclass.
+        '''
+
+        # Return true only if this forward reference subclass insists that this
+        # object satisfies the external class referenced by this subclass.
+        return cls.__is_instance_beartype__(obj)
+
+
+    def __subclasscheck__(cls: BeartypeForwardRef, obj: object) -> bool:  # type: ignore[misc]
+        '''
+        :data:`True` only if the passed object is a subclass of the external
+        class referenced by the passed **forward reference subclass** (i.e.,
+        :class:`.BeartypeForwardRefABC` subclass whose metaclass is this
+        metaclass and whose :attr:`.BeartypeForwardRefABC.__name_beartype__`
+        class variable is the fully-qualified name of that external class).
+
+        Parameters
+        ----------
+        cls : Type[BeartypeForwardRefABC]
+            Forward reference subclass to test this object against.
+        obj : object
+            Arbitrary object to be tested as a subclass of the external class
+            referenced by this forward reference subclass.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this object is a subclass of the external class
+            referenced by this forward reference subclass.
+        '''
+
+        # Return true only if this forward reference subclass insists that this
+        # object is an instance of the external class referenced by this
+        # subclass.
+        return cls.__is_subclass_beartype__(obj)
+
+
+    def __repr__(cls: BeartypeForwardRef) -> str:  # type: ignore[misc]
+        '''
+        Machine-readable string representing this forward reference subclass.
+        '''
+
+        # Machine-readable representation to be returned.
+        #
+        # Note that this representation is intentionally prefixed by the
+        # @beartype-specific substring "<forwardref ", resembling the
+        # representation of classes (e.g., "<class 'bool'>"). Why? Because
+        # various other @beartype submodules ignore objects whose
+        # representations are prefixed by the "<" character, which are usefully
+        # treated as having a standard representation that is ignorable for most
+        # intents and purposes. This includes:
+        # * The die_if_hint_pep604_inconsistent() raiser.
+        cls_repr = (
+            f'<forwardref {cls.__name__}('
+              f'__name_beartype__={repr(cls.__name_beartype__)}'
+            f', __scope_name_beartype__={repr(cls.__scope_name_beartype__)}'
+        )
+
+        #FIXME: Unit test this edge case, please.
+        # If this is a subscripted forward reference subclass, append additional
+        # metadata representing this subscription.
+        #
+        # Ideally, we would test whether this is a subclass of the
+        # "_BeartypeForwardRefIndexedABC" superclass as follows:
+        #     if issubclass(cls, _BeartypeForwardRefIndexedABC):
+        #
+        # Sadly, doing so invokes the __subclasscheck__() dunder method defined
+        # above, which invokes the
+        # BeartypeForwardRefABC.__is_subclass_beartype__() method defined
+        # above, which tests the type referred to by this subclass rather than
+        # this subclass itself. In short, this is why you play with madness.
+        try:
+            cls_repr += (
+                f', __args_beartype__={repr(cls.__args_beartype__)}'
+                f', __kwargs_beartype__={repr(cls.__kwargs_beartype__)}'
+            )
+        # If doing so fails with the expected "AttributeError", then this is
+        # *NOT* a subscripted forward reference subclass. Since this is
+        # ignorable, silently ignore this common case. *sigh*
+        except AttributeError:
+            pass
+
+        # Close this representation.
+        cls_repr += ')>'
+
+        # Return this representation.
+        return cls_repr
+
+    # ....................{ PROPERTIES                     }....................
+    @property
+    def __type_beartype__(cls: BeartypeForwardRef) -> type:  # type: ignore[misc]
+        '''
+        **Forward referee** (i.e., type hint referenced by this forward
+        reference subclass, which is usually but *not* necessarily a class).
+
+        This class property is manually memoized for efficiency. However, note
+        this class property is *not* automatically memoized (e.g., by the
+        ``property_cached`` decorator). Why? Because manual memoization enables
+        other functionality in the beartype codebase to explicitly unmemoize all
+        previously memoized forward referees across all forward reference
+        proxies, effectively forcing all subsequent calls of this property
+        across all forward reference proxies to reimport their forward referees.
+        Why is that desirable? Because other functionality in the beartype
+        codebase detects when the user has manually reloaded user-defined
+        modules defining user-defined types annotating user-defined callables
+        previously decorated by the :mod:`beartype.beartype` decorator. Since
+        reloading those modules redefines those types, all previously cached
+        types (including those memoized by this property) *must* then be assumed
+        to be invalid and thus uncached. In short, manual memoization allows
+        beartype to avoid desynchronization between memoized and actual types.
+
+        Raises
+        ------
+        BeartypeCallHintForwardRefException
+            If either:
+
+            * This forward referee is unimportable.
+            * This forward referee is importable but either:
+
+              * Not a type.
+              * A type that is this forward reference proxy, implying this proxy
+                circularly proxies itself.
+        '''
+
+        # Forward referee referred to by this forward reference proxy if a prior
+        # access of this property has already resolved this referee *OR* "None"
+        # otherwise (i.e., if this is the first access of this property).
+        referee = _forwardref_to_referee.get(cls)
+
+        # If this forward referee has yet to be resolved, this is the first call
+        # to this property. In this case...
+        if referee is None:  # type: ignore[has-type]
+            # print(f'Importing forward ref "{cls.__name_beartype__}" from module "{cls.__scope_name_beartype__}"...')
+
+            # Forward referee dynamically imported from this module.
+            referee = import_module_attr(
+                attr_name=cls.__name_beartype__,
+                module_name=cls.__scope_name_beartype__,
+                exception_cls=BeartypeCallHintForwardRefException,
+                exception_prefix='Forward reference ',
+            )
+
+            # If this referee is this forward reference subclass, then this
+            # subclass circularly proxies itself. Since allowing this edge case
+            # would openly invite infinite recursion, we detect this edge case
+            # and instead raise a human-readable exception.
+            if referee is cls:
+                raise BeartypeCallHintForwardRefException(
+                    f'Forward reference proxy {repr(cls)} circularly '
+                    f'(i.e., infinitely recursively) references itself.'
+                )
+            # Else, this referee is *NOT* this forward reference subclass.
+            #
+            # If this referee is a subscripted generic (e.g.,
+            # "MuhGeneric[int]"), reduce this referee to the class subscripting
+            # this generic (e.g., "int").
+            elif is_hint_pep484585_generic(referee):
+                referee = get_hint_pep484585_generic_type(
+                    hint=referee,
+                    exception_cls=BeartypeCallHintForwardRefException,
+                    exception_prefix='Forward reference ',
+                )
+            # Else, this referee is *NOT* a subscripted generic.
+
+            # If this referee is *NOT* an isinstanceable class, raise an
+            # exception.
+            die_unless_object_isinstanceable(
+                obj=referee,
+                exception_cls=BeartypeCallHintForwardRefException,
+                exception_prefix='Forward reference ',
+            )
+            # Else, this referee is an isinstanceable class.
+
+            # Cache this referee for subsequent lookup by this property.
+            _forwardref_to_referee[cls] = referee
+        # Else, this referee has already been resolved.
+        #
+        # In either case, this referee is now resolved.
+
+        # Return this previously resolved referee.
+        return referee  # type: ignore[return-value]
+
+# ....................{ PRIVATE ~ globals                  }....................
+_forwardref_to_referee: Dict[BeartypeForwardRef, type] = {}
+'''
+**Forward reference referee cache** (i.e., dictionary mapping from each forward
+reference proxy to the arbitrary class referred to by that proxy).
+
+This cache serves a dual purpose. Notably, this cache both enables:
+
+* External callers to iterate over all previously instantiated forward reference
+  proxies. This is particularly useful when responding to module reloading,
+  which requires that *all* previously cached types be uncached.
+* The
+  :attr:`.BeartypeForwardRefMeta.__type_beartype__` property to internally
+  memoize the arbitrary class referred to by this referee. Since the existing
+  ``property_cached`` decorator could trivially do so as well, however, this is
+  only a negligible side effect.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/forward/reference/fwdreftest.py
@@ -0,0 +1,39 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **forward reference testers** (i.e.,  low-level callables testing
+various properties of forward reference proxy subclasses deferring the
+resolution of a stringified type hint referencing an attribute that has yet to
+be defined and annotating a class or callable decorated by the
+:func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.forward.reference.fwdrefmeta import BeartypeForwardRefMeta
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_forwardref(obj: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a **forward reference subclass**
+    (i.e., class whose metaclass is class:`.BeartypeForwardRefMeta`).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be tested.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a forward reference subclass.
+    '''
+
+    # Return true only if the class of this object is the metaclass of all
+    # forward reference subclasses, implying this object to be such a subclass.
+    return obj.__class__ is BeartypeForwardRefMeta
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/util/_checkutilsnip.py
@@ -0,0 +1,136 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **type-checking function utility code snippets** (i.e.,
+triple-quoted pure-Python string constants formatted and concatenated together
+to dynamically generate the implementations of functions type-checking arbitrary
+objects against arbitrary PEP-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkmagic import (
+    ARG_NAME_GETRANDBITS,
+    VAR_NAME_RANDOM_INT,
+)
+from beartype._data.code.datacodeindent import CODE_INDENT_1
+
+# ....................{ CODE                               }....................
+CODE_SIGNATURE_ARG = (
+    # Indentation prefixing all wrapper parameters.
+    f'{CODE_INDENT_1}'
+    # Default this parameter to the current value of the module-scoped attribute
+    # of the same name, passed to the make_func() function by the parent
+    # @beartype decorator. While awkward, this is the optimally efficient means
+    # of exposing arbitrary attributes to the body of this wrapper function.
+    f'{{arg_name}}={{arg_name}},{{arg_comment}}'
+    # Newline for readability.
+    f'\n'
+)
+'''
+Code snippet declaring a **hidden parameter** (i.e., parameter whose name is
+prefixed by ``"__beartype_"`` and whose value is that of an external attribute
+internally referenced in the body of a type-checking callable) in the signature
+of that callable.
+'''
+
+# ....................{ CODE ~ init                        }....................
+#FIXME: Note that NumPy provides an efficient means of generating a large
+#number of pseudo-random integers all-at-once. The core issue there, of
+#course, is that we then need to optionally depend upon and detect NumPy,
+#which then requires us to split our random integer generation logic into two
+#parallel code paths that we'll then have to maintain -- and the two will be
+#rather different. In any case, here's how one generates a NumPy array
+#containing 100 pseudo-random integers in the range [0, 127]:
+#    random_ints = numpy.random.randint(128, size=100)
+#
+#To leverage that sanely, we'd need to:
+#* Globally cache that array somewhere.
+#* Globally cache the current index into that array.
+#* When NumPy is unimportable, fallback to generating a Python list containing
+#  the same number of pseudo-random integers in the same range.
+#* In either case, we'd probably want to wrap that logic in a globally
+#  accessible infinite generator singleton that returns another pseudo-random
+#  integer every time you iterate it. This assumes, of course, that iterating
+#  generators is reasonably fast in Python. (If not, just make that a getter
+#  method of a standard singleton object.)
+#* Replace the code snippet below with something resembling:
+#      '''
+#      __beartype_random_int = next(__beartype_random_int_generator)
+#      '''
+#Note that thread concurrency issues are probable ignorable here, but that
+#there's still a great deal of maintenance and refactoring that would need to
+#happen to sanely support this. In other words, ain't happenin' anytime soon.
+#FIXME: To support both NumPy and non-NumPy code paths transparently, design a
+#novel private data structure named "_BeartypeRNJesus" whose __next__() dunder
+#method transparently returns a new random integer. The implementation of that
+#method then handles all of the low-level minutiae like:
+#* Storing and iterating the 0-based index of the next index into an internally
+#  cached NumPy array created by calling numpy.random.randint().
+#* Creating a new cached NumPy array after exhausting the prior cached array.
+
+CODE_INIT_RANDOM_INT = f'''
+    # Generate and localize a sufficiently large pseudo-random integer for
+    # subsequent indexation in type-checking randomly selected container items.
+    {VAR_NAME_RANDOM_INT} = {ARG_NAME_GETRANDBITS}(32)'''
+'''
+PEP-specific code snippet generating and localizing a pseudo-random unsigned
+32-bit integer for subsequent use in type-checking randomly indexed container
+items.
+
+This bit length was intentionally chosen to correspond to the number of bits
+generated by each call to Python's C-based Mersenne Twister underlying the
+:func:`random.getrandbits` function called here. Exceeding this number of bits
+would cause that function to inefficiently call the Twister multiple times.
+
+This bit length produces unsigned 32-bit integers efficiently representable as
+C-based atomic integers rather than **big numbers** (i.e., aggregations of
+C-based atomic integers) ranging 0–``2**32 - 1`` regardless of the word size of
+the active Python interpreter.
+
+Since the cost of generating integers to this maximum bit length is
+approximately the same as generating integers of much smaller bit lengths, this
+maximum is preferred. Although big numbers transparently support the same
+operations as non-big integers, the latter are dramatically more efficient with
+respect to both space and time consumption and thus preferred.
+
+Usage
+-----
+Since *most* containers are likely to contain substantially fewer items than
+the maximum integer in this range, pseudo-random container indices are
+efficiently selectable by simply taking the modulo of this local variable with
+the lengths of those containers.
+
+Any container containing more than this maximum number of items is typically
+defined as a disk-backed data structure (e.g., Pandas dataframe) rather than an
+in-memory standard object (e.g., :class:`list`). Since :mod:`beartype`
+currently ignores the former with respect to deep type-checking, this local
+typically suffices for real-world in-memory containers. For edge-case
+containers containing more than this maximum number of items, :mod:`beartype`
+will only deeply type-check items with indices in this range; all trailing
+items will *not* be deeply type-checked, which we consider an acceptable
+tradeoff, given the infeasibility of even storing such objects in memory.
+
+Caveats
+-------
+**The only safely callable function declared by the stdlib** :mod:`random`
+**module is** :func:`random.getrandbits`. While that function is efficiently
+implemented in C, all other functions declared by that module are inefficiently
+implemented in Python. In fact, their implementations are sufficiently
+inefficient that there exist numerous online articles lamenting the fact.
+
+See Also
+--------
+https://stackoverflow.com/a/11704178/2809027
+    StackOverflow answer demonstrating Python's C-based Mersenne Twister
+    underlying the :func:`random.getrandbits` function to generate 32 bits of
+    pseudo-randomness at a time.
+https://gist.github.com/terrdavis/1b23b7ff8023f55f627199b09cfa6b24#gistcomment-3237209
+    Self GitHub comment introducing the core concepts embodied by this snippet.
+https://eli.thegreenplace.net/2018/slow-and-fast-methods-for-generating-random-integers-in-python
+    Authoritative article profiling various :mod:`random` callables.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_check/util/checkutilmake.py
@@ -0,0 +1,153 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype type-checking function code utility factories** (i.e., low-level
+callables dynamically generating pure-Python code snippets type-checking
+arbitrary objects passed to arbitrary callables against PEP-compliant type hints
+passed to those same callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Callable
+from beartype._check.checkmagic import (
+    ARG_NAME_GETRANDBITS,
+)
+from beartype._check.util._checkutilsnip import (
+    CODE_SIGNATURE_ARG,
+    CODE_INIT_RANDOM_INT,
+)
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+)
+from beartype._util.text.utiltextrepr import represent_object
+
+# ....................{ MAKERS ~ signature                 }....................
+#FIXME: Unit test us up, please.
+def make_func_signature(
+    # Mandatory parameters.
+    func_name: str,
+    func_scope: LexicalScope,
+    code_signature_format: str,
+    conf: BeartypeConf,
+
+    # Optional parameters.
+    code_signature_prefix: str = '',
+
+    # String globals required only for their bound str.format() methods.
+    CODE_SIGNATURE_ARG_format: Callable = (
+        CODE_SIGNATURE_ARG.format),
+) -> str:
+    '''
+    **Type-checking signature factory** (i.e., low-level function dynamically
+    generating and returning the **signature** (i.e., callable declaration
+    prefixing the body of that callable) of a callable type-checking arbitrary
+    objects against arbitrary PEP-compliant type hints to be subsequently
+    defined, described by the passed parameters.
+
+    Parameters
+    ----------
+    func_name : str
+        Unqualified basename of the callable declared by this signature.
+    func_scope : LexicalScope
+        **Local scope** (i.e., dictionary mapping from the name to value of
+        each hidden parameter declared in this signature) of that callable,
+        where a "hidden parameter" is a parameter whose name is prefixed by
+        ``"__beartype_"`` and whose value is that of an external attribute
+        internally referenced in the body of that callable.
+    code_signature_format : str
+        Code snippet declaring the unformatted signature of that callable, which
+        this factory then formats by replacing these format variables in this
+        code snippet:
+
+        * ``{func_name}``, replaced by the value of the ``func_name`` parameter.
+        * ``{code_signature_prefix}``, replaced by the value of the
+          ``code_signature_prefix`` parameter.
+        * ``{code_signature_args}``, replaced by the declaration of all hidden
+          parameters in the passed ``func_scope`` parameter.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    code_signature_prefix : str, optional
+        Code snippet prefixing this signature, typically either:
+
+        * For synchronous callables, the empty string.
+        * For asynchronous callables (e.g., asynchronous generators,
+          coroutines), the space-suffixed keyword ``"async "``.
+
+        Defaults to the empty string and thus synchronous behaviour.
+
+    Yields
+    ------
+    str
+        Signature of this callable.
+    '''
+    assert isinstance(func_name, str), f'{repr(func_name)} not string.'
+    assert isinstance(func_scope, dict), f'{repr(func_scope)} not dictionary.'
+    assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+    assert isinstance(code_signature_format, str), (
+        f'{repr(code_signature_format)} not string.')
+    assert isinstance(code_signature_prefix, str), (
+        f'{repr(code_signature_prefix)} not string.')
+
+    # Python code snippet declaring all optional private beartype-specific
+    # parameters directly derived from the local scope established by the above
+    # calls to the _code_check_args() and _code_check_return() functions.
+    code_signature_args = ''
+
+    # For the name and value of each such parameter...
+    for arg_name, arg_value in func_scope.items():
+        # Machine-readable representation of this parameter's initial value,
+        # stripped of newline and truncated to a (hopefully) sensible length.
+        # Since the represent_object() function called below to sanitize this
+        # value is incredibly slow, this representation is conditionally
+        # appended as a human-readable comment to the declaration of this
+        # parameter below *ONLY* if the caller explicitly requested debugging.
+        arg_comment = (
+            f' # is {represent_object(arg_value)}'
+            if conf.is_debug else
+            ''
+        )
+
+        # Compose the declaration of this parameter in the signature of this
+        # wrapper from...
+        code_signature_args += CODE_SIGNATURE_ARG_format(
+            arg_name=arg_name,
+            arg_comment=arg_comment,
+        )
+
+    #FIXME: *YIKES.* We need to pass a unique tester function signature here
+    #resembling:
+    #    def {{func_name}}(obj: object) -> bool:
+    #To do so sanely, let's generalize this factory to accept an additional
+    #mandatory "func_signature" parameter, please. We'll need to note in the
+    #docstring exactly what format variables that parameter is expected to
+    #contain, of course.
+
+    # Python code snippet declaring the signature of this wrapper.
+    code_signature = code_signature_format.format(
+        func_name=func_name,
+        code_signature_prefix=code_signature_prefix,
+        code_signature_args=code_signature_args,
+    )
+
+    # Python code snippet of preliminary statements (e.g., local variable
+    # assignments) if any *AFTER* generating snippets type-checking parameters
+    # and returns (which modifies dataclass variables tested below).
+    code_body_init = (
+        # If the body of this wrapper requires a pseudo-random integer, append
+        # code generating and localizing such an integer to this signature.
+        CODE_INIT_RANDOM_INT
+        if ARG_NAME_GETRANDBITS in func_scope else
+        # Else, this body requires *NO* such integer. In this case, preserve
+        # this signature as is.
+        ''
+    )
+
+    # Return this signature suffixed by zero or more preliminary statements.
+    return f'{code_signature}{code_body_init}'
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_conf/_confget.py
@@ -0,0 +1,144 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **configuration class getters** (i.e., low-level callables inspecting
+and introspecting various metadata of interest to the high-level
+:class:`beartype.BeartypeConf` dataclass).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeConfShellVarException
+from beartype.roar._roarwarn import BeartypeConfShellVarWarning
+from beartype._data.func.datafuncarg import ARG_VALUE_UNPASSED
+from beartype._data.hint.datahinttyping import (
+    BoolTristateUnpassable,
+    BoolTristate,
+)
+from beartype._data.os.dataosshell import (
+    SHELL_VAR_CONF_IS_COLOR_NAME,
+    SHELL_VAR_CONF_IS_COLOR_VALUE_TO_OBJ,
+)
+from beartype._util.error.utilerrwarn import issue_warning
+from beartype._util.os.utilosshell import get_shell_var_value_or_none
+from beartype._util.text.utiltextjoin import join_delimited_disjunction
+
+# ....................{ GETTERS                            }....................
+def get_is_color(is_color: BoolTristateUnpassable) -> BoolTristate:
+    '''
+    Final value of the ``is_color`` tri-state boolean parameter accepted by the
+    :meth:`beartype.BeartypeConf.__init__` constructor, derived from the passed
+    parameter originally passed to that constructor as well as the external
+    ``${BEARTYPE_IS_COLOR}`` shell environment variable.
+
+    This getter derives the value of the ``is_color`` parameter as follows:
+
+    * If the external ``${BEARTYPE_IS_COLOR}`` environment variable is set, this
+      getter:
+
+      * If the caller also explicitly passed the ``is_color`` parameter a
+        different and thus conflicting value to that environment variable, emits
+        a non-fatal warning informing the caller of this conflict.
+      * Returns the value of that variable coerced from a useless string to the
+        corresponding native Python object (e.g., from
+        ``BEARTYPE_IS_COLOR="True"`` to :data:`True`).
+
+    * Else, this getter returns the value of the ``is_color`` parameter as is.
+
+    Parameters
+    ----------
+    is_color : BoolTristateUnpassable
+        Original ``is_color`` parameter passed to that constructor.
+
+    Returns
+    ----------
+    BoolTristate
+        Final ``is_color`` parameter to be used inside that constructor.
+
+    Raises
+    ----------
+    BeartypeConfParamException
+        If the original``is_color`` parameter is *not* a tri-state boolean.
+    BeartypeConfShellVarException
+        If the external ``${BEARTYPE_IS_COLOR}`` shell environment variable is
+        set to an unrecognized string (i.e., neither ``"True"``, ``"False"``,
+        nor ``"None"``).
+    '''
+
+    # String value of the external shell environment variable
+    # "${BEARTYPE_IS_COLOR}" globally overriding the passed "is_color" parameter
+    # if the caller set this environment variable *OR* "None" otherwise.
+    is_color_shell_var_value = get_shell_var_value_or_none(
+        SHELL_VAR_CONF_IS_COLOR_NAME)
+
+    # If the caller set this environment variable...
+    if is_color_shell_var_value is not None:
+        # If the string value of this environment variable is unrecognized...
+        if (is_color_shell_var_value not in
+            SHELL_VAR_CONF_IS_COLOR_VALUE_TO_OBJ):
+            # Human-readable string listing the names of all valid string values
+            # of this environment variable, double-quoting each such name for
+            # additional readability.
+            IS_COLOR_SHELL_VAR_VALUES = join_delimited_disjunction(
+                strs=SHELL_VAR_CONF_IS_COLOR_VALUE_TO_OBJ.keys(),
+                is_double_quoted=True,
+            )
+
+            # Raise an exception embedding this string.
+            raise BeartypeConfShellVarException(
+                f'Beartype configuration environment variable '
+                f'"${{{SHELL_VAR_CONF_IS_COLOR_NAME}}}" '
+                f'value {repr(is_color_shell_var_value)} invalid '
+                f'(i.e., neither {IS_COLOR_SHELL_VAR_VALUES}).'
+            )
+        # Else, the string value of this environment variable is recognized.
+
+        # Value of the "is_color" parameter represented by this string value
+        # (e.g., boolean True for the string "True"). By the above validation,
+        # this value is now guaranteed to be valid.
+        is_color_override = SHELL_VAR_CONF_IS_COLOR_VALUE_TO_OBJ.get(
+            is_color_shell_var_value)
+
+        # If...
+        if (
+            # The value of the "is_color" parameter is *NOT* that of our
+            # unpassed argument placeholder, then the caller explicitly passed
+            # some value for this parameter. If this is the case *AND*...
+            is_color != ARG_VALUE_UNPASSED and
+            # The value of this parameter differs from (and thus conflicts with)
+            # the value of this environment variable...
+            is_color != is_color_override
+        ):
+            # Warn the caller that @beartype non-fatally resolved this conflict
+            # by ignoring this parameter in favour of this environment variable.
+            issue_warning(
+                cls=BeartypeConfShellVarWarning,
+                message=(
+                    f'Beartype configuration parameter "is_color" '
+                    f'value {repr(is_color)} ignored in favour of '
+                    f'environment variable '
+                    f'"${{{SHELL_VAR_CONF_IS_COLOR_NAME}}}" '
+                    f'value {repr(is_color_override)}.'
+                ),
+            )
+
+        # Override the value of the passed "is_color" parameter with
+        # that of this environment variable.
+        is_color = is_color_override
+    # Else, the caller did *NOT* set this environment variable.
+    #
+    # If the value of the "is_color" parameter is that of our unpassed argument
+    # placeholder, then the caller did *NOT* explicitly pass some value for this
+    # parameter. In this case, default this parameter to "None".
+    elif is_color == ARG_VALUE_UNPASSED:
+        is_color = None
+    # Else, the value of the "is_color" parameter is *NOT* that of our unpassed
+    # argument placeholder. In this case, the caller did explicitly passed some
+    # value for this parameter. Preserve this value as is.
+
+    # Return this boolean.
+    return is_color
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_conf/confcls.py
@@ -0,0 +1,1171 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **configuration class hierarchy** (i.e., public dataclasses enabling
+users to configure :mod:`beartype` with optional runtime behaviours).
+
+Most of the public attributes defined by this private submodule are explicitly
+exported to external users in our top-level :mod:`beartype.__init__` submodule.
+This private submodule is *not* intended for direct importation by downstream
+callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Generalize "warning_cls_on_decorator_exception", please. Specifically:
+#* Deprecate "warning_cls_on_decorator_exception".
+#* Define a new "decoration_exception_type: Optional[TypeException] = None"
+#  parameter accepting *ANY* arbitrary exception rather than merely a warning.
+
+#FIXME: [DOCOS] Document all newly defined configuration parameters in our
+#reST-formatted docos, please -- including:
+#* "claw_is_pep526".
+#* "hint_overrides".
+#* "violation_door_type".
+#* "violation_param_type".
+#* "violation_return_type".
+#* "violation_type".
+#* "violation_verbosity".
+#* "warning_cls_on_decorator_exception".
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarwarn import (
+    _BeartypeConfReduceDecoratorExceptionToWarningDefault,
+)
+from beartype.typing import (
+    TYPE_CHECKING,
+    Dict,
+    Optional,
+)
+from beartype._conf.confenum import (
+    BeartypeStrategy,
+    BeartypeViolationVerbosity,
+)
+from beartype._conf.confoverrides import (
+    BEARTYPE_HINT_OVERRIDES_EMPTY,
+    BeartypeHintOverrides,
+)
+from beartype._conf.conftest import (
+    default_conf_kwargs_after,
+    default_conf_kwargs_before,
+    die_if_conf_kwargs_invalid,
+)
+from beartype._conf._confget import get_is_color
+from beartype._data.hint.datahinttyping import (
+    BoolTristateUnpassable,
+    DictStrToAny,
+    TypeException,
+    TypeWarning,
+)
+from beartype._data.func.datafuncarg import ARG_VALUE_UNPASSED
+from beartype._util.utilobject import get_object_type_basename
+from threading import Lock
+
+# ....................{ CLASSES                            }....................
+class BeartypeConf(object):
+    '''
+    **Beartype configuration** (i.e., self-caching dataclass encapsulating all
+    flags, options, settings, and other metadata configuring each type-checking
+    operation performed by :mod:`beartype` -- including each decoration of a
+    callable or class by the :func:`beartype.beartype` decorator).
+
+    Attributes
+    ----------
+    _claw_is_pep526 : bool
+        :data:`True` only if type-checking **annotated variable assignments**
+        (i.e., :pep:`526`-compliant assignments to local, global, class, and
+        instance variables annotated by type hints) when importing modules
+        under import hooks published by the :mod:`beartype.claw` subpackage. See
+        also the :meth:`__new__` method docstring.
+    _conf_args : tuple
+        Tuple of the values of *all* possible keyword parameters (in arbitrary
+        order) configuring this configuration.
+    _conf_kwargs : Dict[str, object]
+        Dictionary mapping from the names to values of *all* possible keyword
+        parameters configuring this configuration.
+    _hash : int
+        Precomputed configuration hash returned by the :meth:`__hash__` dunder
+        method for efficiency.
+    _hint_overrides : Dict
+        **Type hint overrides** (i.e., frozen dictionary mapping from arbitrary
+        source to target type hints), enabling callers to lie to both their
+        users and all other packages other than :mod:`beartype`. This dictionary
+        enables callers to externally present a public API annotated by
+        simplified type hints while internally instructing :mod:`beartype` to
+        privately type-check that API under a completely different set of
+        (typically more complicated) type hints.
+    _is_color : Optional[bool]
+        Tri-state boolean governing how and whether beartype colours
+        **type-checking violations** (i.e.,
+        :class:`beartype.roar.BeartypeCallHintViolation` exceptions) with
+        POSIX-compliant ANSI escape sequences for readability. Specifically, if
+        this boolean is:
+
+        * :data:`False`, beartype *never* colours type-checking violations
+          raised by callables configured with this configuration.
+        * :data:`True`, beartype *always* colours type-checking violations
+          raised by callables configured with this configuration.
+        * :data:`None`, beartype conditionally colours type-checking violations
+          raised by callables configured with this configuration only when
+          standard output is attached to an interactive terminal.
+    _is_debug : bool
+        :data:`True` only if debugging :mod:`beartype`. See also the
+        :meth:`__new__` method docstring.
+    _is_pep484_tower : bool
+        :data:`True` only if enabling support for the :pep:`484`-compliant
+        implicit numeric tower. See also the :meth:`__new__` method docstring.
+    _is_violation_door_warn : bool
+        :data:`True` only if :attr:`violation_door_type` is a warning subclass.
+        Note that this is stored only as a negligible optimization to avoid
+        needless recomputation of this boolean during code generation.
+    _is_violation_param_warn : bool
+        :data:`True` only if :attr:`violation_param_type` is a warning subclass.
+        Note that this is stored only as a negligible optimization to avoid
+        needless recomputation of this boolean during code generation.
+    _is_violation_return_warn : bool
+        :data:`True` only if :attr:`violation_return_type` is a warning
+        subclass. Note that this is stored only as a negligible optimization to
+        avoid needless recomputation of this boolean during code generation.
+    _is_warning_cls_on_decorator_exception_set : bool
+        :data:`True` only if the caller explicitly passed the
+        :attr:`_warning_cls_on_decorator_exception` parameter. See
+        also the :meth:`__new__` method docstring.
+    _repr : Optional[str]
+        Either:
+
+        * If the :func:`repr` builtin has yet to call the :meth:`__repr__`
+          dunder method, :data:`None`.
+        * Else, the machine-readable representation of this configuration,
+    _strategy : BeartypeStrategy
+        **Type-checking strategy** (i.e., :class:`BeartypeStrategy` enumeration
+        member) with which to implement all type-checks in the wrapper function
+        dynamically generated by the :func:`beartype.beartype` decorator for
+        the decorated callable.
+    violation_door_type : TypeException
+        **DOOR violation type** (i.e., type of exception raised by the
+        :func:`beartype.door.die_if_unbearable` type-checker when the object
+        passed to that type-checker violates the type hint passed to that
+        type-checker). See also the :meth:`__new__` method docstring.
+    _violation_param_type : TypeException
+        **Parameter violation type** (i.e., type of exception raised by
+        callables generated by the :func:`beartype.beartype` decorator when
+        those callables receive parameters violating the type hints annotating
+        those parameters). See also the :meth:`__new__` method docstring.
+    _violation_return_type : TypeException
+        **Return violation type** (i.e., type of exception raised by callables
+        generated by the :func:`beartype.beartype` decorator when those
+        callables return values violating the type hints annotating those
+        returns). See also the :meth:`__new__` method docstring.
+    _violation_type : Optional[TypeException]
+        **Default violation type** (i.e., type of exception to default whichever
+        of the ``violation_door_type``, ``violation_param_type``, and
+        ``violation_return_type`` exception types are unpassed and thus
+        :data:`None`). See also the :meth:`__new__` method docstring.
+    _violation_verbosity : BeartypeViolationVerbosity
+        **Violation verbosity** (i.e., positive integer in the inclusive range
+        ``[1, 5]`` governing the verbosity of exception messages raised by
+        type-checking wrappers generated by the :func:`beartype.beartype`
+        decorator when either receiving parameters *or* returning values
+        violating their annotated type hints). See also the :meth:`__new__`
+        method docstring.
+    _warning_cls_on_decorator_exception : Optional[TypeWarning]
+        Configuration parameter governing whether the :func:`beartype.beartype`
+        decorator reduces otherwise fatal exceptions raised at decoration time
+        to equivalent non-fatal warnings of this warning category. See also the
+        :meth:`__new__` method docstring.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize this slots list with the implementations of:
+    # * The __new__() dunder method.
+    # * The __eq__() dunder method.
+    # * The __hash__() dunder method.
+    # * The __repr__() dunder method.
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats our purposes.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_claw_is_pep526',
+        '_conf_args',
+        '_conf_kwargs',
+        '_hash',
+        '_hint_overrides',
+        '_is_color',
+        '_is_debug',
+        '_is_pep484_tower',
+        '_is_violation_door_warn',
+        '_is_violation_param_warn',
+        '_is_violation_return_warn',
+        '_is_warning_cls_on_decorator_exception_set',
+        '_repr',
+        '_strategy',
+        '_violation_door_type',
+        '_violation_param_type',
+        '_violation_return_type',
+        '_violation_type',
+        '_violation_verbosity',
+        '_warning_cls_on_decorator_exception',
+    )
+
+    # Squelch false negatives from mypy. This is absurd. This is mypy. See:
+    #     https://github.com/python/mypy/issues/5941
+    if TYPE_CHECKING:
+        _claw_is_pep526: bool
+        _conf_args: tuple
+        _conf_kwargs: DictStrToAny
+        _hash: int
+        _hint_overrides: BeartypeHintOverrides
+        _is_color: Optional[bool]
+        _is_debug: bool
+        _is_pep484_tower: bool
+        _is_violation_door_warn: bool
+        _is_violation_param_warn: bool
+        _is_violation_return_warn: bool
+        _is_warning_cls_on_decorator_exception_set: bool
+        _repr: Optional[str]
+        _strategy: BeartypeStrategy
+        _violation_door_type: TypeException
+        _violation_param_type: TypeException
+        _violation_return_type: TypeException
+        _violation_type: Optional[TypeException]
+        _violation_verbosity: BeartypeViolationVerbosity
+        _warning_cls_on_decorator_exception: Optional[TypeWarning]
+
+    # ..................{ INSTANTIATORS                      }..................
+    # Note that this __new__() dunder method implements the superset of the
+    # functionality typically implemented by the __init__() dunder method. Due
+    # to Python instantiation semantics, the __init__() dunder method is
+    # intentionally left undefined. Why? Because Python unconditionally invokes
+    # __init__() if defined, even when the initialization performed by that
+    # __init__() has already been performed for the cached instance returned by
+    # __new__(). In short, __init__() and __new__() are largely mutually
+    # exclusive; one typically defines one or the other but *NOT* both.
+
+    def __new__(
+        cls,
+
+        # Optional keyword-only parameters.
+        *,
+
+        # Uncomment us when implementing O(n) type-checking, please.
+        # check_time_max_multiplier: Union[int, None] = 1000,
+        claw_is_pep526: bool = True,
+        hint_overrides: BeartypeHintOverrides = BEARTYPE_HINT_OVERRIDES_EMPTY,
+        is_color: BoolTristateUnpassable = ARG_VALUE_UNPASSED,
+        is_debug: bool = False,
+        is_pep484_tower: bool = False,
+        strategy: BeartypeStrategy = BeartypeStrategy.O1,
+        violation_door_type: Optional[TypeException] = None,
+        violation_param_type: Optional[TypeException] = None,
+        violation_return_type: Optional[TypeException] = None,
+        violation_type: Optional[TypeException] = None,
+        violation_verbosity: BeartypeViolationVerbosity = (
+            BeartypeViolationVerbosity.DEFAULT),
+        warning_cls_on_decorator_exception: Optional[TypeWarning] = (
+            _BeartypeConfReduceDecoratorExceptionToWarningDefault),
+    ) -> 'BeartypeConf':
+        '''
+        Instantiate this configuration if needed (i.e., if *no* prior
+        configuration with these same parameters was previously instantiated)
+        *or* reuse that previously instantiated configuration otherwise.
+
+        This dunder methods guarantees beartype configurations to be memoized:
+
+        .. code-block:: python
+
+           >>> from beartype import BeartypeConf
+           >>> BeartypeConf() is BeartypeConf()
+           True
+
+        This memoization is *not* merely an optimization. The
+        :func:`beartype.beartype` decorator internally memoizes the private
+        closure it creates and returns on the basis of this configuration,
+        which *must* thus also be memoized.
+
+        Parameters
+        ----------
+        check_time_max_multiplier : Union[int, None] = 1000
+            **Deadline multiplier** (i.e., positive integer instructing
+            :mod:`beartype` to prematurely halt the current type-check when the
+            total running time of the active Python interpreter exceeds this
+            integer multiplied by the running time consumed by both the current
+            type-check and all prior type-checks *and* the caller also passed a
+            non-default ``strategy``) *or* :data:`None` if :mod:`beartype`
+            should never prematurely halt runtime type-checks.
+
+            Increasing this integer increases the number of container items that
+            :mod:`beartype` type-checks at a cost of decreasing application
+            responsiveness. Likewise, decreasing this integer increases
+            application responsiveness at a cost of decreasing the number of
+            container items that :mod:`beartype` type-checks.
+
+            Ignored when ``strategy`` is :attr:`BeartypeStrategy.O1`, as that
+            strategy is already effectively instantaneous; imposing deadlines
+            and thus bureaucratic bookkeeping on that strategy would only
+            reduce its efficiency for no good reason, which is a bad reason.
+
+            Defaults to 1000, in which case a maximum of 0.10% of the total
+            runtime of the active Python process will be devoted to performing
+            non-constant :mod:`beartype` type-checks over container items. This
+            default has been carefully tuned to strike a reasonable balance
+            between runtime type-check coverage and application responsiveness,
+            typically enabling smaller containers to be fully type-checked
+            without noticeably impacting codebase performance.
+
+            **Theory time.** Let:
+
+            * :math:`T` be the total time this interpreter has been running.
+            * :math:``b` be the total time :mod:`beartype` has spent
+              type-checking in this interpreter.
+
+            Clearly, :math:`b <= T`. Generally, :math:`b <<<<<<< T` (i.e.,
+            type-checks consume much less time than the total time consumed by
+            the process). However, it's all too easy to exhibit worst-case
+            behaviour of :math:`b ~= T` (i.e., type-checks consume most of the
+            total time). How? By passing the :func:`beartype.door.is_bearable`
+            tester an absurdly large nested container subject to the non-default
+            ``strategy`` of :attr:`BeartypeStrategy.On`.
+
+            This deadline multiplier mitigates that worst-case behaviour.
+            Specifically, :mod:`beartype` will prematurely halt any iterative
+            type-check across a container when this constraint is triggered:
+
+            .. code-block:: python
+
+               b * check_time_max_multiplier >= T
+        claw_is_pep526 : bool, optional
+            :data:`True` only if implicitly type-checking **annotated variable
+            assignments** (i.e., :pep:`526`-compliant assignments to local,
+            global, class, and instance variables annotated by type hints) when
+            importing modules under import hooks published by the
+            :mod:`beartype.claw` subpackage by injecting calls to the
+            :func:`beartype.door.die_if_unbearable` function immediately *after*
+            those assignments in those modules. Enabling this boolean:
+
+            * Effectively augments :mod:`beartype` into a full-blown **hybrid
+              runtime-static type-checker** (i.e., performing both standard
+              runtime type-checking *and* non-standard static type-checking at
+              runtime).
+            * Adds negligible runtime overhead to all annotated variable
+              assignments in all modules imported under those import hooks.
+              Although the *individual* cost of this overhead for any given
+              assignment is negligible, the *aggregate* cost across all such
+              assignments could be non-negligible in worst-case use cases.
+
+            Ideally, this boolean should only be disabled for a small subset of
+            performance-sensitive modules *after* profiling those modules to
+            suffer performance regressions under import hooks published by the
+            :mod:`beartype.claw` subpackage. Defaults to :data:`True`.
+        hint_overrides : BeartypeHintOverrides
+            **Type hint overrides** (i.e., frozen dictionary mapping from
+            arbitrary source to target type hints), enabling callers to lie to
+            both their users and all other packages other than :mod:`beartype`.
+            This dictionary enables callers to externally present a public API
+            annotated by simplified type hints while internally instructing
+            :mod:`beartype` to privately type-check that API under a completely
+            different set of (typically more complicated) type hints. Doing so
+            preserves a facade of simplicity for downstream consumers like end
+            users, static type-checkers, and document generators. Defaults to
+            the empty dictionary.
+
+            Specifically, for each source type hint annotating each callable,
+            class, or variable assignment observed by :mod:`beartype`, if that
+            source type hint is a key of this dictionary, :mod:`beartype` maps
+            that source type hint to the corresponding target type hint in this
+            dictionary. That target type hint then globally "overrides" (i.e.,
+            replaces, substitutes for) that source type hint. :mod:`beartype`
+            then uses that target type hint in place of that source type hint.
+
+            For example, consider this Abomination Unto the Eyes of Guido:
+
+            .. code-block:: python
+
+               from beartype, BeartypeConf, BeartypeHintOverrides
+
+               # @beartype decorator configured to expand all "float" type hints
+               # to "int | float" type hints.
+               lyingbeartype = beartype(conf=BeartypeConf(
+                   hint_overrides=BeartypeHintOverrides({float: int | float})))
+
+               # The @lyingbeartype decorator now expands this signature...
+               @lyingbeartype
+               def lies(all_lies: list[int]) -> int:
+                   return all_lies[0]
+
+               # ...as if it had been annotated like this instead.
+               @beartype
+               def lies(all_lies: list[int | float]) -> int | float:
+                   return all_lies[0]
+        is_color : BoolTristateUnpassable
+            Tri-state boolean governing how and whether beartype colours
+            **type-checking violations** (i.e.,
+            :class:`beartype.roar.BeartypeCallHintViolation` exceptions) with
+            POSIX-compliant ANSI escape sequences for readability. Specifically,
+            if this boolean is:
+
+            * :data:`False`, beartype *never* colours type-checking violations
+              raised by callables configured with this configuration.
+            * :data:`True`, beartype *always* colours type-checking violations
+              raised by callables configured with this configuration.
+            * :data:`None`, beartype conditionally colours type-checking
+              violations raised by callables configured with this configuration
+              only when standard output is attached to an interactive terminal.
+
+            The ``${BEARTYPE_IS_COLOR}`` environment variable globally overrides
+            *all* attempts by *all* callers to explicitly pass this parameter,
+            enabling end users to enforce a global colour policy across their
+            full app stack. If ``${BEARTYPE_IS_COLOR}`` is set to a different
+            value than that of this parameter, this constructor emits a
+            non-fatal :class:`beartype.roar.BeartypeConfShellVarWarning` warning
+            informing the caller of this configuration conflict. To avoid this
+            conflict, open-source libraries are recommended to *not* pass this
+            parameter; ideally, *only* end user apps should pass this parameter.
+
+            Effectively defaults to :data:`None`. Technically, this parameter
+            defaults to a private magic constant *not* intended to be passed by
+            callers, enabling :mod:`beartype` to reliably detect whether the
+            caller has explicitly passed this parameter or not.
+        is_debug : bool, optional
+            :data:`True` only if debugging :mod:`beartype`. Enabling this
+            boolean:
+
+            * Prints the definition (including both the signature and body) of
+              each type-checking wrapper function dynamically generated by
+              :mod:`beartype` to standard output.
+            * Caches the body of each type-checking wrapper function dynamically
+              generated by :mod:`beartype` with the standard :mod:`linecache`
+              module, enabling these function bodies to be introspected at
+              runtime *and* improving the readability of tracebacks whose call
+              stacks contain one or more calls to these
+              :func:`beartype.beartype`-decorated functions.
+            * Appends to the declaration of each **hidden parameter** (i.e.,
+              whose name is prefixed by ``"__beartype_"`` and whose value is
+              that of an external attribute internally referenced in the body of
+              that function) the machine-readable representation of the initial
+              value of that parameter, stripped of newlines and truncated to a
+              hopefully sensible length. Since the
+              :func:`beartype._util.text.utiltextrepr.represent_object` function
+              called to do so is shockingly slow, these substrings are
+              conditionally embedded in the returned signature *only* when
+              enabling this boolean.
+
+            Defaults to :data:`False`.
+        is_pep484_tower : bool, optional
+            :data:`True` only if enabling support for the :pep:`484`-compliant
+            **implicit numeric tower** (i.e., lossy conversion of integers to
+            floating-point numbers *and* both integers and floating-point
+            numbers to complex numbers). Specifically, enabling this instructs
+            :mod:`beartype` to automatically expand:
+
+            * All :class:`float` type hints to ``float | int``, thus implicitly
+              accepting both integers and floating-point numbers for objects
+              annotated as only accepting floating-point numbers.
+            * All :class:`complex` type hints to ``complex | float | int``, thus
+              implicitly accepting integers, floating-point, and complex numbers
+              for objects annotated as only accepting complex numbers.
+
+            Defaults to :data:`False` to minimize precision error introduced by
+            lossy conversions from integers to floating-point numbers to complex
+            numbers. Since most integers do *not* have exact representations
+            as floating-point numbers, each conversion of an integer into a
+            floating-point number typically introduces a small precision error
+            that accumulates over multiple conversions and operations into a
+            larger precision error. Enabling this improves the usability of
+            public APIs at a cost of introducing precision errors.
+        strategy : BeartypeStrategy, optional
+            **Type-checking strategy** (i.e., :class:`BeartypeStrategy`
+            enumeration member) with which to implement all type-checks in the
+            wrapper function dynamically generated by the
+            :func:`beartype.beartype` decorator for the decorated callable.
+            Defaults to :attr: `BeartypeStrategy.O1`, the ``O(1)`` constant-time
+            strategy.
+        violation_door_type : Optional[TypeException]
+            **DOOR violation type** (i.e., type of exception raised by the
+            :func:`beartype.door.die_if_unbearable` type-checker when the object
+            passed to that type-checker violates the type hint passed to that
+            type-checker). Defaults to :data:`None`, in which case this type
+            defaults to either:
+
+            * If ``violation_type`` is passed and *not* :data:`None`, that type.
+            * Else, :exc:`.BeartypeDoorHintViolation`.
+        violation_param_type : Optional[TypeException]
+            **Parameter violation type** (i.e., type of exception raised by
+            callables generated by the :func:`beartype.beartype` decorator when
+            those callables receive parameters violating the type hints
+            annotating those parameters). Defaults to :data:`None`, in which
+            case this type defaults to either:
+
+            * If ``violation_type`` is passed and *not* :data:`None`, that type.
+            * Else, :exc:`.BeartypeCallHintParamViolation`.
+        violation_return_type : Optional[TypeException]
+            **Return violation type** (i.e., type of exception raised by
+            callables generated by the :func:`beartype.beartype` decorator when
+            those callables return values violating the type hints annotating
+            those returns). Defaults to :data:`None`, in which case this type
+            defaults to either:
+
+            * If ``violation_type`` is passed and *not* :data:`None`, that type.
+            * Else, :exc:`.BeartypeCallHintReturnViolation`.
+        violation_type : Optional[TypeException]
+            **Default violation type** (i.e., type of exception to default
+            whichever of the ``violation_door_type``, ``violation_param_type``,
+            and ``violation_return_type`` exception types are unpassed and thus
+            :data:`None`).  This parameter is merely a convenience enabling
+            callers to trivially control the ``violation_door_type``,
+            ``violation_param_type``, and ``violation_return_type`` parameters
+            *without* having to explicitly pass all three of those parameters.
+            Specifically, if this parameter is:
+
+            * *Not* :data:`None`, then the ``violation_door_type``,
+              ``violation_param_type``, and ``violation_return_type`` parameters
+              all default to the value of this parameter.
+            * :data:`None`, then:
+
+              * ``violation_door_type`` defaults to
+                :exc:`.BeartypeDoorHintViolation`.
+              * ``violation_param_type`` defaults to
+                :exc:`.BeartypeCallHintParamViolation`.
+              * ``violation_return_type`` defaults to
+                :exc:`.BeartypeCallHintReturnViolation`.
+
+            Defaults to :data:`None`.
+        violation_verbosity : BeartypeViolationVerbosity, optional
+            **Violation verbosity** (i.e., positive integer in the inclusive
+            range ``[1, 5]`` governing the verbosity of exception messages
+            raised by type-checking wrappers generated by the
+            :func:`beartype.beartype` decorator when either receiving parameters
+            *or* returning values violating their annotated type hints).
+            Defaults to :attr:`.BeartypeViolationVerbosity.DEFAULT`.
+        warning_cls_on_decorator_exception : Optional[TypeWarning]
+            Configuration parameter governing whether the
+            :func:`beartype.beartype` decorator reduces what would otherwise be
+            fatal exceptions raised at decoration time to equivalent non-fatal
+            warnings of the passed **warning category** (i.e., subclass of the
+            standard :class:`Warning` class). Specifically, this parameter may
+            be either:
+
+            * :data:`None`, in which case the :func:`beartype.beartype`
+              decorator raises fatal exceptions at decoration time.
+            * A warning category, in which case the :func:`beartype.beartype`
+              decorator reduces fatal exceptions to non-fatal warnings of this
+              category at decoration time.
+
+            Defaults to a private warning type *not* intended to be passed by
+            callers, enabling :mod:`beartype` to reliably detect when the caller
+            has *not* explicitly passed this parameter and respond accordingly
+            by defaulting this parameter to a context-dependent value. Notably,
+            if this parameter is *not* explicitly passed:
+
+            * The :func:`beartype.beartype` decorator defaults this parameter to
+              :data:`None`, thus raising decoration-time exceptions.
+            * The :mod:`beartype.claw` API defaults this parameter to the public
+              :class:`beartype.roar.BeartypeClawDecorWarning` warning category,
+              thus reducing decoration-time exceptions to warnings of that
+              category when performing import hooks. This default behaviour
+              significantly increases the likelihood that import hooks installed
+              by :mod:`beartype.claw` will successfully decorate the entirety of
+              their target packages rather than prematurely halt with a single
+              fatal exception at the first decoration issue.
+
+        Returns
+        -------
+        BeartypeConf
+            Beartype configuration memoized with these parameters.
+
+        Raises
+        ------
+        BeartypeConfParamException
+            If either:
+
+            * ``is_color`` is *not* a tri-state boolean.
+            * ``is_debug`` is *not* a boolean.
+            * ``is_pep484_tower`` is *not* a boolean.
+            * ``strategy`` is *not* a :class:`BeartypeStrategy` enumeration
+              member.
+            * ``warning_cls_on_decorator_exception`` is neither :data:`None`
+              *nor* a **warning category** (i.e., :class:`Warning` subclass).
+        BeartypeConfShellVarException
+            If either:
+
+            * The external ``${BEARTYPE_IS_COLOR}`` shell environment variable
+              is set to an unrecognized string (i.e., neither ``"True"``,
+              ``"False"``, nor ``"None"``).
+        '''
+
+        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+        # CAUTION: Synchronize this tuple with the similar "self._conf_kwargs"
+        # dictionary defined below.
+        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+        # In a non-reentrant thread lock specific to beartype configurations...
+        #
+        # Note that this lock is potentially overkill and thus unnecessary.
+        # Nonetheless, since the number of beartype configurations instantiated
+        # over the lifetime of the average Python interpreter is small, since
+        # non-reentrant thread locks are reasonably fast to enter, and since the
+        # cost of race conditions is high, this lock does no real-world harm and
+        # may actually do a great deal of real-world good. Safety first, all!
+        with _beartype_conf_lock:
+            # ..................{ CACHE                      }..................
+            # Validate and possibly override the "is_color" parameter by the
+            # value of the ${BEARTYPE_IS_COLOR} environment variable (if set).
+            is_color = get_is_color(is_color)
+
+            # Efficiently hashable tuple of these parameters in arbitrary order.
+            conf_args = (
+                claw_is_pep526,
+                hint_overrides,
+                is_color,
+                is_debug,
+                is_pep484_tower,
+                strategy,
+                violation_door_type,
+                violation_param_type,
+                violation_return_type,
+                violation_type,
+                violation_verbosity,
+                warning_cls_on_decorator_exception,
+            )
+
+            # If this method has already instantiated a configuration with these
+            # parameters, return that configuration for consistency and
+            # efficiency.
+            if conf_args in _beartype_conf_args_to_conf:
+                return _beartype_conf_args_to_conf[conf_args]
+            # Else, this method has *NOT* yet instantiated a configuration with
+            # these parameters. In this case, continue to do so and then cache
+            # that configuration.
+
+            # Dictionary mapping from the names to values of *ALL* possible
+            # keyword parameters configuring this configuration, intentionally
+            # defined *AFTER* this method first attempts to efficiently reduce
+            # to a noop by returning a previously instantiated configuration.
+            conf_kwargs = dict(
+                claw_is_pep526=claw_is_pep526,
+                hint_overrides=hint_overrides,
+                is_color=is_color,
+                is_debug=is_debug,
+                is_pep484_tower=is_pep484_tower,
+                strategy=strategy,
+                violation_door_type=violation_door_type,
+                violation_param_type=violation_param_type,
+                violation_return_type=violation_return_type,
+                violation_type=violation_type,
+                violation_verbosity=violation_verbosity,
+                warning_cls_on_decorator_exception=(
+                    warning_cls_on_decorator_exception),
+            )
+
+            # Default all parameters not explicitly passed by the user to sane
+            # defaults *BEFORE* validating these parameters.
+            default_conf_kwargs_before(conf_kwargs)
+
+            # If one or more passed parameters are invalid, raise an exception.
+            die_if_conf_kwargs_invalid(conf_kwargs)
+            # Else, all passed parameters are valid.
+
+            # Default all parameters not explicitly passed by the user to sane
+            # defaults *AFTER* validating these parameters.
+            default_conf_kwargs_after(conf_kwargs)
+
+            # ..................{ INSTANTIATE                }..................
+            # Instantiate a new configuration of this type.
+            self = super().__new__(cls)
+
+            # Nullify critical instance variables for safety.
+            self._repr = None
+
+            # Precompute the hash to be returned by the __hash__() dunder method
+            # as the hash of a tuple containing these parameters in an arbitrary
+            # (albeit well-defined) order.
+            #
+            # Note this has been profiled to be the optimal means of hashing
+            # object attributes in Python, where "optimal" means:
+            # * Optimally fast. CPython in particular optimizes the creation and
+            #   garbage collection of "small" tuples, where "small" is
+            #   ill-defined but almost certainly applies here.
+            # * Optimally uniformly distributed, thus minimizing the likelihood
+            #   of expensive hash collisions.
+            self._hash = hash(conf_args)
+
+            # Store data structures encapsulating these passed parameters for
+            # subsequent reuse *BEFORE* possibly modifying the values of these
+            # parameters below.
+            self._conf_args = conf_args
+            self._conf_kwargs = conf_kwargs
+
+            # Assert that these two data structures encapsulate the same number
+            # of configuration parameters (as a feeble safety check).
+            assert len(self._conf_args) == len(self._conf_kwargs)
+
+            # Cache this configuration with all relevant dictionary singletons
+            # *BEFORE* possibly modifying the values of passed parameters below.
+            _beartype_conf_args_to_conf[conf_args] = self
+
+            # ..................{ CLASSIFY                   }..................
+            # Classify all passed parameters that have now been possibly
+            # modified above with this configuration.
+            #
+            # Note that this classification intentionally accesses these
+            # parameters from the "conf_kwargs" dictionary possibly modified by
+            # the above call to the default_conf_kwargs() function rather than
+            # the original passed values of these parameters.
+            self._claw_is_pep526 = conf_kwargs['claw_is_pep526']  # pyright: ignore
+            self._hint_overrides = conf_kwargs['hint_overrides']  # pyright: ignore
+            self._is_color = conf_kwargs['is_color']  # pyright: ignore
+            self._is_debug = conf_kwargs['is_debug']  # pyright: ignore
+            self._is_pep484_tower = conf_kwargs['is_pep484_tower']  # pyright: ignore
+            self._strategy = conf_kwargs['strategy']  # pyright: ignore
+            self._violation_door_type = conf_kwargs['violation_door_type']  # pyright: ignore
+            self._violation_param_type = conf_kwargs['violation_param_type']  # pyright: ignore
+            self._violation_return_type = conf_kwargs['violation_return_type']  # pyright: ignore
+            self._violation_type = conf_kwargs['violation_type']  # pyright: ignore
+            self._violation_verbosity = conf_kwargs['violation_verbosity']  # pyright: ignore
+
+            # Classify all remaining instance variables.
+            self._is_violation_door_warn = issubclass(
+                self._violation_door_type, Warning)  # pyright: ignore
+            self._is_violation_param_warn = issubclass(
+                self._violation_param_type, Warning)  # pyright: ignore
+            self._is_violation_return_warn = issubclass(
+                self._violation_return_type, Warning)  # pyright: ignore
+
+            # ..................{ CLASSIFY ~ more            }..................
+            # If the value of the "warning_cls_on_decorator_exception" parameter
+            # is still the default private fake warning category established
+            # above, then the caller failed to explicitly pass a valid value. In
+            # this case...
+            if (
+                warning_cls_on_decorator_exception is
+                _BeartypeConfReduceDecoratorExceptionToWarningDefault
+            ):
+                # Note this fact for subsequent reference elsewhere (e.g., in
+                # the "beartype.claw" subpackage).
+                self._is_warning_cls_on_decorator_exception_set = False
+
+                # Default this parameter to "None" for safety. Since this
+                # default private fake warning category is *NOT* an actual
+                # warning category intended for real-world use, this category
+                # *MUST* be replaced with a sane default that is safely usable.
+                warning_cls_on_decorator_exception = None
+            # Else, the caller explicitly passed a valid value for this
+            # parameter. In this case, preserve this value and note this fact.
+            else:
+                self._is_warning_cls_on_decorator_exception_set = True
+
+            self._warning_cls_on_decorator_exception = (
+                warning_cls_on_decorator_exception)
+
+        # Return this configuration.
+        return self
+
+    # ..................{ PROPERTIES                         }..................
+    # Read-only public properties effectively prohibiting mutation of their
+    # underlying private attributes.
+
+    #FIXME: Publicly document this in our reST-formatted docos, please.
+    @property
+    def kwargs(self) -> DictStrToAny:
+        '''
+        **Beartype configuration keyword dictionary** (i.e., dictionary mapping
+        from the names of all keyword parameters accepted by the :meth:`__new__`
+        method to the corresponding values of those parameters in this
+        configuration).
+
+        This property can be used to permute new configurations from existing
+        configurations, overriding only a small handful of parameters while
+        preserving all other parameters as is: e.g.,
+
+        .. code-block:: python
+
+           # Arbitrary input beartype configuration.
+           conf = BeartypeConf(is_color=True)
+
+           # New keyword dictionary permuted from this input.
+           conf_kwargs = conf.kwargs.copy()
+           conf_kwargs['is_debug'] = True
+
+           # New beartype configuration initialized by this dictionary.
+           debug_conf = BeartypeConf(**conf_kwargs)
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._conf_kwargs
+
+    # ..................{ PROPERTIES ~ options               }..................
+    # Read-only public properties with which this configuration was originally
+    # instantiated (as keyword-only parameters).
+
+    @property
+    def hint_overrides(self) -> BeartypeHintOverrides:
+        '''
+        **Type hint overrides** (i.e., frozen dictionary mapping from arbitrary
+        source to target type hints), enabling callers to lie to both their
+        users and all other packages other than :mod:`beartype`. This dictionary
+        enables callers to externally present a public API annotated by
+        simplified type hints while internally instructing :mod:`beartype` to
+        privately type-check that API under a completely different set of
+        (typically more complicated) type hints.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._hint_overrides
+
+
+    @property
+    def strategy(self) -> BeartypeStrategy:
+        '''
+        **Type-checking strategy** (i.e., :class:`BeartypeStrategy`
+        enumeration member) with which to implement all type-checks in the
+        wrapper function dynamically generated by the
+        :func:`beartype.beartype` decorator for the decorated callable.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._strategy
+
+
+    @property
+    def warning_cls_on_decorator_exception(self) -> (
+        Optional[TypeWarning]):
+        '''
+        Configuration parameter governing whether the :func:`beartype.beartype`
+        decorator reduces otherwise fatal exceptions raised at decoration time
+        to equivalent non-fatal warnings of this warning category.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._warning_cls_on_decorator_exception
+
+    # ..................{ PROPERTIES ~ options : bool        }..................
+    # Read-only public properties with which this configuration was originally
+    # instantiated (as keyword-only parameters).
+
+    @property
+    def claw_is_pep526(self) -> bool:
+        '''
+        :data:`True` only if type-checking **annotated variable assignments**
+        (i.e., :pep:`526`-compliant assignments to local, global, class, and
+        instance variables annotated by type hints) when importing modules
+        under import hooks published by the :mod:`beartype.claw` subpackage.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._claw_is_pep526
+
+
+    @property
+    def is_color(self) -> Optional[bool]:
+        '''
+        Tri-state boolean governing how and whether beartype colours
+        **type-checking violations** (i.e.,
+        :class:`beartype.roar.BeartypeCallHintViolation` exceptions) with
+        POSIX-compliant ANSI escape sequences for readability. Specifically, if
+        this boolean is:
+
+        * :data:`False`, beartype *never* colours type-checking violations
+          raised by callables configured with this configuration.
+        * :data:`True`, beartype *always* colours type-checking violations
+          raised by callables configured with this configuration.
+        * :data:`None`, beartype conditionally colours type-checking violations
+          raised by callables configured with this configuration only when
+          standard output is attached to an interactive terminal.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._is_color
+
+
+    @property
+    def is_debug(self) -> bool:
+        '''
+        :data:`True` only if debugging :mod:`beartype`.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._is_debug
+
+
+    @property
+    def is_pep484_tower(self) -> bool:
+        '''
+        :data:`True` only if enabling support for the :pep:`484`-compliant
+        implicit numeric tower.
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._is_pep484_tower
+
+    # ..................{ PROPERTIES ~ options : violation   }..................
+    @property
+    def violation_door_type(self) -> TypeException:
+        '''
+        **DOOR violation type** (i.e., type of exception raised by the
+        :func:`beartype.door.die_if_unbearable` type-checker when the object
+        passed to that type-checker violates the type hint passed to that
+        type-checker).
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._violation_door_type
+
+
+    @property
+    def violation_param_type(self) -> TypeException:
+        '''
+        **Parameter violation type** (i.e., type of exception raised by
+        callables generated by the :func:`beartype.beartype` decorator when
+        those callables receive parameters violating the type hints annotating
+        those parameters).
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._violation_param_type
+
+
+    @property
+    def violation_return_type(self) -> TypeException:
+        '''
+        **Return violation type** (i.e., type of exception raised by callables
+        generated by the :func:`beartype.beartype` decorator when those
+        callables return values violating the type hints annotating those
+        returns).
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._violation_return_type
+
+
+    @property
+    def violation_type(self) -> Optional[TypeException]:
+        '''
+        **Default violation type** (i.e., type of exception to default whichever
+        of the ``violation_door_type``, ``violation_param_type``, and
+        ``violation_return_type`` exception types are unpassed and thus
+        :data:`None`).
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._violation_type
+
+
+    @property
+    def violation_verbosity(self) -> BeartypeViolationVerbosity:
+        '''
+        **Violation verbosity** (i.e., positive integer in the inclusive range
+        ``[1, 5]`` governing the verbosity of exception messages raised by
+        type-checking wrappers generated by the :func:`beartype.beartype`
+        decorator when either receiving parameters *or* returning values
+        violating their annotated type hints).
+
+        See Also
+        --------
+        :meth:`__new__`
+            Further details.
+        '''
+
+        return self._violation_verbosity
+
+    # ..................{ DUNDERS                            }..................
+    def __eq__(self, other: object) -> bool:
+        '''
+        **Beartype configuration equality comparator.**
+
+        Parameters
+        ----------
+        other : object
+            Arbitrary object to be compared for equality against this
+            configuration.
+
+        Returns
+        -------
+        Union[bool, type(NotImplemented)]
+            Either:
+
+            * If this other object is also a beartype configuration, either:
+
+              * If these configurations share the same settings, :data:`True`.
+              * Else, :data:`False`.
+
+            * Else, :data:`NotImplemented`.
+
+        See Also
+        --------
+        :func:`_hash_beartype_conf`
+            Further details.
+        '''
+
+        # Return either...
+        return (
+            # If this other object is also a beartype configuration, true only
+            # if these configurations share the same settings;
+            self._conf_args == other._conf_args
+            if isinstance(other, BeartypeConf) else
+            # Else, this other object is *NOT* also a beartype configuration. In
+            # this case, the standard singleton informing Python that this
+            # equality comparator fails to support this comparison.
+            NotImplemented  # type: ignore[return-value]
+        )
+
+
+    def __hash__(self) -> int:
+        '''
+        **Hash** (i.e., non-negative integer quasi-uniquely identifying this
+        beartype configuration with respect to hashable container membership).
+
+        Returns
+        -------
+        int
+            Hash of this configuration.
+        '''
+
+        # Return the precomputed hash for this configuration.
+        return self._hash
+
+
+    def __repr__(self) -> str:
+        '''
+        **Beartype configuration representation** (i.e., machine-readable
+        string which, when dynamically evaluated as code, restores access to
+        this exact configuration object).
+
+        Returns
+        -------
+        str
+            Representation of this configuration.
+        '''
+
+        # If machine-readable representation of this configuration has yet to be
+        # computed...
+        if self._repr is None:
+            # Initialize this representation to the unqualified basename of the
+            # class of this configuration.
+            conf_repr = f'{get_object_type_basename(self)}('
+
+            # Dictionary mapping from the names to values of *ALL* possible
+            # keyword parameters configuring the default beartype configuration.
+            KWARGS_DEFAULT = BEARTYPE_CONF_DEFAULT._conf_kwargs
+
+            # For the name and value of each keyword parameter with which this
+            # configuration was instantiated...
+            for kwarg_name, kwarg_value in self._conf_kwargs.items():
+                # If this value differs from that of the default value for this
+                # keyword parameter...
+                if kwarg_value != KWARGS_DEFAULT[kwarg_name]:
+                    # Append a comma-delimited representation of this keyword
+                    # argument to this representation.
+                    conf_repr += f'{kwarg_name}={kwarg_value}, '
+                # Else, this value is the default value for this keyword
+                # parameter. In this case, silently ignore this value. Appending
+                # this value to this representation would convey *NO* meaningful
+                # semantics and, indeed, only inhibit the readability of this
+                # representation for end users and developers alike.
+
+            # If this representation is suffixed by a whitespaced comma, remove
+            # that suffix.
+            if conf_repr[-2:] == ', ':
+                conf_repr = conf_repr[:-2]
+            # Else, this representation is *NOT* suffixed by a comma. In this
+            # case, preserve this representation as is.
+
+            # Preserve this representation for subsequent use.
+            self._repr = f'{conf_repr})'
+        # Else, the machine-readable representation of this configuration has
+        # already been computed.
+
+        # Return the machine-readable representation of this configuration.
+        return self._repr
+
+# ....................{ PRIVATE ~ globals                  }....................
+_beartype_conf_lock = Lock()
+'''
+**Non-reentrant beartype configuration thread lock** (i.e., low-level thread
+locking mechanism implemented as a highly efficient C extension, defined as an
+global for non-reentrant reuse elsewhere as a context manager).
+'''
+
+
+_beartype_conf_args_to_conf: Dict[tuple, BeartypeConf] = {}
+'''
+Non-thread-safe **beartype configuration parameter cache** (i.e., dictionary
+mapping from the hash of each set of parameters accepted by a prior call of the
+:meth:`BeartypeConf.__new__` instantiator to the unique :class:`BeartypeConf`
+instance instantiated by that call).
+
+Caveats
+-------
+**This cache is non-thread-safe.** However, since this cache is only used as a
+memoization optimization, the only harmful consequences of a race condition
+between threads contending over this cache is a mildly inefficient (but
+otherwise harmless) repeated re-memoization of duplicate configurations.
+'''
+
+# ....................{ GLOBALS                            }....................
+# This global is intentionally defined *AFTER* all other attributes above, which
+# this global implicitly assumes to be defined.
+BEARTYPE_CONF_DEFAULT = BeartypeConf()
+'''
+**Default beartype configuration** (i.e., :class:`BeartypeConf` class
+instantiated with *no* parameters and thus default parameters), globalized to
+trivially optimize external access to this configuration throughout this
+codebase.
+
+Note that this global is *not* publicized to end users, who can simply
+instantiate ``BeartypeConf()`` to obtain the same singleton.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_conf/confenum.py
@@ -0,0 +1,120 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **configuration enumerations** (i.e., public enumerations whose members
+may be passed as initialization-time parameters to the
+:meth:`beartype._conf.confcls.BeartypeConf.__init__` constructor to configure
+:mod:`beartype` with optional runtime type-checking behaviours).
+
+Most of the public attributes defined by this private submodule are explicitly
+exported to external users in our top-level :mod:`beartype.__init__` submodule.
+This private submodule is *not* intended for direct importation by downstream
+callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from enum import (
+    Enum,
+    IntEnum,
+    auto as next_enum_member_value,
+    unique as die_unless_enum_member_values_unique,
+)
+
+# ....................{ ENUMERATIONS                       }....................
+@die_unless_enum_member_values_unique
+class BeartypeStrategy(Enum):
+    '''
+    Enumeration of all kinds of **type-checking strategies** (i.e., competing
+    procedures for type-checking objects passed to or returned from
+    :func:`beartype.beartype`-decorated callables, each with concomitant
+    tradeoffs with respect to runtime complexity and quality assurance).
+
+    Strategies are intentionally named according to `conventional Big O
+    notation <Big O_>`__ (e.g., :attr:`BeartypeStrategy.On` enables the
+    ``O(n)`` strategy). Strategies are established per-decoration at the
+    fine-grained level of callables decorated by the :func:`beartype.beartype`
+    decorator by setting the :attr:`beartype.BeartypeConf.strategy` parameter of
+    the :class:`beartype.BeartypeConf` object passed as the optional ``conf``
+    parameter to that decorator.
+
+    Strategies enforce their corresponding runtime complexities (e.g., ``O(n)``)
+    across *all* type-checks performed for callables enabling those strategies.
+    For example, a callable configured by the :attr:`BeartypeStrategy.On`
+    strategy will exhibit linear ``O(n)`` complexity as its overhead for
+    type-checking each nesting level of each container passed to and returned
+    from that callable.
+
+    .. _Big O:
+       https://en.wikipedia.org/wiki/Big_O_notation
+
+    Attributes
+    ----------
+    O0 : EnumMemberType
+        **No-time strategy** (i.e, disabling type-checking for a decorated
+        callable by reducing :func:`beartype.beartype` to the identity
+        decorator for that callable). Although seemingly useless, this strategy
+        enables users to selectively blacklist (prevent) callables from being
+        type-checked by our as-yet-unimplemented import hook. When implemented,
+        that hook will type-check all callables within a package or module
+        *except* those callables explicitly decorated by this strategy.
+    O1 : EnumMemberType
+        **Constant-time strategy** (i.e., the default ``O(1)`` strategy,
+        type-checking a single randomly selected item of each container). As
+        the default, this strategy need *not* be explicitly enabled.
+    Ologn : EnumMemberType
+        **Logarithmic-time strategy** (i.e., the ``O(log n)`` strategy,
+        type-checking a randomly selected number of items ``log(len(obj))`` of
+        each container ``obj``). This strategy is **currently unimplemented.**
+        (*To be implemented by a future beartype release.*)
+    On : EnumMemberType
+        **Linear-time strategy** (i.e., the ``O(n)`` strategy, type-checking
+        *all* items of a container). This strategy is **currently
+        unimplemented.** (*To be implemented by a future beartype release.*)
+    '''
+
+    O0 = next_enum_member_value()
+    O1 = next_enum_member_value()
+    Ologn = next_enum_member_value()
+    On = next_enum_member_value()
+
+
+@die_unless_enum_member_values_unique
+class BeartypeViolationVerbosity(IntEnum):
+    '''
+    Enumeration of all kinds of **violation verbosities** (i.e., positive
+    integers in the inclusive range ``[1, 5]`` governing the verbosity of
+    exception messages raised by type-checking wrappers generated by the
+    :func:`beartype.beartype` decorator when either receiving parameters *or*
+    returning values violating their annotated type hints).
+
+    Verbosities transparently reduce to integers and can thus be used wherever
+    integers are used (e.g., ``BeartypeViolationVerbosity.DEFAULT + 1`` is the next
+    level of verbosity beyond that of the default). Verbosities are established
+    per-decoration at the fine-grained level of callables decorated by the
+    :func:`beartype.beartype` decorator by setting the
+    :attr:`beartype.BeartypeConf.violation_verbosity` parameter of the
+    :class:`beartype.BeartypeConf` object passed as the optional ``conf``
+    parameter to that decorator.
+
+    Attributes
+    ----------
+    MINIMAL : EnumMemberType
+        **Minimal verbosity,** intended for end users potentially lacking core
+        expertise in Python.
+    DEFAULT : EnumMemberType
+        **Default verbosity,** intended for a general developer audience assumed
+        to be fluent in Python.
+    MAXIMAL : EnumMemberType
+        **Maximum verbosity,** extending the default verbosity with additional
+        contextual metadata intended for debugging violations. This includes:
+
+        * A machine-readable representation of the beartype configuration under
+          which the current violation occurred.
+    '''
+
+    MINIMAL = next_enum_member_value()
+    DEFAULT = next_enum_member_value()
+    MAXIMAL = next_enum_member_value()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_conf/confoverrides.py
@@ -0,0 +1,127 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **hint overrides class hierarchy** (i.e., public classes implementing
+immutable mappings intended to be passed as the value of the ``hint_overrides``
+parameter accepted by the :class:`beartype.BeartypeConf.__init__` method).
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.meta import URL_ISSUES
+from beartype.roar import BeartypeHintOverridesException
+from beartype._data.hint.datahinttyping import (
+    Pep484TowerComplex,
+    Pep484TowerFloat,
+)
+from beartype._util.kind.map.utilmapfrozen import FrozenDict
+from re import (
+    escape as re_escape,
+    search as re_search,
+)
+
+# ....................{ CLASSES                            }....................
+#FIXME: Unit test us up, please.
+class BeartypeHintOverrides(FrozenDict):
+    '''
+    Beartype **hint overrides** (i.e., immutable mapping intended to be passed
+    as the value of the ``hint_overrides`` parameter accepted by the
+    :class:`beartype.BeartypeConf.__init__` method).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, *args, **kwargs) -> None:
+
+        # Instantiate this immutable dictionary with all passed parameters.
+        super().__init__(*args, **kwargs)
+
+        # For each source and target hint override in this dictionary...
+        for hint_override_src, hint_override_trg in self.items():
+            # The machine-readable representation of this source override,
+            # escaped to protect all regex-specific syntax in this
+            # representation from being erroneously parsed as that syntax.
+            HINT_OVERRIDE_SRC_REPR = re_escape(repr(hint_override_src))
+
+            # Regular expression matching subscription-style recursion in this
+            # hint override (e.g., 'str: list[str]').
+            #
+            # Note that:
+            # * Beartype currently only supports union-style recursion (e.g.,
+            #   "float: int | float").
+            # * Regular expressions inevitably fail in edge cases (e.g.,
+            #   "str: Literal['str']"). Thankfully, hint overrides *AND* these
+            #   edge cases are sufficiently rare that we can conveniently ignore
+            #   them until some GitHub pyromaniac inevitably complains and
+            #   starts lighting dumpster fires on our issue tracker.
+            HINT_OVERRIDE_RECURSION_REGEX = (
+                # An opening "[" delimeter followed by zero or more characters
+                # that are *NOT* the corresponding closing "]" delimiter.
+                r'\[[^]]*'
+                # The machine-readable representation of this source override,
+                # bounded before but *NOT* after by a word boundary. Why?
+                # Consider an invalid recursive non-union type hint resembling:
+                #     BeartypeHintOverrides({List[str]: Tuple[List[str], ...]})
+                #
+                # In the above case, "HINT_OVERRIDE_SRC_REPR == 'List[str]'.
+                # Bounding that source string:
+                # * Before by a word boundary guards against false positives
+                #   that would otherwise match valid larger target strings
+                #   merely suffixed by that string but otherwise unrelated and
+                #   thus non-recursive (e.g., "Tuple[MuhList[str]]").
+                # * After by a word boundary would effectively prevent
+                #   *ANYTHING* from matching, because only alphanumeric
+                #   characters match the word boundary following a punctuation
+                #   character (e.g., "List[str]]!]?...").
+                fr'\b{HINT_OVERRIDE_SRC_REPR}'
+                # Zero or more characters that are *NOT* the corresponding
+                # closing "]" delimiter followed by that delimiter.
+                r'[^]]*\]'
+            )
+            # print(f'HINT_OVERRIDE_RECURSION_REGEX: {HINT_OVERRIDE_RECURSION_REGEX}')
+
+            # Match object if this hint override contains one or more instances
+            # of subscription-style recursion *OR* "None" otherwise.
+            hint_override_recursion = re_search(
+                HINT_OVERRIDE_RECURSION_REGEX, repr(hint_override_trg))
+
+            # If this hint override contains one or more instances of
+            # subscription-style recursion, raise an exception.
+            if hint_override_recursion is not None:
+                raise BeartypeHintOverridesException(
+                    f'Recursive type hint override '
+                    f'{repr(hint_override_src)}: {repr(hint_override_trg)} '
+                    f'currently unsupported. Please complain on our friendly '
+                    f'issue tracker if you feel that this is dumb:\n'
+                    f'\t{URL_ISSUES}'
+                )
+            # Else, this hint override contains *NO* such recursion.
+
+# ....................{ GLOBALS                            }....................
+BEARTYPE_HINT_OVERRIDES_EMPTY = BeartypeHintOverrides()
+'''
+**Empty type hint overrides** (i.e., default :class:`.BeartypeHintOverrides`
+instance overriding *no* type hints).
+'''
+
+
+BEARTYPE_HINT_OVERRIDES_PEP484_TOWER = BeartypeHintOverrides({
+    float: Pep484TowerFloat,
+    complex: Pep484TowerComplex,
+})
+'''
+:pep:`484`-compliant **implicit tower type hint overrides** (i.e.,
+:class:`.BeartypeHintOverrides` instance lossily convering integers to
+floating-point numbers *and* both integers and floating-point numbers to complex
+numbers).
+
+Specifically, these overrides instruct :mod:`beartype` to automatically expand:
+
+* All :class:`float` type hints to ``float | int``, thus implicitly accepting
+  both integers and floating-point numbers for objects annotated as only
+  accepting floating-point numbers.
+* All :class:`complex` type hints to ``complex | float | int``, thus implicitly
+  accepting integers, floating-point, and complex numbers for objects annotated
+  as only accepting complex numbers.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_conf/conftest.py
@@ -0,0 +1,309 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **configuration class testers** (i.e., low-level callables testing and
+validating various metadata of interest to the high-level
+:class:`beartype.BeartypeConf` dataclass).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+import beartype
+from beartype.roar import (
+    BeartypeConfException,
+    BeartypeConfParamException,
+    BeartypeCallHintParamViolation,
+    BeartypeCallHintReturnViolation,
+    BeartypeDoorHintViolation,
+)
+from beartype.typing import Optional
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._conf.confenum import (
+    BeartypeStrategy,
+    BeartypeViolationVerbosity,
+)
+from beartype._conf.confoverrides import (
+    BEARTYPE_HINT_OVERRIDES_PEP484_TOWER,
+    BeartypeHintOverrides,
+)
+from beartype._data.hint.datahinttyping import DictStrToAny
+from beartype._util.cls.utilclstest import is_type_subclass
+
+# ....................{ RAISERS                            }....................
+def die_unless_conf(conf: 'beartype.BeartypeConf') -> None:
+    '''
+    Raise an exception unless the passed object is a beartype configuration.
+
+    Parameters
+    ----------
+    conf : beartype.BeartypeConf
+        Object to be validated.
+
+    Raises
+    ------
+    BeartypeConfException
+        If this object is *not* a beartype configuration.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._conf.confcls import BeartypeConf
+
+    # If this object is *NOT* a configuration, raise an exception.
+    if not isinstance(conf, BeartypeConf):
+        raise BeartypeConfException(
+            f'{repr(conf)} not beartype configuration.')
+    # Else, this object is a configuration.
+
+
+def die_if_conf_kwargs_invalid(conf_kwargs: DictStrToAny) -> None:
+    '''
+    Raise an exception if one or more configuration parameters in the passed
+    dictionary of such parameters are invalid.
+
+    Parameters
+    ----------
+    conf_kwargs : Dict[str, object]
+        Dictionary mapping from the names to values of *all* possible keyword
+        parameters configuring this configuration.
+
+    Raises
+    ------
+    BeartypeConfParamException
+        If one or more configurations parameter in this dictionary are invalid.
+    '''
+
+    # ..................{ VALIDATE                           }..................
+    # If "claw_is_pep526" is *NOT* a boolean, raise an exception.
+    if not isinstance(conf_kwargs['claw_is_pep526'], bool):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "claw_is_pep526" '
+            f'value {repr(conf_kwargs["claw_is_pep526"])} not boolean.'
+        )
+    # Else, "claw_is_pep526" is a boolean.
+    #
+    # If "hint_overrides" is *NOT* a frozen dict, raise an exception.
+    elif not isinstance(conf_kwargs['hint_overrides'], BeartypeHintOverrides):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "hint_overrides" '
+            f'value {repr(conf_kwargs["hint_overrides"])} not '
+            f'frozen dictionary '
+            f'(i.e., "beartype.BeartypeHintOverrides" instance).'
+        )
+    # Else, "hint_overrides" is a frozen dict.
+    #
+    # If "is_color" is *NOT* a tri-state boolean, raise an exception.
+    elif not isinstance(conf_kwargs['is_color'], NoneTypeOr[bool]):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "is_color" '
+            f'value {repr(conf_kwargs["is_color"])} not tri-state boolean '
+            f'(i.e., "True", "False", or "None").'
+        )
+    # Else, "is_color" is a tri-state boolean.
+    #
+    # If "is_debug" is *NOT* a boolean, raise an exception.
+    elif not isinstance(conf_kwargs['is_debug'], bool):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "is_debug" '
+            f'value {repr(conf_kwargs["is_debug"])} not boolean.'
+        )
+    # Else, "is_debug" is a boolean.
+    #
+    # If "is_pep484_tower" is *NOT* a boolean, raise an exception.
+    elif not isinstance(conf_kwargs['is_pep484_tower'], bool):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "is_pep484_tower" '
+            f'value {repr(conf_kwargs["is_debug"])} not boolean.'
+        )
+    # Else, "is_pep484_tower" is a boolean.
+    #
+    # If "strategy" is *NOT* an enumeration member, raise an exception.
+    elif not isinstance(conf_kwargs['strategy'], BeartypeStrategy):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "strategy" '
+            f'value {repr(conf_kwargs["strategy"])} not '
+            f'"beartype.BeartypeStrategy" enumeration member.'
+        )
+    # Else, "strategy" is an enumeration member.
+    #
+    # If "violation_verbosity" is *NOT* an enumeration member, raise an
+    # exception.
+    elif not isinstance(
+        conf_kwargs['violation_verbosity'], BeartypeViolationVerbosity):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "violation_verbosity" '
+            f'value {repr(conf_kwargs["violation_verbosity"])} not '
+            f'"beartype.BeartypeViolationVerbosity" enumeration member.'
+        )
+    # Else, "violation_verbosity" is an enumeration member.
+    #
+    # If "warning_cls_on_decorator_exception" is neither "None" *NOR* a
+    # warning category, raise an exception.
+    elif not (
+        conf_kwargs['warning_cls_on_decorator_exception'] is None or
+        is_type_subclass(
+            conf_kwargs['warning_cls_on_decorator_exception'], Warning)
+    ):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter '
+            f'"warning_cls_on_decorator_exception" value '
+            f'{repr(conf_kwargs["warning_cls_on_decorator_exception"])} '
+            f'neither "None" nor warning category '
+            f'(i.e., "Warning" subclass).'
+        )
+    # Else, "warning_cls_on_decorator_exception" is either "None" *OR* a
+    # warning category.
+
+    # For the name of each keyword parameter whose value is expected to be an
+    # exception subclass...
+    for arg_name_exception_subclass in _ARG_NAMES_EXCEPTION_SUBCLASS:
+        # If the value of this keyword parameter is *NOT* an exception subclass,
+        # raise an exception.
+        if not is_type_subclass(
+            conf_kwargs[arg_name_exception_subclass], Exception):
+            raise BeartypeConfParamException(
+                f'Beartype configuration parameter '
+                f'"{arg_name_exception_subclass}" value '
+                f'{repr(conf_kwargs[arg_name_exception_subclass])} not '
+                f'exception type.'
+            )
+
+# ....................{ DEFAULTERS                         }....................
+def default_conf_kwargs_before(conf_kwargs: DictStrToAny) -> None:
+    '''
+    Sanitize the passed dictionary of configuration parameters by defaulting all
+    parameters not explicitly passed by the user to sane internal defaults
+    *before* the :func:`.die_if_conf_kwargs_invalid` raiser validates these
+    parameters.
+
+    Parameters
+    ----------
+    conf_kwargs : Dict[str, object]
+        Dictionary mapping from the names to values of *all* possible keyword
+        parameters configuring this configuration.
+    '''
+
+    # ..................{ DEFAULT ~ violation_*type          }..................
+    # Default violation type if passed *OR* "None" if unpassed.
+    violation_type = conf_kwargs['violation_type']
+
+    # If...
+    if (
+        # The caller explicitly passed a default violation type...
+        violation_type is not None and
+        # That is *NOT* an exception subclass...
+        not is_type_subclass(violation_type, Exception)
+    # Raise an exception.
+    ):
+        raise BeartypeConfParamException(
+            f'Beartype configuration parameter "violation_type" value '
+            f'{repr(violation_type)} not exception type.'
+        )
+    # Else, the caller either passed *NO* default violation type or passed a
+    # valid default violation type.
+
+    # If the caller did *NOT* explicitly pass a DOOR violation type, default
+    # this type to either the default violation type if passed *OR* the default
+    # DOOR violation type if unpassed.
+    if conf_kwargs['violation_door_type'] is None:
+        conf_kwargs['violation_door_type'] = (
+            violation_type or BeartypeDoorHintViolation)
+    # Else, the caller explicitly passed a DOOR violation type.
+
+    # If the caller did *NOT* explicitly pass a parameter violation type,
+    # default this type to either the default violation type if passed *OR* the
+    # default DOOR violation type if unpassed.
+    if conf_kwargs['violation_param_type'] is None:
+        conf_kwargs['violation_param_type'] = (
+            violation_type or BeartypeCallHintParamViolation)
+
+    # If the caller did *NOT* explicitly pass a return violation type, default
+    # this type to either the default violation type if passed *OR* the default
+    # DOOR violation type if unpassed.
+    if conf_kwargs['violation_return_type'] is None:
+        conf_kwargs['violation_return_type'] = (
+            violation_type or BeartypeCallHintReturnViolation)
+    # Else, the caller explicitly passed a DOOR violation type.
+
+
+def default_conf_kwargs_after(conf_kwargs: DictStrToAny) -> None:
+    '''
+    Sanitize the passed dictionary of configuration parameters by defaulting all
+    parameters not explicitly passed by the user to sane internal defaults
+    *after* the :func:`.die_if_conf_kwargs_invalid` raiser validates these
+    parameters.
+
+    Parameters
+    ----------
+    conf_kwargs : Dict[str, object]
+        Dictionary mapping from the names to values of *all* possible keyword
+        parameters configuring this configuration.
+    '''
+
+    # ..................{ DEFAULT ~ hint_overrides           }..................
+    # If enabling the PEP 484-compliant implicit numeric tower...
+    if conf_kwargs['is_pep484_tower']:
+        # Hint overrides if passed by the caller *OR* "None" otherwise.
+        hint_overrides = conf_kwargs['hint_overrides']
+
+        # Target hint overrides for the source "float" and "complex" types if
+        # any *OR* "None" otherwise.
+        hint_overrides_float = hint_overrides.get(float)
+        hint_overrides_complex = hint_overrides.get(complex)
+
+        # Whichever of the "float" or "complex" types are already existing
+        # overrides in the passed type hint overrides.
+        hint_override_cls_conflict: Optional[type] = None
+
+        # If these overrides already define conflicting overrides for either the
+        # "float" or "complex" types, record that fact.
+        if (
+            hint_overrides_float and
+            hint_overrides_float != BEARTYPE_HINT_OVERRIDES_PEP484_TOWER[float]
+        ):
+            hint_override_cls_conflict = float
+        elif (
+            hint_overrides_complex and
+            hint_overrides_complex != BEARTYPE_HINT_OVERRIDES_PEP484_TOWER[
+                complex]
+        ):
+            hint_override_cls_conflict = complex
+        # Else, these overrides do *NOT* already define conflicting overrides
+        # for either the "float" or "complex" types.
+
+        # If these overrides already define conflicting overrides for either the
+        # "float" or "complex" types, raise an exception.
+        if hint_override_cls_conflict:
+            raise BeartypeConfParamException(
+                f'Beartype configuration '
+                f'parameter "is_pep484_tower" conflicts with '
+                f'parameter "hint_overrides" key '
+                f'"{hint_override_cls_conflict.__name__}" '
+                f'value '
+                f'{repr(hint_overrides[hint_override_cls_conflict])}.'
+            )
+        # Else, these overrides do *NOT* already define conflicting overrides
+        # for either the "float" or "complex" types.
+
+        # Add hint overrides expanding the passed type hint overrides with
+        # additional overrides mapping:
+        # * The "float" type to the "float | int" type hint.
+        # * The "complex" type to the "complex | float | int" type hint.
+        conf_kwargs['hint_overrides'] = (
+            hint_overrides | BEARTYPE_HINT_OVERRIDES_PEP484_TOWER)  # type: ignore[assignment]
+    # Else, the PEP 484-compliant implicit numeric tower is disabled.
+
+# ....................{ PRIVATE ~ globals                  }....................
+_ARG_NAMES_EXCEPTION_SUBCLASS = (
+    'violation_door_type',
+    'violation_param_type',
+    'violation_return_type',
+)
+'''
+Tuple of the names of all keyword parameters to the
+:meth:`beartype.BeartypeConf.__new__` dunder method whose values are expected to
+be exception subclasses.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/ast/dataast.py
@@ -0,0 +1,46 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **abstract syntax tree (AST) singletons** (i.e., objects pertaining
+to ASTs commonly required throughout this codebase, reducing space and time
+consumption by preallocating widely used AST-centric objects).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    ClassDef,
+    FunctionDef,
+    Load,
+    Store,
+)
+
+# ....................{ NODES                              }....................
+NODE_CONTEXT_LOAD = Load()
+'''
+**Node context load singleton** (i.e., object suitable for passing as the
+``ctx`` keyword parameter accepted by the ``__init__()`` method of various
+abstract syntax tree (AST) node classes).
+'''
+
+
+NODE_CONTEXT_STORE = Store()
+'''
+**Node context store singleton** (i.e., object suitable for passing as the
+``ctx`` keyword parameter accepted by the ``__init__()`` method of various
+abstract syntax tree (AST) node classes).
+'''
+
+# ....................{ TYPES                              }....................
+TYPES_NODE_LEXICAL_SCOPE = frozenset((
+    ClassDef,
+    FunctionDef,
+))
+'''
+Frozen set of all **lexically scoping abstract syntax tree (AST) node types**
+(i.e., types of all AST nodes whose declaration defines a new lexical scope).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/cls/datacls.py
@@ -0,0 +1,168 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **class globals** (i.e., global constants describing various
+well-known types).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Dict,
+    ForwardRef,
+    FrozenSet,
+)
+from beartype._cave._cavefast import (
+    ClassType,
+    EnumMemberType,
+    FunctionType,
+    MethodDecoratorBuiltinTypes,
+    NoneType,
+)
+from collections.abc import (
+    Set as SetABC,
+)
+from pathlib import Path
+
+# ....................{ TYPES ~ abc                        }....................
+TYPES_CONTEXTMANAGER_FAKE = (Path,)
+'''
+Tuple of all **fake context manager types** (i.e., types that erroneously
+masquerade as being context managers by defining fake ``__enter__()`` dunder
+methods, which typically emit non-fatal warnings and reduce to noops).
+
+This set includes:
+
+* The :class:`pathlib.Path` superclass, whose subclasses under Python < 3.13
+  defined fake ``__enter__()`` dunder methods that are now deprecated.
+'''
+
+
+TYPES_SET_OR_TUPLE = (SetABC, tuple)
+'''
+2-tuple containing the superclasses of all frozen sets and tuples.
+
+Note that the :class:`Set` abstract base class (ABC) rather than the concrete
+:class:`set` subclass is intentionally listed here, as the concrete
+:class:`frozenset` subclass subclasses the former but *not* latter: e.g.,
+
+.. code-block:: python
+
+   >>> from collections.abc import Set
+   >>> issubclass(frozenset, Set)
+   True
+   >>> issubclass(frozenset, set)
+   False
+'''
+
+# ....................{ TYPES ~ beartype                   }....................
+# Types of *ALL* objects that may be decorated by @beartype, intentionally
+# listed in descending order of real-world prevalence for negligible efficiency
+# gains when performing isinstance()-based tests against this tuple. These
+# include the types of *ALL*...
+TYPES_BEARTYPEABLE = (
+    # Pure-Python unbound functions and methods.
+    FunctionType,
+    # Pure-Python classes.
+    ClassType,
+    # C-based builtin method descriptors wrapping pure-Python unbound methods,
+    # including class methods, static methods, and property methods.
+    MethodDecoratorBuiltinTypes,
+)
+'''
+Tuple of all **beartypeable types** (i.e., types of all objects that may be
+decorated by the :func:`beartype.beartype` decorator).
+'''
+
+# ....................{ TYPES ~ module                     }....................
+# Defined below by the _init() function.
+TYPE_BUILTIN_NAME_TO_TYPE: Dict[str, type] = None  # type: ignore[assignment]
+'''
+Dictionary mapping from the name of each **builtin type** (i.e., globally
+accessible C-based type implicitly accessible from all scopes and thus
+requiring *no* explicit importation) to that type.
+'''
+
+
+# Defined below by the _init() function.
+TYPES_BUILTIN: FrozenSet[type] = None  # type: ignore[assignment]
+'''
+Frozen set of all **builtin types** (i.e., globally accessible C-based types
+implicitly accessible from all scopes and thus requiring *no* explicit
+importation).
+'''
+
+# ....................{ PEP ~ (484|585)                    }....................
+TYPES_PEP484585_REF = (str, ForwardRef)
+'''
+Tuple union of all :pep:`484`- or :pep:`585`-compliant **forward reference
+types** (i.e., classes of all forward reference objects).
+
+Specifically, this union contains:
+
+* :class:`str`, the class of all :pep:`585`-compliant forward reference objects
+  implicitly preserved by all :pep:`585`-compliant type hint factories when
+  subscripted by a string.
+* :class:`HINT_PEP484_FORWARDREF_TYPE`, the class of all :pep:`484`-compliant
+  forward reference objects implicitly created by all :mod:`typing` type hint
+  factories when subscripted by a string.
+
+While :pep:`585`-compliant type hint factories preserve string-based forward
+references as is, :mod:`typing` type hint factories coerce string-based forward
+references into higher-level objects encapsulating those strings. The latter
+approach is the demonstrably wrong approach, because encapsulating strings only
+harms space and time complexity at runtime with *no* concomitant benefits.
+'''
+
+# ....................{ PEP ~ 586                          }....................
+TYPES_PEP586_ARG = (bool, bytes, int, str, EnumMemberType, NoneType)
+'''
+Tuple of all types of objects permissible as arguments subscripting the
+:pep:`586`-compliant :attr:`typing.Literal` singleton.
+
+These types are explicitly listed by :pep:`586` as follows:
+
+    Literal may be parameterized with literal ints, byte and unicode strings,
+    bools, Enum values and None.
+'''
+
+# ....................{ PRIVATE ~ init                     }....................
+def _init() -> None:
+    '''
+    Initialize this submodule.
+    '''
+
+    # Function-specific imports.
+    from builtins import __dict__ as BUILTIN_NAME_TO_TYPE  # type: ignore[attr-defined]
+
+    # Global variables redefined below.
+    global TYPE_BUILTIN_NAME_TO_TYPE, TYPES_BUILTIN
+
+    # Dictionary mapping from,...
+    TYPE_BUILTIN_NAME_TO_TYPE = {
+        # The name of each builtin type to that type
+        builtin_name: builtin_value
+        # For each attribute defined by the standard "builtins" module...
+        for builtin_name, builtin_value in BUILTIN_NAME_TO_TYPE.items()
+        # If...
+        if (
+            # This attribute is a type *AND*...
+            isinstance(builtin_value, type) and
+            # This is *NOT* a dunder attribute.
+            not (
+                builtin_name.startswith('__') and
+                builtin_name.endswith  ('__')
+            )
+        )
+    }
+
+    # Frozenset of all builtin types, derived from this dictionary.
+    TYPES_BUILTIN = frozenset(TYPE_BUILTIN_NAME_TO_TYPE.values())
+
+
+# Initialize this submodule.
+_init()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/code/datacodeindent.py
@@ -0,0 +1,112 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python expression indentation substrings** (i.e., string
+constants intended to be embedded as syntactically valid indentation in
+dynamically generated Python expressions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ SUBCLASSES                         }....................
+class IndentLevelToCode(dict):
+    '''
+    **Indentation cache** (i.e., dictionary mapping from 1-based indentation
+    levels to the corresponding indentation string constant).
+
+    See Also
+    --------
+    :data:`.INDENT_LEVEL_TO_CODE`
+        Singleton instance of this dictionary subclass.
+    '''
+
+    # ....................{ DUNDERS                        }....................
+    def __missing__(self, indent_level: int) -> str:
+        '''
+        Dunder method explicitly called by the superclass
+        :meth:`dict.__getitem__` method implicitly called on the first ``[``-
+        and ``]``-delimited attempt to access an indentation string constant
+        with the passed indentation level.
+
+        Parameters
+        ----------
+        indent_level : int
+            1-based level of indentation to be created, cached, and returned.
+
+        Returns
+        -------
+        str
+            String constant indented to this level of indentation.
+
+        Raises
+        ------
+        AssertionError
+            If either:
+
+            * ``indent_level`` is *not* an integer.
+            * ``indent_level`` is a **non-positive integer** (i.e., is less than
+              or equal to 0).
+        '''
+        assert isinstance(indent_level, int), (
+            f'{repr(indent_level)} not integer.')
+        assert indent_level > 0, f'{indent_level} <= 0.'
+        # print(f'Generating indentation level {indent_level}...')
+
+        # String constant indented to this level of indentation.
+        #
+        # Note that this could also be done recursively (e.g., as
+        # "self[indent_level - 1]"), but that doing so would be needlessly cute,
+        # overly slow, and dangerously fragile for *NO* good reason.
+        indent_code = '    ' * indent_level
+
+        # Cache this string constant.
+        self[indent_level] = indent_code
+
+        # Return this string constant.
+        return indent_code
+
+# ....................{ MAPPINGS                           }....................
+INDENT_LEVEL_TO_CODE = IndentLevelToCode()
+'''
+**Indentation cache singleton** (i.e., global dictionary efficiently mapping
+from 1-based indentation levels to the corresponding indentation string
+constant).
+
+Caveats
+-------
+**Indentation string constants should always be accessed via this cache rather
+than manually generated.** This cache dynamically creates and efficiently caches
+indentation string constants on the first access of those constants, obviating
+the performance cost of string formatting required to create these constants.
+
+Examples
+--------
+.. code-block:: pycon
+
+   >>> from beartype._data.code.datacodeindent import INDENT_LEVEL_TO_CODE
+   >>> INDENT_LEVEL_TO_CODE[1]
+   '    '
+   >>> INDENT_LEVEL_TO_CODE[2]
+   '        '
+'''
+
+# ....................{ STRINGS                            }....................
+CODE_INDENT_1 = INDENT_LEVEL_TO_CODE[1]
+'''
+Code snippet expanding to a single level of indentation.
+'''
+
+
+CODE_INDENT_2 = INDENT_LEVEL_TO_CODE[2]
+'''
+Code snippet expanding to two levels of indentation.
+'''
+
+
+CODE_INDENT_3 = INDENT_LEVEL_TO_CODE[3]
+'''
+Code snippet expanding to three levels of indentation.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/code/datacodemagic.py
@@ -0,0 +1,27 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **magic Python expression substrings** (i.e., string constants
+intended to be embedded in dynamically generated Python expressions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ CODE ~ operator                    }....................
+LINE_RSTRIP_INDEX_AND = -len(' and')
+'''
+Negative index relative to the end of any arbitrary newline-delimited Python
+code string suffixed by the boolean operator ``" and"`` required to strip that
+suffix from that substring.
+'''
+
+
+LINE_RSTRIP_INDEX_OR = -len(' or')
+'''
+Negative index relative to the end of any arbitrary newline-delimited Python
+code string suffixed by the boolean operator ``" or"`` required to strip that
+suffix from that substring.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/error/dataerrmagic.py
@@ -0,0 +1,81 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **magic error substrings** (i.e., string constants intended to be
+embedded in exception and warning messages or otherwise pertaining to exceptions
+and warnings).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ STRINGS                            }....................
+EXCEPTION_PLACEHOLDER = '$%ROOT_PITH_LABEL/~'
+'''
+Non-human-readable source substring to be globally replaced by a human-readable
+target substring in the messages of memoized exceptions passed to the
+:func:`reraise_exception` function.
+
+This substring prefixes most exception messages raised by memoized callables,
+including code generation factories memoized on passed PEP-compliant type hints
+(e.g., the :mod:`beartype._check` and :mod:`beartype._decor` submodules). The
+:func:`beartype._util.error.utilerrraise.reraise_exception_placeholder` function
+then dynamically replaces this prefix of the message of the passed exception
+with a human-readable synopsis of the current unmemoized exception context,
+including the name of both the currently decorated callable *and* the currently
+iterated parameter or return of that callable for aforementioned code generation
+factories.
+
+Usage
+-----
+This substring is typically hard-coded into non-human-readable exception
+messages raised by low-level callables memoized with the
+:func:`beartype._util.cache.utilcachecall.callable_cached` decorator. Why?
+Memoization prohibits those callables from raising human-readable exception
+messages. Why? Doing so would require those callables to accept fine-grained
+parameters unique to each call to those callables, which those callables would
+then dynamically format into human-readable exception messages raised by those
+callables. The standard example would be a ``exception_prefix`` parameter
+labelling the human-readable category of type hint being inspected by the
+current call (e.g., ``@beartyped muh_func() parameter "muh_param" PEP type hint
+"List[int]"`` for a ``List[int]`` type hint on the `muh_param` parameter of a
+``muh_func()`` function decorated by the :func:`beartype.beartype` decorator).
+Since the whole point of memoization is to cache callable results between calls,
+any callable accepting any fine-grained parameter unique to each call to that
+callable is effectively *not* memoizable in any meaningful sense of the
+adjective "memoizable." Ergo, memoized callables *cannot* raise human-readable
+exception messages unique to each call to those callables.
+
+This substring indirectly solves this issue by inverting the onus of human
+readability. Rather than requiring memoized callables to raise human-readable
+exception messages unique to each call to those callables (which we've shown
+above to be pragmatically infeasible), memoized callables instead raise
+non-human-readable exception messages containing this substring where they
+instead would have contained the human-readable portions of their messages
+unique to each call to those callables. This indirection renders exceptions
+raised by memoized callables generic between calls and thus safely memoizable.
+
+This indirection has the direct consequence, however, of shifting the onus of
+human readability from those lower-level memoized callables onto higher-level
+non-memoized callables -- which are then required to explicitly (in order):
+
+#. Catch exceptions raised by those lower-level memoized callables.
+#. Call the :func:`reraise_exception_placeholder` function with those
+   exceptions and desired human-readable substrings. That function then:
+
+   #. Replaces this magic substring hard-coded into those exception messages
+      with those human-readable substring fragments.
+   #. Reraises the original exceptions in a manner preserving their original
+      tracebacks.
+
+Unsurprisingly, as with most inversion of control schemes, this approach is
+non-intuitive. Surprisingly, however, the resulting code is actually *more*
+elegant than the standard approach of raising human-readable exceptions from
+low-level callables. Why? Because the standard approach percolates
+human-readable substring fragments from the higher-level callables defining
+those fragments to the lower-level callables raising exception messages
+containing those fragments. The indirect approach avoids percolation, thus
+streamlining the implementations of all callables involved. Phew!
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/func/datafunc.py
@@ -0,0 +1,71 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable globals** (i.e., global constants describing various
+well-known functions and methods).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ SETS                               }....................
+METHOD_NAMES_DUNDER_BINARY = frozenset((
+    '__add__',
+    '__and__',
+    '__cmp__',
+    '__divmod__',
+    '__div__',
+    '__eq__',
+    '__floordiv__',
+    '__ge__',
+    '__gt__',
+    '__iadd__',
+    '__iand__',
+    '__idiv__',
+    '__ifloordiv__',
+    '__ilshift__',
+    '__imatmul__',
+    '__imod__',
+    '__imul__',
+    '__ior__',
+    '__ipow__',
+    '__irshift__',
+    '__isub__',
+    '__itruediv__',
+    '__ixor__',
+    '__le__',
+    '__lshift__',
+    '__lt__',
+    '__matmul__',
+    '__mod__',
+    '__mul__',
+    '__ne__',
+    '__or__',
+    '__pow__',
+    '__radd__',
+    '__rand__',
+    '__rdiv__',
+    '__rfloordiv__',
+    '__rlshift__',
+    '__rmatmul__',
+    '__rmod__',
+    '__rmul__',
+    '__ror__',
+    '__rpow__',
+    '__rrshift__',
+    '__rshift__',
+    '__rsub__',
+    '__rtruediv__',
+    '__rxor__',
+    '__sub__',
+    '__truediv__',
+    '__xor__',
+))
+'''
+Frozen set of the unqualified names of all **binary dunder methods** (i.e.,
+methods whose names are both prefixed and suffixed by ``__``, which the active
+Python interpreter implicitly calls to perform binary operations on instances
+whose first operands are instances of the classes declaring those methods).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/func/datafuncarg.py
@@ -0,0 +1,63 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable argument metadata** (i.e., global magic constants
+describing arguments accepted by various functions and methods).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+
+# ....................{ NAMES ~ return                     }....................
+ARG_NAME_RETURN = 'return'
+'''
+Unique name arbitrarily assigned by Python to the key of the ``__annotations__``
+dunder attribute providing the type hint annotating the return of callables.
+
+Note that Python itself prohibits callable parameters from being named
+``"return"`` and thus guarantees this name to be safe and unambiguous.
+'''
+
+
+ARG_NAME_RETURN_REPR = repr(ARG_NAME_RETURN)
+'''
+Object representation of the magic string implying a return value in various
+Python objects (e.g., the ``__annotations__`` dunder dictionary of annotated
+callables).
+'''
+
+# ....................{ VALUES                             }....................
+ARG_VALUE_UNPASSED = 0xBABECAFE
+'''
+**Unpassed argument value** (i.e., arbitrary magic constant serving as the
+default value of an optional parameter accepted by a callable).
+
+This constant is intentionally defined as an arbitrary integer literal
+compatible with the :pep:`586`-compatible :obj:`typing.Literal` type hint
+factory, simplifying annotations for optional parameters defaulting to this
+unpassed argument value: e.g.,
+
+.. code-block:: python
+
+   from typing import Literal
+
+   def muh_func(muh_arg: Literal[True, False, None, ARG_VALUE_UNPASSED] = (
+       ARG_VALUE_UNPASSED)) -> None: ...
+
+Usage of this default value enables a callable to deterministically
+differentiate between two otherwise indistinguishable cases in call-time
+semantics:
+
+* When a caller explicitly passes that callable that optional parameter as a
+  value that is possibly :data:`None`. In this case, that value is effectively
+  guaranteed to *not* be this arbitrary magic constant. Moreover, since that
+  value is possibly :data:`None`, testing for :data:`None` does *not* suffice to
+  decide whether the caller explicitly passed that value or not.
+* When a caller does *not* explicitly pass that callable that optional
+  parameter. In this case, the value of that parameter is guaranteed to be this
+  arbitrary magic constant.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/func/datafunccodeobj.py
@@ -0,0 +1,25 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **code object globals** (i.e., global constants describing code
+objects of callables, classes, and modules).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ STRINGS                            }....................
+FUNC_CODEOBJ_NAME_MODULE = '<module>'
+'''
+Arbitrary string constant unconditionally assigned to the ``co_name`` instance
+variables of the code objects of all pure-Python modules (i.e., the top-most
+lexical scope of each module in the current call stack).
+
+This constant enables callers to reliably differentiate between code objects
+encapsulating:
+
+* Module scopes, whose ``co_name`` variable is this constant.
+* Callable scopes, whose ``co_name`` variable is *not* this constant.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/hint/datahintfactory.py
@@ -0,0 +1,58 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **type hints** (i.e., PEP-compliant type hints annotating callables
+and classes declared throughout this codebase, either for compliance with
+:pep:`561`-compliant static type checkers like :mod:`mypy` or simply for
+documentation purposes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: This approach is *PHENOMENAL.* No. Seriously, We could implement a
+#full-blown "beartype.typing" subpackage (or perhaps even separate "beartyping"
+#package) extending this core concept to *ALL* type hint factories, enabling
+#users to trivially annotate with any type hint factory regardless of the
+#current version of Python or whether "typing_extensions" is installed or not.
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    TYPE_CHECKING,
+)
+from beartype._util.hint.utilhintfactory import TypeHintTypeFactory
+from beartype._util.api.utilapityping import import_typing_attr_or_fallback
+
+# ....................{ FACTORIES                          }....................
+# Portably import the PEP 647-compliant "typing.TypeGuard" type hint factory
+# first introduced by Python >= 3.10, regardless of the current version of
+# Python and regardless of whether this submodule is currently being subject to
+# static type-checking or not. Praise be to MIT ML guru and stunning Hypothesis
+# maintainer @rsokl (Ryan Soklaski) for this brilliant circumvention. \o/
+#
+# Usage of this factory is a high priority. Hinting the return of the
+# is_bearable() tester with a type guard created by this factory effectively
+# coerces that tester in an arbitrarily complete type narrower and thus type
+# parser at static analysis time, substantially reducing complaints from static
+# type-checkers in end user code deferring to that tester.
+#
+# If this submodule is currently being statically type-checked (e.g., mypy),
+# intentionally import from the third-party "typing_extensions" module rather
+# than the standard "typing" module. Why? Because doing so eliminates Python
+# version complaints from static type-checkers (e.g., mypy, pyright). Static
+# type-checkers could care less whether "typing_extensions" is actually
+# installed or not; they only care that "typing_extensions" unconditionally
+# defines this type factory across all Python versions, whereas "typing" only
+# conditionally defines this type factory under Python >= 3.10. *facepalm*
+if TYPE_CHECKING:
+    from typing_extensions import TypeGuard as TypeGuard
+# Else, this submodule is currently being imported at runtime by Python. In this
+# case, dynamically import this factory from whichever of the standard "typing"
+# module *OR* the third-party "typing_extensions" module declares this factory,
+# falling back to the builtin "bool" type if none do.
+else:
+    TypeGuard = import_typing_attr_or_fallback(
+        'TypeGuard', TypeHintTypeFactory(bool))
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/hint/datahinttyping.py
@@ -0,0 +1,558 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **type hints** (i.e., PEP-compliant type hints annotating callables
+and classes declared throughout this codebase, either for compliance with
+:pep:`561`-compliant static type checkers like :mod:`mypy` or simply for
+documentation purposes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+import beartype #  <-- satisfy mypy [note to self: i can't stand you, mypy]
+from ast import (
+    AST,
+    AsyncFunctionDef,
+    ClassDef,
+    FunctionDef,
+)
+from beartype.typing import (
+    AbstractSet,
+    Any,
+    Callable,
+    Dict,
+    ForwardRef,
+    Iterable,
+    List,
+    Literal,
+    Mapping,
+    Optional,
+    Tuple,
+    Type,
+    TypeVar,
+    Union,
+)
+from beartype._cave._cavefast import (
+    MethodBoundInstanceOrClassType,
+    MethodDecoratorClassType,
+    MethodDecoratorPropertyType,
+    MethodDecoratorStaticType,
+)
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.func.datafuncarg import ARG_VALUE_UNPASSED
+from collections.abc import Callable as CallableABC
+from importlib.abc import PathEntryFinder
+from pathlib import Path
+from types import (
+    CodeType,
+    FrameType,
+    GeneratorType,
+)
+
+# ....................{ TYPEVARS                           }....................
+S = TypeVar('S')
+'''
+**Unbound type variable** (i.e., matching *any* arbitrary type) locally bound to
+different types than the :data:`.T` type variable.
+'''
+
+
+T = TypeVar('T')
+'''
+**Unbound type variable** (i.e., matching *any* arbitrary type) locally bound to
+different types than the :data:`.S` type variable.
+'''
+
+
+CallableT = TypeVar('CallableT', bound=CallableABC)
+'''
+**Callable type variable** (i.e., bound to match *only* callables).
+'''
+
+
+NodeT = TypeVar('NodeT', bound=AST)
+'''
+**Node type variable** (i.e., type variable constrained to match *only* abstract
+syntax tree (AST) nodes).
+'''
+
+# ....................{ AST                                }....................
+NodeCallable = Union[FunctionDef, AsyncFunctionDef]
+'''
+PEP-compliant type hint matching a **callable node** (i.e., abstract syntax tree
+(AST) node encapsulating the definition of a pure-Python function or method that
+is either synchronous or asynchronous).
+'''
+
+
+NodeDecoratable = Union[NodeCallable, ClassDef]
+'''
+PEP-compliant type hint matching a **decoratable node** (i.e., abstract syntax
+tree (AST) node encapsulating the definition of a pure-Python object supporting
+decoration by one or more ``"@"``-prefixed decorations, including both
+pure-Python classes *and* callables).
+'''
+
+
+NodeVisitResult = Optional[Union[AST, List[AST]]]
+'''
+PEP-compliant type hint matching a **node visitation result** (i.e., object
+returned by any visitor method of an :class:`ast.NodeVisitor` subclass).
+
+Specifically, this hint matches either:
+
+* A single node, in which case a visitor method has effectively preserved the
+  currently visited node passed to that method in the AST.
+* A list of zero or more nodes, in which case a visitor method has replaced the
+  currently visited node passed to that method with those nodes in the AST.
+* :data:`None`, in which case a visitor method has effectively destroyed the
+  currently visited node passed to that method from the AST.
+'''
+
+
+NodesList = List[AST]
+'''
+PEP-compliant type hint matching an **abstract syntax tree (AST) node list**
+(i.e., list of zero or more AST nodes).
+'''
+
+# ....................{ BOOL                               }....................
+BoolTristate = Literal[True, False, None]
+'''
+PEP-compliant type hint matching a **tri-state boolean** whose value may be
+either:
+
+* :data:`True`.
+* :data:`False`.
+* :data:`None`, implying that the actual value of this boolean is contextually
+  dependent on context-sensitive program state.
+'''
+
+
+BoolTristateUnpassable = Literal[True, False, None, ARG_VALUE_UNPASSED]  # type: ignore[valid-type]
+'''
+PEP-compliant type hint matching an **unpassable tri-state boolean** whose value
+may be either:
+
+* :data:`True`.
+* :data:`False`.
+* :data:`None`, implying that the actual value of this boolean is contextually
+  dependent on context-sensitive program state.
+* :data:`.ARG_VALUE_UNPASSED`, enabling any callable that annotates a tri-state
+  boolean parameter by this type hint to deterministically identify whether the
+  caller explicitly passed that parameter or not. Since the caller may
+  explicitly pass :data:`None` as a valid value, testing that parameter against
+  :data:`None` does *not* suffice to decide this decision problem.
+'''
+
+# ....................{ CALLABLE ~ early                   }....................
+# Callable-specific type hints required by subsequent type hints below.
+
+CallableAny = Callable[..., Any]
+'''
+PEP-compliant type hint matching any callable in a manner explicitly matching
+all possible callable signatures.
+'''
+
+# ....................{ TYPEVAR ~ early                    }....................
+# Type variables required by subsequent type hints below.
+
+BeartypeableT = TypeVar(
+    'BeartypeableT',
+    # The @beartype decorator decorates objects that are either...
+    bound=Union[
+        # An arbitrary class *OR*...
+        type,
+
+        # An arbitrary callable *OR*...
+        CallableAny,
+
+        # A C-based unbound class method descriptor (i.e., a pure-Python unbound
+        # function decorated by the builtin @classmethod decorator) *OR*...
+        MethodDecoratorClassType,
+
+        # A C-based unbound property method descriptor (i.e., a pure-Python
+        # unbound function decorated by the builtin @property decorator) *OR*...
+        MethodDecoratorPropertyType,
+
+        # A C-based unbound static method descriptor (i.e., a pure-Python
+        # unbound function decorated by the builtin @staticmethod decorator).
+        MethodDecoratorStaticType,
+
+        #FIXME: Currently unused, but preserved for posterity.
+        # # A C-based bound method descriptor (i.e., a pure-Python unbound
+        # # function bound to an object instance on Python's instantiation of that
+        # # object) *OR*...
+        # MethodBoundInstanceOrClassType,
+    ],
+)
+'''
+:pep:`484`-compliant **generic beartypeable type variable** (i.e., type hint
+matching any arbitrary object decoratable by the :func:`beartype.beartype`
+decorator, including pure-Python callables and classes, C-based descriptors, and
+even more exotic objects).
+
+This type variable notifies static analysis performed by both static type
+checkers (e.g., :mod:`mypy`) and type-aware IDEs (e.g., VSCode) that the
+:func:`beartype.beartype` decorator preserves:
+
+* Callable signatures by creating and returning callables with the same
+  signatures as passed callables.
+* Class hierarchies by preserving passed classes with respect to inheritance,
+  including metaclasses and method-resolution orders (MRO) of those classes.
+'''
+
+# ....................{ CALLABLE                           }....................
+# Callable-specific type hints *NOT* required by subsequent type hints below.
+
+CallableRaiser = Callable[[object], None]
+'''
+PEP-compliant type hint matching a **raiser callable** (i.e., arbitrary callable
+accepting a single arbitrary object and either raising an exception or emitting
+a warning rather than returning any value).
+'''
+
+
+CallableRaiserOrTester = Callable[[object], Optional[bool]]
+'''
+PEP-compliant type hint matching a **raiser or tester callable** (i.e.,
+arbitrary callable accepting a single arbitrary object and either returning no
+value or returning either :data:`True` if that object satisfies an arbitrary
+constraint *or* :data:`False` otherwise).
+'''
+
+
+CallableTester = Callable[[object], bool]
+'''
+PEP-compliant type hint matching a **tester callable** (i.e., arbitrary callable
+accepting a single arbitrary object and returning either :data:`True` if that
+object satisfies an arbitrary constraint *or* :data:`False` otherwise).
+'''
+
+
+Codeobjable = Union[Callable, CodeType, FrameType, GeneratorType]
+'''
+PEP-compliant type hint matching a **codeobjable** (i.e., pure-Python object
+directly associated with a code object and thus safely passable as the first
+parameter to the :func:`beartype._util.func.utilfunccodeobj.get_func_codeobj`
+getter retrieving the code object associated with this codeobjable).
+
+Specifically, this hint matches:
+
+* Code objects.
+* Pure-Python callables, including generators (but *not* C-based callables,
+  which lack code objects).
+* Pure-Python callable stack frames.
+'''
+
+
+MethodDescriptorNondata = Union[
+    # A C-based unbound class method descriptor (i.e., a pure-Python unbound
+    # function decorated by the builtin @classmethod decorator) *OR*...
+    MethodDecoratorClassType,
+
+    # A C-based unbound static method descriptor (i.e., a pure-Python
+    # unbound function decorated by the builtin @staticmethod decorator).
+    MethodDecoratorStaticType,
+
+    # A C-based bound method descriptor (i.e., a pure-Python unbound
+    # function bound to an object instance on Python's instantiation of that
+    # object) *OR*...
+    MethodBoundInstanceOrClassType,
+]
+'''
+PEP-compliant type hint matching any **builtin method non-data descriptor**
+(i.e., C-based descriptor builtin to Python defining only the ``__get__()``
+dunder method, encapsulating read-only access to some kind of method).
+'''
+
+# ....................{ CALLABLE ~ args                    }....................
+CallableMethodGetitemArg = Union[int, slice]
+'''
+PEP-compliant type hint matching the standard type of the single positional
+argument accepted by the ``__getitem__` dunder method.
+'''
+
+# ....................{ CALLABLE ~ decor                   }....................
+BeartypeConfedDecorator = Callable[[BeartypeableT], BeartypeableT]
+'''
+PEP-compliant type hint matching a **configured beartype decorator** (i.e.,
+closure created and returned from the :func:`beartype.beartype` decorator when
+passed a beartype configuration via the optional ``conf`` parameter rather than
+an arbitrary object to be decorated via the optional ``obj`` parameter).
+'''
+
+
+BeartypeReturn = Union[BeartypeableT, BeartypeConfedDecorator]
+'''
+PEP-compliant type hint matching any possible value returned by any invocation
+of the :func:`beartype.beartype` decorator, including calls to that decorator
+in both configuration and decoration modes.
+'''
+
+# ....................{ DICT                               }....................
+HintSignTrie = Dict[str, Union[HintSign, 'HintSignTrie']]
+'''
+PEP-compliant type hint matching a **sign trie** (i.e.,
+dictionary-of-dictionaries tree data structure enabling efficient mapping from
+the machine-readable representations of type hints created by an arbitrary
+number of type hint factories defined by an external third-party package to
+their identifying sign).
+'''
+
+# ....................{ DICT ~ any                         }....................
+DictStrToAny = Dict[str, Any]
+'''
+PEP-compliant type hint matching a mapping whose keys are *all* strings.
+'''
+
+
+HintAnnotations = DictStrToAny
+'''
+PEP-compliant type hint matching **annotations** (i.e., dictionary mapping from
+the name of each annotated parameter or return of a callable or annotated
+variable of a class to the type hint annotating that parameter, return, or
+variable).
+'''
+
+
+MappingStrToAny = Mapping[str, object]
+'''
+PEP-compliant type hint matching a mapping whose keys are *all* strings.
+'''
+
+# ....................{ CODE                               }....................
+LexicalScope = DictStrToAny
+'''
+PEP-compliant type hint matching a **lexical scope** (i.e., dictionary mapping
+from the relative unqualified name to value of each locally or globally scoped
+attribute accessible to a callable or class).
+'''
+
+
+CodeGenerated = Tuple[str, LexicalScope, Tuple[str, ...]]
+'''
+PEP-compliant type hint matching **generated code** (i.e., a tuple containing
+a Python code snippet dynamically generated on-the-fly by a
+:mod:`beartype`-specific code generator and metadata describing that code).
+
+Specifically, this hint matches a 3-tuple ``(func_wrapper_code,
+func_wrapper_scope, hint_refs_type_basename)``, where:
+
+* ``func_wrapper_code`` is a Python code snippet type-checking an arbitrary
+  object against this hint. For the common case of code generated for a
+  :func:`beartype.beartype`-decorated callable, this snippet type-checks a
+  previously localized parameter or return value against this hint.
+* ``func_wrapper_scope`` is the **local scope** (i.e., dictionary mapping from
+  the name to value of each attribute referenced one or more times in this code)
+  of the body of the function embedding this code.
+* ``hint_refs_type_basename`` is a tuple of the unqualified classnames
+  of :pep:`484`-compliant relative forward references visitable from this hint
+  (e.g., ``('MuhClass', 'YoClass')`` given the hint ``Union['MuhClass',
+  List['YoClass']]``).
+'''
+
+# ....................{ ITERABLE                           }....................
+IterableStrs = Iterable[str]
+'''
+PEP-compliant type hint matching *any* iterable of zero or more strings.
+'''
+
+# ....................{ PATH                               }....................
+CommandWords = IterableStrs
+'''
+PEP-compliant type hint matching **command words** (i.e., an iterable of one or
+more shell words comprising a shell command, suitable for passing as the
+``command_words`` parameter accepted by most callables declared in the
+test-specific :mod:`beartype_test._util.command.pytcmdrun` submodule).
+'''
+
+# ....................{ TUPLE                              }....................
+TupleTypes = Tuple[type, ...]
+'''
+PEP-compliant type hint matching a tuple of zero or more classes.
+
+Equivalently, this hint matches all tuples passable as the second parameters to
+the :func:`isinstance` and :func:`issubclass` builtins.
+'''
+
+
+TypeOrTupleTypes = Union[type, TupleTypes]
+'''
+PEP-compliant type hint matching either a single class *or* a tuple of zero or
+more classes.
+
+Equivalently, this hint matches all objects passable as the second parameters
+to the :func:`isinstance` and :func:`issubclass` builtins.
+'''
+
+
+SetOrTupleTypes = Union[AbstractSet[type], TupleTypes]
+'''
+PEP-compliant type hint matching a set *or* tuple of zero or more classes.
+'''
+
+# ....................{ TUPLE ~ stack                      }....................
+TypeStack = Optional[Tuple[type, ...]]
+'''
+PEP-compliant type hint matching a **type stack** (i.e., either tuple of zero or
+more arbitrary types *or* :data:`None`).
+
+Objects matched by this hint are guaranteed to be either:
+
+* If the **beartypeable** (i.e., object currently being decorated by the
+  :func:`beartype.beartype` decorator) is an attribute (e.g., method, nested
+  class) of a class currently being decorated by that decorator, the **type
+  stack** (i.e., tuple of one or more lexically nested classes that are either
+  currently being decorated *or* have already been decorated by this decorator
+  in descending order of top- to bottom-most lexically nested) such that:
+
+  * The first item of this tuple is expected to be the **root decorated class**
+    (i.e., module-scoped class initially decorated by this decorator whose
+    lexical scope encloses this beartypeable).
+  * The last item of this tuple is expected to be the **current decorated
+    class** (i.e., possibly nested class currently being decorated by this
+    decorator).
+
+* Else, this beartypeable was decorated directly by this decorator. In this
+  case, :data:`None`.
+
+Parameters annotated by this hint typically default to :data:`None`.
+
+Note that :func:`beartype.beartype` requires *both* the root and currently
+decorated class to correctly resolve edge cases under :pep:`563`: e.g.,
+
+.. code-block:: python
+
+   from __future__ import annotations
+   from beartype import beartype
+
+   @beartype
+   class Outer(object):
+       class Inner(object):
+           # At this time, the "Outer" class has been fully defined but is *NOT*
+           # yet accessible as a module-scoped attribute. Ergo, the *ONLY* means
+           # of exposing the "Outer" class to the recursive decoration of this
+           # get_outer() method is to explicitly pass the "Outer" class as the
+           # "cls_root" parameter to all decoration calls.
+           def get_outer(self) -> Outer:
+               return Outer()
+
+Note also that nested classes have *no* implicit access to either their parent
+classes *or* to class variables declared by those parent classes. Nested classes
+*only* have explicit access to module-scoped classes -- exactly like any other
+arbitrary objects: e.g.,
+
+.. code-block:: python
+
+   class Outer(object):
+       my_str = str
+
+       class Inner(object):
+           # This induces a fatal compile-time exception resembling:
+           #     NameError: name 'my_str' is not defined
+           def get_str(self) -> my_str:
+               return 'Oh, Gods.'
+
+Ergo, the *only* owning class of interest to :mod:`beartype` is the root owning
+class containing other nested classes; *all* of those other nested classes are
+semantically and syntactically irrelevant. Nonetheless, this tuple intentionally
+preserves *all* of those other nested classes. Why? Because :pep:`563`
+resolution can only find the parent callable lexically containing that nested
+class hierarchy on the current call stack (if any) by leveraging the total
+number of classes lexically nesting the currently decorated class as input
+metadata, as trivially provided by the length of this tuple.
+'''
+
+# ....................{ MODULE ~ beartype                  }....................
+BeartypeForwardRef = Type[
+    'beartype._check.forward.reference.fwdrefabc.BeartypeForwardRefABC']  # pyright: ignore
+'''
+PEP-compliant type hint matching a **forward reference proxy** (i.e., concrete
+subclass of the abstract
+:class:`beartype._check.forward.reference.fwdrefabc.BeartypeForwardRefABC`
+superclass).
+'''
+
+
+BeartypeForwardRefArgs = Tuple[Optional[str], str, TupleTypes]
+'''
+PEP-compliant type hint matching a **forward reference proxy argument list**
+(i.e., tuple of all parameters passed to each call of the low-level private
+:func:`beartype._check.forward.reference.fwdrefmake._make_forwardref_subtype`
+factory function, in the same order as positionally accepted by that function).
+'''
+
+# ....................{ MODULE ~ importlib                 }....................
+# Type hints specific to the standard "importlib" package.
+
+ImportPathHook = Callable[[str], PathEntryFinder]
+'''
+PEP-compliant type hint matching an **import path hook** (i.e., factory closure
+creating and returning a new :class:`importlib.abc.PathEntryFinder` instance
+creating and leveraging a new :class:`importlib.machinery.FileLoader` instance).
+'''
+
+# ....................{ MODULE ~ pathlib                   }....................
+# Type hints specific to the standard "pathlib" package.
+
+PathnameLike = Union[str, Path]
+'''
+PEP-compliant type hint matching a **pathname-like object** (i.e., either a
+low-level string possibly signifying a pathname *or* a high-level :class:`Path`
+instance definitely encapsulating a pathname).
+'''
+
+
+PathnameLikeTuple = (str, Path)
+'''
+2-tuple of the types of all **pathname-like objects** (i.e., either
+low-level strings possibly signifying pathnames *or* high-level :class:`Path`
+instances definitely encapsulating pathnames).
+'''
+
+# ....................{ PEP 484                            }....................
+# Type hints required to fully comply with PEP 484.
+
+Pep484TowerComplex = Union[complex, float, int]
+'''
+:pep:`484`-compliant type hint matching the **implicit complex tower** (i.e.,
+complex numbers, floating-point numbers, and integers).
+'''
+
+
+Pep484TowerFloat = Union[float, int]
+'''
+:pep:`484`-compliant type hint matching the **implicit floating-point tower**
+(i.e., both floating-point numbers and integers).
+'''
+
+# ....................{ PEP (484|585)                      }....................
+# Type hints required to fully comply with both PEP 484 *AND* 585.
+
+Pep484585ForwardRef = Union[str, ForwardRef]
+'''
+Union of all :pep:`484`- or :pep:`585`-compliant **forward reference types**
+(i.e., classes of all forward reference objects).
+
+See Also
+--------
+:data:`HINT_PEP484585_FORWARDREF_TYPES`
+    Further details.
+'''
+
+# ....................{ TYPE                               }....................
+TypeException = Type[Exception]
+'''
+PEP-compliant type hint matching *any* exception class.
+'''
+
+
+TypeWarning = Type[Warning]
+'''
+PEP-compliant type hint matching *any* warning category.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/hint/pep/datapeprepr.py
@@ -0,0 +1,706 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **bare PEP-compliant type hint representations** (i.e., global
+constants pertaining to machine-readable strings returned by the :func:`repr`
+builtin suffixed by *no* "["- and "]"-delimited subscription representations).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Dict,
+    FrozenSet,
+    Set,
+    # Union,
+)
+from beartype._data.hint.datahinttyping import HintSignTrie
+from beartype._data.hint.pep.sign import datapepsigns
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignAbstractSet,
+    # HintSignAnnotated,
+    # HintSignAny,
+    HintSignAsyncContextManager,
+    HintSignAsyncIterable,
+    HintSignAsyncIterator,
+    HintSignAsyncGenerator,
+    HintSignAwaitable,
+    HintSignBinaryIO,
+    HintSignByteString,
+    HintSignCallable,
+    HintSignChainMap,
+    # HintSignClassVar,
+    HintSignCollection,
+    # HintSignConcatenate,
+    HintSignContainer,
+    HintSignCoroutine,
+    HintSignContextManager,
+    HintSignCounter,
+    HintSignDefaultDict,
+    HintSignDeque,
+    HintSignDict,
+    # HintSignFinal,
+    HintSignForwardRef,
+    HintSignFrozenSet,
+    HintSignGenerator,
+    # HintSignGeneric,
+    # HintSignHashable,
+    HintSignIO,
+    HintSignItemsView,
+    HintSignIterable,
+    HintSignIterator,
+    HintSignKeysView,
+    HintSignList,
+    # HintSignLiteral,
+    HintSignMapping,
+    HintSignMappingView,
+    HintSignMatch,
+    HintSignMutableMapping,
+    HintSignMutableSequence,
+    HintSignMutableSet,
+    # HintSignNamedTuple,
+    HintSignNewType,
+    HintSignNone,
+    HintSignNumpyArray,
+    # HintSignOptional,
+    HintSignOrderedDict,
+    HintSignPanderaAny,
+    HintSignParamSpec,
+    # HintSignParamSpecArgs,
+    HintSignPep557DataclassInitVar,
+    HintSignTypeAlias,
+    HintSignPep695TypeAlias,
+    # HintSignProtocol,
+    HintSignReversible,
+    HintSignSequence,
+    HintSignSet,
+    # HintSignSized,
+    HintSignPattern,
+    HintSignTextIO,
+    HintSignTuple,
+    HintSignType,
+    HintSignTypeVar,
+    # HintSignTypedDict,
+    HintSignUnion,
+    HintSignValuesView,
+)
+from beartype._util.py.utilpyversion import (
+    IS_PYTHON_AT_LEAST_3_9,
+    IS_PYTHON_AT_MOST_3_8,
+)
+
+# ....................{ MAPPINGS ~ repr                    }....................
+# The majority of this dictionary is initialized with automated inspection below
+# in the _init() function. The *ONLY* key-value pairs explicitly defined here
+# are those *NOT* amenable to such inspection.
+HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN: Dict[str, HintSign] = {
+    # ..................{ PEP 484                            }..................
+    # All other PEP 484-compliant representation prefixes are defined by
+    # automated inspection below.
+
+    # PEP 484-compliant "None" singleton, which transparently reduces to
+    # "types.NoneType". While not explicitly defined by the "typing" module,
+    # PEP 484 explicitly supports this singleton:
+    #     When used in a type hint, the expression None is considered equivalent
+    #     to type(None).
+    #
+    # Note that the representation of the type of the "None" singleton (i.e.,
+    # "<class 'NoneType'>") is intentionally omitted here despite the "None"
+    # singleton reducing to that type. Indeed, the *ONLY* reason we detect this
+    # singleton at all is to enable that reduction. Although this singleton
+    # conveys a PEP-compliant semantic, the type of this singleton explicitly
+    # conveys *NO* PEP-compliant semantics. That type is simply a standard
+    # isinstanceable type (like any other). Indeed, attempting to erroneously
+    # associate the type of the "None" singleton with the same sign here would
+    # cause that type to be detected as conveying sign-specific PEP-compliant
+    # semantics rather than *NO* such semantics, which would then substantially
+    # break and complicate dynamic code generation for no benefit whatsoever.
+    'None': HintSignNone,
+
+    #FIXME: Almost certain that these should be detected instead via the
+    #slightly more efficient and elegant "HINT_TYPE_NAME_TO_SIGN" global below.
+    # PEP 484-compliant abstract base classes (ABCs) requiring non-standard and
+    # non-trivial type-checking. Although most types are trivially type-checked
+    # by the isinstance() builtin, these types break the mold in various ways.
+    "<class 'typing.BinaryIO'>": HintSignBinaryIO,
+    "<class 'typing.IO'>": HintSignIO,
+    "<class 'typing.TextIO'>": HintSignTextIO,
+}
+'''
+Dictionary mapping from the **possibly unsubscripted PEP-compliant type hint
+representation prefix** (i.e., unsubscripted prefix of the machine-readable
+strings returned by the :func:`repr` builtin for PEP-compliant type hints
+permissible in both subscripted and unsubscripted forms) of each hint uniquely
+identifiable by that representation to its identifying sign.
+
+Notably, this dictionary maps from the representation prefixes of:
+
+* *All* :pep:`484`-compliant type hints. Whereas *all* :pep:`585`-compliant type
+  hints (e.g., ``list[str]``) are necessarily subscripted and thus omitted from
+  this dictionary, *all* :pep:`484`-compliant type hints support at least
+  unsubscripted form and most :pep:`484`-compliant type hints support
+  subscription as well. Moreover, the unsubscripted forms of most
+  :pep:`484`-compliant type hints convey deep semantics and thus require
+  detection as PEP-compliant (e.g., :obj:`typing.List`, requiring detection and
+  reduction to :class:`list`).
+'''
+
+
+# The majority of this dictionary is defined by explicit key-value pairs here.
+HINT_REPR_PREFIX_ARGS_1_OR_MORE_TO_SIGN: Dict[str, HintSign] = {
+    # ..................{ PEP 585                            }..................
+    # PEP 585-compliant type hints *MUST* by definition be subscripted (e.g.,
+    # "list[str]" rather than "list"). While the stdlib types underlying those
+    # hints are isinstanceable classes and thus also permissible as type hints
+    # when unsubscripted (e.g., simply "list"), unsubscripted classes convey no
+    # deep semantics and thus need *NOT* be detected as PEP-compliant.
+    #
+    # For maintainability, these key-value pairs are intentionally listed in the
+    # same order as the official list in PEP 585 itself.
+    'tuple': HintSignTuple,
+    'list': HintSignList,
+    'dict': HintSignDict,
+    'set': HintSignSet,
+    'frozenset': HintSignFrozenSet,
+    'type': HintSignType,
+    'collections.deque': HintSignDeque,
+    'collections.defaultdict': HintSignDefaultDict,
+    'collections.OrderedDict': HintSignOrderedDict,
+    'collections.Counter': HintSignCounter,
+    'collections.ChainMap': HintSignChainMap,
+    'collections.abc.Awaitable': HintSignAwaitable,
+    'collections.abc.Coroutine': HintSignCoroutine,
+    'collections.abc.AsyncIterable': HintSignAsyncIterable,
+    'collections.abc.AsyncIterator': HintSignAsyncIterator,
+    'collections.abc.AsyncGenerator': HintSignAsyncGenerator,
+    'collections.abc.Iterable': HintSignIterable,
+    'collections.abc.Iterator': HintSignIterator,
+    'collections.abc.Generator': HintSignGenerator,
+    'collections.abc.Reversible': HintSignReversible,
+    'collections.abc.Container': HintSignContainer,
+    'collections.abc.Collection': HintSignCollection,
+    'collections.abc.Callable': HintSignCallable,
+    'collections.abc.Set': HintSignAbstractSet,
+    'collections.abc.MutableSet': HintSignMutableSet,
+    'collections.abc.Mapping': HintSignMapping,
+    'collections.abc.MutableMapping': HintSignMutableMapping,
+    'collections.abc.Sequence': HintSignSequence,
+    'collections.abc.MutableSequence': HintSignMutableSequence,
+    'collections.abc.ByteString': HintSignByteString,
+    'collections.abc.MappingView': HintSignMappingView,
+    'collections.abc.KeysView': HintSignKeysView,
+    'collections.abc.ItemsView': HintSignItemsView,
+    'collections.abc.ValuesView': HintSignValuesView,
+    'contextlib.AbstractContextManager': HintSignContextManager,
+    'contextlib.AbstractAsyncContextManager': HintSignAsyncContextManager,
+    're.Pattern': HintSignPattern,
+    're.Match': HintSignMatch,
+
+    # ..................{ NON-PEP ~ lib : numpy              }..................
+    # The PEP-noncompliant "numpy.typing.NDArray" type hint is permissible in
+    # both subscripted and unsubscripted forms. In the latter case, this hint
+    # is implicitly subscripted by generic type variables. In both cases, this
+    # hint presents a uniformly reliable representation -- dramatically
+    # simplifying detection via a common prefix of that representation here:
+    #     >>> import numpy as np
+    #     >>> import numpy.typing as npt
+    #     >>> repr(npt.NDArray)
+    #     numpy.ndarray[typing.Any, numpy.dtype[+ScalarType]]
+    #     >>> repr(npt.NDArray[np.float64])
+    #     repr: numpy.ndarray[typing.Any, numpy.dtype[numpy.float64]]
+    #
+    # Ergo, unsubscripted "numpy.typing.NDArray" type hints present themselves
+    # as implicitly subscripted through their representation.
+    'numpy.ndarray': HintSignNumpyArray,
+}
+'''
+Dictionary mapping from the **necessarily subscripted PEP-compliant type hint
+representation prefixes** (i.e., unsubscripted prefix of the machine-readable
+strings returned by the :func:`repr` builtin for subscripted PEP-compliant type
+hints) of all hints uniquely identifiable by those representations to
+their identifying signs.
+
+Notably, this dictionary maps from the representation prefixes of:
+
+* All :pep:`585`-compliant type hints. Whereas all :pep:`484`-compliant type
+  hints support both subscripted and unsubscripted forms (e.g.,
+  ``typing.List``, ``typing.List[str]``), all :pep:`585`-compliant type hints
+  necessarily require subscription. While the stdlib types underlying
+  :pep:`585`-compliant type hints are isinstanceable classes and thus also
+  permissible as type hints when unsubscripted (e.g., simply :class:`list`),
+  isinstanceable classes convey *no* deep semantics and thus need *not* be
+  detected as PEP-compliant.
+'''
+
+# ....................{ MAPPINGS ~ repr : trie             }....................
+# The majority of this trie is defined by explicit key-value pairs here.
+HINT_REPR_PREFIX_TRIE_ARGS_0_OR_MORE_TO_SIGN: HintSignTrie = {
+    # ..................{ NON-PEP ~ lib : pandera            }..................
+    # All PEP-noncompliant "pandera.typing" type hints are permissible in
+    # both subscripted and unsubscripted forms.
+    'pandera': {
+        'typing': HintSignPanderaAny,
+    }
+}
+'''
+**Sign trie** (i.e., dictionary-of-dictionaries tree data structure enabling
+efficient mapping from the machine-readable representations of type hints
+created by an arbitrary number of type hint factories defined by an external
+third-party package to their identifying sign) from the **possibly unsubscripted
+PEP-compliant type hint representation prefix** (i.e., unsubscripted prefix of
+the machine-readable strings returned by the :func:`repr` builtin for
+PEP-compliant type hints permissible in both subscripted and unsubscripted
+forms) of each hint uniquely identifiable by that representation to its
+identifying sign.
+'''
+
+# ....................{ MAPPINGS ~ type                    }....................
+# The majority of this dictionary is initialized with automated inspection
+# below in the _init() function. The *ONLY* key-value pairs explicitly defined
+# here are those *NOT* amenable to such inspection.
+HINT_TYPE_NAME_TO_SIGN: Dict[str, HintSign] = {
+    # ..................{ PEP 484                            }..................
+    # PEP 484-compliant forward reference type hints may be annotated either:
+    # * Explicitly as "typing.ForwardRef" instances, which automated inspection
+    #   performed by the _init() function below already handles.
+    # * Implicitly as strings, which this key-value pair here detects. Note
+    #   this unconditionally matches *ALL* strings, including both:
+    #   * Invalid Python identifiers (e.g., "0d@yw@r3z").
+    #   * Absolute forward references (i.e., fully-qualified classnames)
+    #     technically non-compliant with PEP 484 but seemingly compliant with
+    #     PEP 585.
+    #   Since the distinction between PEP-compliant and -noncompliant forward
+    #   references is murky at best and since unconditionally matching *ALL*
+    #   string as PEP-compliant substantially simplifies logic throughout the
+    #   codebase, we (currently) opt to do so.
+    'builtins.str': HintSignForwardRef,
+
+    # Python >= 3.10 implements PEP 484-compliant "typing.NewType" type hints as
+    # instances of that class. Regardless of the current Python version,
+    # "typing_extensions.NewType" type hints remain implemented in manner of
+    # Python < 3.10 -- which is to say, as closures of that function. Ergo, we
+    # intentionally omit "typing_extensions.NewType" here. See also:
+    #     https://github.com/python/typing/blob/master/typing_extensions/src_py3/typing_extensions.py
+    'typing.NewType': HintSignNewType,
+
+    # ..................{ PEP 557                            }..................
+    # Python >= 3.8 implements PEP 557-compliant "dataclasses.InitVar" type
+    # hints as instances of that class.
+    'dataclasses.InitVar': HintSignPep557DataclassInitVar,
+
+    # ..................{ PEP 604                            }..................
+    # PEP 604-compliant |-style unions (e.g., "int | float") are internally
+    # implemented as instances of the low-level C-based "types.UnionType" type.
+    # Thankfully, these unions are semantically interchangeable with comparable
+    # PEP 484-compliant unions (e.g., "typing.Union[int, float]"); both kinds
+    # expose equivalent dunder attributes (e.g., "__args__", "__parameters__"),
+    # enabling subsequent code generation to conflate the two without issue.
+    'types.UnionType': HintSignUnion,
+
+    # ..................{ PEP 612                            }..................
+    # Python >= 3.10 implements PEP 612-compliant "typing.ParamSpec" type hints
+    # as instances of that class.
+    'typing.ParamSpec': HintSignParamSpec,
+
+    # ..................{ PEP 695                            }..................
+    # Python >= 3.12 implements PEP 695-compliant "type" aliases as instances of
+    # the low-level C-based "typing.TypeAliasType" type.
+    'typing.TypeAliasType': HintSignPep695TypeAlias,
+}
+'''
+Dictionary mapping from the fully-qualified classnames of all PEP-compliant
+type hints uniquely identifiable by those classnames to their identifying
+signs.
+'''
+
+# ....................{ SETS ~ deprecated                  }....................
+# Initialized with automated inspection below in the _init() function.
+HINTS_PEP484_REPR_PREFIX_DEPRECATED: FrozenSet[str] = set()  # type: ignore[assignment]
+'''
+Frozen set of all **bare deprecated** :pep:`484`-compliant **type hint
+representations** (i.e., machine-readable strings returned by the :func:`repr`
+builtin suffixed by *no* "["- and "]"-delimited subscription representations
+for all :pep:`484`-compliant type hints obsoleted by :pep:`585`-compliant
+subscriptable classes).
+'''
+
+# ....................{ SETS ~ ignorable                   }....................
+# The majority of this dictionary is initialized with automated inspection
+# below in the _init() function. The *ONLY* key-value pairs explicitly defined
+# here are those *NOT* amenable to such inspection.
+HINTS_REPR_IGNORABLE_SHALLOW: FrozenSet[str] = {  # type: ignore[assignment]
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize changes to this set with the corresponding
+    # testing-specific set
+    # "beartype_test.a00_unit.data.hint.pep.data_pep.HINTS_PEP_IGNORABLE_SHALLOW".
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # ..................{ NON-PEP                            }..................
+    # The PEP-noncompliant builtin "object" type is the transitive superclass
+    # of all classes. Ergo, parameters and return values annotated as "object"
+    # unconditionally match *ALL* objects under isinstance()-based type
+    # covariance and thus semantically reduce to unannotated parameters and
+    # return values. This is literally the "beartype.cave.AnyType" type.
+    "<class 'object'>",
+
+    # ..................{ PEP 604                            }..................
+    # The low-level C-based "types.UnionType" class underlying PEP 604-compliant
+    # |-style unions (e.g., "int | float") imposes no constraints and is thus
+    # also semantically synonymous with the ignorable PEP-noncompliant
+    # "beartype.cave.AnyType" and hence "object" types. Nonetheless, this class
+    # *CANNOT* be instantiated from Python code:
+    #     >>> import types
+    #     >>> types.UnionType(int, bool)
+    #     TypeError: cannot create 'types.UnionType' instances
+    #
+    # Likewise, this class *CANNOT* be subscripted. It follows that there exists
+    # no meaningful equivalent of shallow type-checking for these unions. While
+    # trivially feasible, listing "<class 'types.UnionType'>" here would only
+    # prevent callers from meaningfully type-checking these unions passed as
+    # valid parameters or returned as valid returns: e.g.,
+    #     @beartype
+    #     def muh_union_printer(muh_union: UnionType) -> None: print(muh_union)
+    #
+    # Ergo, we intentionally omit this type from consideration here.
+
+    # ....................{ NON-PEP                        }....................
+    # Machine-readable representations of shallowly ignorable type hints
+    # published by PEP-noncompliant third-party type hints, including...
+}
+'''
+Frozen set of all **shallowly ignorable PEP-compliant type hint
+representations** (i.e., machine-readable strings returned by the :func:`repr`
+builtin for all PEP-compliant type hints that are unconditionally ignorable by
+the :func:`beartype.beartype` decorator in *all* possible contexts)
+
+Caveats
+----------
+**The high-level**
+:func:`beartype._util.hint.pep.utilhinttest.is_hint_ignorable` **tester
+function should always be called in lieu of testing type hints against this
+low-level set.** This set is merely shallow and thus excludes **deeply
+ignorable type hints** (e.g., :data:`Union[Any, bool, str]`). Since there exist
+a countably infinite number of deeply ignorable type hints, this set is
+necessarily constrained to the substantially smaller finite subset of only
+shallowly ignorable type hints.
+'''
+
+# ....................{ INITIALIZERS                       }....................
+def _init() -> None:
+    '''
+    Initialize this submodule.
+    '''
+
+    # ..................{ EXTERNALS                          }..................
+    # Defer initialization-specific imports.
+    from beartype._data.module.datamodtyping import TYPING_MODULE_NAMES
+
+    # Permit redefinition of these globals below.
+    global \
+        HINTS_PEP484_REPR_PREFIX_DEPRECATED, \
+        HINTS_REPR_IGNORABLE_SHALLOW
+
+    # ..................{ HINTS                              }..................
+    # Length of the ignorable substring prefixing the name of each sign.
+    _HINT_SIGN_PREFIX_LEN = len('HintSign')
+
+    # ..................{ HINTS ~ repr                       }..................
+    # Dictionary mapping from the unqualified names of typing attributes whose
+    # names are erroneously desynchronized from their bare machine-readable
+    # representations to the actual representations of those attributes.
+    #
+    # The unqualified names and representations of *MOST* typing attributes are
+    # rigorously synchronized. However, those two strings are desynchronized
+    # for a proper subset of Python versions and typing attributes:
+    #     $ ipython3.8
+    #     >>> import typing
+    #     >>> repr(typing.List[str])
+    #     typing.List[str]   # <-- this is good
+    #     >>> repr(typing.ContextManager[str])
+    #     typing.AbstractContextManager[str]   # <-- this is pants
+    #
+    # This dictionary enables subsequent logic to transparently resynchronize
+    # the unqualified names and representations of pants typing attributes.
+    _HINT_TYPING_ATTR_NAME_TO_REPR_PREFIX: Dict[str, str] = {}
+
+    # If the active Python interpreter targets Python >= 3.7.x <= 3.8.x (i.e.,
+    # either Python 3.7 or 3.8), resynchronize the unqualified names and
+    # representations of desynchronized typing attributes. Bizarrely:
+    # * Python 3.7.0 first desynchronized these attributes, despite the
+    #   otherwise insane Python 3.6.x series having actually gotten this right.
+    # * Python 3.8.x preserved this bad behaviour.
+    # * Python 3.9.0 rectified this issue finally. *sigh*
+    if IS_PYTHON_AT_MOST_3_8:
+        _HINT_TYPING_ATTR_NAME_TO_REPR_PREFIX.update({
+            'AsyncContextManager': 'AbstractAsyncContextManager',
+            'ContextManager': 'AbstractContextManager',
+        })
+
+    # ..................{ HINTS ~ types                      }..................
+    # Dictionary mapping from the unqualified names of all classes defined by
+    # typing modules used to instantiate PEP-compliant type hints to their
+    # corresponding signs.
+    _HINT_TYPE_BASENAMES_TO_SIGN = {
+        # ................{ PEP 484                            }................
+        # All PEP 484-compliant forward references are necessarily instances of
+        # the same class.
+        'ForwardRef' : HintSignForwardRef,
+
+        # All PEP 484-compliant type variables are necessarily instances of the
+        # same class.
+        'TypeVar': HintSignTypeVar,
+
+        #FIXME: "Generic" is ignorable when unsubscripted. Excise this up!
+        # The unsubscripted PEP 484-compliant "Generic" superclass is
+        # explicitly equivalent under PEP 484 to the "Generic[Any]"
+        # subscription and thus slightly conveys meaningful semantics.
+        # 'Generic': HintSignGeneric,
+    }
+
+    # ..................{ HINTS ~ deprecated                 }..................
+    # Set of the unqualified names of all deprecated PEP 484-compliant typing
+    # attributes.
+    _HINT_PEP484_TYPING_ATTR_NAMES_DEPRECATED: Set[str] = set()
+
+    # If the active Python interpreter targets Python >= 3.9 and thus
+    # supports PEP 585, add the names of all deprecated PEP 484-compliant
+    # typing attributes (e.g., "typing.List") that have since been obsoleted by
+    # equivalent bare PEP 585-compliant builtin classes (e.g., "list").
+    if IS_PYTHON_AT_LEAST_3_9:
+        _HINT_PEP484_TYPING_ATTR_NAMES_DEPRECATED.update((
+            # ..............{ PEP 484                            }..............
+            'AbstractSet',
+            'AsyncContextManager',
+            'AsyncGenerator',
+            'AsyncIterable',
+            'AsyncIterator',
+            'Awaitable',
+            'ByteString',
+            'Callable',
+            'ChainMap',
+            'Collection',
+            'Container',
+            'ContextManager',
+            'Coroutine',
+            'Counter',
+            'DefaultDict',
+            'Deque',
+            'Dict',
+            'FrozenSet',
+            'Generator',
+            'Hashable',
+            'ItemsView',
+            'Iterable',
+            'Iterator',
+            'KeysView',
+            'List',
+            'MappingView',
+            'Mapping',
+            'Match',
+            'MutableMapping',
+            'MutableSequence',
+            'MutableSet',
+            'OrderedDict',
+            'Pattern',
+            'Reversible',
+            'Sequence',
+            'Set',
+            'Sized',
+            'Tuple',
+            'Type',
+            'ValuesView',
+        ))
+
+    # ..................{ HINTS ~ ignorable                  }..................
+    # Set of the unqualified names of all shallowly ignorable typing non-class
+    # attributes. Since classes and non-class attributes have incommensurate
+    # machine-readable representations, these two types of attributes *MUST* be
+    # isolated to distinct sets. See "_HINT_TYPING_TYPE_NAMES_IGNORABLE" below.
+    _HINT_TYPING_ATTR_NAMES_IGNORABLE = {
+        # ................{ PEP 484                            }................
+        # The "Any" singleton is semantically synonymous with the ignorable
+        # PEP-noncompliant "beartype.cave.AnyType" and hence "object" types.
+        'Any',
+
+        # The unsubscripted "Optional" singleton semantically expands to the
+        # implicit "Optional[Any]" singleton by the same argument. Since PEP
+        # 484 also stipulates that all "Optional[t]" singletons semantically
+        # expand to "Union[t, type(None)]" singletons for arbitrary arguments
+        # "t", "Optional[Any]" semantically expands to merely "Union[Any,
+        # type(None)]". Since all unions subscripted by "Any" semantically
+        # reduce to merely "Any", the "Optional" singleton also reduces to
+        # merely "Any".
+        #
+        # This intentionally excludes "Optional[type(None)]", which the
+        # "typing" module physically reduces to merely "type(None)". *shrug*
+        'Optional',
+
+        # The unsubscripted "Union" singleton semantically expands to the
+        # implicit "Union[Any]" singleton by the same argument. Since PEP 484
+        # stipulates that a union of one type semantically reduces to only that
+        # type, "Union[Any]" semantically reduces to merely "Any". Despite
+        # their semantic equivalency, however, these objects remain
+        # syntactically distinct with respect to object identification: e.g.,
+        #     >>> Union is not Union[Any]
+        #     True
+        #     >>> Union is not Any
+        #     True
+        #
+        # This intentionally excludes:
+        #
+        # * The "Union[Any]" and "Union[object]" singletons, since the "typing"
+        #   module physically reduces:
+        #   * "Union[Any]" to merely "Any" (i.e., "Union[Any] is Any"), which
+        #     this frozen set already contains.
+        #   * "Union[object]" to merely "object" (i.e., "Union[object] is
+        #     object"), which this frozen set also already contains.
+        # * "Union" singleton subscripted by one or more ignorable type hints
+        #   contained in this set (e.g., "Union[Any, bool, str]"). Since there
+        #   exist a countably infinite number of these subscriptions, these
+        #   subscriptions *CANNOT* be explicitly listed in this set. Instead,
+        #   these subscriptions are dynamically detected by the high-level
+        #   beartype._util.hint.pep.utilhinttest.is_hint_ignorable() tester
+        #   function and thus referred to as deeply ignorable type hints.
+        'Union',
+    }
+
+    # Set of the unqualified names of all shallowly ignorable typing classes.
+    _HINT_TYPING_TYPE_NAMES_IGNORABLE = {
+        # ................{ PEP 484                            }................
+        # The "Generic" superclass imposes no constraints and is thus also
+        # semantically synonymous with the "object" superclass. Since PEP
+        # 484 stipulates that *ANY* unsubscripted subscriptable PEP-compliant
+        # singleton including "typing.Generic" semantically expands to that
+        # singleton subscripted by an implicit "Any" argument, "Generic"
+        # semantically expands to the implicit "Generic[Any]" singleton.
+        'Generic',
+
+        # ................{ PEP 544                            }................
+        # Note that ignoring the "typing.Protocol" superclass is vital here. For
+        # unknown and presumably uninteresting reasons, *ALL* possible objects
+        # satisfy this superclass. Ergo, this superclass is synonymous with the
+        # "object" root superclass: e.g.,
+        #     >>> import typing as t
+        #     >>> isinstance(object(), t.Protocol)
+        #     True
+        #     >>> isinstance('wtfbro', t.Protocol)
+        #     True
+        #     >>> isinstance(0x696969, t.Protocol)
+        #     True
+        'Protocol',
+    }
+
+    # ..................{ CONSTRUCTION                       }..................
+    # For the fully-qualified name of each quasi-standard typing module...
+    for typing_module_name in TYPING_MODULE_NAMES:
+        # For the name of each sign...
+        #
+        # Note that:
+        # * The inspect.getmembers() getter could also be called here. However,
+        #   that getter internally defers to dir() and getattr() with a
+        #   considerable increase in runtime complexity for no tangible benefit.
+        # * The "__dict__" dunder attribute should *NEVER* be accessed directly
+        #   on a module, as that attribute commonly contains artificial entries
+        #   *NOT* explicitly declared by that module (e.g., "__", "e__",
+        #   "ns__").
+        for hint_sign_name in dir(datapepsigns):
+            # If this name is *NOT* prefixed by the substring prefixing the
+            # names of all signs, this name is *NOT* the name of a sign. In this
+            # case, silently continue to the next sign.
+            if not hint_sign_name.startswith('HintSign'):
+                continue
+            # Else, this name is that of a sign.
+
+            # Sign with this name.
+            hint_sign = getattr(datapepsigns, hint_sign_name)
+
+            # Unqualified name of the typing attribute identified by this sign.
+            typing_attr_name = hint_sign_name[_HINT_SIGN_PREFIX_LEN:]
+            assert typing_attr_name, f'{hint_sign_name} not sign name.'
+
+            # Substring prefixing the machine-readable representation of this
+            # attribute, conditionally defined as either:
+            # * If this name is erroneously desynchronized from this
+            #   representation under the active Python interpreter, the actual
+            #   representation of this attribute under this interpreter (e.g.,
+            #   "AbstractContextManager" for the "typing.ContextManager" hint).
+            # * Else, this name is correctly synchronized with this
+            #   representation under the active Python interpreter. In this
+            #   case, fallback to this name as is (e.g., "List" for the
+            #   "typing.List" hint).
+            hint_repr_prefix = _HINT_TYPING_ATTR_NAME_TO_REPR_PREFIX.get(
+                typing_attr_name, typing_attr_name)
+
+            #FIXME: It'd be great to eventually generalize this to support
+            #aliases from one unwanted sign to another wanted sign. Perhaps
+            #something resembling:
+            ## In global scope above:
+            #_HINT_SIGN_REPLACE_SOURCE_BY_TARGET = {
+            #    HintSignProtocol: HintSignGeneric,
+            #}
+            #
+            #    # In this iteration here:
+            #    ...
+            #    hint_sign_replaced = _HINT_SIGN_REPLACE_SOURCE_BY_TARGET.get(
+            #        hint_sign, hint_sign)
+            #
+            #    # Map from that attribute in this module to this sign.
+            #    # print(f'[datapeprepr] Mapping repr("{typing_module_name}.{hint_repr_prefix}[...]") -> {repr(hint_sign)}...')
+            #    HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN[
+            #        f'{typing_module_name}.{hint_repr_prefix}'] = hint_sign_replaced
+
+            # Map from that attribute in this module to this sign.
+            # print(f'[datapeprepr] Mapping repr("{typing_module_name}.{hint_repr_prefix}[...]") -> {repr(hint_sign)}...')
+            HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN[
+                f'{typing_module_name}.{hint_repr_prefix}'] = hint_sign
+
+        # For the unqualified classname identifying each sign to that sign...
+        for typing_attr_name, hint_sign in _HINT_TYPE_BASENAMES_TO_SIGN.items():
+            # Map from that classname in this module to this sign.
+            # print(f'[datapeprepr] Mapping type "{typing_module_name}.{typing_attr_name}" -> {repr(hint_sign)}...')
+            HINT_TYPE_NAME_TO_SIGN[
+                f'{typing_module_name}.{typing_attr_name}'] = hint_sign
+
+        # For each shallowly ignorable typing non-class attribute name...
+        for typing_attr_name in _HINT_TYPING_ATTR_NAMES_IGNORABLE:
+            # Add that attribute relative to this module to this set.
+            # print(f'[datapeprepr] Registering ignorable non-class "{typing_module_name}.{typing_attr_name}"...')
+            HINTS_REPR_IGNORABLE_SHALLOW.add(  # type: ignore[attr-defined]
+                f'{typing_module_name}.{typing_attr_name}')
+
+        # For each shallowly ignorable typing classname...
+        for typing_type_name in _HINT_TYPING_TYPE_NAMES_IGNORABLE:
+            # Add that classname relative to this module to this set.
+            # print(f'[datapeprepr] Registering ignorable class "{typing_module_name}.{typing_attr_name}"...')
+            HINTS_REPR_IGNORABLE_SHALLOW.add(  # type: ignore[attr-defined]
+                f"<class '{typing_module_name}.{typing_type_name}'>")
+
+        # For each deprecated PEP 484-compliant typing attribute name...
+        for typing_attr_name in _HINT_PEP484_TYPING_ATTR_NAMES_DEPRECATED:
+            # Add that attribute relative to this module to this set.
+            # print(f'[datapeprepr] Registering deprecated "{typing_module_name}.{typing_attr_name}"...')
+            HINTS_PEP484_REPR_PREFIX_DEPRECATED.add(  # type: ignore[attr-defined]
+                f'{typing_module_name}.{typing_attr_name}')
+
+    # ..................{ SYNTHESIS                          }..................
+    # Freeze all relevant global sets for safety.
+    HINTS_PEP484_REPR_PREFIX_DEPRECATED = frozenset(
+        HINTS_PEP484_REPR_PREFIX_DEPRECATED)
+    HINTS_REPR_IGNORABLE_SHALLOW = frozenset(HINTS_REPR_IGNORABLE_SHALLOW)
+
+    # ..................{ DEBUGGING                          }..................
+    # Uncomment as needed to display the contents of these objects.
+
+    # from pprint import pformat
+    # print(f'HINTS_PEP484_REPR_PREFIX_DEPRECATED: {pformat(HINTS_PEP484_REPR_PREFIX_DEPRECATED)}')
+    # print(f'HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN: {pformat(HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN)}')
+    # print(f'HINT_REPR_PREFIX_ARGS_1_OR_MORE_TO_SIGN: {pformat(HINT_REPR_PREFIX_ARGS_1_OR_MORE_TO_SIGN)}')
+    # print(f'HINT_TYPE_NAME_TO_SIGN: {pformat(HINT_TYPE_NAME_TO_SIGN)}')
+
+# Initialize this submodule.
+_init()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/hint/pep/sign/datapepsigncls.py
@@ -0,0 +1,79 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **sign classes** (i.e., classes whose instances uniquely
+identifying PEP-compliant type hints in a safe, non-deprecated manner
+regardless of the Python version targeted by the active Python interpreter).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Union
+
+# ....................{ CLASSES                            }....................
+class HintSign(object):
+    '''
+    **Sign** (i.e., object uniquely identifying PEP-compliant type hints in a
+    safe, non-deprecated manner regardless of the Python version targeted by
+    the active Python interpreter).
+
+    Attributes
+    ----------
+    name : str
+        Uniqualified name of the :mod:`typing` attribute uniquely identified by
+        this sign (e.g., ``Literal`` for :pep:`586`-compliant type hints).
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently
+    # called @beartype decorations. Slotting has been shown to reduce read and
+    # write costs by approximately ~10%, which is non-trivial.
+    __slots__ = ('name',)
+
+    # ..................{ DUNDERS                            }..................
+    def __init__(self, name: str) -> None:
+        '''
+        Initialize this sign.
+
+        Parameters
+        ----------
+        name : str
+            Uniqualified name of the :mod:`typing` attribute uniquely
+            identified by this sign (e.g., ``Literal`` for :pep:`586`-compliant
+            type hints).
+        '''
+        assert isinstance(name, str), f'{repr(name)} not string.'
+
+        # Classify all passed parameters.
+        self.name = name
+
+
+    def __repr__(self) -> str:
+        '''
+        Machine-readable representation of this sign.
+        '''
+
+        return f"HintSign('{self.name}')"
+
+
+    def __str__(self) -> str:
+        '''
+        Human-readable stringification of this sign.
+        '''
+
+        return f'"HintSign{self.name}"'
+
+# ....................{ HINTS                              }....................
+HintSignOrType = Union[HintSign, type]
+'''
+PEP-compliant type hint matching either a **sign** (i.e., object uniquely
+identifying PEP-compliant type hints in a safe, non-deprecated manner
+regardless of the Python version targeted by the active Python interpreter) or
+**isinstanceable class** (i.e., class safely passable as the second argument to
+the :func:`isinstance` builtin).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/hint/pep/sign/datapepsigns.py
@@ -0,0 +1,269 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python version-agnostic signs** (i.e., instances of the
+:class:`beartype._data.hint.pep.sign.datapepsigncls.HintSign` class
+uniquely identifying PEP-compliant type hints in a safe, non-deprecated manner
+regardless of the Python version targeted by the active Python interpreter).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: Attributes imported here at module scope *MUST* be explicitly
+# deleted from this module's namespace below.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign as _HintSign
+
+# ....................{ SIGNS ~ explicit                   }....................
+# Signs with explicit analogues in the stdlib "typing" module.
+#
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: Signs defined by this module are synchronized with the "__all__"
+# list global of the "typing" module bundled with the most recent CPython
+# release. For that reason, these signs are:
+# * Intentionally declared in the exact same order prefixed by the exact same
+#   inline comments as for that list global.
+# * Intentionally *NOT* commented with docstrings, both because:
+#   * These docstrings would all trivially reduce to a single-line sentence
+#     fragment resembling "Alias of typing attribute."
+#   * These docstrings would inhibit diffing and synchronization by inspection.
+# * Intentionally *NOT* conditionally isolated to the specific range of Python
+#   versions whose "typing" module lists these attributes. For example, the
+#   "HintSignAsyncContextManager" sign identifying the
+#   "typing.AsyncContextManager" attribute that only exists under Python >=
+#   3.7 could be conditionally isolated to that range of Python versions.
+#   Technically, there exists *NO* impediment to doing so; pragmatically, doing
+#   so would be ineffectual. Why? Because attributes *NOT* defined by the
+#   "typing" module of the active Python interpreter cannot (by definition) be
+#   used to annotate callables decorated by the @beartype decorator.
+#
+# When bumping beartype to support a new CPython release:
+# * Declare one new attribute here for each new "typing" attribute added by
+#   that CPython release regardless of whether beartype explicitly supports
+#   that attribute yet. The subsequently called die_unless_hint_pep_supported()
+#   validator will raise exceptions when passed these attributes.
+# * Preserve attributes here that have since been removed from the "typing"
+#   module in that CPython release to ensure their continued usability when
+#   running beartype against older CPython releases.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+# Super-special typing primitives.
+HintSignAnnotated = _HintSign(name='Annotated')
+HintSignAny = _HintSign(name='Any')
+HintSignCallable = _HintSign(name='Callable')
+HintSignClassVar = _HintSign(name='ClassVar')
+HintSignConcatenate = _HintSign(name='Concatenate')
+HintSignFinal = _HintSign(name='Final')
+HintSignForwardRef = _HintSign(name='ForwardRef')
+HintSignGeneric = _HintSign(name='Generic')
+HintSignLiteral = _HintSign(name='Literal')
+HintSignOptional = _HintSign(name='Optional')
+HintSignParamSpec = _HintSign(name='ParamSpec')
+HintSignProtocol = _HintSign(name='Protocol')
+HintSignTuple = _HintSign(name='Tuple')
+HintSignType = _HintSign(name='Type')
+HintSignTypeVar = _HintSign(name='TypeVar')
+HintSignTypeVarTuple = _HintSign(name='TypeVarTuple')
+HintSignUnion = _HintSign(name='Union')
+
+# ABCs (from collections.abc).
+HintSignAbstractSet = _HintSign(name='AbstractSet')
+HintSignByteString = _HintSign(name='ByteString')
+HintSignContainer = _HintSign(name='Container')
+HintSignContextManager = _HintSign(name='ContextManager')
+HintSignHashable = _HintSign(name='Hashable')
+HintSignItemsView = _HintSign(name='ItemsView')
+HintSignIterable = _HintSign(name='Iterable')
+HintSignIterator = _HintSign(name='Iterator')
+HintSignKeysView = _HintSign(name='KeysView')
+HintSignMapping = _HintSign(name='Mapping')
+HintSignMappingView = _HintSign(name='MappingView')
+HintSignMutableMapping = _HintSign(name='MutableMapping')
+HintSignMutableSequence = _HintSign(name='MutableSequence')
+HintSignMutableSet = _HintSign(name='MutableSet')
+HintSignSequence = _HintSign(name='Sequence')
+HintSignSized = _HintSign(name='Sized')
+HintSignValuesView = _HintSign(name='ValuesView')
+HintSignAwaitable = _HintSign(name='Awaitable')
+HintSignAsyncIterator = _HintSign(name='Iterator')
+HintSignAsyncIterable = _HintSign(name='Iterable')
+HintSignCoroutine = _HintSign(name='Coroutine')
+HintSignCollection = _HintSign(name='Collection')
+HintSignAsyncGenerator = _HintSign(name='AsyncGenerator')
+HintSignAsyncContextManager = _HintSign(name='ContextManager')
+
+# Structural checks, a.k.a. protocols.
+HintSignReversible = _HintSign(name='Reversible')
+# SupportsAbs   <-- not a useful type hint (already an isinstanceable ABC)
+# SupportsBytes   <-- not a useful type hint (already an isinstanceable ABC)
+# SupportsComplex   <-- not a useful type hint (already an isinstanceable ABC)
+# SupportsFloat   <-- not a useful type hint (already an isinstanceable ABC)
+# SupportsIndex   <-- not a useful type hint (already an isinstanceable ABC)
+# SupportsInt   <-- not a useful type hint (already an isinstanceable ABC)
+# SupportsRound   <-- not a useful type hint (already an isinstanceable ABC)
+
+# Concrete collection types.
+HintSignChainMap = _HintSign(name='ChainMap')
+HintSignCounter = _HintSign(name='Counter')
+HintSignDeque = _HintSign(name='Deque')
+HintSignDict = _HintSign(name='Dict')
+HintSignDefaultDict = _HintSign(name='DefaultDict')
+HintSignList = _HintSign(name='List')
+HintSignOrderedDict = _HintSign(name='OrderedDict')
+HintSignSet = _HintSign(name='Set')
+HintSignFrozenSet = _HintSign(name='FrozenSet')
+HintSignNamedTuple = _HintSign(name='NamedTuple')
+HintSignTypedDict = _HintSign(name='TypedDict')
+HintSignGenerator = _HintSign(name='Generator')
+
+# Other concrete types.
+HintSignMatch = _HintSign(name='Match')
+HintSignPattern = _HintSign(name='Pattern')
+
+# Other concrete type aliases.
+HintSignIO = HintSignGeneric
+HintSignBinaryIO = HintSignGeneric
+HintSignTextIO = HintSignGeneric
+
+# One-off things.
+# AnyStr   <-- not a unique type hint (just a constrained "TypeVar")
+# cast   <-- unusable as a type hint
+# final   <-- unusable as a type hint
+# get_args   <-- unusable as a type hint
+# get_origin   <-- unusable as a type hint
+# get_type_hints   <-- unusable as a type hint
+# is_typeddict   <-- unusable as a type hint
+HintSignLiteralString = _HintSign(name='LiteralString')
+HintSignNever = _HintSign(name='Never')
+HintSignNewType = _HintSign(name='NewType')
+# no_type_check   <-- unusable as a type hint
+# no_type_check_decorator   <-- unusable as a type hint
+
+# Note that "NoReturn" is contextually valid *ONLY* as a top-level return hint.
+# Since this use case is extremely limited, we explicitly generate code for this
+# use case outside of the general-purpose code generation pathway for standard
+# type hints. Since "NoReturn" is an unsubscriptable singleton, we explicitly
+# detect this type hint with an identity test and thus require *NO* sign to
+# uniquely identify this type hint.
+#
+# Theoretically, explicitly defining a sign uniquely identifying this type hint
+# could erroneously encourage us to use that sign elsewhere; we should avoid
+# that, as "NoReturn" is invalid in almost all possible contexts. Pragmatically,
+# doing so nonetheless improves orthogonality when detecting and validating
+# PEP-compliant type hints, which ultimately matters more than our subjective
+# feelings about the matter. Wisely, we choose pragmatics.
+#
+# In short, "NoReturn" is insane.
+HintSignNoReturn = _HintSign(name='NoReturn')
+
+HintSignNotRequired = _HintSign(name='NotRequired')
+# overload   <-- unusable as a type hint
+HintSignParamSpecArgs = _HintSign(name='ParamSpecArgs')
+HintSignParamSpecKwargs = _HintSign(name='ParamSpecKwargs')
+HintSignRequired = _HintSign(name='Required')
+# runtime_checkable   <-- unusable as a type hint
+HintSignSelf = _HintSign(name='Self')
+# Text   <-- not actually a type hint (literal alias for "str")
+# TYPE_CHECKING   <-- unusable as a type hint
+HintSignTypeAlias = _HintSign(name='TypeAlias')
+HintSignTypeGuard = _HintSign(name='TypeGuard')
+HintSignUnpack = _HintSign(name='Unpack')
+
+# Wrapper namespace for re type aliases.
+#
+# Note that "typing.__all__" intentionally omits the "Match" and "Pattern"
+# attributes, which it oddly considers to comprise another namespace. *shrug*
+
+# ....................{ SIGNS ~ implicit                   }....................
+# Signs with *NO* explicit analogues in the stdlib "typing" module but
+# nonetheless standardized by one or more PEPs.
+
+HintSignNone = _HintSign(name='None')
+'''
+:pep:`484` explicitly supports the :data:`None` singleton, albeit implicitly:
+
+    When used in a type hint, the expression None is considered equivalent to
+    type(None).
+'''
+
+# ....................{ SIGNS ~ implicit : lib             }....................
+# Signs identifying PEP-noncompliant third-party type hints published by...
+#
+# ....................{ SIGNS ~ implicit : lib : numpy     }....................
+HintSignNumpyArray = _HintSign(name='NumpyArray')   # <-- "numpy.typing.NDArray"
+'''
+...the :mod:`numpy.typing` subpackage.
+'''
+
+# ....................{ SIGNS ~ implicit : lib : pandera   }....................
+HintSignPanderaAny = _HintSign(name='PanderaAny')   # <-- "pandera.typing.*"
+'''
+...the :mod:`pandera.typing` subpackage.
+
+Specifically, define a single sign unconditionally matching *all* type hints
+published by the :mod:`pandera.typing` subpackage. Why? Because Pandera insanely
+publishes its own Pandera-specific PEP-noncompliant runtime type-checking
+decorator :func:`pandera.check_types` that supports *only* Pandera-specific
+PEP-noncompliant :mod:`pandera.typing` type hints. Since Pandera users are
+already accustomed to decorating *all* Pandera-based callables (i.e., callables
+accepting one or more parameters and/or returning one or more values which are
+Pandera objects) by :func:`pandera.check_types`, attempting to type-check the
+same objects already type-checked by that decorator would only inefficiently and
+needlessly slow :mod:`beartype` down. Ergo, we ignore *all* Pandera type hints
+by:
+
+* Defining this catch-all singleton for Pandera type hints here.
+* Denoting this singleton to be unconditionally ignorable elsewhere.
+'''
+
+# ....................{ SIGNS ~ implicit : pep : 557       }....................
+# dataclasses.InitVar[...].
+HintSignPep557DataclassInitVar = _HintSign(name='Pep557DataclassInitVar')
+'''
+:pep:`557`-compliant :obj:`dataclasses.InitVar` type hint factory, annotating
+class-scoped variable annotations of :func:`dataclass.dataclass`-decorated
+data classes.
+'''
+
+# ....................{ SIGNS ~ implicit : pep : 585       }....................
+# os.PathLike[...], weakref.weakref[...], et al.
+HintSignPep585BuiltinSubscriptedUnknown = _HintSign(
+    name='Pep585BuiltinSubscriptedUnknown')
+'''
+:pep:`585`-compliant C-based :class:`types.GenericAlias` superclass inheritable
+by PEP-noncompliant pure-Python subclasses in either the standard library or
+third-party packages, which when subscripted by otherwise PEP-compliant child
+type hints produce PEP-noncompliant **unrecognized subscripted builtin type
+hints** (i.e., C-based type hints that are *not* isinstanceable types,
+instantiated by subscripting pure-Python origin classes unrecognized by
+:mod:`beartype` and thus PEP-noncompliant).
+
+Examples include:
+
+* ``os.PathLike[...]`` type hints.
+* ``weakref.weakref[...]`` type hints.
+
+Unsurprisingly, :mod:`beartype` reduces C-based unrecognized subscripted builtin
+type hints (which are *not* type-checkable as is) to their unsubscripted
+pure-Python origin classes (which are type-checkable as is).
+'''
+
+# ....................{ SIGNS ~ implicit : pep : 695       }....................
+# "type {alias_name} = {alias_value}" statements.
+HintSignPep695TypeAlias = _HintSign(name='HintSignPep695TypeAlias')
+'''
+:pep:`695`-compliant C-based :class:`types.TypeAliasType` class of all
+:pep:`695`-compliant **type aliases** (i.e., objects created as the left-hand
+sides of statements of the form ``type {alias_name} = {alias_value}``).
+'''
+
+# ....................{ CLEANUP                            }....................
+# Prevent all attributes imported above from polluting this namespace. Why?
+# Logic elsewhere subsequently assumes a one-to-one mapping between the
+# attributes of this namespace and signs.
+del _HintSign
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/hint/pep/sign/datapepsignset.py
@@ -0,0 +1,619 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **type hint sign sets** (i.e., frozen set globals aggregating
+instances of the :class:`beartype._data.hint.pep.sign.datapepsigncls.HintSign`
+class, enabling efficient categorization of signs as belonging to various
+categories of type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignAbstractSet,
+    HintSignAnnotated,
+    HintSignAny,
+    HintSignAsyncContextManager,
+    HintSignAsyncGenerator,
+    HintSignAsyncIterator,
+    HintSignAsyncIterable,
+    HintSignAwaitable,
+    HintSignBinaryIO,
+    HintSignByteString,
+    HintSignCallable,
+    HintSignChainMap,
+    HintSignCollection,
+    HintSignConcatenate,
+    HintSignContainer,
+    HintSignContextManager,
+    HintSignCoroutine,
+    HintSignCounter,
+    HintSignPep557DataclassInitVar,
+    HintSignDefaultDict,
+    HintSignDeque,
+    HintSignDict,
+    HintSignFinal,
+    HintSignForwardRef,
+    HintSignFrozenSet,
+    HintSignGenerator,
+    HintSignGeneric,
+    HintSignHashable,
+    HintSignIO,
+    HintSignItemsView,
+    HintSignIterable,
+    HintSignIterator,
+    HintSignKeysView,
+    HintSignList,
+    HintSignLiteral,
+    HintSignLiteralString,
+    HintSignMapping,
+    HintSignMappingView,
+    HintSignMatch,
+    HintSignMutableMapping,
+    HintSignMutableSequence,
+    HintSignMutableSet,
+    HintSignNewType,
+    HintSignNumpyArray,
+    HintSignNone,
+    HintSignOptional,
+    HintSignOrderedDict,
+    # HintSignPanderaAny,
+    HintSignParamSpec,
+    HintSignPattern,
+    HintSignPep585BuiltinSubscriptedUnknown,
+    HintSignTypeAlias,
+    HintSignPep695TypeAlias,
+    HintSignProtocol,
+    HintSignReversible,
+    HintSignSelf,
+    HintSignSequence,
+    HintSignSet,
+    HintSignSized,
+    HintSignTextIO,
+    HintSignTuple,
+    HintSignType,
+    HintSignTypedDict,
+    HintSignTypeGuard,
+    HintSignTypeVar,
+    HintSignUnion,
+    HintSignValuesView,
+)
+
+# ....................{ SETS ~ deprecated                  }....................
+#FIXME: Currently unused but preserved for posterity. *shrug*
+# HINT_SIGNS_DEPRECATED = frozenset((
+#     # ..................{ PEP 613                            }..................
+#     # PEP 613-compliant "typing.TypeAlias" type hint singletons have been
+#     # deprecated by PEP 695-compliant type aliases under Python >= 3.12.
+#     HintSignTypeAlias,
+# ))
+# '''
+# Frozen set of all **deprecated signs** (i.e., arbitrary objects uniquely
+# identifying PEP-compliant type hints unconditionally obsoleted by equivalent
+# PEP-compliant type hints standardized by more recently released PEPs).
+# '''
+
+# ....................{ SIGNS ~ ignorable                  }....................
+HINT_SIGNS_BARE_IGNORABLE = frozenset((
+    # ..................{ PEP 484                            }..................
+    # The "Any" singleton is semantically synonymous with the ignorable
+    # PEP-noncompliant "beartype.cave.AnyType" and hence "object" types.
+    HintSignAny,
+
+    # The "Generic" superclass imposes no constraints and is thus also
+    # semantically synonymous with the ignorable PEP-noncompliant
+    # "beartype.cave.AnyType" and hence "object" types. Since PEP
+    # 484 stipulates that *ANY* unsubscripted subscriptable PEP-compliant
+    # singleton including "typing.Generic" semantically expands to that
+    # singelton subscripted by an implicit "Any" argument, "Generic"
+    # semantically expands to the implicit "Generic[Any]" singleton.
+    HintSignGeneric,
+
+    # The unsubscripted "Optional" singleton semantically expands to the
+    # implicit "Optional[Any]" singleton by the same argument. Since PEP
+    # 484 also stipulates that all "Optional[t]" singletons semantically expand
+    #     to "Union[t, type(None)]" singletons for arbitrary arguments "t",
+    #     "Optional[Any]" semantically expands to merely "Union[Any,
+    #     type(None)]". Since all unions subscripted by "Any" semantically
+    #     reduce to merely "Any", the "Optional" singleton also reduces to
+    # merely "Any".
+    #
+    # This intentionally excludes "Optional[type(None)]", which the "typing"
+    # module physically reduces to merely "type(None)". *shrug*
+    HintSignOptional,
+
+    # The unsubscripted "Union" singleton semantically expands to the implicit
+    # "Union[Any]" singleton by the same argument. Since PEP 484 stipulates that
+    # a union of one type semantically reduces to only that type, "Union[Any]"
+    # semantically reduces to merely "Any". Despite their semantic equivalency,
+    # however, these objects remain syntactically distinct with respect to
+    # object identification: e.g.,
+    #     >>> Union is not Union[Any]
+    #     True
+    #     >>> Union is not Any
+    #     True
+    #
+    # This intentionally excludes:
+    #
+    # * The "Union[Any]" and "Union[object]" singletons, since the "typing"
+    #   module physically reduces:
+    #   * "Union[Any]" to merely "Any" (i.e., "Union[Any] is Any"), which
+    #     this frozen set already contains.
+    #   * "Union[object]" to merely "object" (i.e., "Union[object] is
+    #     object"), which this frozen set also already contains.
+    # * "Union" singleton subscripted by one or more ignorable type hints
+    #   contained in this set (e.g., "Union[Any, bool, str]"). Since there exist
+    #   a countably infinite number of these subscriptions, these subscriptions
+    #   *CANNOT* be explicitly listed in this set. Instead, these subscriptions
+    #   are dynamically detected by the high-level
+    #   beartype._util.hint.pep.utilhinttest.is_hint_ignorable() tester function
+    #   and thus referred to as deeply ignorable type hints.
+    HintSignUnion,
+
+    # ..................{ PEP 544                            }..................
+    # Note that ignoring the "typing.Protocol" superclass is vital here. For
+    # unknown and presumably uninteresting reasons, *ALL* possible objects
+    # satisfy this superclass. Ergo, this superclass is synonymous with the
+    # "object" root superclass: e.g.,
+    #     >>> import typing as t
+    #     >>> isinstance(object(), t.Protocol)
+    #     True
+    #     >>> isinstance('wtfbro', t.Protocol)
+    #     True
+    #     >>> isinstance(0x696969, t.Protocol)
+    #     True
+    HintSignProtocol,
+))
+'''
+Frozen set of all **bare ignorable signs** (i.e., arbitrary objects uniquely
+identifying unsubscripted type hints that are unconditionally ignorable by the
+:func:`beartype.beartype` decorator).
+'''
+
+# ....................{ SETS ~ kind                        }....................
+HINT_SIGNS_CALLABLE_PARAMS = frozenset((
+    # ..................{ PEP 612                            }..................
+    HintSignConcatenate,
+    HintSignParamSpec,
+))
+'''
+Frozen set of all **callable argument signs** (i.e., arbitrary objects uniquely
+identifying PEP-compliant child type hints typing the argument lists of parent
+:class:`collections.abc.Callable` type hints).
+
+This set necessarily excludes:
+
+* **Standard callable argument lists** (e.g., ``Callable[[bool, int], str]``),
+  which are specified as standard lists and thus identified by *no* signs.
+* **Ellipsis callable argument lists** (e.g., ``Callable[..., str]``), which are
+  specified as the ellipsis singleton and thus identified by *no* signs.
+'''
+
+
+HINT_SIGNS_MAPPING = frozenset((
+    # ..................{ PEP (484|585)                      }..................
+    HintSignDefaultDict,
+    HintSignDict,
+    HintSignMapping,
+    HintSignMutableMapping,
+    HintSignOrderedDict,
+))
+'''
+Frozen set of all **standard mapping signs** (i.e., arbitrary objects uniquely
+identifying :pep:`484`- and :pep:`585`-compliant type hints subscripted by
+exactly two child type hints constraining *all* key-value pairs of compliant
+mappings, which necessarily satisfy the :class:`collections.abc.Mapping`
+protocol with guaranteed :math:`O(1)` indexation of at least the first key-value
+pair).
+'''
+
+
+HINT_SIGNS_SEQUENCE_ARGS_1 = frozenset((
+    # ..................{ PEP (484|585)                      }..................
+    HintSignByteString,
+    HintSignList,
+    HintSignMutableSequence,
+    HintSignSequence,
+))
+'''
+Frozen set of all **standard sequence signs** (i.e., arbitrary objects uniquely
+identifying :pep:`484`- and :pep:`585`-compliant type hints subscripted by
+exactly one child type hint constraining *all* items of compliant sequences,
+which necessarily satisfy the :class:`collections.abc.Sequence` protocol with
+guaranteed :math:`O(1)` indexation across all sequence items).
+
+This set intentionally excludes the:
+
+* :obj:`typing.AnyStr` sign, which accepts only the :class:`str` and
+  :class:`bytes` types as its sole subscripted argument, which does *not*
+  unconditionally constrain *all* items (i.e., unencoded and encoded characters
+  respectively) of compliant sequences but instead parametrizes this attribute.
+* :obj:`typing.ByteString` sign, which accepts *no* subscripted arguments.
+  :obj:`typing.ByteString` is simply an alias for the
+  :class:`collections.abc.ByteString` abstract base class (ABC) and thus
+  already handled by our fallback logic for supported PEP-compliant type hints.
+* :obj:`typing.Deque` sign, whose compliant objects (i.e.,
+  :class:`collections.deque` instances) only `guarantee O(n) indexation across
+  all sequence items <collections.deque_>`__:
+
+     Indexed access is ``O(1)`` at both ends but slows to ``O(n)`` in the
+     middle. For fast random access, use lists instead.
+
+* :obj:`typing.NamedTuple` sign, which embeds a variadic number of
+  PEP-compliant field type hints and thus requires special-cased handling.
+* :obj:`typing.Text` sign, which accepts *no* subscripted arguments.
+  :obj:`typing.Text` is simply an alias for the builtin :class:`str` type and
+  thus handled elsewhere as a PEP-noncompliant type hint.
+* :obj:`typing.Tuple` sign, which accepts a variadic number of subscripted
+  arguments and thus requires special-cased handling.
+
+.. _collections.deque:
+   https://docs.python.org/3/library/collections.html#collections.deque
+'''
+
+
+HINT_SIGNS_UNION = frozenset((
+    # ..................{ PEP 484                            }..................
+    HintSignOptional,
+    HintSignUnion,
+))
+'''
+Frozen set of all **union signs** (i.e., arbitrary objects uniquely identifying
+:pep:`484`- and :pep:`604`-compliant type hints unifying one or more subscripted
+type hint arguments into a disjunctive set union of these arguments).
+
+If the active Python interpreter targets:
+
+* Python >= 3.9, the :obj:`typing.Optional` and :obj:`typing.Union`
+  attributes are distinct.
+* Python < 3.9, the :obj:`typing.Optional` attribute reduces to the
+  :obj:`typing.Union` attribute, in which case this set is technically
+  semantically redundant. Since tests of both object identity and set
+  membership are :math:`O(1)`, this set incurs no significant performance
+  penalty versus direct usage of the :obj:`typing.Union` attribute and is thus
+  unconditionally used as is irrespective of Python version.
+'''
+
+# ....................{ SIGNS ~ origin                     }....................
+HINT_SIGNS_ORIGIN_ISINSTANCEABLE = frozenset((
+    # ..................{ PEP (484|585)                      }..................
+    HintSignAbstractSet,
+    HintSignAsyncContextManager,
+    HintSignAsyncGenerator,
+    HintSignAsyncIterable,
+    HintSignAsyncIterator,
+    HintSignAwaitable,
+    HintSignByteString,
+    HintSignCallable,
+    HintSignChainMap,
+    HintSignCollection,
+    HintSignContainer,
+    HintSignContextManager,
+    HintSignCoroutine,
+    HintSignCounter,
+    HintSignDefaultDict,
+    HintSignDeque,
+    HintSignDict,
+    HintSignFrozenSet,
+    HintSignGenerator,
+    HintSignHashable,
+    HintSignItemsView,
+    HintSignIterable,
+    HintSignIterator,
+    HintSignKeysView,
+    HintSignList,
+    HintSignMapping,
+    HintSignMappingView,
+    HintSignMatch,
+    HintSignMutableMapping,
+    HintSignMutableSequence,
+    HintSignMutableSet,
+    HintSignOrderedDict,
+    HintSignPattern,
+    HintSignReversible,
+    HintSignSequence,
+    HintSignSet,
+    HintSignSized,
+    HintSignTuple,
+    HintSignType,
+    HintSignValuesView,
+
+    # ..................{ NON-PEP                            }..................
+    HintSignPep585BuiltinSubscriptedUnknown,
+))
+'''
+Frozen set of all signs uniquely identifying PEP-compliant type hints
+originating from an **isinstanceable origin type** (i.e., isinstanceable class
+such that *all* objects satisfying this hint are instances of this class).
+
+All hints identified by signs in this set are guaranteed to define
+``__origin__`` dunder instance variables whose values are the standard origin
+types they originate from. Since any object is trivially type-checkable against
+such a type by passing that object and type to the :func:`isinstance` builtin,
+*all* objects annotated by hints identified by signs in this set are at least
+shallowly type-checkable from wrapper functions generated by the
+:func:`beartype.beartype` decorator.
+'''
+
+# ....................{ SIGNS ~ origin : args              }....................
+HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_1 = frozenset((
+    HintSignAbstractSet,
+    HintSignAsyncContextManager,
+    HintSignAsyncIterable,
+    HintSignAsyncIterator,
+    HintSignAwaitable,
+    HintSignCollection,
+    HintSignContainer,
+    HintSignContextManager,
+    HintSignCounter,
+    HintSignDeque,
+    HintSignFrozenSet,
+    HintSignIterable,
+    HintSignIterator,
+    HintSignKeysView,
+    HintSignList,
+    HintSignMatch,
+    HintSignMappingView,
+    HintSignMutableSequence,
+    HintSignMutableSet,
+    HintSignPattern,
+    HintSignReversible,
+    HintSignSequence,
+    HintSignSet,
+    HintSignType,
+    HintSignValuesView,
+))
+'''
+Frozen set of all signs uniquely identifying **single-argument PEP-compliant
+type hints** (i.e., type hints subscriptable by only one child type hint)
+originating from an **isinstanceable origin type** (i.e., isinstanceable class
+such that *all* objects satisfying this hint are instances of this class).
+
+Note that the corresponding types in the typing module will have an ``_nparams``
+instance variable with a value equal to 1.
+'''
+
+
+HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_2 = frozenset((
+    HintSignAsyncGenerator,
+    # HintSignCallable,  # defined explicitly below
+    HintSignChainMap,
+    HintSignDefaultDict,
+    HintSignDict,
+    HintSignItemsView,
+    HintSignMapping,
+    HintSignMutableMapping,
+    HintSignOrderedDict,
+))
+'''
+Frozen set of all signs uniquely identifying **two-argument PEP-compliant
+type hints** (i.e., type hints subscriptable by exactly two child type hints)
+
+Note that the corresponding types in the typing module will have an ``_nparams``
+instance variable with a value equal to 2.
+'''
+
+
+HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_3 = frozenset((
+    HintSignCoroutine,
+    HintSignGenerator,
+))
+'''
+Frozen set of all signs uniquely identifying **three-argument PEP-compliant
+type hints** (i.e., type hints subscriptable by exactly three child type hints)
+
+Note that the corresponding types in the typing module will have an ``_nparams``
+instance variable with a value equal to 3.
+'''
+
+# ....................{ SIGNS ~ return                     }....................
+HINT_SIGNS_RETURN_GENERATOR_ASYNC = frozenset((
+    # ..................{ PEP (484|585)                      }..................
+    HintSignAsyncGenerator,
+    HintSignAsyncIterable,
+    HintSignAsyncIterator,
+))
+'''
+Frozen set of all signs uniquely identifying **PEP-compliant asynchronous
+generator return type hints** (i.e., hints permissible as the return
+annotations of asynchronous generators).
+
+See Also
+--------
+:data:`.HINT_SIGNS_RETURN_GENERATOR_SYNC`
+    Further discussion.
+'''
+
+
+HINT_SIGNS_RETURN_GENERATOR_SYNC = frozenset((
+    # ..................{ PEP (484|585)                      }..................
+    HintSignGenerator,
+    HintSignIterable,
+    HintSignIterator,
+))
+'''
+Frozen set of all signs uniquely identifying **PEP-compliant synchronous
+generator return type hints** (i.e., hints permissible as the return
+annotations of synchronous generators).
+
+Generator callables are simply syntactic sugar for non-generator callables
+returning generator objects. For this reason, generator callables *must* be
+annotated as returning a type compatible with generator objects -- including:
+
+* :data:`HintSignGenerator`, the narrowest abstract base class (ABC) to which
+  all generator objects necessarily conform.
+* :data:`HintSignIterator`, the immediate superclass of
+  :data:`HintSignGenerator`.
+* :data:`HintSignIterable`, the immediate superclass of
+  :data:`HintSignIterator`.
+
+Technically, :pep:`484` states that generator callables may only be annotated
+as only returning a subscription of the :obj:`typing.Generator` factory:
+
+    The return type of generator functions can be annotated by the generic type
+    ``Generator[yield_type, send_type, return_type]`` provided by ``typing.py``
+    module:
+
+Pragmatically, official documentation for the :mod:`typing` module seemingly
+*never* standardized by an existing PEP additionally states that generator
+callables may be annotated as also returning a subscription of either the
+:obj:`typing.Iterable` or :obj:`typing.Iterator` factories:
+
+    Alternatively, annotate your generator as having a return type of either
+    ``Iterable[YieldType]`` or ``Iterator[YieldType]``:
+
+See Also
+--------
+https://github.com/beartype/beartype/issues/65#issuecomment-954468111
+    Further discussion.
+'''
+
+# ....................{ SIGNS ~ type                       }....................
+HINT_SIGNS_TYPE_MIMIC = frozenset((
+    # ..................{ PEP 484                            }..................
+    HintSignNewType,
+
+    # ..................{ PEP 593                            }..................
+    HintSignAnnotated,
+))
+'''
+Frozen set of all signs uniquely identifying **PEP-compliant type hint mimics**
+(i.e., hints maliciously masquerading as another type by explicitly overriding
+their ``__module__`` dunder instance variable to that of that type).
+
+Notably, this set contains the signs of:
+
+* :pep:`484`-compliant :obj:`typing.NewType` type hints under Python >= 3.10,
+  which badly masquerade as their first passed argument to such an extreme
+  degree that they even intentionally prefix their machine-readable
+  representation by the fully-qualified name of the caller's module: e.g.,
+
+  .. code-block:: python
+
+     # Under Python >= 3.10:
+     >>> import typing
+     >>> new_type = typing.NewType('List', bool)
+     >>> repr(new_type)
+     __main__.List   # <---- this is genuine bollocks
+
+* :pep:`593`-compliant :obj:`typing.Annotated` type hints, which badly
+  masquerade as their first subscripted argument (e.g., the :class:`int` in
+  ``typing.Annotated[int, 63]``) such that the value of the ``__module__``
+  attributes of these hints is that of that argument rather than their own.
+  Oddly, their machine-readable representation remains prefixed by
+  ``"typing."``, enabling an efficient test that also generalizes to all other
+  outlier edge cases that are probably lurking about.
+
+I have no code and I must scream.
+'''
+
+# ....................{ SETS ~ supported                   }....................
+_HINT_SIGNS_SUPPORTED_SHALLOW = frozenset((
+    # ..................{ PEP 484                            }..................
+    HintSignTypeVar,
+
+    # ..................{ PEP 589                            }..................
+    #FIXME: Shift into "HINT_SIGNS_SUPPORTED_DEEP" *AFTER* deeply type-checking
+    #typed dictionaries.
+    HintSignTypedDict,
+
+    # ..................{ PEP 591                            }..................
+    HintSignFinal,
+
+    # ..................{ PEP 613                            }..................
+    HintSignTypeAlias,
+
+    # ..................{ PEP 647                            }..................
+    HintSignTypeGuard,
+
+    # ..................{ PEP 673                            }..................
+    HintSignSelf,
+
+    # ..................{ PEP 675                            }..................
+    HintSignLiteralString,
+
+    # ..................{ PEP 695                            }..................
+    HintSignPep695TypeAlias,
+))
+'''
+Frozen set of all **shallowly supported non-originative signs** (i.e., arbitrary
+objects uniquely identifying PEP-compliant type hints *not* originating from an
+isinstanceable type for which the :func:`beartype.beartype` decorator generates
+shallow type-checking code).
+'''
+
+
+HINT_SIGNS_SUPPORTED_DEEP = (
+    HINT_SIGNS_MAPPING |
+    HINT_SIGNS_SEQUENCE_ARGS_1 |
+    frozenset((
+    # ..................{ PEP 484                            }..................
+    # Note that the "NoReturn" type hint is invalid in almost all possible
+    # syntactic contexts and thus intentionally omitted here. See the
+    # "datapepsigns" submodule for further commentary.
+    HintSignAny,
+    HintSignBinaryIO,
+    HintSignForwardRef,
+    HintSignIO,
+    HintSignNewType,
+    HintSignNone,
+    HintSignTextIO,
+
+    # Note that "typing.Union" implicitly subsumes "typing.Optional" *ONLY*
+    # under Python <= 3.9. The implementations of the "typing" module under
+    # those older Python versions transparently reduced "typing.Optional" to
+    # "typing.Union" at runtime. Since this reduction is no longer the case,
+    # both *MUST* now be explicitly listed here.
+    HintSignOptional,
+    HintSignUnion,
+
+    # ..................{ PEP (484|585)                      }..................
+    HintSignGeneric,
+    HintSignTuple,
+    HintSignType,
+
+    # ..................{ PEP 544                            }..................
+    HintSignProtocol,
+
+    # ..................{ PEP 557                            }..................
+    HintSignPep557DataclassInitVar,
+
+    # ..................{ PEP 586                            }..................
+    HintSignLiteral,
+
+    # ..................{ PEP 593                            }..................
+    HintSignAnnotated,
+
+    # ..................{ NON-PEP ~ package : numpy          }..................
+    #FIXME: This should probably be in "HINT_SIGNS_SUPPORTED_SHALLOW", instead.
+    HintSignNumpyArray,
+)))
+'''
+Frozen set of all **deeply supported signs** (i.e., arbitrary objects uniquely
+identifying PEP-compliant type hints for which the :func:`beartype.beartype`
+decorator generates deeply type-checking code).
+
+This set contains *every* sign explicitly supported by one or more conditional
+branches in the body of the
+:func:`beartype._check.code.codemake.make_func_pith_code` function
+generating code deeply type-checking the current pith against the PEP-compliant
+type hint annotated by a subscription of that attribute.
+'''
+
+
+HINT_SIGNS_SUPPORTED = frozenset((
+    # Set of all deeply supported signs.
+    HINT_SIGNS_SUPPORTED_DEEP |
+    # Set of all shallowly supported signs *NOT* originating from a class.
+    _HINT_SIGNS_SUPPORTED_SHALLOW |
+    # Set of all shallowly supported signs originating from a class.
+    HINT_SIGNS_ORIGIN_ISINSTANCEABLE
+))
+'''
+Frozen set of all **supported signs** (i.e., arbitrary objects uniquely
+identifying PEP-compliant type hints).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/kind/datakinddict.py
@@ -0,0 +1,40 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **mapping singletons** (i.e., dictionaries commonly required
+throughout this codebase, reducing space and time consumption by preallocating
+widely used dictionary-centric objects).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    Dict,
+)
+
+# ....................{ DICTS                              }....................
+# Note that this exact type annotation is required to avoid mypy complaints. :O
+DICT_EMPTY: Dict[Any, Any] = {}
+'''
+**Empty dictionary singleton.**
+
+Whereas Python guarantees the **empty tuple** (i.e., ``()``) to be a singleton,
+Python does *not* extend that guarantee to dictionaries. This empty dictionary
+singleton amends that oversight, providing efficient reuse of empty
+dictionaries: e.g.,
+
+.. code-block::
+
+   >>> () is ()
+   True  # <-- good. this is good.
+   >>> {} is {}
+   False  # <-- bad. this is bad.
+   >>> from beartype._data.kind.datakinddict import DICT_EMPTY
+   >>> DICT_EMPTY is DICT_EMPTY
+   True  # <-- good. this is good, because we made it so.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/kind/datakindsequence.py
@@ -0,0 +1,50 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **sequence singletons** (i.e., lists and tuples commonly required
+throughout this codebase, reducing space and time consumption by preallocating
+widely used set-centric objects).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    List,
+    Tuple,
+)
+
+# ....................{ LISTS                              }....................
+# Note that this exact type annotation is required to avoid mypy complaints. :O
+LIST_EMPTY: List[Any] = []
+'''
+**Empty list singleton.**
+'''
+
+# ....................{ TUPLES                             }....................
+# Note that this exact type annotation is required to avoid mypy complaints. :O
+TUPLE_EMPTY: Tuple[Any, ...] = ()
+'''
+**Empty tuple singleton.**
+
+Yes, we know exactly what you're thinking: "Why would anyone do this, @leycec?
+Why not just directly access the empty tuple singleton as ()?" Because Python
+insanely requires us to do this under Python >= 3.8 to detect empty tuples:
+
+.. code-block:: bash
+
+   $ python3.7
+   >>> () is ()
+   True   # <-- yes, this is good
+
+   $ python3.8
+   >>> () is ()
+   SyntaxWarning: "is" with a literal. Did you mean "=="?  # <-- WUT
+   >>> TUPLE_EMPTY = ()
+   >>> TUPLE_EMPTY is TUPLE_EMPTY
+   True  # <-- *FACEPALM*
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/kind/datakindset.py
@@ -0,0 +1,40 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **set singletons** (i.e., sets and frozen sets commonly required
+throughout this codebase, reducing space and time consumption by preallocating
+widely used set-centric objects).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    FrozenSet,
+)
+
+# ....................{ SETS                               }....................
+# Note that this exact type annotation is required to avoid mypy complaints. :O
+FROZENSET_EMPTY: FrozenSet[Any] = frozenset()
+'''
+**Empty frozen set singleton.**
+
+Whereas Python guarantees the **empty tuple** (i.e., ``()``) to be a singleton,
+Python does *not* extend that guarantee to frozen sets. This empty frozen set
+singleton amends that oversight, providing efficient reuse of empty frozen sets:
+e.g.,
+
+.. code-block:: pycon
+
+   >>> () is ()
+   True  # <-- good. this is good.
+   >>> frozenset() is frozenset()
+   False  # <-- bad. this is bad.
+   >>> from beartype._data.kind.datakindset import FROZENSET_EMPTY
+   >>> FROZENSET_EMPTY is FROZENSET_EMPTY
+   True  # <-- good. this is good, because we made it so.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/kind/datakindtext.py
@@ -0,0 +1,26 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **string singletons** (i.e., strings and data structures of strings
+commonly required throughout this codebase, reducing space and time consumption
+by preallocating widely used string-centric objects).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from string import punctuation
+
+# ....................{ SETS ~ punctuation                 }....................
+CHARS_PUNCTUATION = frozenset(punctuation)
+'''
+Frozen set of all **ASCII punctuation characters** (i.e., non-Unicode
+characters satisfying the conventional definition of English punctuation).
+
+Note that the :attr:`string.punctuation` object is actually an inefficient
+string of these characters rather than an efficient collection. Ergo, this set
+should *ALWAYS* be accessed in lieu of that string.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/module/datamodcontextlib.py
@@ -0,0 +1,69 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :mod:`contextlib` **globals** (i.e., global constants describing
+the standard :mod:`contextlib` module bundled with CPython's standard library).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Iterator
+from beartype._util.func.utilfunccodeobj import get_func_codeobj_basename
+from contextlib import contextmanager
+
+# ....................{ STRINGS                            }....................
+@contextmanager
+def _noop_context_manager() -> Iterator[None]:
+    '''
+    Arbitrary :func:`contextlib.contextmanager`-based context manager defined
+    solely to inspect various dunder attributes common to all such managers.
+    '''
+
+    yield
+
+
+CONTEXTLIB_CONTEXTMANAGER_CODEOBJ_NAME = get_func_codeobj_basename(
+    _noop_context_manager)
+'''
+Fully-qualified name of the code object underlying the isomorphic decorator
+closure created and returned by the :func:`contextlib.contextmanager` decorator.
+
+This name enables functionality elsewhere to reliably detect when a function has
+been decorated by that decorator. This is critical, as the type of *all* objects
+created and returned by :func:`contextlib.contextmanager`-based context managers
+is a private class of the :mod:`contextlib` module rather than the types implied
+by the type hints originally annotating the returns of those context managers.
+If :mod:`beartype` did *not* actively detect and intervene in this edge case,
+then runtime type-checkers dynamically generated by :mod:`beartype` for those
+managers would erroneously raise type-checking violations after calling those
+managers and detecting a seeming type violation: e.g.,
+
+.. code-block:: python
+
+   >>> from beartype.typing import Iterator
+   >>> from contextlib import contextmanager
+   >>> @contextmanager
+   ... def _noop_context_manager() -> Iterator[None]: yield
+   >>> type(_noop_context_manager())
+   <class 'contextlib._GeneratorContextManager'>  # <-- not an "Iterator", bro
+   >>> _noop_context_manager.__qualname__
+   _noop_context_manager  # <-- that looks sane... but *IS* it?
+   >>> _noop_context_manager.__code__.co_qualname
+   contextmanager.<locals>.helper  # <-- So. The truth is revealed at last.
+
+As the above example demonstrates, the ``__qualname__`` dunder attribute of the
+isomorphic decorator closure created and returned by the
+:func:`contextlib.contextmanager` decorator publicly lies about its identity by
+masquerading as the decorated generator factory function. Only the secretive
+``__code__.co_qualname`` dunder attribute of that closure tells the truth.
+'''
+# print(f'CONTEXTLIB_CONTEXTMANAGER_CODEOBJ_NAME: {CONTEXTLIB_CONTEXTMANAGER_CODEOBJ_NAME}')
+
+
+# Delete this context manager now that we no longer require it as a negligible
+# safety (and possible space complexity) measure.
+del _noop_context_manager
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/module/datamodpy.py
@@ -0,0 +1,26 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **standard Python module globals** (i.e., global constants
+describing modules and packages bundled with CPython's standard library).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ NAMES                              }....................
+BUILTINS_MODULE_NAME = 'builtins'
+'''
+Fully-qualified name of the **builtins module** (i.e., objects defined by the
+standard :mod:`builtins` module and thus globally available by default
+*without* requiring explicit importation).
+'''
+
+
+SCRIPT_MODULE_NAME = '__main__'
+'''
+Fully-qualified name of the **script module** (i.e., arbitrary module name
+assigned to scripts run outside of a package context).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/module/datamodtyping.py
@@ -0,0 +1,59 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **typing module globals** (i.e., global constants describing
+quasi-standard typing modules).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+
+# ....................{ SETS                               }....................
+TYPING_MODULE_NAMES_STANDARD = frozenset((
+    # Official typing module bundled with the Python stdlib.
+    'typing',
+    # Third-party typing compatibility layer bundled with @beartype itself.
+    'beartype.typing',
+))
+'''
+Frozen set of the fully-qualified names of all **standard typing modules**
+(i.e., modules whose public APIs *exactly* conform to that of the standard
+:mod:`typing` module).
+
+This set includes both the standard :mod:`typing` module and comparatively
+more standard :mod:`beartype.typing` submodule while excluding the third-party
+:mod:`typing_extensions` module, whose runtime behaviour often significantly
+diverges in non-standard fashion from that of the aforementioned modules.
+'''
+
+
+TYPING_MODULE_NAMES = TYPING_MODULE_NAMES_STANDARD | frozenset((
+    # Third-party module backporting "typing" attributes introduced in newer
+    # Python versions to older Python versions.
+    'typing_extensions',
+))
+'''
+Frozen set of the fully-qualified names of all **quasi-standard typing
+modules** (i.e., modules defining attributes usable for creating PEP-compliant
+type hints accepted by both static and runtime type checkers).
+'''
+
+
+TYPING_MODULE_NAMES_DOTTED = frozenset(
+    f'{typing_module_name}.' for typing_module_name in TYPING_MODULE_NAMES)
+'''
+Frozen set of the fully-qualified ``.``-suffixed names of all typing modules.
+
+This set is a negligible optimization enabling callers to perform slightly more
+efficient testing of string prefixes against items of this specialized set than
+those of the more general-purpose :data:`TYPING_MODULE_NAMES` set.
+
+See Also
+----------
+:data:`TYPING_MODULE_NAMES`
+    Further details.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_data/os/dataosshell.py
@@ -0,0 +1,44 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **shell singletons** (i.e., magic constants pertaining to the
+parent shell encapsulating the active Python interpreter, including the names of
+:mod:`beartype`-specific environment variables officially recognized by
+:mod:`beartype`).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Dict,
+    Optional,
+)
+
+# ....................{ VARS ~ conf                        }....................
+# @beartype-specific environment variables configuring beartype configurations
+# (i.e., "beartype.BeartypeConf" instances).
+
+SHELL_VAR_CONF_IS_COLOR_NAME = 'BEARTYPE_IS_COLOR'
+'''
+Name of the **color configuration environment variable** (i.e.,
+:mod:`beartype`-specific environment variable officially recognized by
+:mod:`beartype` as globally configuring the value of the
+:attr:`beartype.BeartypeConf.is_color` tri-state boolean).
+'''
+
+
+SHELL_VAR_CONF_IS_COLOR_VALUE_TO_OBJ: Dict[str, Optional[bool]] = {
+    'True': True,
+    'False': False,
+    'None': None,
+}
+'''
+Dictionary mapping from each permissible string value for the **color
+configuration environment variable** (i.e., whose name is
+:data:`.CONF_IS_COLOR_NAME`) to the corresponding value of the
+:attr:`beartype.BeartypeConf.is_color` tri-state boolean.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/__init__.py
@@ -0,0 +1,222 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+# ....................{ TODO                               }....................
+#FIXME: "typing.LiteralString". We just had a mildly brilliant revelation in
+#the "beartype.claw._clawast" submodule as to how we might go about performing
+#static analysis at runtime via the third-party "executing" submodule. \o/
+
+#FIXME: [PEP 484]: Support subscripted bounded type variables. We didn't even
+#know this was a thing -- but it makes sense. An example is probably the best
+#way to explain this madness. Witness!
+#    from beartype import beartype
+#    from typing import Iterable
+#    
+#    T = TypeVar('T', bound=Iterable)
+#    
+#    @beartype
+#    def stringify_iterable_items(arg: T[int]) -> T[str]:
+#        return type(arg)(str(item) for item in arg)
+#
+#Clearly, @beartype should just quietly reduce both the "T[int]" and "T[str]"
+#type hints that we can't really do anything with to "Iterable[int]" and
+#"Iterable[str]" type hints, which we can. Does @beartype currently do that?
+#Probably... not. At the least, we should begin testing this exhaustively.
+
+#FIXME: [PEP 585] It looks like CPython's stdlib quietly extended PEP 585
+#support to a variety of undocumented classes, including:
+#* "asyncio.Future[T]".
+#* "asyncio.Task[T]".
+#* "asyncio.Queue[T]".
+#* "pathlib.PathLike[T]".
+#
+#Yes, we can verify that *ALL* of those actually are subscriptable at runtime.
+#@beartype will need to add corresponding support for such hints, beginning with
+#defining new sign singletons suffixed by the same basenames (e.g.,
+#"HintSignFuture", "HintSignTask"). Or... maybe not? Maybe everything just
+#behaves as expected as is?
+#
+#At the least, we'll want to rigorously test *ALL* of the above in our test
+#suite to ensure that @beartype does indeed type-check these as expected.
+#FIXME: Sadly, we do need to explicitly do *SOMETHING*. @beartype currently
+#raises exceptions on callables annotated by any of the above, as the metaclass
+#of these hints prohibits isinstance() checks: e.g.,
+#    asyncio.Task[~T] uncheckable at runtime (i.e., not passable as second
+#    parameter to isinstance(), due to raising "isinstance() argument 2 cannot
+#    be a parameterized generic" from metaclass __instancecheck__() method).
+#
+#Rather than explicitly matching all of the above, we instead want @beartype to
+#perform an automated solution implicitly matching all of the above. Notably,
+#improve @beartype to:
+#
+#* Detect parametrized generic hints that are otherwise unrecognized (e.g.,
+#  "asyncio.Task[~T]"). 
+#* Introspect the origin (i.e., "__origin__" dunder attribute) from these hints.
+#* Internally replace each such parametrized generic hint with its origin when
+#  generating type-checking code. Voila!
+
+#FIXME: [PEP] Add PEP 613 support (i.e., "typing.TypeAlias"). Thankfully, this
+#is trivial. "typing.TypeAlias" is prohibited in callable definitions and
+#inside the bodies of callables. Ergo, @beartype should just raise a
+#decoration-time exception if any parameter or return is annotated as an
+#explicit "TypeAlias". That constitutes full support for PEP 613 from our
+#side. Good enough! :p
+
+#FIXME: [SPEED] As a useful MACROoptimization, render the entire @beartype
+#toolchain thread-safe upfront rather than doing so piecemeal throughout the
+#toolchain. While the latter certainly works as well, the former is
+#*SUBSTANTIALLY* more efficient due to the non-trivial expense of each
+#threadsafe context manager. To do so:
+#* Simply wrap the body of the implementation of the @beartype decorator in a
+#  context manager locking on a globally declared lock: e.g.,
+#      with lock:
+#          ...
+#  Note that an "RLock" is neither needed nor desired here, as @beartype
+#  *NEVER* invokes itself recursively. A non-reentrant "Lock" suffices.
+#* Rip out all now-redundant "with lock:" expressions throughout the codebase.
+
+#FIXME: [SPEED] As a useful microoptimization, consider memoizing "repr(hint)"
+#calls. We strongly suspect these calls to be a performance bottleneck, because
+#we repeat them so frequently for the same hint throughout the codebase. The
+#best approach to doing so is to:
+#* Define a new memoized "beartype._util.hint.utilhintget" getter: e.g.,
+#      @callable_cached
+#      def get_hint_repr(hint: object) -> str:
+#          return repr(hint)
+#* Globally replace all calls to the repr() builtin throughout the codebase
+#  passed a hint with calls to get_hint_repr() instead.
+
+#FIXME: [SPEED] As a useful microoptimization, unroll *ALL* calls to the any()
+#and all() builtins into equivalent "for" loops in our critical path. Since we
+#typically pass these builtins generator comprehensions created and destroyed
+#on-the-fly, we've profiled these builtins to incur substantially higher
+#runtime costs than equivalent "for" loops. Thanks alot, CPython. *sigh*
+
+#FIXME: [FEATURE] Plugin architecture. The NumPy type hints use case will come
+#up again and again. So, let's get out ahead of that use case rather than
+#continuing to reinvent the wheel. Let's begin by defining a trivial plugin API
+#enabling users to define their own arbitrary type hint *REDUCTIONS.* Because
+#it's capitalized, we know the term "REDUCTIONS" is critical here. We are *NOT*
+#(at least, *NOT* initially) defining a full-blown plugin API. We're only
+#enabling users to reduce arbitrary type hints:
+#* From domain-specific objects they implement and annotate their code with...
+#* Into PEP-compliant type hints @beartype already supports.
+#Due to their versatility, the standard use case is reducing PEP-noncompliant
+#type hints to PEP 593-compliant beartype validators. To do so, consider:
+#* Defining a new public "beartype.plug" subpackage, defining:
+#  * A private "_PLUGIN_NAME_TO_SIGN" dictionary mapping from each "name"
+#    parameter passed to each prior call of the plug_beartype() function to the
+#    "HintSign" object that function dynamically creates to represent
+#    PEP-noncompliant type hints handled by that plugin. This dictionary
+#    effectively maps from the thing our users care about but we don't (i.e.,
+#    plugin names) to the thing our users don't care about but we do (i.e.,
+#    hint signs).
+#  * A public plug_beartype() function with signature resembling:
+#       def plug_beartype(
+#           # Mandatory parameters.
+#           name: str,
+#           hint_reduce: Callable[[object,], object],
+#
+#           # Optional parameters.
+#           hint_detect_from_repr_prefix_args_1_or_more: Optional[str] = None,
+#           hint_detect_from_type_name: Optional[str] = None,
+#       ) -> None:
+#    ...where:
+#    * The "name" parameter is an arbitrary non-empty string (e.g., "Numpy").
+#      This function will then synthesize a new hint sign suffixed by this
+#      substring (e.g., f'HintSign{name}') and map this name to that sign in
+#      the "_PLUGIN_NAME_TO_SIGN" dictionary.
+#    * The "hint_detect_from_repr_prefix_args_1_or_more" parameter is an
+#      arbitrary non-empty string typically corresponding to the
+#      fully-qualified name of a subclass of "types.GenericAlias" serving as a
+#      PEP 585-compliant type hint factory(e.g.,
+#      "muh_package.MuhTypeHintFactory"), corresponding exactly to the items
+#      of the "HINT_REPR_PREFIX_ARGS_1_OR_MORE_TO_SIGN" set.
+#    * The "hint_detect_from_type_name" parameter is the fully-qualified name
+#      of a caller-defined class (e.g., "muh_package.MuhTypeHintFactoryType"),
+#      corresponding exactly to the items of the "HINT_TYPE_NAME_TO_SIGN" set.
+#    * The "hint_reduce" parameter is an arbitrary caller-defined callable
+#      reducing all type hints identified by one or more of the detection
+#      schemes below to another arbitrary (but hopefully PEP-compliant and
+#      beartype-supported) type hint. Again, that will typically be a
+#      PEP 593-compliant beartype validator.
+#  * A public unplug_beartype() function with signature resembling:
+#       def unplug_beartype(name: str) -> None:
+#    This function simply looks up the passed name in various internal data
+#    structures (e.g.,"_PLUGIN_NAME_TO_SIGN") to undo the effects of the prior
+#    plug_beartype() call passed that name.
+#
+#Given that, we should then entirely reimplement our current strategy for
+#handling NumPy type hints into a single call to plug_beartype(): e.g.,
+#    # Pretty boss, ain't it? Note we intentionally pass
+#    # "hint_detect_from_repr_prefix_args_1_or_more" here, despite the fact
+#    # that the unsubscripted "numpy.typing.NDArray" factory is a valid type
+#    # hint. Yes, this actually works. Why? Because that factory implicitly
+#    # subscripts itself when unsubscripted. In other words, there is *NO* such
+#    # thing as an unsubscripted typed NumPy array. O_o
+#    def plug_beartype(
+#        name='NumpyArray',
+#        hint_reduce=reduce_hint_numpy_ndarray,
+#        hint_detect_from_repr_prefix_args_1_or_more='numpy.ndarray',
+#    )
+#
+#Yes, this would then permit us to break backward compatibility by bundling
+#that logic into a new external "beartype_numpy" plugin for @beartype -- but we
+#absolutely should *NOT* do that, both because it would severely break backward
+#compatibility *AND* because everyone (including us) wants NumPy support
+#out-of-the-box. We're all data scientists here. Do the right thing.
+
+#FIXME: [FEATURE] Define the following supplementary decorators:
+#* @beartype.beartype_O1(), identical to the current @beartype.beartype()
+#  decorator but provided for disambiguity. This decorator only type-checks
+#  exactly one item from each container for each call rather than all items.
+#* @beartype.beartype_Ologn(), type-checking log(n) random items from each
+#  container of "n" items for each call.
+#* @beartype.beartype_On(), type-checking all items from each container for
+#  each call. We have various ideas littered about GitHub on how to optimize
+#  this for various conditions, but this is never going to be ideal and should
+#  thus never be the default.
+#
+#To differentiate between these three strategies, consider:
+#* Declare an enumeration in "beartype._check.checkcall" resembling:
+#    from enum import Enum
+#    BeartypeStrategyKind = Enum('BeartypeStrategyKind ('O1', 'Ologn', 'On',))
+#* Define a new "BeartypeCall.strategy_kind" instance variable.
+#* Set this variable to the corresponding "BeartypeStrategyKind" enumeration
+#  member based on which of the three decorators listed above was called.
+#* Explicitly pass the value of the "BeartypeCall.strategy_kind" instance
+#  variable to the beartype._check.code.codemake.make_func_pith_code()
+#  function as a new memoized "strategy_kind" parameter.
+#* Conditionally generate type-checking code throughout that function depending
+#  on the value of that parameter.
+
+#FIXME: Emit one non-fatal warning for each annotated type that is either:
+#
+#* "beartype.cave.UnavailableType".
+#* "beartype.cave.UnavailableTypes".
+#
+#Both cases imply user-side misconfiguration, but not sufficiently awful enough
+#to warrant fatal exceptions. Moreover, emitting warnings rather than
+#exceptions enables end users to unconditionally disable all unwanted warnings,
+#whereas no such facilities exist for unwanted exceptions.
+#FIXME: Validate all tuple annotations to be non-empty *EXCLUDING*
+#"beartype.cave.UnavailableTypes", which is intentionally empty.
+#FIXME: Unit test the above edge case.
+
+#FIXME: Add support for all possible kinds of parameters. @beartype currently
+#supports most but *NOT* all types. Specifically:
+#
+#* Type-check variadic keyword arguments. Currently, only variadic positional
+#  arguments are type-checked. When doing so, remove the
+#  "Parameter.VAR_KEYWORD" type from the "_PARAM_KIND_IGNORABLE" set.
+#* Type-check positional-only arguments under Python >= 3.8. Note that, since
+#  C-based callables have *ALWAYS* supported positional-only arguments, the
+#  "Parameter.POSITIONAL_ONLY" type is defined for *ALL* Python versions
+#  despite only being usable in actual Python from Python >= 3.8. In other
+#  words, support for type-checking positional-only arguments should be added
+#  unconditionally without reference to Python version -- we suspect, anyway.
+#  When doing so, remove the "Parameter.POSITIONAL_ONLY" type from the
+#  "_PARAM_KIND_IGNORABLE" set.
+#* Remove the "_PARAM_KIND_IGNORABLE" set entirely.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/_decornontype.py
@@ -0,0 +1,811 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Unmemoized beartype non-type decorators** (i.e., low-level decorators
+decorating *all* types of decoratable objects except classes, which the sibling
+:mod:`beartype._decor._decortype` submodule handles, on behalf of the parent
+:mod:`beartype._decor.decorcore` submodule).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeDecorWrappeeException,
+    BeartypeDecorWrapperException,
+)
+from beartype.typing import no_type_check
+from beartype._cave._cavefast import (
+    MethodBoundInstanceOrClassType,
+    MethodDecoratorClassType,
+    MethodDecoratorBuiltinTypes,
+    MethodDecoratorPropertyType,
+    MethodDecoratorStaticType,
+)
+from beartype._check.checkcall import make_beartype_call
+from beartype._conf.confcls import BeartypeConf
+from beartype._conf.confenum import BeartypeStrategy
+from beartype._data.hint.datahinttyping import (
+    BeartypeableT,
+)
+from beartype._decor.wrap.wrapmain import generate_code
+from beartype._util.api.utilapibeartype import (
+    is_func_unbeartypeable,
+    set_func_beartyped,
+)
+from beartype._util.api.utilapicontextlib import (
+    is_func_contextlib_contextmanager)
+from beartype._util.api.utilapifunctools import is_func_functools_lru_cache
+from beartype._util.cache.pool.utilcachepoolobjecttyped import (
+    release_object_typed)
+from beartype._util.func.utilfuncget import get_func_boundmethod_self
+from beartype._util.func.utilfuncmake import make_func
+from beartype._util.func.utilfunctest import (
+    is_func_boundmethod,
+    is_func_python,
+)
+from beartype._util.func.utilfuncwrap import (
+    unwrap_func_once,
+    unwrap_func_boundmethod_once,
+    unwrap_func_classmethod_once,
+    unwrap_func_staticmethod_once,
+)
+from beartype._util.py.utilpyversion import IS_PYTHON_3_8
+from contextlib import contextmanager
+from functools import lru_cache
+
+# ....................{ DECORATORS ~ non-func              }....................
+def beartype_nontype(obj: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Decorate the passed **non-class beartypeable** (i.e., caller-defined object
+    that may be decorated by the :func:`beartype.beartype` decorator but is
+    *not* a class) with dynamically generated type-checking.
+
+    Parameters
+    ----------
+    obj : BeartypeableT
+        Non-class beartypeable to be decorated.
+
+    All remaining keyword parameters are passed as is to a lower-level decorator
+    defined by this submodule (e.g., :func:`.beartype_func`).
+
+    Returns
+    -------
+    BeartypeableT
+        New pure-Python callable wrapping this beartypeable with type-checking.
+    '''
+
+    # Validate that the passed object is *NOT* a class.
+    assert not isinstance(obj, type), f'{repr(obj)} is class.'
+    # print(f'Decorating non-type {repr(obj)}...')
+
+    # Type of this object.
+    obj_type = type(obj)
+
+    # If this object is an uncallable builtin method descriptor (i.e., either a
+    # property, class method, instance method, or static method object),
+    # @beartype was listed above rather than below the builtin decorator
+    # generating this descriptor in the chain of decorators decorating this
+    # decorated callable. Although @beartype typically *MUST* decorate a
+    # callable directly, this edge case is sufficiently common *AND* trivial to
+    # resolve to warrant doing so. To do so, this conditional branch effectively
+    # reorders @beartype to be the first decorator decorating the pure-Python
+    # function underlying this method descriptor: e.g.,
+    #     # This branch detects and reorders this edge case...
+    #     class MuhClass(object):
+    #         @beartype
+    #         @classmethod
+    #         def muh_classmethod(cls) -> None: pass
+    #
+    #     # ...to resemble this direct decoration instead.
+    #     class MuhClass(object):
+    #         @classmethod
+    #         @beartype
+    #         def muh_classmethod(cls) -> None: pass
+    #
+    # Note that most but *NOT* all of these objects are uncallable. Regardless,
+    # *ALL* of these objects are unsuitable for direct decoration. Specifically:
+    # * Under Python < 3.10, *ALL* of these objects are uncallable.
+    # * Under Python >= 3.10:
+    #   * Descriptors created by @classmethod and @property are uncallable.
+    #   * Descriptors created by @staticmethod are technically callable but
+    #     C-based and thus unsuitable for decoration.
+    if obj_type in MethodDecoratorBuiltinTypes:
+        return beartype_descriptor_decorator_builtin(obj, **kwargs)  # type: ignore[return-value]
+    # Else, this object is *NOT* an uncallable builtin method descriptor.
+    #
+    # If this object is uncallable, raise an exception.
+    elif not callable(obj):
+        raise BeartypeDecorWrappeeException(
+            f'Uncallable {repr(obj)} not decoratable by @beartype.')
+    # Else, this object is callable.
+    #
+    # If this object is *NOT* a pure-Python function, this object is a
+    # pseudo-callable (i.e., arbitrary pure-Python *OR* C-based object whose
+    # class defines the __call__() dunder method enabling this object to be
+    # called like a standard callable). In this case, attempt to monkey-patch
+    # runtime type-checking into this pure-Python callable by replacing the
+    # bound method descriptor of the type of this object implementing the
+    # __call__() dunder method with a comparable descriptor calling a
+    # @beartype-generated runtime type-checking wrapper function. Go with it.
+    elif not is_func_python(obj):
+        return beartype_pseudofunc(obj, **kwargs)  # type: ignore[return-value]
+    # Else, this object is a pure-Python function.
+    #
+    # If this function is a @contextlib.contextmanager-based isomorphic
+    # decorator closure (i.e., closure both created and returned by the standard
+    # @contextlib.contextmanager decorator where that closure isomorphically
+    # preserves both the number and types of all passed parameters and returns
+    # by accepting only a variadic positional argument and variadic keyword
+    # argument), @beartype was listed above rather than below the
+    # @contextlib.contextmanager decorator creating and returning this closure
+    # in the chain of decorators decorating this decorated callable. This is
+    # non-ideal, as the type of *ALL* objects created and returned by
+    # @contextlib.contextmanager-decorated context managers is a private class
+    # of the "contextlib" module rather than the types implied by the type hints
+    # originally annotating the returns of those context managers. If @beartype
+    # did *not* actively detect and intervene in this edge case, then runtime
+    # type-checkers dynamically generated by @beartype for those managers would
+    # erroneously raise type-checking violations after calling those managers
+    # and detecting the apparent type violation: e.g.,
+    #     >>> from beartype.typing import Iterator
+    #     >>> from contextlib import contextmanager
+    #     >>> @contextmanager
+    #     ... def muh_context_manager() -> Iterator[None]: yield
+    #     >>> type(muh_context_manager())
+    #     <class 'contextlib._GeneratorContextManager'>  # <-- not an "Iterator"
+    #
+    # This conditional branch effectively reorders @beartype to be the first
+    # decorator decorating the callable underlying this context manager,
+    # preserving consistency between return types *AND* return type hints: e.g.,
+    #     from beartype.typing import Iterator
+    #     from contextlib import contextmanager
+    #
+    #     # This branch detects and reorders this edge case...
+    #     @beartype
+    #     @contextmanager
+    #     def muh_contextmanager(cls) -> Iterator[None]: yield
+    #
+    #     # ...to resemble this direct decoration instead.
+    #     @contextmanager
+    #     @beartype
+    #     def muh_contextmanager(cls) -> Iterator[None]: yield
+    elif is_func_contextlib_contextmanager(obj):
+        return beartype_func_contextlib_contextmanager(obj, **kwargs)  # type: ignore[return-value]
+    # Else, this function is *NOT* a @contextlib.contextmanager-based isomorphic
+    # decorator closure.
+
+    # Return a new callable decorating that callable with type-checking.
+    return beartype_func(obj, **kwargs)  # type: ignore[return-value]
+
+# ....................{ DECORATORS ~ func                  }....................
+def beartype_func(
+    # Mandatory parameters.
+    func: BeartypeableT,
+    conf: BeartypeConf,
+
+    # Variadic keyword parameters.
+    **kwargs
+) -> BeartypeableT:
+    '''
+    Decorate the passed callable with dynamically generated type-checking.
+
+    Parameters
+    ----------
+    func : BeartypeableT
+        Callable to be decorated by :func:`beartype.beartype`.
+    conf : BeartypeConf
+        Beartype configuration configuring :func:`beartype.beartype` uniquely
+        specific to this callable.
+
+    All remaining keyword parameters are passed as is to the
+    :meth:`beartype._check.checkcall.BeartypeCall.reinit` method.
+
+    Returns
+    -------
+    BeartypeableT
+        New pure-Python callable wrapping this callable with type-checking.
+    '''
+    assert callable(func), f'{repr(func)} uncallable.'
+    # assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+    # assert isinstance(cls_root, NoneTypeOr[type]), (
+    #     f'{repr(cls_root)} neither type nor "None".')
+    # assert isinstance(cls_curr, NoneTypeOr[type]), (
+    #     f'{repr(cls_curr)} neither type nor "None".')
+
+    #FIXME: Uncomment to display all annotations in "pytest" tracebacks.
+    # func_hints = func.__annotations__
+
+    # If this configuration enables the no-time strategy performing *NO*
+    # type-checking, monkey-patch that callable with the standard
+    # @typing.no_type_check decorator detected above by the call to the
+    # is_func_unbeartypeable() tester on all subsequent decorations passed the
+    # same callable... Doing so prevents all subsequent decorations from
+    # erroneously ignoring this previously applied no-time strategy.
+    if conf.strategy is BeartypeStrategy.O0:
+        no_type_check(func)  # pyright: ignore[reportGeneralTypeIssues]
+    # Else, this configuration enables a positive-time strategy performing at
+    # least the minimal amount of type-checking.
+
+    # If that callable is unbeartypeable (i.e., if this decorator should
+    # preserve that callable as is rather than wrap that callable with
+    # constant-time type-checking), silently reduce to the identity decorator.
+    #
+    # Note that this conditional implicitly handles the prior conditional! :O
+    if is_func_unbeartypeable(func):  # type: ignore[arg-type]
+        # print(f'Ignoring unbeartypeable callable {repr(func)}...')
+        return func  # type: ignore[return-value]
+    # Else, that callable is beartypeable. Let's do this, folks.
+
+    # Beartype call metadata describing that callable.
+    bear_call = make_beartype_call(func, conf, **kwargs)  # pyright: ignore[reportGeneralTypeIssues]
+
+    # Generate the raw string of Python statements implementing this wrapper.
+    func_wrapper_code = generate_code(bear_call)
+
+    # If that callable requires *NO* type-checking, silently reduce to a noop
+    # and thus the identity decorator by returning that callable as is.
+    if not func_wrapper_code:
+        return func  # type: ignore[return-value]
+    # Else, that callable requires type-checking. Let's *REALLY* do this, fam.
+
+    # Function wrapping that callable with type-checking to be returned.
+    #
+    # For efficiency, this wrapper accesses *ONLY* local rather than global
+    # attributes. The latter incur a minor performance penalty, since local
+    # attributes take precedence over global attributes, implying all global
+    # attributes are *ALWAYS* first looked up as local attributes before falling
+    # back to being looked up as global attributes.
+    func_wrapper = make_func(
+        func_name=bear_call.func_wrapper_name,
+        func_code=func_wrapper_code,
+        func_locals=bear_call.func_wrapper_scope,
+
+        #FIXME: String formatting is infamously slow. As an optimization, it'd
+        #be strongly preferable to instead pass a lambda function accepting *NO*
+        #parameters and returning the desired string, which make_func() should
+        #then internally call on an as-needed basis to make this string: e.g.,
+        #    func_label_factory=lambda: f'@beartyped {bear_call.func_wrapper_name}() wrapper',
+        #
+        #This is trivial. The only question then is: "Which is actually faster?"
+        #Before finalizing this refactoring, let's profile both, adopt whichever
+        #outperforms the other, and then document this choice in make_func().
+        #FIXME: *WAIT.* We don't need a lambda at all. All we need is to:
+        #* Define a new BeartypeCall.label_func_wrapper() method resembling:
+        #      def label_func_wrapper(self) -> str:
+        #          return f'@beartyped {self.func_wrapper_name}() wrapper'
+        #* Refactor make_func() to accept a new optional keyword-only
+        #  "func_label_factory" parameter, passed here as:
+        #      func_label_factory=bear_call.label_func_wrapper,
+        #
+        #That's absolutely guaranteed to be the fastest approach.
+        func_label=f'@beartyped {bear_call.func_wrapper_name}() wrapper',
+
+        func_wrapped=func,
+        is_debug=conf.is_debug,
+        exception_cls=BeartypeDecorWrapperException,
+    )
+
+    # Declare this wrapper to be generated by @beartype, which tests for the
+    # existence of this attribute above to avoid re-decorating callables
+    # already decorated by @beartype by efficiently reducing to a noop.
+    set_func_beartyped(func_wrapper)
+
+    # Release this beartype call metadata back to its object pool.
+    release_object_typed(bear_call)
+
+    # Return this wrapper.
+    return func_wrapper  # type: ignore[return-value]
+
+
+def beartype_func_contextlib_contextmanager(
+    func: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Decorate the passed :func:`contextlib.contextmanager`-based **isomorphic
+    decorator closure** (i.e., closure both defined and returned by the standard
+    :func:`contextlib.contextmanager` decorator where that closure
+    isomorphically preserves both the number and types of all passed parameters
+    and returns by accepting only a variadic positional argument and variadic
+    keyword argument) with dynamically generated type-checking.
+
+    Parameters
+    ----------
+    descriptor : BeartypeableT
+        Context manager to be decorated by :func:`beartype.beartype`.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.beartype_func` decorator internally called by this higher-level
+    decorator on the pure-Python function encapsulated in this descriptor.
+
+    Returns
+    -------
+    BeartypeableT
+        New pure-Python callable wrapping this context manager with
+        type-checking.
+    '''
+
+    # Original pure-Python generator factory function decorated by
+    # @contextlib.contextmanager.
+    generator = unwrap_func_once(func)
+
+    # Decorate this generator factory function with type-checking.
+    generator_checked = beartype_func(func=generator, **kwargs)
+
+    # Re-decorate this generator factory function by @contextlib.contextmanager.
+    generator_checked_contextmanager = contextmanager(generator_checked)
+
+    # Return this context manager.
+    return generator_checked_contextmanager  # type: ignore[return-value]
+
+# ....................{ DECORATORS ~ descriptor            }....................
+def beartype_descriptor_decorator_builtin(
+    descriptor: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Decorate the passed **builtin decorator object** (i.e., C-based unbound
+    method descriptor produced by the builtin :class:`classmethod`,
+    :class:`property`, or :class:`staticmethod` decorators) with dynamically
+    generated type-checking.
+
+    Parameters
+    ----------
+    descriptor : BeartypeableT
+        Descriptor to be decorated by :func:`beartype.beartype`.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.beartype_func` decorator internally called by this higher-level
+    decorator on the pure-Python function encapsulated in this descriptor.
+
+    Returns
+    -------
+    BeartypeableT
+        New pure-Python callable wrapping this descriptor with type-checking.
+
+    Raises
+    ------
+    BeartypeDecorWrappeeException
+        If this descriptor is neither a class, property, or static method
+        descriptor.
+    '''
+    # assert isinstance(descriptor, MethodDecoratorBuiltinTypes), (
+    #     f'{repr(descriptor)} not builtin method descriptor.')
+    # assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+
+    # Type of this descriptor.
+    descriptor_type = type(descriptor)
+
+    # If this descriptor is a property method...
+    #
+    # Note that property method descriptors are intentionally tested next, due
+    # to their ubiquity "in the wild." Class and static method descriptors are
+    # comparatively rarefied by comparison.
+    if descriptor_type is MethodDecoratorPropertyType:
+        # Pure-Python unbound getter, setter, and deleter functions wrapped by
+        # this descriptor if any *OR* "None" otherwise (i.e., for each such
+        # function currently unwrapped by this descriptor).
+        descriptor_getter  = descriptor.fget  # type: ignore[assignment,union-attr]
+        descriptor_setter  = descriptor.fset  # type: ignore[assignment,union-attr]
+        descriptor_deleter = descriptor.fdel  # type: ignore[assignment,union-attr]
+
+        # Decorate this getter function with type-checking.
+        #
+        # Note that *ALL* property method descriptors wrap at least a getter
+        # function (but *NOT* necessarily a setter or deleter function). This
+        # function is thus guaranteed to be non-"None".
+        descriptor_getter = beartype_func(  # type: ignore[type-var]
+            func=descriptor_getter,  # pyright: ignore
+            **kwargs
+        )
+
+        # If this property method descriptor additionally wraps a setter and/or
+        # deleter function, type-check those functions as well.
+        if descriptor_setter is not None:
+            descriptor_setter = beartype_func(descriptor_setter, **kwargs)
+        if descriptor_deleter is not None:
+            descriptor_deleter = beartype_func(descriptor_deleter, **kwargs)
+
+        # Return a new property method descriptor decorating all of these
+        # functions, implicitly destroying the prior descriptor.
+        #
+        # Note that the "property" class interestingly has this signature:
+        #     class property(fget=None, fset=None, fdel=None, doc=None): ...
+        return property(  # type: ignore[return-value]
+            fget=descriptor_getter,
+            fset=descriptor_setter,
+            fdel=descriptor_deleter,
+            doc=descriptor.__doc__,
+        )
+    # Else, this descriptor is *NOT* a property method.
+    #
+    # If this descriptor is a class method...
+    elif descriptor_type is MethodDecoratorClassType:
+        # Possibly C-based callable wrappee object decorated by this descriptor.
+        #
+        # Note that this wrappee is typically but *NOT* necessarily a
+        # pure-Python unbound function. This descriptor explicitly permits the
+        # decorated object to be a callable C-based type (i.e., defining the
+        # __call__() dunder method), which numerous standard and third-party
+        # pure-Python classes then leverage to augment those classes into
+        # subscriptable type hint factories via a simple one-liner: e.g.,
+        #     from abc import ABCMeta
+        #     from beartype import beartype
+        #     from types import GenericAlias
+        #
+        #     @beartype
+        #     class MuhTypeHintFactory(metaclass=ABCMeta):
+        #         # This exact one liner appears verbatim throughout the
+        #         # standard library (as well as third-party packages).
+        #         __class_getitem__ = classmethod(GenericAlias)
+        #
+        # Ergo, the name "__func__" of this dunder attribute is disingenuous.
+        # This descriptor does *NOT* merely decorate functions; this descriptor
+        # permissively decorates all callable objects.
+        descriptor_wrappee = unwrap_func_classmethod_once(descriptor)  # type: ignore[arg-type]
+
+        # If this wrappee is *NOT* a pure-Python unbound function, this wrappee
+        # is C-based and/or a type. In either case, avoid type-checking this
+        # wrappee by silently preserving this descriptor as is. Why? If this
+        # wrappee is:
+        # * C-based, this wrappee *CANNOT* be decorated with type-checking.
+        # * A type, this wrappee *COULD* be effectively decorated with
+        #   type-checking by decorating its __call__() dunder method. However,
+        #   this type may *NOT* have been intended to be decorated by @beartype.
+        #   Indeed, this type may *NOT* even reside within the same package.
+        #   That the current class references this type is an insufficient
+        #   reason to transitively decorate external types without user consent.
+        if not is_func_python(descriptor_wrappee):
+            return descriptor
+        # Else, this wrappee is a pure-Python unbound function.
+
+        # Pure-Python unbound function type-checking this class method.
+        # Note that:
+        # * Python 3.8, 3.9, and 3.10 explicitly permit the @classmethod
+        #   decorator to be chained into the @property decorator: e.g.,
+        #       class MuhClass(object):
+        #           @classmethod  # <-- this is fine under Python < 3.11
+        #           @property
+        #           def muh_property(self) -> ...: ...
+        # * Python ≥ 3.11 explicitly prohibits that by emitting a non-fatal
+        #   "DeprecationWarning" on each attempt to do so. Under Python ≥ 3.11,
+        #   users *MUST* instead refactor the above simplistic decorator
+        #   chaining use case as follows:
+        #   * Define a metaclass for each class requiring a class property.
+        #   * Define each class property on that metaclass rather than on that
+        #     class instead.
+        #
+        #   In other words:
+        #       class MuhClassMeta(type):  # <-- Python ≥ 3.11 demands sacrifice
+        #          '''
+        #          Metaclass of the :class`.MuhClass` class, defining class
+        #          properties for that class.
+        #          '''
+        #
+        #          @property
+        #          def muh_property(cls) -> ...: ...
+        #
+        #      class MuhClass(object, metaclass=MuhClassMeta):
+        #          pass
+        # * Technically, all Python versions currently supported by @beartype
+        #   permit this. Ergo, @beartype currently defers to:
+        #   * The high-level beartype_nontype() decorator (which permits the
+        #     passed object to be the descriptor created and returned by the
+        #     @property decorator and thus implicitly allows @classmethod to be
+        #     chained into @property) rather than...
+        #   * The low-level beartype_func() decorator (which requires the passed
+        #     object to be callable, which the descriptor created and returned
+        #     by the @property decorator is *NOT*).
+        func_checked = beartype_nontype(descriptor_wrappee,  **kwargs)
+
+        # Return a new class method descriptor decorating the pure-Python
+        # unbound function wrapped by this descriptor with type-checking,
+        # implicitly destroying the prior descriptor.
+        return classmethod(func_checked)  # type: ignore[return-value]
+    # Else, this descriptor is *NOT* a class method.
+    #
+    # If this descriptor is a static method...
+    elif descriptor_type is MethodDecoratorStaticType:
+        # Possibly C-based callable wrappee object decorated by this descriptor.
+        descriptor_wrappee = unwrap_func_staticmethod_once(descriptor)  # type: ignore[arg-type]
+
+        # Pure-Python unbound function type-checking this static method.
+        func_checked = beartype_func(descriptor_wrappee, **kwargs) # type: ignore[union-attr]
+
+        # Return a new static method descriptor decorating the pure-Python
+        # unbound function wrapped by this descriptor with type-checking,
+        # implicitly destroying the prior descriptor.
+        return staticmethod(func_checked)  # type: ignore[return-value]
+    # Else, this descriptor is *NOT* a static method.
+
+    # Raise a fallback exception. This should *NEVER happen. This *WILL* happen.
+    raise BeartypeDecorWrappeeException(
+        f'Builtin method descriptor {repr(descriptor)} '
+        f'not decoratable by @beartype '
+        f'(i.e., neither property, class method, nor static method descriptor).'
+    )
+
+# ....................{ PRIVATE ~ decorators               }....................
+def _beartype_descriptor_boundmethod(
+    descriptor: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Decorate the passed **builtin bound method object** (i.e., C-based bound
+    method descriptor produced by Python on instantiation for each instance and
+    class method defined by the class being instantiated) with dynamically
+    generated type-checking.
+
+    Parameters
+    ----------
+    descriptor : BeartypeableT
+        Descriptor to be decorated by :func:`beartype.beartype`.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.beartype_func` decorator internally called by this higher-level
+    decorator on the pure-Python function encapsulated in this descriptor.
+
+    Returns
+    -------
+    BeartypeableT
+        New pure-Python callable wrapping this descriptor with type-checking.
+    '''
+    assert is_func_boundmethod(descriptor), (
+        f'{repr(descriptor)} not builtin bound method descriptor.')
+
+    # Possibly C-based callable wrappee object encapsulated by this descriptor.
+    descriptor_wrappee = unwrap_func_boundmethod_once(descriptor)
+
+    # Instance object to which this descriptor was bound at instantiation time.
+    descriptor_self = get_func_boundmethod_self(descriptor)
+
+    # Pure-Python unbound function decorating the similarly pure-Python unbound
+    # function encapsulated by this descriptor with type-checking.
+    #
+    # Note that doing so:
+    # * Implicitly propagates dunder attributes (e.g., "__annotations__",
+    #   "__doc__") from the original function onto this new function. Good.
+    # * Does *NOT* implicitly propagate the same dunder attributes from the
+    #   original descriptor encapsulating the original function to the new
+    #   descriptor (created below) encapsulating this wrapper function. Bad!
+    #   Thankfully, only one such attribute exists as of this time: "__doc__".
+    #   We propagate this attribute manually below.
+    func_checked = beartype_func(func=descriptor_wrappee, **kwargs)  # pyright: ignore
+
+    # New instance method descriptor rebinding this function to the instance of
+    # the class bound to the prior descriptor.
+    #
+    # Note that:
+    # * This is required, as the "__func__" attribute of method descriptors is
+    #   read-only. Attempting to do so raises this non-human-readable exception:
+    #     AttributeError: readonly attribute
+    #   This implies that the passed descriptor *CANNOT* be meaningfully
+    #   modified. Our only recourse is to define an entirely new descriptor,
+    #   effectively discarding the passed descriptor, which will then be
+    #   subsequently garbage-collected. This is wasteful. This is Python.
+    # * This can also be implemented by abusing the descriptor protocol:
+    #       descriptor_new = descriptor_func_new.__get__(descriptor.__self__)
+    #   That said, there exist *NO* benefits to doing so. Indeed, doing so only
+    #   reduces the legibility and maintainability of this operation.
+    descriptor_new = MethodBoundInstanceOrClassType(
+        func_checked, descriptor_self)  # type: ignore[return-value]
+
+    #FIXME: Actually, Python doesn't appear to support this at the moment.
+    #Attempting to do so raises this exception:
+    #    AttributeError: attribute '__doc__' of 'method' objects is not writable
+    #
+    #See also this open issue on the Python bug tracker requesting this be
+    #resolved. Sadly, Python has yet to resolve this:
+    #    https://bugs.python.org/issue47153
+    # # Propagate the docstring from the prior to the new descriptor.
+    # #
+    # # Note that Python guarantees this attribute to exist. If the original
+    # # function had a docstring, this attribute is non-"None"; else, this
+    # # attribute is "None". In either case, this attribute exists. Ergo,
+    # # additional validation is neither required nor desired.
+    # descriptor_new.__doc__ = descriptor.__doc__
+
+    # Return this new descriptor, implicitly destroying the prior descriptor.
+    return descriptor_new  # type: ignore[return-value]
+
+# ....................{ DECORATORS ~ pseudo-callable       }....................
+def beartype_pseudofunc(pseudofunc: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Monkey-patch the passed **pseudo-callable** (i.e., arbitrary pure-Python
+    *or* C-based object whose class defines the ``__call__``) dunder method
+    enabling this object to be called like a standard callable) with dynamically
+    generated type-checking.
+
+    For each bound method descriptor encapsulating a method bound to this
+    object, this function monkey-patches (i.e., replaces) that descriptor with a
+    comparable descriptor calling a new :func:`beartype.beartype`-generated
+    runtime type-checking wrapper function wrapping the original method.
+
+    Parameters
+    ----------
+    pseudofunc : BeartypeableT
+        Pseudo-callable to be monkey-patched by :func:`beartype.beartype`.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.beartype_func` decorator internally called by this higher-level
+    decorator on the pure-Python function encapsulated in this descriptor.
+
+    Returns
+    -------
+    BeartypeableT
+        The object monkey-patched by :func:`beartype.beartype`.
+    '''
+    # print(f'@beartyping pseudo-callable {repr(obj)}...')
+
+    # __call__() dunder method defined by this object if this object defines
+    # this method *OR* "None" otherwise.
+    pseudofunc_call_method = getattr(pseudofunc, '__call__')
+
+    # If this object does *NOT* define this method, this object is *NOT* a
+    # pseudo-callable. In this case, raise an exception.
+    #
+    # Note this edge case should *NEVER* occur. By definition, this object has
+    # already been validated to be callable. But this object is *NOT* a
+    # pure-Python function. Since the only other category of callable in Python
+    # is a pseudo-callable, this object *MUST* be a pseudo-callable. That said,
+    # languages change; it's not inconceivable that Python could introduce yet
+    # another kind of callable object under future versions.
+    if pseudofunc_call_method is None:
+        raise BeartypeDecorWrappeeException(  # pragma: no cover
+            f'Callable {repr(pseudofunc)} not pseudo-callable '
+            f'(i.e., callable object defining __call__() dunder method).'
+        )
+    # Else, this object is a pseudo-callable.
+    #
+    # If this method is *NOT* pure-Python, this method is C-based. In this
+    # case...
+    #
+    # Note that this is non-ideal. Whereas logic below safely monkey-patches
+    # pure-Python pseudo-callables in a general-purpose manner, that same logic
+    # does *NOT* apply to C-based pseudo-callables; indeed, there exists *NO*
+    # general-purpose means of safely monkey-patching the latter. Instead,
+    # specific instances of the latter *MUST* be manually detected and handled.
+    elif not is_func_python(pseudofunc_call_method):
+        # If this is a C-based @functools.lru_cache-memoized callable (i.e.,
+        # low-level C-based callable object both created and returned by the
+        # standard @functools.lru_cache decorator), @beartype was listed above
+        # rather than below the @functools.lru_cache decorator creating and
+        # returning this callable in the chain of decorators decorating this
+        # decorated callable.
+        #
+        # This conditional branch effectively reorders @beartype to be the first
+        # decorator decorating the pure-Python callable underlying this C-based
+        # pseudo-callable: e.g.,
+        #
+        #     from functools import lru_cache
+        #
+        #     # This branch detects and reorders this edge case...
+        #     @beartype
+        #     @lru_cache
+        #     def muh_lru_cache() -> None: pass
+        #
+        #     # ...to resemble this direct decoration instead.
+        #     @lru_cache
+        #     @beartype
+        #     def muh_lru_cache() -> None: pass
+        if is_func_functools_lru_cache(pseudofunc):
+            # Return a new callable decorating that callable with type-checking.
+            return beartype_pseudofunc_functools_lru_cache(  # type: ignore
+                pseudofunc=pseudofunc, **kwargs)  # pyright: ignore
+        # Else, this is *NOT* a C-based @functools.lru_cache-memoized callable.
+
+    # Replace the existing bound method descriptor to this __call__() dunder
+    # method with a new bound method descriptor to a new __call__() dunder
+    # method wrapping the old method with runtime type-checking.
+    #
+    # Note that:
+    # * This is a monkey-patch. Since the caller is intentionally decorating
+    #   this pseudo-callable with @beartype, this is exactly what the caller
+    #   wanted. Probably. Hopefully. Okay! We're crossing our fingers here.
+    # * This monkey-patches the *CLASS* of this object rather than this object
+    #   itself. Why? Because Python. For unknown reasons (so, speed is what
+    #   we're saying), Python accesses the __call__() dunder method on the
+    #   *CLASS* of an object rather than on the object itself. Of course, this
+    #   implies that *ALL* instances of this pseudo-callable (rather than merely
+    #   the passed instance) will be monkey-patched. This may *NOT* necessarily
+    #   be what the caller wanted. Unfortunately, the only alternative would be
+    #   for @beartype to raise an exception when passed a pseudo-callable. Since
+    #   doing something beneficial is generally preferable to doing something
+    #   harmful, @beartype prefers the former. See also official documentation
+    #   on the subject:
+    #       https://docs.python.org/3/reference/datamodel.html#special-method-names
+    pseudofunc.__class__.__call__ = _beartype_descriptor_boundmethod(  # type: ignore[assignment,method-assign]
+        descriptor=pseudofunc_call_method, **kwargs)
+
+    # Return this monkey-patched object.
+    return pseudofunc  # type: ignore[return-value]
+
+
+def beartype_pseudofunc_functools_lru_cache(
+    pseudofunc: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Monkey-patch the passed :func:`functools.lru_cache`-memoized
+    **pseudo-callable** (i.e., low-level C-based callable object both created
+    and returned by the standard :func:`functools.lru_cache` decorator) with
+    dynamically generated type-checking.
+
+    Parameters
+    ----------
+    pseudofunc : BeartypeableT
+        Pseudo-callable to be monkey-patched by :func:`beartype.beartype`.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.beartype_func` decorator internally called by this higher-level
+    decorator on the pure-Python function encapsulated in this descriptor.
+
+    Returns
+    -------
+    BeartypeableT
+        New pseudo-callable monkey-patched by :func:`beartype.beartype`.
+    '''
+
+    # If this pseudo-callable is *NOT* actually a @functools.lru_cache-memoized
+    # callable, raise an exception.
+    if not is_func_functools_lru_cache(pseudofunc):
+        raise BeartypeDecorWrappeeException(  # pragma: no cover
+            f'@functools.lru_cache-memoized callable {repr(pseudofunc)} not  '
+            f'decorated by @functools.lru_cache.'
+        )
+    # Else, this pseudo-callable is a @functools.lru_cache-memoized callable.
+
+    # Original pure-Python callable decorated by @functools.lru_cache.
+    func = unwrap_func_once(pseudofunc)
+
+    # If the active Python interpreter targets Python 3.8, then this
+    # pseudo-callable fails to declare the cache_parameters() lambda function
+    # called below to recover the keyword parameters originally passed by the
+    # caller to that decorator. In this case, we have *NO* recourse but to
+    # explicitly inform the caller of this edge case by raising a human-readable
+    # exception providing a pragmatic workaround.
+    if IS_PYTHON_3_8:
+        raise BeartypeDecorWrappeeException(  # pragma: no cover
+            f'@functools.lru_cache-memoized callable {repr(func)} not '
+            f'decoratable by @beartype under Python 3.8. '
+            f'Consider manually decorating this callable by '
+            f'@beartype first and then by @functools.lru_cache to preserve '
+            f'Python 3.8 compatibility: e.g.,\n'
+            f'    # Do this...\n'
+            f'    @lru_cache(maxsize=42)\n'
+            f'    @beartype\n'
+            f'    def muh_func(...) -> ...: ...\n'
+            f'\n'
+            f'    # Rather than either this...\n'
+            f'    @beartype\n'
+            f'    @lru_cache(maxsize=42)\n'
+            f'    def muh_func(...) -> ...: ...\n'
+            f'\n'
+            f'    # Or this (if you use "beartype.claw", which you really should).\n'
+            f'    @lru_cache(maxsize=42)\n'
+            f'    def muh_func(...) -> ...: ...\n'
+        )
+    # Else, the active Python interpreter targets Python >= 3.9.
+
+    # Decorate that callable with type-checking.
+    func_checked = beartype_func(func=func, **kwargs)
+
+    # Dictionary mapping from the names of all keyword parameters originally
+    # passed by the caller to that decorator, enabling the re-decoration of that
+    # callable. Thankfully, that decorator preserves these parameters via the
+    # decorator-specific "cache_parameters" instance variable whose value is a
+    # bizarre argumentless lambda function (...for unknown reasons that are
+    # probably indefensible) creating and returning this dictionary: e.g.,
+    #     >>> from functools import lru_cache
+    #     >>> @lru_cache(maxsize=3)
+    #     ... def plus_one(n: int) -> int: return n +1
+    #     >>> plus_one.cache_parameters()
+    #     {'maxsize': 3, 'typed': False}
+    lru_cache_kwargs = pseudofunc.cache_parameters()  # type: ignore[attr-defined]
+
+    # Closure defined and returned by the @functools.lru_cache decorator when
+    # passed these keyword parameters.
+    lru_cache_configured = lru_cache(**lru_cache_kwargs)
+
+    # Re-decorate that callable by @functools.lru_cache by the same parameters
+    # originally passed by the caller to that decorator.
+    pseudofunc_checked = lru_cache_configured(func_checked)
+
+    # Return that new pseudo-callable.
+    return pseudofunc_checked
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/_decortype.py
@@ -0,0 +1,435 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Unmemoized beartype type decorators** (i.e., low-level decorators decorating
+classes on behalf of the parent :mod:`beartype._decor.decorcore` submodule).
+
+This private submodule is effectively the :func:`beartype.beartype` decorator
+despite *not* actually being that decorator (due to being unmemoized).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Dict,
+    Set,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._check.checkcache import clear_checker_caches
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.cls.datacls import TYPES_BEARTYPEABLE
+from beartype._data.hint.datahinttyping import (
+    BeartypeableT,
+    TypeStack,
+)
+from beartype._util.cls.utilclsset import set_type_attr
+from beartype._util.module.utilmodget import get_object_module_name_or_none
+from collections import defaultdict
+from functools import wraps
+
+# ....................{ DECORATORS ~ type                  }....................
+def beartype_type(
+    # Mandatory parameters.
+    cls: BeartypeableT,
+    conf: BeartypeConf,
+
+    # Optional parameters.
+    cls_stack: TypeStack = None,
+) -> BeartypeableT:
+    '''
+    Decorate the passed class with dynamically generated type-checking.
+
+    Parameters
+    ----------
+    cls : BeartypeableT
+        Class to be decorated by :func:`beartype.beartype`.
+    conf : BeartypeConf
+        Beartype configuration configuring :func:`beartype.beartype` uniquely
+        specific to this class.
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either a tuple of the one or more
+        :func:`beartype.beartype`-decorated classes lexically containing the
+        class variable or method annotated by this hint *or* :data:`None`).
+        Defaults to :data:`None`.
+
+    Returns
+    ----------
+    BeartypeableT
+        This class decorated by :func:`beartype.beartype`.
+    '''
+    assert isinstance(cls, type), f'{repr(cls)} not type.'
+    assert isinstance(cls_stack, NoneTypeOr[tuple]), (
+        f'{repr(cls_stack)} neither tuple nor "None".')
+    # assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+    # print(f'Decorating type {repr(obj)}...')
+
+    # ....................{ IMPORTS                        }....................
+    # Avoid circular import dependencies.
+    from beartype._decor.decorcore import beartype_object
+
+    # ....................{ NOOP                           }....................
+    # Original C-based __sizeof__() dunder method defined by this class, which
+    # this decorator subsequently wraps with a pure-Python __sizeof__() dunder
+    # method. Why? Tangential reasons that are obscure, profane, and have
+    # absolutely *NOTHING* to do with the __sizeof__() dunder method itself.
+    # Succinctly, @beartype needs a reasonably safe place to persist
+    # @beartype-specific attributes pertaining to this class.
+    #
+    # Clearly, the obvious place would be this class itself. However, doing so
+    # would fundamentally modify this class and thus *ALL* instances of this
+    # class in an unexpected and thus possibly unsafe manner. Consider common
+    # use cases like slots, introspection, pickling, and sizing. Clearly,
+    # monkey-patching attributes into class dictionaries without the explicit
+    # consent of class designers is an ill-advised approach.
+    #
+    # A less obvious but safer place is required. A method of this class would
+    # be the ideal candidate; whereas everybody cares about object attributes
+    # and thus class dictionaries, nobody cares about method attributes. This is
+    # why @beartype safely monkey-patches attributes into @beartype-decorated
+    # methods. However, which method? Most methods are *NOT* guaranteed to exist
+    # across all possible classes. Adding a new method to this class would be no
+    # better than adding a new attribute to this class; both modify class
+    # dictionaries. Fortunately, Python currently guarantees *ALL* classes to
+    # define at least 24 dunder methods as of Python 3.11. How? Via the root
+    # "object" superclass. Unfortunately, *ALL* of these methods are C-based and
+    # thus do *NOT* directly support monkey-patching: e.g.,
+    #     >>> class AhMahGoddess(object): pass
+    #     >>> AhMahGoddess.__init__.__beartyped_cls = AhMahGoddess
+    #     AttributeError: 'wrapper_descriptor' object has no attribute
+    #     '__beartyped_cls'
+    #
+    # Fortunately, *ALL* of these methods may be wrapped by pure-Python
+    # equivalents whose implementations defer to their original C-based methods.
+    # Unfortunately, doing so slightly reduces the efficiency of calling these
+    # methods. Fortunately, a subset of these methods are rarely called under
+    # production workloads; slightly reducing the efficiency of calling these
+    # methods is irrelevant to almost all use cases. Of these, the most obscure,
+    # largely useless, poorly documented, and single-use is the __sizeof__()
+    # dunder method -- which is only ever called by the sys.getsizeof() utility
+    # function, which itself is only ever called manually in a REPL or by
+    # third-party object sizing packages. In short, __sizeof__() is perfect.
+    cls_sizeof_old = cls.__sizeof__
+
+    # True only if this decorator has already decorated this class, as indicated
+    # by the @beartype-specific class variable "__beartyped_cls" monkey-patched
+    # into a pure-Python __sizeof__() dunder method wrapper by a prior call to
+    # this decorator passed this class.
+    is_cls_beartyped = getattr(cls_sizeof_old, '__beartyped_cls', None)
+
+    # If the value of this variable is that of this class, a prior call to this
+    # decorator has already decorated this class. In this case, silently reduce
+    # to a noop by returning this class as is.
+    #
+    # See where this variable is set below for further details.
+    if is_cls_beartyped is cls:
+        # print(f'Ignoring repeat decoration of {repr(cls)}...')
+        return cls  # type: ignore[return-value]
+    # Else, this decorator has yet to decorate this class.
+
+    # ....................{ LOCALS                         }....................
+    # Replace the passed class stack with a new class stack appending this
+    # decorated class to the top of this stack, reflecting the fact that this
+    # decorated class is now the most deeply lexically nested class for the
+    # currently recursive chain of @beartype-decorated classes.
+    cls_stack = (
+        # If the caller passed *NO* class stack, then this class is necessarily
+        # the first decorated class being decorated directly by @beartype and
+        # thus the root decorated class.
+        #
+        # Note this is the common case and thus tested first. Since nested
+        # classes effectively do *NOT* exist in the wild, this comprises
+        # 99.999% of all real-world cases.
+        (cls,)
+        if cls_stack is None else
+        # Else, the caller passed a clack stack comprising at least a root
+        # decorated class. Preserve that class as is to properly expose that
+        # class elsewhere.
+        cls_stack + (cls,)
+    )
+
+    # ....................{ DECORATION                     }....................
+    # Clear *ALL* beartype-specific internal caches that have been shown to fail
+    # when a class is redefined if the passed class is detected as having been
+    # redefined in its module.
+    _uncache_beartype_if_type_redefined(cls)
+
+    # For the unqualified name and value of each direct (i.e., *NOT* indirectly
+    # inherited) attribute of this class...
+    for attr_name, attr_value in cls.__dict__.items():  # pyright: ignore[reportGeneralTypeIssues]
+        # True only if this attribute is directly beartypeable (e.g., is either
+        # a function, class, or builtin method descriptor).
+        is_attr_beartypeable = isinstance(attr_value, TYPES_BEARTYPEABLE)
+
+        # If this attribute is *NOT* directly beartypeable (e.g., is neither a
+        # function, class, nor builtin method descriptor), this attribute
+        # *COULD* still be indirectly beartypeable. How? By being a non-standard
+        # object implemented by some third-party package wrapping a standard
+        # object that *is* directly beartypeable. Although the original use case
+        # was non-standard function wrappers implemented by the third-party
+        # Equinox package, this logic transparently generalizes to *ALL*
+        # third-party packages. Consequently, *ALL* third-party packages
+        # defining non-standard objects wrapping standard objects should
+        # endeavour to support @beartype by reproducing the general-purpose
+        # solution that Equinox adopted.
+        #
+        # Notably, third-party packages should ideally add "support for such
+        # monkey-patching, by adding a __setattr__() that checks for functions
+        # and wraps them into one of Equinox's function-wrappers." See also:
+        #     https://github.com/patrick-kidger/equinox/issues/584#issuecomment-1806260288
+        #
+        # Specifically, if this attribute is *NOT* directly beartypeable...
+        if not is_attr_beartypeable:
+            # Uncomment to debug this insanity. *sigh*
+            # attr_value_old = attr_value
+
+            # Override the previously retrieved static value of this attribute
+            # (i.e., the direct value of this attribute *WITHOUT* regard to
+            # dynamic descriptor lookup, which in the case of a standard
+            # descriptor builtin like @classmethod is that C-based @classmethod
+            # descriptor itself) with the dynamic value of this attribute
+            # (i.e., the indirect value of this attribute *WITH* regard to
+            # dynamic descriptor lookup, which in the case of a standard
+            # descriptor builtin like @classmethod is the pure-Python function
+            # wrapped by that C-based @classmethod descriptor) if this attribute
+            # supports the descriptor protocol *OR* reduce to a noop otherwise.
+            attr_value = getattr(cls, attr_name)
+
+            # True only if this attribute is directly beartypeable.
+            is_attr_beartypeable = isinstance(attr_value, TYPES_BEARTYPEABLE)
+        # Else, this attribute is directly beartypeable.
+
+        # If this attribute is...
+        if (
+            # Now directly beartypeable *AND*...
+            is_attr_beartypeable and
+            # It is *NOT* the case that...
+            #
+            # Note that this condition intentionally excludes class variables
+            # whose values are types from consideration, thus preventing
+            # @beartype from erroneously decorating those types. Why? Because
+            # the caller did *NOT* explicitly instruct us to decorate those
+            # types. Moreover, attempting to do so can ignite infinite recursion
+            # in common edge cases and is thus fundamentally dangerous.
+            #
+            # Consider this sample user-defined class:
+            #     class ParentClass(object):
+            #         class_var: type = type
+            #         class NestedClass(object):
+            #             pass
+            #
+            # Syntactically, the class variable "ParentClass.class_var" and
+            # nested class "ParentClass.NestedClass" share *NO* commonality.
+            # Semantically, however, @beartype treats those two attributes of
+            # the parent class "ParentClass" as effectively identical. The
+            # values of those two attributes are both classes, which @beartype
+            # typically tries to recursively decorate. But only the latter are
+            # safely decoratable by @beartype.
+            #
+            # Class variables whose values are types are *NOT* safely
+            # decoratable by @beartype. In the best case, doing so would
+            # decorate external classes *NOT* intended to be decorated; in the
+            # worst case, doing so would provoke infinite recursion. Indeed, the
+            # worst case is exactly what once happened. Previously, decorating
+            # concrete "enum.Enum" subclasses with @beartype once provoked
+            # infinite recursion. Why? Because:
+            #
+            # * *ALL* "enum.Enum" subclasses define a private "_member_type_"
+            #   attribute whose value is the "object" superclass, which
+            #   @beartype then decorated.
+            # * However, the "object" superclass defines the "__class__" dunder
+            #   attribute whose value is the "type" superclass, which @beartype
+            #   then decorated.
+            # * However, the "type" superclass defines the "__base__" dunder
+            #   attribute whose value is the "object" superclass, which
+            #   @beartype then decorated.
+            # * *INFINITE FRIGGIN' RECURSION*. Anarchy today.
+            #
+            # In both the best and worst cases above, class variables whose
+            # values are types *CANNOT* be safely decorated by @beartype.
+            not (
+                # This attribute is a class *AND*...
+                isinstance(attr_value, type) and
+                # This class was declared elsewhere and merely defined here as a
+                # class attribute of the currently decorated class whose value
+                # is this class (rather than as a nested class of the currently
+                # decorated class)...
+                not attr_value.__qualname__.startswith(cls.__qualname__)
+            )
+        ):
+            # This attribute decorated with type-checking configured by this
+            # configuration if *NOT* already decorated.
+            attr_value_beartyped = beartype_object(
+                obj=attr_value,
+                conf=conf,
+                cls_stack=cls_stack,
+            )
+
+            # Replace this undecorated attribute with this decorated attribute.
+            set_type_attr(cls, attr_name, attr_value_beartyped)
+            # print(f'Decorating {repr(cls)} attribute "{attr_name}"...')
+            # print(f'type: {type(attr_value)}; dir: {dir(attr_value)}')
+        # Else, this attribute is *NOT* beartypeable. In this case, silently
+        # ignore this attribute.
+
+    # ....................{ MONKEY-PATCH                   }....................
+    # Pure-Python __sizeof__() dunder method wrapping the original C-based
+    # __sizeof__() dunder method declared by this class.
+    @wraps(cls_sizeof_old)
+    def cls_sizeof_new(self) -> int:
+        return cls_sizeof_old(self)  # type: ignore[call-arg]
+
+    # Monkey-patch a @beartype-specific instance variable into this wrapper,
+    # recording that this decorator has now decorated this class.
+    #
+    # Note that we intentionally set this variable to this class rather than an
+    # arbitrary value (e.g., "False", "None"). Why? Because subclasses of this
+    # class will inherit this wrapper. If we simply set this variable to an
+    # arbitrary value, we would be unable to decide above between the following
+    # two cases:
+    # * Whether this wrapper was inherited from its superclass, in which case
+    #   this class has yet to be decorated by @beartype.
+    # * Whether this wrapper was *NOT* inherited from its superclass, in which
+    #   case this class has already been decorated by @beartype.
+    cls_sizeof_new.__beartyped_cls = cls  # type: ignore[attr-defined]
+
+    # Replace the original C-based __sizeof__() dunder method with this wrapper.
+    # We intentionally call our set_type_attr() setter rather than attempting to
+    # set this attribute directly. The latter approach efficiently succeeds for
+    # standard pure-Python mutable classes but catastrophically fails for
+    # non-standard C-based immutable classes (e.g., "enum.Enum" subclasses).
+    set_type_attr(cls, '__sizeof__', cls_sizeof_new)
+
+    # Return this class as is.
+    return cls  # type: ignore[return-value]
+
+# ....................{ PRIVATE ~ globals                  }....................
+_BEARTYPED_MODULE_TO_TYPE_NAME: Dict[str, Set[str]] = defaultdict(set)
+'''
+**Decorated classname registry (i.e., dictionary mapping from the
+fully-qualified name of each module defining one or more classes decorated by
+the :func:`beartype.beartype` decorator to the set of the unqualified basenames
+of all classes in that module decorated by that decorator).
+'''
+
+# ....................{ PRIVATE ~ globals                  }....................
+def _uncache_beartype_if_type_redefined(cls: type) -> None:
+    '''
+    Clear *all* :mod:`beartype`-specific internal caches that have been shown to
+    fail when a class is redefined if the passed class is detected as having
+    been redefined in its module.
+
+    If a class with the same unqualified basename defined in a module with the
+    same fully-qualified name has already been marked as decorated by this
+    decorator, then either:
+
+    * That module has been externally reloaded. In this case, this class (along
+      with the remainder of that module) has now been redefined. Common examples
+      include:
+
+      * Rerunning a Jupyter cell defining this class.
+      * Refreshing a web app enabling hot reloading (i.e., automatic reloading
+        of on-disk modules whose contents have been externally modified *after*
+        that app was initially run). Since most Python web app frameworks (e.g.,
+        Flask, Streamlit) support hot reloading, this is the common case.
+
+    * That module has internally redefined this class two or more times. This
+      behaviour, while typically a bug, is also technically valid: e.g.,
+
+      .. code-block:: python
+
+         @beartype
+         def MuhClass(object): ...
+         @beartype
+         def MuhClass(object): ...   # <-- this makes me squint
+
+    In either case, this class has been redefined. Since :mod:`beartype` has no
+    efficient means of deciding which internal caches to clear in response,
+    :mod:`beartype` instead now unconditionally clears *all* internal caches.
+    Doing so incurs a minor performance penalty whenever a module reload occurs
+    while preserving user-facing usability across module reloads. In short, the
+    minor performance penalty is worth this major usability gain.
+    '''
+
+    # Fully-qualified name of the module defining this class if this class is
+    # defined by a module *OR* "None" otherwise (e.g., if this class is only
+    # dynamically defined in-memory outside of any module structure).
+    module_name = get_object_module_name_or_none(cls)
+
+    # If this class is defined by a module...
+    if module_name:
+        # Unqualified basename of this class.
+        type_name = cls.__name__
+
+        # Set of the unqualified basenames of *ALL* classes in that module
+        # previously decorated by this decorator.
+        type_names_beartyped = _BEARTYPED_MODULE_TO_TYPE_NAME[module_name]
+
+        # If a class with the same unqualified basename defined in a module with
+        # the same fully-qualified name has already been marked as decorated by
+        # this decorator, then this class is currently being redefined. In this
+        # case, clear *ALL* beartype-specific internal caches that have been
+        # shown to fail when classes are redefined.
+        if type_name in type_names_beartyped:
+            #FIXME: Consider emitting a logging message instead if this branch
+            #ever becomes computationally intensive, please.
+            # print(f'@beartyped class "{module_name}.{type_name}" redefined!')
+
+            # Clear the previously accessed set of the unqualified basenames of
+            # *ALL* classes in that module previously decorated by this
+            # decorator. Technically, this is optional. Pragmatically, this
+            # *SHOULD* significantly improve the space and time constraints
+            # associated with this class redefinition. Why? Because this class
+            # being redefined implies that the module defining this class is
+            # being redefined, which implies that all classes in that module are
+            # being redefined as well. If we did *NOT* clear this set here, then
+            # this set would continue to contain the unqualified basenames of
+            # those other classes in that module; each @beartype-decorated
+            # redefinition of those other classes would then unnecessarily clear
+            # the same caches already cleared by the first @beartype-decorated
+            # redefinition of a class in that module. Since doing so would be
+            # overly aggressive and thus inefficient, avoiding doing so improves
+            # efficiency in the common case of module redefinition.
+            _BEARTYPED_MODULE_TO_TYPE_NAME.clear()
+
+            # Set of the unqualified basenames of *ALL* classes in that module
+            # previously decorated by this decorator, redefined *AFTER* clearing
+            # that set above to enable the addition of this type back to this
+            # new set below. Nobody ever said type-checking was gonna be easy.
+            type_names_beartyped = _BEARTYPED_MODULE_TO_TYPE_NAME[module_name]
+
+            # Clear *ALL* type-checking caches. Notably:
+            # * The forward reference referee cache (i.e., private
+            #   "beartype._check.forward.reference.fwdrefmeta._forwardref_to_referee"
+            #   dictionary) is problematic, due to mapping from forward
+            #   reference proxies (which are themselves classes) to arbitrary
+            #   (and thus usually user-defined) classes -- one or more of which
+            #   might be this class or other similarly redefined classes.
+            # * The type hint coercion cache (i.e., private
+            #   "beartype._check.convert.convcoerce._hint_repr_to_hint"
+            #   dictionary) is problematic, due to mapping from the
+            #   machine-readable representations of previously seen
+            #   non-self-cached type hints (e.g., "list[MuhClass]") to the first
+            #   seen instance of those hints (e.g., list[MuhClass]). Since this
+            #   class has been redefined, the first seen instance of those hints
+            #   could contain a reference to the first definition of this class.
+            #
+            # If any of these caches contain such desynchronized key-value
+            # pairs, there now exists a discrepancy between the current
+            # definition of this class and existing references in these caches
+            # to the prior definition of this class. For safety, all caches
+            # possibly containing those references must now be assumed to be
+            # invalid. Failing to clear these caches causes @beartype-decorated
+            # wrapper functions to raise erroneous type-checking violations.
+            clear_checker_caches()
+        # Else, this is the first decoration of this class by this decorator.
+
+        # Record that this class has now been decorated by this decorator.
+        # Technically, this should (probably) be performed *AFTER* this
+        # decorator has actually successfully decorated this class.
+        # Pragmatically, doing so here is simply faster and... simpler.
+        type_names_beartyped.add(type_name)
+    # Else, this class is *NOT* defined by a module.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/decorcache.py
@@ -0,0 +1,157 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Memoized beartype decorator.**
+
+This private submodule defines the core :func:`beartype.beartype` decorator,
+conditionally imported (in order):
+
+#. Into the parent :mod:`beartype._decor.decormain` submodule if this decorator
+   is *not* currently reducing to a noop (e.g., due to ``python3 -O``
+   optimization).
+#. Into the root :mod:`beartype.__init__` submodule if the :mod:`beartype`
+   package is *not* currently being installed by :mod:`setuptools`.
+
+This private submodule is literally the :func:`beartype.beartype` decorator,
+despite *not* actually being that decorator (due to being unmemoized).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeConfException
+from beartype.typing import (
+    Dict,
+    Optional,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._data.hint.datahinttyping import (
+    BeartypeConfedDecorator,
+    BeartypeReturn,
+    BeartypeableT,
+)
+from beartype._decor.decorcore import beartype_object
+
+# ....................{ DECORATORS                         }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: Synchronize the signature of this non-identity decorator with the
+# identity decorator defined by the "beartype._decor.decormain" submodule.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: The parent "beartype._decor.decormain" submodule intentionally
+# defines the docstring for this decorator.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+def beartype(
+    # Optional positional or keyword parameters.
+    obj: Optional[BeartypeableT] = None,
+
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> BeartypeReturn:
+
+    # If "conf" is *NOT* a configuration, raise an exception.
+    if not isinstance(conf, BeartypeConf):
+        raise BeartypeConfException(
+            f'{repr(conf)} not beartype configuration.')
+    # Else, "conf" is a configuration.
+    #
+    # If passed an object to be decorated, this decorator is in decoration
+    # rather than configuration mode. In this case, decorate this object with
+    # type-checking configured by this configuration.
+    #
+    # Note this branch is typically *ONLY* entered when the "conf" parameter
+    # is *NOT* explicitly passed and thus defaults to the default
+    # configuration. While callers may technically run this decorator in
+    # decoration mode with a non-default configuration, doing so would be both
+    # highly irregular *AND* violate PEP 561-compliance by violating the
+    # decorator overloads declared above. Nonetheless, we're largely permissive
+    # here; callers that are doing this are sufficiently intelligent to be
+    # trusted to violate PEP 561-compliance if they so choose. So... *shrug*
+    elif obj is not None:
+        return beartype_object(obj, conf)
+    # Else, we were passed *NO* object to be decorated. In this case, this
+    # decorator is in configuration rather than decoration mode.
+
+    # Private decorator (possibly previously generated and cached by a prior
+    # call to this decorator also in configuration mode) generically applying
+    # this configuration to any beartypeable object passed to that decorator
+    # if a prior call to this public decorator has already been passed the same
+    # configuration (and thus generated and cached this private decorator) *OR*
+    # "None" otherwise (i.e., if this is the first call to this public
+    # decorator passed this configuration in configuration mode). Phew!
+    beartype_confed_cached = _bear_conf_to_decor.get(conf)
+
+    # If a prior call to this public decorator has already been passed the same
+    # configuration (and thus generated and cached this private decorator),
+    # return this private decorator for subsequent use in decoration mode.
+    if beartype_confed_cached:
+        return beartype_confed_cached
+    # Else, this is the first call to this public decorator passed this
+    # configuration in configuration mode.
+
+    # Define a private decorator generically applying this configuration to any
+    # beartypeable object passed to this decorator.
+    def beartype_confed(obj: BeartypeableT) -> BeartypeableT:
+        '''
+        Decorate the passed **beartypeable** (i.e., pure-Python callable or
+        class) with optimal type-checking dynamically generated unique to
+        that beartypeable under the beartype configuration passed to a
+        prior call to the :func:`beartype.beartype` decorator.
+
+        Parameters
+        ----------
+        obj : BeartypeableT
+            Beartypeable to be decorated.
+
+        Returns
+        ----------
+        BeartypeableT
+            Either:
+
+            * If the passed object is a class, this existing class
+              embellished with dynamically generated type-checking.
+            * If the passed object is a callable, a new callable wrapping
+              that callable with dynamically generated type-checking.
+
+        See Also
+        ----------
+        :func:`beartype.beartype`
+            Further details.
+        '''
+
+        # Decorate this object with type-checking configured by this
+        # configuration.
+        return beartype_object(obj, conf)
+
+    # Cache this private decorator against this configuration.
+    _bear_conf_to_decor[conf] = beartype_confed
+
+    # Return this private decorator.
+    return beartype_confed
+
+# ....................{ SINGLETONS                         }....................
+_bear_conf_to_decor: Dict[BeartypeConf, BeartypeConfedDecorator] = {}
+'''
+Non-thread-safe **beartype decorator cache.**
+
+This cache is implemented as a singleton dictionary mapping from each
+**beartype configuration** (i.e., self-caching dataclass encapsulating all
+flags, options, settings, and other metadata configuring the current decoration
+of the decorated callable or class) to the corresponding **configured beartype
+decorator** (i.e., closure created and returned from the
+:func:`beartype.beartype` decorator when passed a beartype configuration via
+the optional ``conf`` parameter rather than an object to be decorated via
+the optional ``obj`` parameter).
+
+Caveats
+----------
+**This cache is not thread-safe.** Although rendering this cache thread-safe
+would be trivial, doing so would needlessly reduce efficiency. This cache is
+merely a runtime optimization and thus need *not* be thread-safe.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/decorcore.py
@@ -0,0 +1,262 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Unmemoized beartype decorators** (i.e., core lower-level unmemoized decorators
+underlying the higher-level memoized :func:`beartype.beartype` decorator, whose
+implementation in the parent :mod:`beartype._decor.decorcache` submodule
+is a thin wrapper efficiently memoizing closures internally created and returned
+by that decorator; in turn, those closures directly defer to this submodule).
+
+This private submodule is effectively the :func:`beartype.beartype` decorator
+despite *not* actually being that decorator (due to being unmemoized).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeException
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.hint.datahinttyping import (
+    BeartypeableT,
+    TypeWarning,
+)
+from beartype._decor._decornontype import beartype_nontype
+from beartype._decor._decortype import beartype_type
+from beartype._util.cls.utilclstest import is_type_subclass
+from beartype._util.error.utilerrwarn import issue_warning
+from beartype._util.text.utiltextlabel import (
+    label_exception,
+    label_object_context,
+)
+from beartype._util.text.utiltextmunge import (
+    truncate_str,
+    uppercase_str_char_first,
+)
+from beartype._util.text.utiltextprefix import prefix_beartypeable
+from traceback import format_exc
+from warnings import warn
+
+# ....................{ DECORATORS                         }....................
+def beartype_object(
+    # Mandatory parameters.
+    obj: BeartypeableT,
+    conf: BeartypeConf,
+
+    # Variadic keyword parameters.
+    **kwargs
+) -> BeartypeableT:
+    '''
+    Decorate the passed **beartypeable** (i.e., caller-defined object that may
+    be decorated by the :func:`beartype.beartype` decorator) with optimal
+    type-checking dynamically generated unique to that beartypeable.
+
+    Parameters
+    ----------
+    obj : BeartypeableT
+        **Beartypeable** (i.e., pure-Python callable or class) to be decorated.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., dataclass encapsulating all flags,
+        options, settings, and other metadata configuring the current decoration
+        of the decorated callable or class).
+
+    All remaining keyword parameters are passed as is to whichever lower-level
+    decorator this higher-level decorator calls on the passed beartypeable.
+
+    Returns
+    ----------
+    BeartypeableT
+        Either:
+
+        * If the passed object is a class, this existing class embellished with
+          dynamically generated type-checking.
+        * If the passed object is a callable, a new callable wrapping that
+          callable with dynamically generated type-checking.
+
+    See Also
+    ----------
+    :func:`beartype._decor.decormain.beartype`
+        Memoized parent decorator wrapping this unmemoized child decorator.
+    '''
+    # print(f'Decorating object {repr(obj)}...')
+
+    # Return either...
+    return (
+        _beartype_object_fatal(obj, conf=conf, **kwargs)
+        # If this beartype configuration requests that this decorator raise
+        # fatal exceptions at decoration time, defer to the lower-level
+        # decorator doing so;
+        if conf.warning_cls_on_decorator_exception is None else
+        # Else, this beartype configuration requests that this decorator emit
+        # fatal warnings at decoration time. In this case, defer to the
+        # lower-level decorator doing so.
+        _beartype_object_nonfatal(obj, conf=conf, **kwargs)
+    )
+
+# ....................{ PRIVATE ~ decorators               }....................
+def _beartype_object_fatal(obj: BeartypeableT, **kwargs) -> BeartypeableT:
+    '''
+    Decorate the passed **beartypeable** (i.e., caller-defined object that may
+    be decorated by the :func:`beartype.beartype` decorator) with optimal
+    type-checking dynamically generated unique to that beartypeable.
+
+    Parameters
+    ----------
+    obj : BeartypeableT
+        **Beartypeable** (i.e., pure-Python callable or class) to be decorated.
+
+    All remaining keyword parameters are passed as is to a lower-level decorator
+    defined by this submodule (e.g., :func:`.beartype_func`).
+
+    Returns
+    ----------
+    BeartypeableT
+        Either:
+
+        * If the passed object is a class, this existing class embellished with
+          dynamically generated type-checking.
+        * If the passed object is a callable, a new callable wrapping that
+          callable with dynamically generated type-checking.
+
+    See Also
+    ----------
+    :func:`beartype._decor.decormain.beartype`
+        Memoized parent decorator wrapping this unmemoized child decorator.
+    '''
+
+    # Return either...
+    return (
+        # If this object is a class, this class decorated with type-checking.
+        beartype_type(obj, **kwargs)  # type: ignore[return-value]
+        if isinstance(obj, type) else
+        # Else, this object is a non-class. In this case, this non-class
+        # decorated with type-checking.
+        beartype_nontype(obj, **kwargs)  # type: ignore[return-value]
+    )
+
+
+#FIXME: Unit test us up, please.
+def _beartype_object_nonfatal(
+    # Mandatory parameters.
+    obj: BeartypeableT,
+    conf: BeartypeConf,
+
+    # Variadic keyword parameters.
+    **kwargs
+) -> BeartypeableT:
+    '''
+    Decorate the passed **beartypeable** (i.e., pure-Python callable or class)
+    with optimal type-checking dynamically generated unique to that
+    beartypeable and any otherwise uncaught exception raised by doing so safely
+    coerced into a warning instead.
+
+    Motivation
+    ----------
+    This decorator is principally intended to be called by our **import hook
+    API** (i.e., public functions exported by the :mod:`beartype.claw`
+    subpackage). Raising detailed exception tracebacks on unexpected error
+    conditions is:
+
+    * The right thing to do for callables and classes manually type-checked with
+      the :func:`beartype.beartype` decorator.
+    * The wrong thing to do for callables and classes automatically type-checked
+      by import hooks installed by public functions exported by the
+      :mod:`beartype.claw` subpackage. Why? Because doing so would render those
+      import hooks fragile to the point of being practically useless on
+      real-world packages and codebases by unexpectedly failing on the first
+      callable or class defined *anywhere* under a package that is not
+      type-checkable by :func:`beartype.beartype` (whether through our fault or
+      that package's). Instead, the right thing to do is to:
+
+      * Emit a warning for each callable or class that :func:`beartype.beartype`
+        fails to generate a type-checking wrapper for.
+      * Continue to the next callable or class.
+
+    Parameters
+    ----------
+    obj : BeartypeableT
+        **Beartypeable** (i.e., pure-Python callable or class) to be decorated.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., dataclass encapsulating all flags,
+        options, settings, and other metadata configuring the current decoration
+        of the decorated callable or class).
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`._beartype_object_fatal` decorator internally called by this
+    higher-level decorator on the passed beartypeable.
+
+    Returns
+    ----------
+    BeartypeableT
+        Either:
+
+        * If :func:`.beartype_object_fatal` raises an exception, the passed
+          object unmodified as is.
+        * If :func:`.beartype_object_fatal` raises no exception:
+
+          * If the passed object is a class, this existing class embellished with
+            dynamically generated type-checking.
+          * If the passed object is a callable, a new callable wrapping that
+            callable with dynamically generated type-checking.
+
+    Warns
+    ----------
+    warning_category
+        If :func:`.beartype_object_fatal` fails to generate a type-checking
+        wrapper for this callable or class by raising a fatal exception, this
+        decorator coerces that exception into a non-fatal warning instead.
+    '''
+
+    # Attempt to decorate the passed beartypeable.
+    try:
+        return _beartype_object_fatal(obj, conf=conf, **kwargs)
+    # If doing so unexpectedly raises an exception, coerce that fatal exception
+    # into a non-fatal warning for nebulous safety.
+    except Exception as exception:
+        # Category of warning to be emitted.
+        warning_category: TypeWarning = conf.warning_cls_on_decorator_exception  # type: ignore[assignment]
+        assert is_type_subclass(warning_category, Warning), (
+            f'{repr(warning_category)} not warning category.')
+
+        # Original lower-level error message to be embedded in the higher-level
+        # warning message to be emitted below, defined as either...
+        error_message = (
+            # If this exception is beartype-specific, this exception's message
+            # is probably human-readable as is. In this case, maximize brevity
+            # and readability by coercing *ONLY* this message (rather than both
+            # this message *AND* traceback) truncated to a reasonable maximum
+            # length into a warning message.
+            truncate_str(text=label_exception(exception), max_len=1024)
+            if isinstance(exception, BeartypeException) else
+            # Else, this exception is *NOT* beartype-specific. In this case,
+            # this exception's message is probably *NOT* human-readable as is.
+            # Prepend that non-human-readable message by this exception's
+            # traceback for disambiguity and debuggability. Note that the
+            # format_exc() function appends this exception's message to this
+            # traceback and thus suffices as is.
+            format_exc()
+        )
+
+        # Indent this message by globally replacing *EVERY* newline in this
+        # message with a newline followed by four spaces. Doing so visually
+        # offsets this lower-level exception message from the higher-level
+        # warning message embedding this exception message below.
+        error_message = f'\n{error_message}'.replace('\n', '\n    ')
+
+        # Warning message to be emitted, consisting of:
+        # * A human-readable label contextually describing this beartypeable,
+        #   capitalized such that the first character is uppercase.
+        # * This indented exception message.
+        warning_message = uppercase_str_char_first(
+            f'{prefix_beartypeable(obj)}{label_object_context(obj)}:'
+            f'{error_message}'
+        )
+
+        # Emit this message under this category.
+        issue_warning(cls=warning_category, message=warning_message)
+
+    # Return this object unmodified, as @beartype failed to successfully wrap
+    # this object with a type-checking class or callable. So it goes, fam.
+    return obj  # type: ignore[return-value]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/decormain.py
@@ -0,0 +1,232 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Public beartype decorator.**
+
+This private submodule defines the core :func:`beartype` decorator, which the
+:mod:`beartype.__init__` submodule then imports for importation as the public
+:mod:`beartype.beartype` decorator by downstream callers -- completing the
+virtuous cycle of code life.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+# All "FIXME:" comments for this submodule reside in this package's "__init__"
+# submodule to improve maintainability and readability here.
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    TYPE_CHECKING,
+    Callable,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._data.hint.datahinttyping import (
+    BeartypeReturn,
+    BeartypeableT,
+)
+from beartype._util.py.utilpyinterpreter import is_python_optimized
+
+# Intentionally import the standard mypy-friendly @typing.overload decorator
+# rather than a possibly mypy-unfriendly @beartype.typing.overload decorator --
+# which, in any case, would be needlessly inefficient and thus bad.
+from typing import overload
+
+# ....................{ OVERLOADS                          }....................
+# Declare PEP 484-compliant overloads to avoid breaking downstream code
+# statically type-checked by a static type checker (e.g., mypy). The concrete
+# @beartype decorator declared below is permissively annotated as returning a
+# union of multiple types desynchronized from the types of the passed arguments
+# and thus fails to accurately convey the actual public API of that decorator.
+# See also:
+#     https://www.python.org/dev/peps/pep-0484/#function-method-overloading
+#
+# Note that the "Callable[[BeartypeableT], BeartypeableT]" type hint should
+# ideally instead be a reference to our "BeartypeConfedDecorator" type hint.
+# Indeed, it used to be. Unfortunately, a significant regression in mypy
+# required us to inline that type hint away. See also this issue:
+#     https://github.com/beartype/beartype/issues/332
+@overload  # type: ignore[misc,no-overload-impl]
+def beartype(obj: BeartypeableT) -> BeartypeableT: ...
+@overload
+def beartype(*, conf: BeartypeConf) -> Callable[
+    [BeartypeableT], BeartypeableT]: ...
+
+# ....................{ DECORATORS                         }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: *THE ORDER OF CONDITIONAL STATEMENTS BELOW IS SIGNIFICANT.* Notably,
+# mypy 0.940 erroneously emits this fatal error when the "TYPE_CHECKING or"
+# condition is *NOT* the first condition of this "if" statement:
+#     beartype/_decor/main.py:294: error: Condition can't be inferred, unable
+#     to merge overloads [misc]
+# See also: https://github.com/python/mypy/issues/12335#issuecomment-1065591703
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# If the active Python interpreter is either...
+if (
+    # Running under an external static type checker -- in which case there is
+    # no benefit to attempting runtime type-checking whatsoever...
+    #
+    # Note that this test is largely pointless. By definition, static type
+    # checkers should *NOT* actually run any code -- merely parse and analyze
+    # that code. Ergo, this boolean constant should *ALWAYS* be false from the
+    # runtime context under which @beartype is only ever run. Nonetheless, this
+    # test is only performed once per process and is thus effectively free.
+    TYPE_CHECKING or
+    # Optimized at process invocation time (e.g., at least one "-O" command-line
+    # option was set when this interpreter forked) *OR*...
+    not __debug__ or
+    # Optimized *AFTER* process invocation time (e.g., in an interactive REPL by
+    # the external user). Yes, our awesome userbase actually requested this.
+    is_python_optimized()
+):
+# Then unconditionally disable @beartype-based type-checking across the entire
+# codebase by reducing the @beartype decorator to the identity decorator.
+# Ideally, this would have been implemented at the top rather than bottom of
+# this submodule as a conditional resembling:
+#     if __debug__:
+#         def beartype(func: CallableTypes) -> CallableTypes:
+#             return func
+#         return
+#
+# Tragically, Python fails to support module-scoped "return" statements. *sigh*
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: Synchronize the signature of this identity decorator with the
+# non-identity decorator imported below.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    def beartype(  # type: ignore[no-redef]
+        obj: BeartypeableT,  # pyright: ignore[reportInvalidTypeVarUse]
+
+        # Optional keyword-only parameters.
+        *,
+        conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+    ) -> BeartypeReturn:
+        return obj
+# Else, the active Python interpreter is in a standard runtime state. In this
+# case, define the @beartype decorator in the standard way.
+else:
+    # This is where @beartype *REALLY* lives. Grep here for all the goods.
+    from beartype._decor.decorcache import beartype
+
+# ....................{ DECORATORS ~ doc                   }....................
+# Document the @beartype decorator with the same documentation regardless of
+# which of the above implementations currently implements that decorator.
+beartype.__doc__ = (
+    '''
+    Decorate the passed **beartypeable** (i.e., pure-Python callable or
+    class) with optimal type-checking dynamically generated unique to that
+    beartypeable under the passed beartype configuration.
+
+    This decorator supports two distinct (albeit equally efficient) modes
+    of operation:
+
+    * **Decoration mode.** The caller activates this mode by passing this
+      decorator a type-checkable object via the ``obj`` parameter; this
+      decorator then creates and returns a new callable wrapping that object
+      with optimal type-checking. Specifically:
+
+      * If this object is a callable, this decorator creates and returns a new
+        **runtime type-checker** (i.e., pure-Python function validating all
+        parameters and returns of all calls to that callable against all
+        PEP-compliant type hints annotating those parameters and returns). The
+        type-checker returned by this decorator is:
+
+        * Optimized uniquely for the passed callable.
+        * Guaranteed to run in ``O(1)`` constant-time with negligible constant
+          factors.
+        * Type-check effectively instantaneously.
+        * Add effectively no runtime overhead to the passed callable.
+
+      * If the passed object is a class, this decorator iteratively applies
+        itself to all annotated methods of this class by dynamically wrapping
+        each such method with a runtime type-checker (as described previously).
+
+    * **Configuration mode.** The caller activates this mode by passing this
+      decorator a beartype configuration via the ``conf`` parameter; this
+      decorator then creates and returns a new beartype decorator enabling that
+      configuration. That decorator may then be called (in decoration mode) to
+      create and return a new callable wrapping the passed type-checkable
+      object with optimal type-checking configured by that configuration.
+
+    If optimizations are enabled by the active Python interpreter (e.g., due to
+    option ``-O`` passed to this interpreter), this decorator silently reduces
+    to a noop.
+
+    Parameters
+    ----------
+    obj : Optional[BeartypeableT]
+        **Beartypeable** (i.e., pure-Python callable or class) to be decorated.
+        Defaults to ``None``, in which case this decorator is in configuration
+        rather than decoration mode. In configuration mode, this decorator
+        creates and returns an efficiently cached private decorator that
+        generically applies the passed beartype configuration to any
+        beartypeable object passed to that decorator. Look... It just works.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object). Defaults
+        to ``BeartypeConf()``, the default ``O(1)`` constant-time configuration.
+
+    Returns
+    ----------
+    BeartypeReturn
+        Either:
+
+        * If in decoration mode (i.e., ``obj`` is *not* ``None` while ``conf``
+          is ``None``) *and*:
+
+          * If ``obj`` is a callable, a new callable wrapping that callable
+            with dynamically generated type-checking.
+          * If ``obj`` is a class, this existing class embellished with
+            dynamically generated type-checking.
+
+        * If in configuration mode (i.e., ``obj`` is ``None` while ``conf`` is
+          *not* ``None``), a new beartype decorator enabling this
+          configuration.
+
+    Raises
+    ----------
+    BeartypeConfException
+        If the passed configuration is *not* actually a configuration (i.e.,
+        instance of the :class:`BeartypeConf` class).
+    BeartypeDecorHintException
+        If any annotation on this callable is neither:
+
+        * A **PEP-compliant type** (i.e., instance or class complying with a
+          PEP supported by :mod:`beartype`), including:
+
+          * :pep:`484` types (i.e., instance or class declared by the stdlib
+            :mod:`typing` module).
+
+        * A **PEP-noncompliant type** (i.e., instance or class complying with
+          :mod:`beartype`-specific semantics rather than a PEP), including:
+
+          * **Fully-qualified forward references** (i.e., strings specified as
+            fully-qualified classnames).
+          * **Tuple unions** (i.e., tuples containing one or more classes
+            and/or forward references).
+    BeartypePep563Exception
+        If :pep:`563` is active for this callable and evaluating a **postponed
+        annotation** (i.e., annotation whose value is a string) on this
+        callable raises an exception (e.g., due to that annotation referring to
+        local state no longer accessible from this deferred evaluation).
+    BeartypeDecorParamNameException
+        If the name of any parameter declared on this callable is prefixed by
+        the reserved substring ``__beartype_``.
+    BeartypeDecorWrappeeException
+        If this callable is either:
+
+        * Uncallable.
+        * A class, which :mod:`beartype` currently fails to support.
+        * A C-based callable (e.g., builtin, third-party C extension).
+    BeartypeDecorWrapperException
+        If this decorator erroneously generates a syntactically invalid wrapper
+        function. This should *never* happen, but here we are, so this probably
+        happened. Please submit an upstream issue with our issue tracker if you
+        ever see this. (Thanks and abstruse apologies!)
+    '''
+)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/wrap/__init__.py
@@ -0,0 +1,571 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                           )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+# ....................{ TODO                              }....................
+#FIXME: Major optimization: duplicate the signature of the decorated callable
+#as the signature of our wrapper function. Why? Because doing so obviates the
+#need to explicitly test whether each possible parameter was passed and how
+#that parameter was passed (e.g., positional, keyword) as well as the need to
+#localize "__beartype_args_len" and so on. In short, this is a massive win.
+#Again, see the third-party "makefun" package, which purports to already do so.
+
+#FIXME: Cray-cray optimization: don't crucify us here, folks, but eliminating
+#the innermost call to the original callable in the generated wrapper may be
+#technically feasible. It's probably a BadIdea™, but the idea goes like this:
+#
+#    # Source code for this callable as a possibly multiline string,
+#    # dynamically parsed at runtime with hacky regular expressions from
+#    # the physical file declaring this callable if any *OR* "None" otherwise
+#    # (e.g., if this callable is defined dynamically or cannot be parsed from
+#    # that file).
+#    func_source = None
+#
+#    # Attempt to find the source code for this callable.
+#    try:
+#        func_source = inspect.getsource(func)
+#    # If the inspect.getsource() function fails to do so, shrug.
+#    except OSError:
+#        pass
+#
+#    # If the source code for this callable cannot be found, fallback to
+#    # simply calling this callable in the conventional way.
+#    if func_source is None:
+#       #FIXME: Do what we currently do here.
+#    # Else, the source code for this callable was found. In this case,
+#    # carefully embed this code into the code generated for this wrapper.
+#    else:
+#       #FIXME: Do something wild, crazy, and dangerous here.
+#
+#Extreme care will need to be taken, including:
+#
+#* Ensuring code is indented correctly.
+#* Preserving the signature (especially with respect to passed parameters) of
+#  the original callable in the wrapper. See the third-party "makefun" package,
+#  which purports to already do so. So, this is mostly a solved problem --
+#  albeit still non-trivial, as "beartype" will never have dependencies.
+#* Don't bother reading any of this. Just skip to the synopsis below:
+#  * Preventing local attributes defined by this wrapper as well as global
+#    attributes imported into this wrapper's namespace from polluting the
+#    namespace expected by the original callable. The former is trivial; simply
+#    explicitly "del {attr_name1},...,{attr_nameN}" immediately before
+#    embedding the source code for that callable. The latter is tricky; we'd
+#    probably want to stop passing "globals()" to exec() below and instead pass
+#    a much smaller list of attributes explicitly required by this wrapper.
+#    Even then, though, there's probably no means of perfectly insulating the
+#    original code from all wrapper-specific global attributes. Or:
+#    * Perhaps this isn't an issue? After all, *ALL* locals and globals exposed
+#      to decorated callables are now guaranteed to be "__bear"-prefixed. This
+#      implies that searching the body of the decorated callable for the
+#      substring "\b__bear" and then raising an exception if any such
+#      substrings are found should suffice to prevent name collision.
+#  * Rewriting return values and yielded values. Oh, boy. That's the killer,
+#    honestly. Regular expression-based parsing only gets us so far. We could
+#    try analyzing the AST for that code, but... yikes. Each "return" and
+#    "yield" statement would need to be replaced by a beartype-specific
+#    "return" or "yield" statement checking the types of the values to be
+#    returned or
+#    yielded. We can guarantee that that rapidly gets cray-cray, especially
+#    when implementing non-trivial PEP 484-style type checking requiring
+#    multiple Python statements and local variables and... yeah. Actually:
+#    * Why *CAN'T* regex-based parsing suffice? Python's Backus-Naur form (BNF)
+#      is almost certainly quite constrained. We'll have to check where exactly
+#      "return" and "yield" statements are permissible, but we're fairly sure
+#      they're permissible only after newlines followed by sufficient
+#      indentation.
+#    * Note that the objects produced by Python's standard "ast" *AND* "dis"
+#      modules contain line number attributes yielding the line numbers on
+#      which those syntactic object were parsed. Ergo, whichever of these is
+#      the more efficient almost certainly the simplest (and possibly even)
+#      fastest approach. Is this worth benchmarking? Perhaps we should simply
+#      adopt the "ast" approach, as that's likely to be substantially more
+#      robust *AND* generalize to the case of annotated local variables, where
+#      naive regexes (and probably "dis" as well) fall down. Of course, "dis"
+#      is likely to be *MUCH* more space- and time-performant than "ast".
+#    * *SIGH.* Yes, absolutely use the standard "ast" module. Absolutely do
+#      *NOT* use either hand-rolled regexes or the standard "dis" module. Why?
+#      Because:
+#      * The low-level internals of the "ast" module are implemented in C. That
+#        means it's likely to be fast enough for our purposes.
+#      * CPython *ALREADY* has to do all (or at least, enough) of the AST
+#        analysis performed by the "ast" module. Since that cost has to be paid
+#        anyway, we'd might as well avoid paying additional regex or "dis"
+#        costs by reusing "ast" with @beartype. Oh, wait... No, that's not how
+#        things work at all. You basically can't reverse-engineer an AST from a
+#        callable code object. Since Python doesn't preserve the AST it
+#        internally produces to generate byte-code for a callable on that
+#        callable, we have no choice but to:
+#        * Get the source for that callable (e.g., with dill.source.getsource()
+#          or inspect.getsource()).
+#        * Pass that source string to ast.parse(). Man, that sure blows chunks.
+#      * So, ignore the prior point. The only additional meaningful point is
+#        that, unlike the "dis" module, the "ast" module makes it trivial to:
+#        * Transform the produced AST by injecting additional nodes (e.g.,
+#          dynamically generated statements) into the AST.
+#        * Compile that AST down into a code object.
+#      Does any of the above help us? Maybe not. All we really need from "ast"
+#      and "dis" are line numbers and the ability to crudely identify:
+#      * "return" statements. "dis" trivially does this.
+#      * "yield" statements. "dis" trivially does this.
+#      * Local annotated variable assignments. "dis" *PROBABLY* does not
+#        trivially do this. Indeed, it's not necessarily clear that "ast" does
+#        this either. Actually, that's absolutely *NOT* true. "ast" appears to
+#        trivially detect local annotated variable assignments, which is nice.
+#       Hilariously, regexes *DO* trivially detect local annotated variable
+#       assignments, because that's just a search for
+#       r"\n\s*[a-zA-Z_][a-zA-Z0-9_]*\s*:". Like, seriously. That's by far the
+#       easiest way to do that. Detecting "return" and "yield" statements is
+#       similarly trivial (we think, anyway) with regexes.
+#       *WAIT.* Regexes may vary well detect the *START* of a local annotated
+#       variable assignment, but they clearly fail to detect the *END*, as that
+#       requires context-free parsing. Welp. That's the death-knell for both
+#       regexes and "dis", then. "ast" is it!
+#
+#In synopsis, don't bother reading the above. Just know that parsing "return"
+#and "yield" statements as well as annotated local variable assignments
+#unsurprisingly requires use of the standard "ast" module. Specifically:
+#* Get the source for the decorated callable. Ideally, we'll want to do so by
+#  implementing our own get_callable_source() utility getter inspired by the
+#  third-party "dill" implementation at dill.source.getsource() rather than the
+#  standard inspect.getsource().
+#* Pass that source string to ast.parse(). Note that the following snippet
+#  appears to be the most robust means of doing so, as it implicitly accounts
+#  for encoding issues that we do *NOT* want to concern ourselves with:
+#      import ast
+#      import tokenize
+#
+#      def parse_file(filename):
+#          with tokenize.open(filename) as f:
+#              return ast.parse(f.read(), filename=filename)
+#  Please cite the original source for this, which is this blog article:
+#  https://julien.danjou.info/finding-definitions-from-a-source-file-and-a-line-number-in-python
+#* Search the resulting AST for any nodes referencing an object name (e.g.,
+#  variable, callable, class) prefixed by "__bear" and raise an exception on
+#  the first such node to prevent name collision.
+#* Munge that AST as required.
+#* Compile that AST -- ideally directly into a callable (but possibly first
+#  indirectly into a code object into then that directly into a callable).
+#
+#I suppose we could gradually roll out support by (in order):
+#* Initially duplicating the signature of the decorated callable onto the
+#  wrapper function. Since this is both a hard prerequisite for all subsequent
+#  work *AND* yields tangible benefits in and of itself (e.g., for runtime
+#  introspection), this is absolutely the first big ticket item here. Note that
+#  several approaches exist here:
+#  * Programmatically reconstruct this signature. This is almost certainly the
+#    optimal technique.
+#  * Use "ast" to find the line interval for the signature of the decorated
+#    callable in its source file.
+#  * Use "dis" to find the same.
+#
+#  Note that this is complicated by default values, which will need to be
+#  propagated from the decorated callable onto the wrapper function. As we
+#  recall, the "callable.__defaults__" dunder variable contains these defaults,
+#  so that's probably trivial. Just copy that variable, right? Similarly, the
+#  "callable.__annotations__" dunder variable should also be propagated.
+#
+#  Actually, just see the standard inspect._signature_from_function() function,
+#  which implements the core callable signature parsing logic. Alternately, I
+#  believe we'd previously found a third-party library or two whose sole reason
+#  for existence was parsing and duplicating callable signatures, wasn't it?
+#* Then optimizing callables annotated by either no return type hint *OR* a
+#  deeply ignorable return hint, which reduces to a significantly simpler edge
+#  case requiring *NO* "ast" use.
+#* Then optimizing callables returning and yielding nothing by falling back to
+#  the unoptimized approach for callables that do so.
+#* Then optimizing callables terminating in a single "return" or "yield"
+#  statement that *DIRECTLY* return a local or global variable. This is the
+#  easy common case, as we can then immediately precede that statement with a
+#  type-check on that variable.
+#* Then optimizing callables terminating in a single "return" or "yield"
+#  statement that return an arbitrary expression. If that expression is *NOT* a
+#  local or global variable, we need to capture that expression into a new
+#  local variable *BEFORE* type-checking that variable *BEFORE* returning that
+#  variable. So it goes.
+#* Then optimizing callables containing multiple such statements.
+#
+#Note lastly that the third-party "dill" package provides a
+#dill.source.getsource() function with the same API as the stdlib
+#inspect.getsource() function but augmented in various favourable ways. *shrug*
+#
+#Although this will probably never happen, it's still mildly fun to ponder.
+#FIXME: Actually, this should probably happen -- but not necessarily for the
+#reasons stipulated above. Don't get us wrong; optimizing away the additional
+#stack frame by embedding the body of the decorated callable directly into the
+#wrapper function wrapping that callable is a clever (albeit highly
+#non-trivial) optimization.
+#
+#The *REAL* tangible benefit, however, is in type-checking annotated local
+#variables. Currently, neither @beartype nor any other runtime type checker has
+#the means to check annotated local variables: e.g.,
+#    @beartype
+#    def muh_func(muh_list: list[int]) -> int:
+#        list_item: int = list[0]    # <- can't check this
+#        return list_item
+#
+#The reason, of course, is that those variables and thus variable annotations
+#are effectively "locked" behind the additional stack frame separating the
+#decorated callable from its wrapper function. Integrating the former into the
+#latter, however, trivially dissolves this barrier; indeed, since Python
+#currently has no notion of a variable decorator and prohibits function return
+#values from being assigned to as l-values, there is no pragmatic alternative.
+#
+#The idea here is that we could augment the body of the decorated callable when
+#merged into its wrapper function as follows:
+#* Iteratively search that body for local annotated variable declarations.
+#* For each such declaration:
+#  * Inject one or more statements after each such declaration type-checking
+#    that variable against its annotation.
+#
+#The issue here then becomes: *WHERE* after each such declaration? This is a
+#pertinent question, because we could type-check a variable immediately after
+#its declaration, only to have a subsequent assignment to that variable later
+#in the body of the decorated callable silently invalidate the prior
+#type-check. Technically, since @beartype is an O(1) type-checker, we could
+#re-perform type-checks after each assignment to an annotated local variable.
+#But that seems a bit heavy-handed. Perhaps we should simply inject that code
+#at the last possible moment -- which is to say, immediately *BEFORE* each
+#"return" or "yield" statement in that callable. We have to inject code there
+#anyway to type-check that "return" or "yield" statement, so we'd be hitting
+#two birds with one beating stick to additionally type-check annotated local
+#variables there as well.
+#
+#Note that the answer to where we type-check local variables has a profound
+#impact on whether we adopt a regex- or "ast"-based solution. If we type-check
+#everything before "return" or "yield" statements, regex suffices. If we check
+#variables immediately after their declaration or assignment, however, only
+#"ast" suffices. This is, of course, yet another point in favour of checking
+#everything before "return" or "yield" statements, as regex is likely to be
+#substantially faster and more portable (due to changes in "ast" design and
+#implementation across Python versions) than the "ast"-based approach.
+#
+#For example, this regex should (in theory) suffice to detect all annotated
+#local variable declarations in a callable: r"\n\s+[a-zA-Z_][a-zA-Z0-9_]*\s*:".
+#Oh... wait. No. Even that doesn't generalize. Why? Literal triple-quoted
+#strings, obviously. Welp. "ast" it is, then! No point in beating around that
+#context-free bush then, is there? Consider using the third-party "astor"
+#package if available, which purportedly improves upon the standard "ast"
+#module in various ways and is internally leveraged by "pylint" to perform its
+#magic. In any case, Relevant articles include:
+#* "Static Modification of Python With Python: The AST Module", a well-written
+#  introduction to the topic:
+#  https://dzone.com/articles/static-modification-python
+#
+#Note that we have two significant high-level choices here:
+#* Use the "ast" module just to obtain line number intervals for the desired
+#  statements. Note that the existence of the rarely used optional statement
+#  terminator ";" makes this less trivial than desired. We can't simply assume
+#  that statements begin and end on newlines, for example. Instead, we need to
+#  employ either the Python >= 3.8-specific ast.get_source_segment() function
+#  *OR* the Python >= 3.8-specific "end_lineno" and "end_col_offset" attributes
+#  of AST nodes. In either case, Python >= 3.8 will absolutely be required.
+#* Use the "ast" to dynamically transform the AST itself. This is considerably
+#  less trivial *AND* invites significant issues. Sanely transforming the AST
+#  would probably require refactoring our entire workflow to generate new
+#  low-level AST nodes rather than new high-level Python code. Issues include:
+#  * Efficiency. "ast" is both space- and time-inefficient, given both the
+#    large number of objects it creates *AND* the inherent inefficiency of
+#    binary trees as O(n log n) structures.
+#  * Portably. "ast" commonly changes in significant ways between major Python
+#    versions, casting doubts on our ability to reasonably port code
+#    transforming the AST between major Python versions, which is unacceptable.
+#
+#Actually, we'll probably end up combining the two approaches above. We
+#definitely *WILL* want to apply trivial AST transformations, including:
+#* For "return" and "yield" statements, we'll need to split the AST nodes
+#  representing those statements into at least three nodes plus a few new ones:
+#  * The AST node representing each "return" and "yield" statement should be
+#    transformed into a node instead localizing that statement's expression
+#    into a new local variable named "__beartype_pith_0".
+#  * Adding a new AST node returning or yielding the value of that variable.
+#
+#We can't reasonably do that transformation by any other means. Note that this
+#then requires calling the Python >= 3.9-specific ast.unparse() function to
+#losslessly generate source code from that transformed tree, which we then
+#split into lines and inject our desired code after the desired line number
+#corresponding to each shifted "return" and "yield" statement.
+#
+#After performing that hopefully simple transform, we then get the line number
+#of the new AST node returning or yielding the value of that variable and then
+#manually inject our code type-checking "__beartype_pith_0" there. Phew!
+#
+#Alternately, rather than ast.unparse() AST back into source code, we might
+#instead try injecting AST nodes that we auto-generate by:
+#* Passing our code type-checking the current "return" or "yield" statement to
+#  the ast.parse() function.
+#* Inject the target sub-AST returned by that call into the desired node of
+#  the source full AST of the decorated callable. Note that this will probably
+#  require prefixing the body of the decorated callable with our parameter
+#  type-checking code *BEFORE* parsing that body with ast.parse(), to ensure
+#  that references in our code type-checking the current "return" or "yield"
+#  statement are properly resolved when merged back into the full AST.
+#FIXME: Lastly, note that the above is likely to make beartype's
+#decoration-time cost prohibitive under CPython, regardless of the call-time
+#improvements due to stack frame compaction. Ergo, we may want to adopt the
+#following defaults:
+#* Under PyPy, *ENABLE* AST modification by default.
+#* Under all other interpreters (especially including CPython), *DISABLE* AST
+#  modification by default.
+#
+#Naturally, profile this to decide what we should do. To facilitate choice,
+#we'll need to refactor the @beartype decorator to support a new optional
+#"is_ast" parameter defaulting to something resembling these defaults. When
+#this parameter is false, @beartype defaults to the current approach; else,
+#@beartype modifies the AST of decorated callables as above.
+#FIXME: *AH HA!* We just realized that the prior AST approach can be
+#significantly optimized to a degree that might make this reasonably tractable
+#under CPython as well. How? As follows (in order):
+#* Dynamically synthesize the *PRELIMINARY* body of the wrapper function from
+#  (in order):
+#  * Code declaring the signature of the wrapper function. Note that we
+#    *SHOULD* (in theory) be able to trivially extract this *WITHOUT* needing
+#    to programmatically generate this ourselves this by performing a
+#    preliminary walk over the AST of the decorated callable for the node(s)
+#    responsible for declaring that callable's signature. Hopefully trivial.
+#    Why? Because AST nodes provide line number ranges, which leads directly to
+#    trivial extraction of callable signatures. That said... we probably
+#    already need to programmatically generate signatures ourselves for the
+#    common edge case in which the decorated callable is *NOT* annotated by a
+#    return type hint. So, who knows!
+#  * Code typing-checking all parameters, as above.
+#  * Code typing-checking the "return" value. Don't worry about "yield"
+#    statements for now. *YES,* we are intentionally type-checking the "return"
+#    early in the body of the wrapper function. Why? So that we can have the
+#    "ast" module generate a full AST tree containing a node performing that
+#    type-check. Of course, that node will *NOT* be in the correct node
+#    position. But that's fine. A subsequent step will shift that node to its
+#    desired final position in the AST. This code should resemble:
+#        __beartype_pith_0 = True
+#        if ({code_checking_beartype_pith_0_value_here}):
+#            raise {code_raising_beartype_pith_0_exception_here}
+#    This is, of course, valid code that should generate valid AST nodes.
+#  * The body of the decorated callable.
+#* Parse that preliminary body of the wrapper function through the ast.parse()
+#  function, producing an AST.
+#* Transform that AST as follows:
+#  * Iteratively walk that AST until finding a node assigning "True" to
+#    "__beartype_pith_0". This shouldn't be troublesome.
+#  * Extract both that node and the subsequent node subtree consisting of the
+#    type-check and exception raising out of their current position in the AST.
+#    Naturally, save these two nodes for subsequent reinsertion back into the
+#    AST at a different position.
+#  * Iteratively walk the remainder of the AST until finding a node performing
+#    a return.
+#  * Inject the two previously extracted nodes into that node position.
+#  * Repeat until all "return" statements have been transformed.
+#  * Voila!
+#* Compile that AST directly into a code object by calling the ast.compile()
+#  function.
+#* Evaluate that code object by calling either the exec() or eval() builtin to
+#  produce the actual wrapper function.
+#
+#Note that there is a significant annoyance associated with AST
+#transformations: *LINE NUMBERS.* Specifically, the ast.compile() function
+#called above absolutely requires that line numbers be coherent (i.e.,
+#monotonically increase). To ensure this, we'll need to "fix up" line numbers
+#for basically *ALL* nodes following those representing the code
+#typing-checking all parameters (whose line numbers require no modification).
+#This is annoying but inexpensive, given that we have to walk all nodes anyway.
+#Note that the "ast" modules provides functions for repairing line numbers as
+#well (e.g., ast.increment_lineno()), but that those functions are almost
+#certainly inefficient and inapplicable for us.
+#
+#Note that the ast.copy_location() function appears to already do a *BIT* of
+#what we need. Since we need cutting instead of copying, however, we'll
+#probably just want to use that function's implementation as inspiration rather
+#than directly calling that function.
+#
+#And... don't get us wrong. This is absolutely still going to be expensive. But
+#the fact that we can flow directly from:
+#   decorated callable -> source code -> AST -> code object -> wrapper func
+#...does imply that this should be considerable faster than previously thought.
+#FIXME: We just realized that there's a significant optimization here that
+#renders stack frame reduction unconditionally worthwhile across all Python
+#interpreters and versions in a simple common case: callables annotated either
+#with no return type hints *OR* deeply ignorable type hints. Why? Because we
+#can trivially eliminate the additional stack frame in this edge case by
+#unconditionally prefixing the body of the decorated callable by (in order):
+#
+#1. Code type-checking parameters passed to that callable.
+#2. Code deleting *ALL* beartype-specific "__bear"-prefixed locals and globals
+#   referenced by the code type-checking those parameters. This is essential,
+#   as it implies that we then no longer need to iteratively search the body of
+#   the decorated callable for local variables with conflicting names, which
+#   due to strings we can't reliably do without "ast"- or "dis"-style parsing.
+#
+#Note this edge case only applies to callables:
+#* Whose return hint is either:
+#  * Unspecified.
+#  * Deeply ignorable.
+#  * "None", implying this callable to return nothing. Callables explicitly
+#    returning a "None" value should instead be annotated with a return hint of
+#    "beartype.cave.NoneType"; this edge case would *NOT* apply to those.
+#* *DIRECTLY* decorated by @beartype: e.g.,
+#      @beartype
+#      def muh_func(): pass
+#  This edge case does *NOT* apply to callables directly decorated by another
+#  decorator first, as in that case the above procedure would erroneously
+#  discard the dynamic decoration of that other decorator: e.g.,
+#      @beartype
+#      @other_decorator
+#      def wat_func(): pass
+#* *NOT* implicitly transformed by one or more other import hooks. If any other
+#  import hooks are in effect, this edge case does *NOT* apply, as in that case
+#  the above procedure could again erroneously discard the dynamic
+#  transformations applied by those other import hooks.
+#FIXME: *GENERALIZATION:* All of the above would seem to pertain to a
+#prospective higher-level package, which has yet to be officially named but
+#which we are simply referring to as "beartypecache" for now. "beartypecache"
+#has one dependency: unsurprisingly, this is "beartype". The principal goal of
+#"beartypecache" is *NOT* to perform AST translations as detailed above,
+#although that certainly is a laudable secondary goal.
+#
+#The principal goal of "beartypecache" is, as the name suggests, to cache
+#wrapper functions dynamically generated by the @beartype decorator across
+#Python processes. This goal succinctly ties in to the above AST transform
+#concepts, because the *ONLY* sane means of performing these transforms (even
+#under PyPy and similarly fast Python environments) is to cache the results of
+#these transformations across Python processes.
+#
+#The underlying idea here is that the @beartype decorator only needs to be
+#applied once to each version of a callable. If that callable has not changed
+#since the last application of @beartype to that decorator (or since @beartype
+#itself has changed, obviously), then the previously cached application of
+#@beartype to the current version of that callable suffices. Naturally, of
+#course, there exists *NO* efficient means of deciding when a callable has
+#changed over multiple Python invocations. There does, however, exist an
+#efficient means of deciding when an on-disk module defining standard callables
+#has changed: the "__pycache__" directory formalized by "PEP 3147 -- PYC
+#Repository Directories" at:
+#    https://www.python.org/dev/peps/pep-3147
+#
+#Ergo, we soften the above idea to the following: "The @beartype decorator only
+#needs to be applied once to each callable defined by each version of a
+#module." If this sounds like import hooks, you would not be wrong. Sadly,
+#there currently exists no public API in the stdlib for generically applying
+#AST transformations via import hooks. But all is not lost, since we'll simply
+#do it ourselves. In fact, unsurprisingly, this is a sufficiently useful
+#concept that it's already been done by a number of third-party projects -- the
+#most significant of which is "MacroPy3":
+#    https://github.com/lihaoyi/macropy
+#
+#The "MacroPy3" synopsis reads:
+#    "MacroPy provides a mechanism for user-defined functions (macros) to
+#    perform transformations on the abstract syntax tree (AST) of a Python
+#    program at import time."
+#
+#...which is exactly what we need. We certainly are *NOT* going to depend upon
+#"MacroPy3" as a mandatory dependency, however. Like "beartype" before it,
+#"beartypecache" should ideally only depend upon "beartype" as a mandatory
+#dependency. Ideology aside, however, there exists a more significant reason:
+#"beartypecache" is intended to be brutally fast. That's what the "cache"
+#means. "MacroPy3" is undoubtedly slow by compare to a highly micro-optimized
+#variant of that package, because no in the Python world cares about
+#efficiency -- perhaps justifiably, but perhaps not. Moreover, generalization
+#itself incurs space and time efficiency costs. We can eliminate those costs by
+#developing our own internal, private, ad-hoc AST-transform-on-import-hook
+#implementation micro-optimized for our specific use case.
+#
+#Amusingly, even the abandoned prominently references "MacroPy3":
+#    The MacroPy project uses an import hook: it adds its own module finder in
+#    sys.meta_path to hook its AST transformer.
+#
+#Note that "sys.meta_path" is *NOT* necessarily the optimum approach for
+#"beartypecache". Since the @beartype decorator can only, by definition, be
+#applied to third-party user-defined modules, "sys.meta_path" is might or might
+#not be overkill for us, because "sys.meta_path" even applies to builtin
+#stdlib modules. In any case, what we principally care about is the capacity to
+#directly feed low-level *CODE OBJECTS* (rather than high-level *SOURCE CODE*)
+#from our AST transformations into some sort of import hook machinery.
+#
+#Note this relevant StackOverflow answer:
+#    https://stackoverflow.com/a/43573798/2809027
+#The synopsis of that answer reads:
+#    You will also need to examine if you want to use a MetaPathFinder or a
+#    PathEntryFinder as the system to invoke them is different. That is, the
+#    meta path finder goes first and can override builtin modules, whereas the
+#    path entry finder works specifically for modules found on sys.path.
+#That answer then goes on to succinctly define example implementations of both,
+#which is ludicrously helpful. Again, we should adopt whichever allows us to
+#most efficiently generate low-level *CODE OBJECTS* from AST transformations.
+#
+#Note that the public importlib.util.source_from_cache(path) function trivially
+#enables us to obtain the absolute filename of the previously cached byte code
+#file if any from the absolute filename of any arbitrary Python module. That's
+#nice. Additionally, note this preamble to PEP 3147:
+#
+#    Byte code files [in "__pycache__" directories] contain two 32-bit
+#    big-endian numbers followed by the marshaled code object. The 32-bit
+#    numbers represent a magic number and a timestamp. The magic number changes
+#    whenever Python changes the byte code format, e.g. by adding new byte
+#    codes to its virtual machine. This ensures that pyc files built for
+#    previous versions of the VM won't cause problems. The timestamp is used to
+#    make sure that the pyc file match the py file that was used to create it.
+#    When either the magic number or timestamp do not match, the py file is
+#    recompiled and a new pyc file is written.
+#
+#Presumably, there exists some efficient programmatic means of deciding from
+#pure Python whether "the magic number or timestamp do not match" for the byte
+#code file cached for an arbitrary module.
+#
+#We're almost there. We then need some efficient means of deciding whether an
+#arbitrary byte code file has been instrumented by "beartypecache" yet.
+#That's... a much tougher nut to crack. We can think of two possible approaches
+#here, both equally valid but one probably easier to implement than the other.
+#For each byte code file cached in a "__pycache__" directory, the
+#"beartypecache" package should either:
+#* The easiest way *BY FAR* is probably to just emit one 0-byte
+#  "beartypecache"-specific file named
+#  "__pycache__/{module_name}.{python_name}.beartypecache" or something.
+#  There's *NO* way any other package is writing that sort of file, so filename
+#  collisions should in theory be infeasible. Given such a file, the "mtime" of
+#  this file should coincide with that of the source module from which this
+#  file is generated. Indeed, this approach suggests we don't even need to
+#  extract the magic number and timestamp from the byte code file. Nice! So,
+#  this is the way... probably.
+#* The harder way *BY FAR* is probably to suffix the contents of this file by a
+#  superfluous byte code statement specific to "beartypecache", effectively the
+#  equivalent of:
+#      __beartypecache_is_cached = True
+#  That's more-or-less a noop and more-or-less trivially generated during our
+#  AST transformation of this source module from an import hook. Given that,
+#  we'd then just to need to compare the end of this file with the expected
+#  byte sequence. This *DOES* entail some I/O overhead and considerably more
+#  complexity than the prior approach, however.
+#
+#In any case, the above then enables us to efficiently cache @beartype
+#decorations and AST transformations across an entire codebase as follows:
+#
+#* The root "__init__.py" module of the top-level package for downstream
+#  third-party consumers should contain the following import:
+#      import beartypecache.all
+#  As a side effect, the "beartypecache.all" submodule then installs an import
+#  hook globally decorating all callables across all subsequently imported
+#  modules with @beartype as well as applying AST transformations. This is the
+#  default approach. Of course, subsequent revisions could then provide some
+#  degree of configurability via different submodules or subpackages.
+#* This "beartypecache.all" import hook then confines itself to each
+#  user-defined submodule *OF THE CALLING PACKAGE THAT IMPORTED*
+#  "beartypecache.all". This is critical. We can't simply globally apply the
+#  "beartypecache.all" import hook to *EVERYTHING*, because many callables will
+#  neither be intended nor able to support decoration by @beartype, which has
+#  rather firm views on PEP-compliant type hints and so on.
+#* For each user-defined submodule of the calling package, this
+#  "beartypecache.all" import hook then performs the following:
+#  * Decide whether the previously cached byte code file for this submodule is
+#    still synchronized with this submodule and has been previously
+#    instrumented by "beartypecache", using one of the above approaches.
+#  * If so, avoid uselessly re-instrumenting this file.
+#  * Else, instrument this file as detailed above. As a first draft
+#    implementation, "beartypecache" should simply:
+#    * Replace the name of each function and method defined in this source
+#      submodule by "__beartype_wrapped_{func_name}". Note this will require a
+#      trivial sort of AST instrumentation. We can't avoid that.
+#    * Define the replacement wrapper function with the name "{func_name}",
+#      thus replacing the original callable with our decorated callable.
+#    This draft implementation efficiently caches @beartype decorations across
+#    the entire codebase, thus serving as a pragmatically useful demonstration
+#    of the underlying concept.
+#
+#All in all, this requires funding. Technically feasible, but cray-cray.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/wrap/_wrapargs.py
@@ -0,0 +1,503 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype decorator parameter code generator** (i.e., low-level callables
+dynamically generating Python expressions type-checking all annotated parameters
+of the callable currently being decorated by the :func:`beartype.beartype`
+decorator in a general-purpose manner).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+# All "FIXME:" comments for this submodule reside in this package's "__init__"
+# submodule to improve maintainability and readability here.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeDecorHintParamDefaultForwardRefWarning,
+    BeartypeDecorHintParamDefaultViolation,
+    BeartypeDecorHintPepException,
+    BeartypeDecorParamNameException,
+)
+from beartype.roar._roarexc import _BeartypeHintForwardRefExceptionMixin
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.checkmake import make_code_raiser_func_pith_check
+from beartype._check.convert.convsanify import sanify_hint_root_func
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+from beartype._decor.wrap.wrapsnip import (
+    CODE_INIT_ARGS_LEN,
+    EXCEPTION_PREFIX_DEFAULT,
+    ARG_KIND_TO_CODE_LOCALIZE,
+)
+from beartype._decor.wrap._wraputil import unmemoize_func_wrapper_code
+from beartype._util.error.utilerrraise import reraise_exception_placeholder
+from beartype._util.error.utilerrwarn import (
+    issue_warning,
+    reissue_warnings_placeholder,
+)
+from beartype._util.func.arg.utilfuncargiter import (
+    ARG_META_INDEX_DEFAULT,
+    ARG_META_INDEX_KIND,
+    ARG_META_INDEX_NAME,
+    ArgKind,
+    ArgMandatory,
+    iter_func_args,
+)
+from beartype._util.hint.utilhinttest import (
+    is_hint_ignorable,
+    is_hint_needs_cls_stack,
+)
+from beartype._util.kind.map.utilmapset import update_mapping
+from beartype._util.text.utiltextmunge import lowercase_str_char_first
+from beartype._util.text.utiltextprefix import (
+    prefix_callable_arg_name,
+    prefix_pith_value,
+)
+from beartype._util.utilobject import SENTINEL
+from warnings import catch_warnings
+
+# ....................{ CODERS                             }....................
+def code_check_args(bear_call: BeartypeCall) -> str:
+    '''
+    Generate a Python code snippet type-checking all annotated parameters of
+    the decorated callable if any *or* the empty string otherwise (i.e., if
+    these parameters are unannotated).
+
+    Parameters
+    ----------
+    bear_call : BeartypeCall
+        Decorated callable to be type-checked.
+
+    Returns
+    -------
+    str
+        Code type-checking all annotated parameters of the decorated callable.
+
+    Raises
+    ------
+    BeartypeDecorParamNameException
+        If the name of any parameter declared on this callable is prefixed by
+        the reserved substring ``__bear``.
+    BeartypeDecorHintNonpepException
+        If any type hint annotating any parameter of this callable is neither:
+
+        * A PEP-noncompliant type hint.
+        * A supported PEP-compliant type hint.
+    '''
+    assert isinstance(bear_call, BeartypeCall), (
+        f'{repr(bear_call)} not beartype call.')
+
+    # ..................{ LOCALS ~ func                      }..................
+    # If *NO* callable parameters are annotated, silently reduce to a noop.
+    #
+    # Note that this is purely an optimization short-circuit mildly improving
+    # efficiency for the common case of callables accepting either no
+    # parameters *OR* one or more parameters, all of which are unannotated.
+    if (
+        # That callable is annotated by only one type hint *AND*...
+        len(bear_call.func_arg_name_to_hint) == 1 and
+        # That type hint annotates that callable's return rather than a
+        # parameter accepted by that callable...
+        ARG_NAME_RETURN in bear_call.func_arg_name_to_hint
+    ):
+        return ''
+    # Else, one or more callable parameters are annotated.
+
+    # Python code snippet to be returned.
+    func_wrapper_code = ''
+
+    # ..................{ LOCALS ~ parameter                 }..................
+    #FIXME: Remove this *AFTER* optimizing signature generation, please.
+    # True only if this callable possibly accepts one or more positional
+    # parameters.
+    is_args_positional = False
+
+    # ..................{ LOCALS ~ hint                      }..................
+    # Type hint annotating the current parameter if any *OR* "_PARAM_HINT_EMPTY"
+    # otherwise (i.e., if this parameter is unannotated).
+    hint_insane = None
+
+    # This type hint sanitized into a possibly different type hint more readily
+    # consumable by @beartype's code generator.
+    hint = None
+
+    # ..................{ GENERATE                           }..................
+    #FIXME: Locally remove the "arg_index" local variable (and thus avoid
+    #calling the enumerate() builtin here) AFTER* refactoring @beartype to
+    #generate callable-specific wrapper signatures.
+
+    # For the 0-based index of each parameter accepted by this callable and the
+    # "ParameterMeta" object describing this parameter (in declaration order)...
+    for arg_index, arg_meta in enumerate(iter_func_args(
+        # Possibly lowest-level wrappee underlying the possibly higher-level
+        # wrapper currently being decorated by the @beartype decorator. The
+        # latter typically fails to convey the same callable metadata conveyed
+        # by the former -- including the names and kinds of parameters accepted
+        # by the possibly unwrapped callable. This renders the latter mostly
+        # useless for our purposes.
+        func=bear_call.func_wrappee_wrappee,
+        func_codeobj=bear_call.func_wrappee_wrappee_codeobj,
+        is_unwrap=False,
+    )):
+        # Kind and name of this parameter.
+        arg_kind: ArgKind = arg_meta[ARG_META_INDEX_KIND]  # type: ignore[assignment]
+        arg_name: str = arg_meta[ARG_META_INDEX_NAME]  # type: ignore[assignment]
+
+        # Default value of this parameter if this parameter is optional *OR* the
+        # "ArgMandatory" singleton otherwise (i.e., if this parameter is
+        # mandatory).
+        arg_default: object = arg_meta[ARG_META_INDEX_DEFAULT]
+
+        # Type hint annotating this parameter if any *OR* the sentinel
+        # placeholder otherwise (i.e., if this parameter is unannotated).
+        #
+        # Note that "None" is a semantically meaningful PEP 484-compliant type
+        # hint equivalent to "type(None)". Ergo, we *MUST* explicitly
+        # distinguish between that type hint and unannotated parameters.
+        hint_insane = bear_call.func_arg_name_to_hint_get(arg_name, SENTINEL)
+
+        # If this parameter is unannotated, continue to the next parameter.
+        if hint_insane is SENTINEL:
+            continue
+        # Else, this parameter is annotated.
+
+        # Attempt to...
+        try:
+            # With a context manager "catching" *ALL* non-fatal warnings emitted
+            # during this logic for subsequent "playrback" below...
+            with catch_warnings(record=True) as warnings_issued:
+                # If this parameter's name is reserved for use by the @beartype
+                # decorator, raise an exception.
+                if arg_name.startswith('__bear'):
+                    raise BeartypeDecorParamNameException(
+                        f'{EXCEPTION_PLACEHOLDER}reserved by @beartype.')
+                # If either the type of this parameter is silently ignorable,
+                # continue to the next parameter.
+                elif arg_kind in _ARG_KINDS_IGNORABLE:
+                    continue
+                # Else, this parameter is non-ignorable.
+
+                # Sanitize this hint into a possibly different type hint more
+                # readily consumable by @beartype's code generator *BEFORE*
+                # passing this hint to any further callables.
+                hint = sanify_hint_root_func(
+                    hint=hint_insane, pith_name=arg_name, bear_call=bear_call)
+
+                # If this hint is ignorable, continue to the next parameter.
+                #
+                # Note that this is intentionally tested *AFTER* this hint has
+                # been coerced into a PEP-compliant type hint to implicitly
+                # ignore PEP-noncompliant type hints as well (e.g., "(object,
+                # int, str)").
+                if is_hint_ignorable(hint):
+                    # print(f'Ignoring {bear_call.func_name} parameter {arg_name} hint {repr(hint)}...')
+                    continue
+                # Else, this hint is unignorable.
+
+                #FIXME: Fundamentally unsafe and thus temporarily disabled *FOR
+                #THE MOMENT.* The issue is that our current implementation of
+                #the is_bearable() tester internally called by this function
+                #refuses to resolve relative forward references -- which is
+                #obviously awful. Ideally, that tester *ABSOLUTELY* should
+                #resolve relative forward references. Until it does, however,
+                #this is verboten dark magic that is unsafe in the general case.
+                #FIXME: Note that there exist even *MORE* edge cases, however:
+                #@dataclass fields, which violate typing semantics: e.g.,
+                #    from dataclasses import dataclass, field
+                #    from typing import Dict
+                #
+                #    from beartype import beartype
+                #
+                #    @beartype
+                #    @dataclass
+                #    class A:
+                #        test_dict: Dict[str, str] = field(default_factory=dict)
+                #FIXME: Once this has been repaired, please reenable:
+                #* The "test_decor_arg_kind_flex_optional" unit test.
+
+                # # If this parameter is optional *AND* the default value of this
+                # # optional parameter violates this hint, raise an exception.
+                # _die_if_arg_default_unbearable(
+                #     bear_call=bear_call, arg_default=arg_default, hint=hint)
+                # # Else, this parameter is either optional *OR* the default value
+                # # of this optional parameter satisfies this hint.
+
+                # If this parameter either may *OR* must be passed positionally,
+                # record this fact.
+                #
+                # Note this conditional branch *MUST* be tested after validating
+                # this parameter to be unignorable; if this branch were instead
+                # nested *BEFORE* validating this parameter to be unignorable,
+                # beartype would fail to reduce to a noop for otherwise
+                # ignorable callables -- which would be rather bad, really.
+                if arg_kind in _ARG_KINDS_POSITIONAL:
+                    is_args_positional = True
+                # Else, this parameter *CANNOT* be passed positionally.
+
+                # Python code template localizing this parameter if this kind of
+                # parameter is supported *OR* "None" otherwise.
+                ARG_LOCALIZE_TEMPLATE = ARG_KIND_TO_CODE_LOCALIZE.get(  # type: ignore
+                    arg_kind, None)
+
+                # If this kind of parameter is unsupported, raise an exception.
+                #
+                # Note this edge case should *NEVER* occur, as the parent
+                # function should have simply ignored this parameter.
+                if ARG_LOCALIZE_TEMPLATE is None:
+                    raise BeartypeDecorHintPepException(
+                        f'{EXCEPTION_PLACEHOLDER}kind {repr(arg_kind)} '
+                        f'currently unsupported by @beartype.'
+                    )
+                # Else, this kind of parameter is supported. Ergo, this code is
+                # non-"None".
+
+                # Type stack if required by this hint *OR* "None" otherwise. See
+                # the is_hint_needs_cls_stack() tester for further discussion.
+                #
+                # Note that the original unsanitized "hint_insane" (e.g.,
+                # "typing.Self") rather than the new sanitized "hint" (e.g., the
+                # class currently being decorated by @beartype) is passed to
+                # that tester. Why? Because the latter may already have been
+                # reduced above to a different (and seemingly innocuous) type
+                # hint that does *NOT* appear to require a type stack at late
+                # *EXCEPTION RAISING TIME* (i.e., the
+                # beartype._check.error.errorget.get_func_pith_violation()
+                # function) but actually does. Only the original unsanitized
+                # "hint_insane" is truth.
+                cls_stack = (
+                    bear_call.cls_stack
+                    # if is_hint_needs_cls_stack(hint) else
+                    if is_hint_needs_cls_stack(hint_insane) else
+                    None
+                )
+                # print(f'arg "{arg_name}" hint {repr(hint)} cls_stack: {repr(cls_stack)}')
+
+                # Code snippet type-checking *ANY* parameter with *ANY*
+                # arbitrary name.
+                (
+                    code_arg_check_pith,
+                    func_scope,
+                    hint_refs_type_basename,
+                ) = make_code_raiser_func_pith_check(
+                    hint,
+                    bear_call.conf,
+                    cls_stack,
+                    True,  # <-- True only for parameters
+                )
+
+                # Merge the local scope required to check this parameter into
+                # the local scope currently required by the current wrapper
+                # function.
+                update_mapping(bear_call.func_wrapper_scope, func_scope)
+
+                # Python code snippet localizing this parameter.
+                code_arg_localize = ARG_LOCALIZE_TEMPLATE.format(
+                    arg_name=arg_name, arg_index=arg_index)
+
+                # Unmemoize this snippet against the current parameter.
+                code_arg_check = unmemoize_func_wrapper_code(
+                    bear_call=bear_call,
+                    func_wrapper_code=code_arg_check_pith,
+                    pith_repr=repr(arg_name),
+                    hint_refs_type_basename=hint_refs_type_basename,
+                )
+
+                # Append code type-checking this parameter against this hint.
+                func_wrapper_code += f'{code_arg_localize}{code_arg_check}'
+
+            # If one or more warnings were issued, reissue these warnings with
+            # each placeholder substring (i.e., "EXCEPTION_PLACEHOLDER"
+            # instance) replaced by a human-readable description of this
+            # callable and annotated parameter.
+            if warnings_issued:
+                # print(f'warnings_issued: {warnings_issued}')
+                reissue_warnings_placeholder(
+                    warnings=warnings_issued,
+                    target_str=prefix_callable_arg_name(
+                        func=bear_call.func_wrappee,
+                        arg_name=arg_name,
+                        is_color=bear_call.conf.is_color,
+                    ),
+                )
+            # Else, *NO* warnings were issued.
+        # If any exception was raised, reraise this exception with each
+        # placeholder substring (i.e., "EXCEPTION_PLACEHOLDER" instance)
+        # replaced by a human-readable description of this callable and
+        # annotated parameter.
+        except Exception as exception:
+            reraise_exception_placeholder(
+                exception=exception,
+                #FIXME: Embed the kind of parameter both here and above as well
+                #(e.g., "positional-only", "keyword-only", "variadic
+                #positional"), ideally by improving the existing
+                #prefix_callable_arg_name() function to introspect this kind from
+                #the callable code object.
+                target_str=prefix_callable_arg_name(
+                    func=bear_call.func_wrappee,
+                    arg_name=arg_name,
+                    is_color=bear_call.conf.is_color,
+                ),
+            )
+
+    # If this callable accepts one or more positional type-checked parameters,
+    # prefix this code by a snippet localizing the number of these parameters.
+    if is_args_positional:
+        func_wrapper_code = f'{CODE_INIT_ARGS_LEN}{func_wrapper_code}'
+    # Else, this callable accepts *NO* positional type-checked parameters. In
+    # this case, preserve this code as is.
+
+    # Return this code.
+    return func_wrapper_code
+
+# ....................{ PRIVATE ~ constants                }....................
+#FIXME: Remove this set *AFTER* handling these kinds of parameters.
+_ARG_KINDS_IGNORABLE = frozenset((
+    ArgKind.VAR_KEYWORD,
+))
+'''
+Frozen set of all :attr:`ArgKind` enumeration members to be ignored
+during annotation-based type checking in the :func:`beartype.beartype`
+decorator.
+
+This includes:
+
+* Constants specific to variadic keyword parameters (e.g., ``**kwargs``), which
+  are currently unsupported by :func:`beartype`.
+* Constants specific to positional-only parameters, which apply only to
+  non-pure-Python callables (e.g., defined by C extensions). The
+  :func:`beartype` decorator applies *only* to pure-Python callables, which
+  provide no syntactic means for specifying positional-only parameters.
+'''
+
+
+_ARG_KINDS_POSITIONAL = frozenset((
+    ArgKind.POSITIONAL_ONLY,
+    ArgKind.POSITIONAL_OR_KEYWORD,
+))
+'''
+Frozen set of all **positional parameter kinds** (i.e.,
+:attr:`ArgKind` enumeration members signifying that a callable parameter
+either may *or* must be passed positionally).
+'''
+
+# ....................{ PRIVATE ~ raisers                  }....................
+def _die_if_arg_default_unbearable(
+    bear_call: BeartypeCall, arg_default: object, hint: object) -> None:
+    '''
+    Raise a violation exception if the annotated optional parameter of the
+    decorated callable with the passed default value violates the type hint
+    annotating that parameter at decoration time.
+
+    Parameters
+    ----------
+    bear_call : BeartypeCall
+        Decorated callable to be type-checked.
+    arg_default : object
+        Either:
+
+        * If this parameter is mandatory, the :data:`.ArgMandatory` singleton.
+        * If this parameter is optional, the default value of this optional
+          parameter to be type-checked.
+    hint : object
+        Type hint to type-check against this default value.
+
+    Warns
+    -----
+    BeartypeDecorHintParamDefaultForwardRefWarning
+        If this type hint contains one or more forward references that *cannot*
+        be resolved at decoration time. While this does *not* necessarily
+        constitute a fatal error from the end user perspective, this does
+        constitute a non-fatal issue worth informing the end user of.
+
+    Raises
+    ------
+    BeartypeDecorHintParamDefaultViolation
+        If this default value violates this type hint.
+    '''
+
+    # ..................{ PREAMBLE                           }..................
+    # If this parameter is mandatory, silently reduce to a noop.
+    if arg_default is ArgMandatory:
+        return
+    # Else, this parameter is optional and thus defaults to a default value.
+
+    assert isinstance(bear_call, BeartypeCall), (
+        f'{repr(bear_call)} not beartype call.')
+
+    # ..................{ IMPORTS                            }..................
+    # Defer heavyweight imports prohibited at global scope.
+    from beartype.door import (
+        die_if_unbearable,
+        is_bearable,
+    )
+
+    # ..................{ MAIN                               }..................
+    # Attempt to...
+    try:
+        # If this default value satisfies this hint, silently reduce to a noop.
+        #
+        # Note that this is a non-negligible optimization. Technically, this
+        # preliminary test is superfluous: only the call to the
+        # die_if_unbearable() raiser below is required. Pragmatically, this
+        # preliminary test avoids a needlessly expensive dictionary copy in the
+        # common case that this value satisfies this hint.
+        if is_bearable(
+            obj=arg_default,
+            hint=hint,
+            conf=bear_call.conf,
+        ):
+            return
+        # Else, this default value violates this hint.
+    # If doing so raises a forward hint exception, this hint contains one or
+    # more unresolvable forward references to user-defined objects that have yet
+    # to be defined. In all likelihood, these objects are subsequently defined
+    # after the definition of this decorated callable. While this does *NOT*
+    # necessarily constitute a fatal error from the end user perspective, this
+    # does constitute a non-fatal issue worth informing the end user of. In this
+    # case, we coerce this exception into a warning.
+    except _BeartypeHintForwardRefExceptionMixin as exception:
+        # Forward hint exception message raised above. To readably embed this
+        # message in the longer warning message emitted below, the first
+        # character of this message is lowercased as well.
+        exception_message = lowercase_str_char_first(str(exception))
+
+        # Emit this non-fatal warning.
+        issue_warning(
+            cls=BeartypeDecorHintParamDefaultForwardRefWarning,
+            message=(
+                f'{EXCEPTION_PREFIX_DEFAULT}value '
+                f'{prefix_pith_value(pith=arg_default, is_color=bear_call.conf.is_color)}'
+                f'uncheckable at @beartype decoration time, as '
+                f'{exception_message}'
+            ),
+        )
+
+        # Loudly reduce to a noop. Since this forward reference is unresolvable,
+        # further type-checking attempts are entirely fruitless.
+        return
+
+    # Modifiable keyword dictionary encapsulating this beartype configuration.
+    conf_kwargs = bear_call.conf.kwargs.copy()
+
+    #FIXME: This should probably be configurable as well. For now, this is fine.
+    #We shrug noncommittally. We shrug, everyone! *shrug*
+    # Set the type of violation exception raised by the subsequent call to the
+    # die_if_unbearable() function to the expected type.
+    conf_kwargs['violation_door_type'] = BeartypeDecorHintParamDefaultViolation
+
+    # New beartype configuration initialized by this dictionary.
+    conf = BeartypeConf(**conf_kwargs)
+
+    # Raise this type of violation exception.
+    die_if_unbearable(
+        obj=arg_default,
+        hint=hint,
+        conf=conf,
+        exception_prefix=EXCEPTION_PREFIX_DEFAULT,
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/wrap/_wrapreturn.py
@@ -0,0 +1,252 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype decorator return code generator** (i.e., low-level callables
+dynamically generating Python expressions type-checking the annotated return of
+the callable currently being decorated by the :func:`beartype.beartype`
+decorator in a general-purpose manner).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import NoReturn
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.checkmake import (
+    make_code_raiser_func_pith_check,
+    make_code_raiser_func_pep484_noreturn_check,
+)
+from beartype._check.convert.convsanify import sanify_hint_root_func
+from beartype._data.func.datafuncarg import (
+    ARG_NAME_RETURN,
+    ARG_NAME_RETURN_REPR,
+)
+from beartype._data.hint.datahinttyping import LexicalScope
+from beartype._decor.wrap.wrapsnip import (
+    CODE_RETURN_CHECK_PREFIX,
+    CODE_RETURN_CHECK_SUFFIX,
+    PEP484_CODE_CHECK_NORETURN,
+)
+from beartype._decor.wrap._wraputil import unmemoize_func_wrapper_code
+from beartype._util.error.utilerrraise import reraise_exception_placeholder
+from beartype._util.error.utilerrwarn import reissue_warnings_placeholder
+from beartype._util.hint.utilhinttest import (
+    is_hint_ignorable,
+    is_hint_needs_cls_stack,
+)
+from beartype._util.kind.map.utilmapset import update_mapping
+from beartype._util.text.utiltextprefix import prefix_callable_return
+from beartype._util.utilobject import SENTINEL
+from warnings import catch_warnings
+
+# ....................{ CODERS                             }....................
+def code_check_return(bear_call: BeartypeCall) -> str:
+    '''
+    Generate a Python code snippet type-checking the annotated return declared
+    by the decorated callable if any *or* the empty string otherwise (i.e., if
+    this return is unannotated).
+
+    Parameters
+    ----------
+    bear_call : BeartypeCall
+        Decorated callable to be type-checked.
+
+    Returns
+    -------
+    str
+        Code type-checking any annotated return of the decorated callable.
+
+    Raises
+    ------
+    BeartypeDecorHintPep484585Exception
+        If this callable is either:
+
+        * A coroutine *not* annotated by a :obj:`typing.Coroutine` type hint.
+        * A generator *not* annotated by a :obj:`typing.Generator` type hint.
+        * An asynchronous generator *not* annotated by a
+          :obj:`typing.AsyncGenerator` type hint.
+    BeartypeDecorHintNonpepException
+        If the type hint annotating this return (if any) of this callable is
+        neither:
+
+        * **PEP-compliant** (i.e., :mod:`beartype`-agnostic hint compliant with
+          annotation-centric PEPs).
+        * **PEP-noncompliant** (i.e., :mod:`beartype`-specific type hint *not*
+          compliant with annotation-centric PEPs)).
+    '''
+    assert isinstance(bear_call, BeartypeCall), (
+        f'{repr(bear_call)} not beartype call.')
+
+    # Type hint annotating this callable's return if any *OR* "SENTINEL"
+    # otherwise (i.e., if this return is unannotated).
+    #
+    # Note that "None" is a semantically meaningful PEP 484-compliant type hint
+    # equivalent to "type(None)". Ergo, we *MUST* explicitly distinguish
+    # between that type hint and an unannotated return.
+    hint = bear_call.func_arg_name_to_hint_get(ARG_NAME_RETURN, SENTINEL)
+
+    # If this return is unannotated, silently reduce to a noop.
+    if hint is SENTINEL:
+        return ''
+    # Else, this return is annotated.
+
+    # Python code snippet to be returned, defaulting to the empty string
+    # implying this callable's return to either be unannotated *OR* annotated by
+    # a safely ignorable type hint.
+    func_wrapper_code = ''
+
+    # Lexical scope (i.e., dictionary mapping from the relative unqualified name
+    # to value of each locally or globally scoped attribute accessible to a
+    # callable or class), initialized to "None" for safety.
+    func_scope: LexicalScope = None  # type: ignore[assignment]
+
+    # Attempt to...
+    try:
+        # With a context manager "catching" *ALL* non-fatal warnings emitted
+        # during this logic for subsequent "playrback" below...
+        with catch_warnings(record=True) as warnings_issued:
+            # Preserve the original unsanitized type hint for subsequent
+            # reference *BEFORE* sanitizing this type hint.
+            hint_insane = hint
+
+            # Sanitize this hint to either:
+            # * If this hint is PEP-noncompliant, the PEP-compliant type hint
+            #   converted from this PEP-noncompliant type hint.
+            # * If this hint is PEP-compliant and supported, this hint as is.
+            # * Else, raise an exception.
+            #
+            # Do this first *BEFORE* passing this hint to any further callables.
+            hint = sanify_hint_root_func(
+                hint=hint, pith_name=ARG_NAME_RETURN, bear_call=bear_call)
+            # print(f'Sanified {repr(bear_call.func_wrappee)} return hint {repr(hint_insane)} to {repr(hint)}...')
+
+            # If this is the PEP 484-compliant "typing.NoReturn" type hint
+            # permitted *ONLY* as a return annotation...
+            if hint is NoReturn:
+                # Pre-generated code snippet validating this callable to *NEVER*
+                # successfully return by unconditionally generating a violation.
+                code_noreturn_check = PEP484_CODE_CHECK_NORETURN.format(
+                    func_call_prefix=bear_call.func_wrapper_code_call_prefix)
+
+                # Code snippet handling the previously generated violation by
+                # either raising that violation as a fatal exception or emitting
+                # that violation as a non-fatal warning.
+                (
+                    code_noreturn_violation,
+                    func_scope,
+                    _
+                ) = make_code_raiser_func_pep484_noreturn_check(bear_call.conf)
+
+                # Full code snippet to be returned.
+                func_wrapper_code = (
+                    f'{code_noreturn_check}{code_noreturn_violation}')
+            # Else, this is *NOT* "typing.NoReturn". In this case...
+            else:
+                # If this PEP-compliant hint is unignorable, generate and return
+                # a snippet type-checking this return against this hint.
+                if not is_hint_ignorable(hint):
+                    # Type stack if required by this hint *OR* "None" otherwise.
+                    # See is_hint_needs_cls_stack() for details.
+                    #
+                    # Note that the original unsanitized "hint_insane" (e.g.,
+                    # "typing.Self") rather than the new sanitized "hint" (e.g.,
+                    # the class currently being decorated by @beartype) is
+                    # passed to that tester. See _code_check_args() for details.
+                    cls_stack = (
+                        bear_call.cls_stack
+                        if is_hint_needs_cls_stack(hint_insane) else
+                        None
+                    )
+                    # print(f'return hint {repr(hint_insane)} -> {repr(hint)} cls_stack: {repr(cls_stack)}')
+
+                    # Empty tuple, passed below to satisfy the
+                    # _unmemoize_func_wrapper_code() API.
+                    hint_refs_type_basename = ()
+
+                    # Code snippet type-checking any arbitrary return.
+                    (
+                        code_return_check_pith,
+                        func_scope,
+                        hint_refs_type_basename,
+                    ) = make_code_raiser_func_pith_check(  # type: ignore[assignment]
+                        hint,
+                        bear_call.conf,
+                        cls_stack,
+                        False,  # <-- True only for parameters
+                    )
+
+                    # Unmemoize this snippet against this return.
+                    code_return_check = unmemoize_func_wrapper_code(
+                        bear_call=bear_call,
+                        func_wrapper_code=code_return_check_pith,
+                        pith_repr=ARG_NAME_RETURN_REPR,
+                        hint_refs_type_basename=hint_refs_type_basename,
+                    )
+
+                    #FIXME: [SPEED] Optimize the following two string munging
+                    #operations into a single string-munging operation resembling:
+                    #    func_wrapper_code = CODE_RETURN_CHECK.format(
+                    #        func_call_prefix=bear_call.func_wrapper_code_call_prefix,
+                    #        check_expr=code_return_check_pith_unmemoized,
+                    #    )
+                    #
+                    #Then define "CODE_RETURN_CHECK" in the "wrapsnip" submodule to
+                    #resemble:
+                    #    CODE_RETURN_CHECK = (
+                    #        f'{CODE_RETURN_CHECK_PREFIX}{{check_expr}}'
+                    #        f'{CODE_RETURN_CHECK_SUFFIX}'
+                    #    )
+
+                    # Code snippet type-checking this return.
+                    code_return_check_prefix = CODE_RETURN_CHECK_PREFIX.format(
+                        func_call_prefix=(
+                            bear_call.func_wrapper_code_call_prefix))
+
+                    # Full code snippet to be returned, consisting of:
+                    # * Calling the decorated callable and localize its return
+                    #   *AND*...
+                    # * Type-checking this return *AND*...
+                    # * Returning this return from this wrapper function.
+                    func_wrapper_code = (
+                        f'{code_return_check_prefix}'
+                        f'{code_return_check}'
+                        f'{CODE_RETURN_CHECK_SUFFIX}'
+                    )
+                # Else, this hint is ignorable.
+                # if not func_wrapper_code: print(f'Ignoring {bear_call.func_name} return hint {repr(hint)}...')
+        # If one or more warnings were issued, reissue these warnings with each
+        # placeholder substring (i.e., "EXCEPTION_PLACEHOLDER" instance)
+        # replaced by a human-readable description of this callable and
+        # annotated return.
+        if warnings_issued:
+            reissue_warnings_placeholder(
+                warnings=warnings_issued,
+                target_str=prefix_callable_return(
+                    func=bear_call.func_wrappee,
+                    is_color=bear_call.conf.is_color,
+                ),
+            )
+        # Else, *NO* warnings were issued.
+    # If any exception was raised, reraise this exception with each placeholder
+    # substring (i.e., "EXCEPTION_PLACEHOLDER" instance) replaced by a
+    # human-readable description of this callable and annotated return.
+    except Exception as exception:
+        reraise_exception_placeholder(
+            exception=exception,
+            target_str=prefix_callable_return(
+                func=bear_call.func_wrappee,
+                is_color=bear_call.conf.is_color,
+            ),
+        )
+
+    # If a local scope is required to type-check this return, merge this scope
+    # into the local scope currently required by the current wrapper function.
+    if func_scope:
+        update_mapping(bear_call.func_wrapper_scope, func_scope)
+    # Else, *NO* local scope is required to type-check this return.
+
+    # Return this code.
+    return func_wrapper_code
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/wrap/_wraputil.py
@@ -0,0 +1,137 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype decorator code generator utilities** (i.e., low-level callables
+assisting the parent :func:`beartype._decor.wrap.wrapmain` submodule).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.checkmagic import CODE_PITH_ROOT_NAME_PLACEHOLDER
+from beartype._check.code.codescope import add_func_scope_ref
+from beartype._check.code.snip.codesnipstr import (
+    CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_PREFIX,
+    CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_SUFFIX,
+)
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585ref import (
+    get_hint_pep484585_ref_names_relative_to)
+from beartype._util.text.utiltextmunge import replace_str_substrs
+from collections.abc import Iterable
+
+# ....................{ CACHERS                            }....................
+def unmemoize_func_wrapper_code(
+    bear_call: BeartypeCall,
+    func_wrapper_code: str,
+    pith_repr: str,
+    hint_refs_type_basename: tuple,
+) -> str:
+    '''
+    Convert the passed memoized code snippet type-checking any parameter or
+    return of the decorated callable into an "unmemoized" code snippet
+    type-checking a specific parameter or return of that callable.
+
+    Specifically, this function (in order):
+
+    #. Globally replaces all references to the
+       :data:`.CODE_PITH_ROOT_NAME_PLACEHOLDER` placeholder substring
+       cached into this code with the passed ``pith_repr`` parameter.
+    #. Unmemoizes this code by globally replacing all relative forward
+       reference placeholder substrings cached into this code with Python
+       expressions evaluating to the classes referred to by those substrings
+       relative to that callable when accessed via the private
+       ``__beartypistry`` parameter.
+
+    Parameters
+    ----------
+    bear_call : BeartypeCall
+        Decorated callable to be type-checked.
+    func_wrapper_code : str
+        Memoized callable-agnostic code snippet type-checking any parameter or
+        return of the decorated callable.
+    pith_repr : str
+        Machine-readable representation of the name of this parameter or
+        return.
+    hint_refs_type_basename : tuple
+        Tuple of the unqualified classnames referred to by all relative forward
+        reference type hints visitable from the current root type hint.
+
+    Returns
+    -------
+    str
+        This memoized code unmemoized by globally resolving all relative
+        forward reference placeholder substrings cached into this code relative
+        to the currently decorated callable.
+    '''
+    assert bear_call.__class__ is BeartypeCall, (
+        f'{repr(bear_call)} not @beartype call.')
+    assert isinstance(func_wrapper_code, str), (
+        f'{repr(func_wrapper_code)} not string.')
+    assert isinstance(pith_repr, str), f'{repr(pith_repr)} not string.'
+    assert isinstance(hint_refs_type_basename, Iterable), (
+        f'{repr(hint_refs_type_basename)} not iterable.')
+
+    # Generate an unmemoized parameter-specific code snippet type-checking this
+    # parameter by replacing in this parameter-agnostic code snippet...
+    func_wrapper_code = replace_str_substrs(
+        text=func_wrapper_code,
+        # This placeholder substring cached into this code with...
+        old=CODE_PITH_ROOT_NAME_PLACEHOLDER,
+        # This object representation of the name of this parameter or return.
+        new=pith_repr,
+    )
+
+    # If this code contains one or more relative forward reference placeholder
+    # substrings memoized into this code, unmemoize this code by globally
+    # resolving these placeholders relative to the decorated callable.
+    if hint_refs_type_basename:
+        # Metadata describing the callable currently being decorated by
+        # beartype, localized purely as a negligible optimization.
+        func = bear_call.func_wrappee
+        func_scope = bear_call.func_wrapper_scope
+        cls_stack = bear_call.cls_stack
+
+        # For each unqualified classname referred to by a relative forward
+        # reference type hints visitable from the current root type hint...
+        for ref_basename in hint_refs_type_basename:
+            # Possibly undefined fully-qualified module name and possibly
+            # unqualified classname referred to by this relative forward
+            # reference, relative to the decorated type stack and callable.
+            ref_module_name, ref_name = get_hint_pep484585_ref_names_relative_to(
+                hint=ref_basename,
+                cls_stack=cls_stack,
+                func=func,
+                exception_prefix=EXCEPTION_PLACEHOLDER,
+            )
+
+            # Name of the hidden parameter providing this forward reference
+            # proxy to be passed to this wrapper function.
+            ref_expr = add_func_scope_ref(
+                func_scope=func_scope,
+                ref_module_name=ref_module_name,
+                ref_name=ref_name,
+                exception_prefix=EXCEPTION_PLACEHOLDER,
+            )
+
+            # Generate an unmemoized callable-specific code snippet checking
+            # this class by globally replacing in this callable-agnostic code...
+            func_wrapper_code = replace_str_substrs(
+                text=func_wrapper_code,
+                # This placeholder substring cached into this code with...
+                old=(
+                    f'{CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_PREFIX}'
+                    f'{ref_name}'
+                    f'{CODE_HINT_REF_TYPE_BASENAME_PLACEHOLDER_SUFFIX}'
+                ),
+                # Python expression evaluating to this class when accessed via
+                # this hidden parameter.
+                new=ref_expr,
+            )
+
+    # Return this unmemoized callable-specific code snippet.
+    return func_wrapper_code
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/wrap/wrapmain.py
@@ -0,0 +1,172 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype decorator code generator.**
+
+This private submodule dynamically generates both the signature and body of the
+wrapper function type-checking all annotated parameters and return value of the
+the callable currently being decorated by the :func:`beartype.beartype`
+decorator in a general-purpose manner. For genericity, this relatively
+high-level submodule implements *no* support for annotation-based PEPs (e.g.,
+:pep:`484`); other lower-level submodules do so instead.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+# All "FIXME:" comments for this submodule reside in this package's "__init__"
+# submodule to improve maintainability and readability here.
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkcall import BeartypeCall
+from beartype._check.checkmagic import ARG_NAME_FUNC
+from beartype._check.util.checkutilmake import make_func_signature
+from beartype._decor.wrap.wrapsnip import (
+    CODE_RETURN_UNCHECKED_format,
+    CODE_SIGNATURE,
+)
+from beartype._decor.wrap._wrapargs import (
+    code_check_args as _code_check_args)
+from beartype._decor.wrap._wrapreturn import (
+    code_check_return as _code_check_return)
+
+# ....................{ GENERATORS                         }....................
+def generate_code(bear_call: BeartypeCall) -> str:
+    '''
+    Generate a Python code snippet dynamically defining the wrapper function
+    type-checking the passed decorated callable.
+
+    This high-level function implements this decorator's core type-checking,
+    converting all unignorable PEP-compliant type hints annotating this
+    callable into pure-Python code type-checking the corresponding parameters
+    and return values of each call to this callable.
+
+    Parameters
+    ----------
+    bear_call : BeartypeCall
+        Decorated callable to be type-checked.
+
+    Returns
+    -------
+    str
+        Generated function wrapper code. Specifically, either:
+
+        * If the decorated callable requires *no* type-checking (e.g., due to
+          all type hints annotating this callable being ignorable), the empty
+          string. Note this edge case is distinct from a related edge case at
+          the head of the :func:`beartype.beartype` decorator reducing to a noop
+          for unannotated callables. By compare, this boolean is ``True`` only
+          for callables annotated with **ignorable type hints** (i.e.,
+          :class:`object`, :class:`beartype.cave.AnyType`, :class:`typing.Any`):
+          e.g.,
+
+          .. code-block:: python
+
+              >>> from beartype.cave import AnyType
+              >>> from typing import Any
+              >>> def muh_func(muh_param1: AnyType, muh_param2: object) -> Any: pass
+              >>> muh_func is beartype(muh_func)
+              True
+
+        * Else, a code snippet defining the wrapper function type-checking the
+          decorated callable, including (in order):
+
+          * A signature declaring this wrapper, accepting both beartype-agnostic
+            and -specific parameters. The latter include:
+
+            * A private ``__beartype_func`` parameter initialized to the
+              decorated callable. In theory, this callable should be accessible
+              as a closure-style local in this wrapper. For unknown reasons
+              (presumably, a subtle bug in the exec() builtin), this is *not*
+              the case. Instead, a closure-style local must be simulated by
+              passing this callable at function definition time as the default
+              value of an arbitrary parameter. To ensure this default is *not*
+              overwritten by a function accepting a parameter of the same name,
+              this unlikely edge case is guarded against elsewhere.
+
+          * Statements type checking parameters passed to the decorated
+            callable.
+          * A call to the decorated callable.
+          * A statement type checking the value returned by the decorated
+            callable.
+
+    Raises
+    ------
+    BeartypeDecorParamNameException
+        If the name of any parameter declared on this callable is prefixed by
+        the reserved substring ``__bear``.
+    BeartypeDecorHintNonpepException
+        If any type hint annotating any parameter of this callable is neither:
+
+        * **PEP-compliant** (i.e., :mod:`beartype`-agnostic hint compliant with
+          annotation-centric PEPs).
+        * **PEP-noncompliant** (i.e., :mod:`beartype`-specific type hint *not*
+          compliant with annotation-centric PEPs)).
+    _BeartypeUtilMappingException
+        If generated code type-checking any pair of parameters and returns
+        erroneously declares an optional private beartype-specific parameter of
+        the same name with differing default value. Since this should *never*
+        happen, a private non-human-readable exception is raised in this case.
+    '''
+
+    # Python code snippet type-checking all callable parameters if one or more
+    # such parameters are annotated with unignorable type hints *OR* the empty
+    # string otherwise.
+    code_check_params = _code_check_args(bear_call)
+
+    # Python code snippet type-checking the callable return if this return is
+    # annotated with an unignorable type hint *OR* the empty string otherwise.
+    code_check_return = _code_check_return(bear_call)
+
+    # If the callable return requires *NO* type-checking...
+    #
+    # Note that this branch *CANNOT* be embedded in the prior call to the
+    # code_check_return() function, as doing so would prevent us from
+    # efficiently reducing to a noop here.
+    if not code_check_return:
+        # If all callable parameters also require *NO* type-checking, this
+        # callable itself requires *NO* type-checking. In this case, return the
+        # empty string instructing the parent @beartype decorator to reduce to a
+        # noop (i.e., the identity decorator returning this callable as is).
+        if not code_check_params:
+            return ''
+        # Else, one or more callable parameters require type-checking.
+
+        # Python code snippet calling this callable unchecked, returning the
+        # value returned by this callable from this wrapper.
+        code_check_return = CODE_RETURN_UNCHECKED_format(
+            func_call_prefix=bear_call.func_wrapper_code_call_prefix)
+    # Else, the callable return requires type-checking.
+
+    # Dictionary mapping from the name to value of each attribute referenced in
+    # the signature of this wrapper function, localized merely for readability.
+    func_scope = bear_call.func_wrapper_scope
+
+    # Pass parameters unconditionally required by *ALL* wrapper functions.
+    func_scope[ARG_NAME_FUNC] = bear_call.func_wrappee
+
+    # Python code snippet declaring the signature of this type-checking wrapper
+    # function, deferred for efficiency until *AFTER* confirming that a wrapper
+    # function is even required.
+    code_signature = make_func_signature(
+        func_name=bear_call.func_wrapper_name,
+        func_scope=func_scope,
+        code_signature_format=CODE_SIGNATURE,
+        code_signature_prefix=bear_call.func_wrapper_code_signature_prefix,
+        conf=bear_call.conf,
+    )
+
+    # Return Python code defining the wrapper type-checking this callable.
+    # While there exist numerous alternatives to string formatting (e.g.,
+    # appending to a list or bytearray before joining the items of that
+    # iterable into a string), these alternatives are either:
+    # * Slower, as in the case of a list (e.g., due to the high up-front cost
+    #   of list construction).
+    # * Cumbersome, as in the case of a bytearray.
+    #
+    # Since string concatenation is heavily optimized by the official CPython
+    # interpreter, the simplest approach is the most ideal. KISS, bro.
+    return f'{code_signature}{code_check_params}{code_check_return}'
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_decor/wrap/wrapsnip.py
@@ -0,0 +1,219 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype decorator **wrapper function code snippets** (i.e., triple-quoted
+pure-Python string constants formatted and concatenated together to dynamically
+generate the implementations of wrapper functions type-checking
+:func:`beartype.beartype`-decorated callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._check.checkmagic import (
+    ARG_NAME_FUNC,
+    ARG_NAME_GET_VIOLATION,
+    VAR_NAME_ARGS_LEN,
+    VAR_NAME_PITH_ROOT,
+)
+from beartype._util.func.arg.utilfuncargiter import ArgKind
+from beartype._data.code.datacodeindent import CODE_INDENT_1
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from collections.abc import Callable
+
+# ....................{ STRINGS                            }....................
+EXCEPTION_PREFIX_DEFAULT = f'{EXCEPTION_PLACEHOLDER}default '
+'''
+Non-human-readable source substring to be globally replaced by a human-readable
+target substring in the messages of memoized exceptions passed to the
+:func:`reraise_exception` function caused by violations raised when
+type-checking the default values of optional parameters for
+:func:`beartype.beartype`-decorated callables.
+'''
+
+# ....................{ CODE                               }....................
+CODE_SIGNATURE = f'''{{code_signature_prefix}}def {{func_name}}(
+    *args,
+{{code_signature_args}}{CODE_INDENT_1}**kwargs
+):'''
+'''
+Code snippet declaring the signature of a type-checking callable.
+
+Note that:
+
+* ``code_signature_prefix`` is usually either:
+
+  * For synchronous callables, the empty string.
+  * For asynchronous callables (e.g., asynchronous generators, coroutines),
+    the space-suffixed keyword ``"async "``.
+'''
+
+
+CODE_INIT_ARGS_LEN = f'''
+    # Localize the number of passed positional arguments for efficiency.
+    {VAR_NAME_ARGS_LEN} = len(args)'''
+'''
+Code snippet localizing the number of passed positional arguments for callables
+accepting one or more such arguments.
+'''
+
+# ....................{ CODE ~ arg                         }....................
+ARG_KIND_TO_CODE_LOCALIZE = {
+    # Snippet localizing any positional-only parameter (e.g.,
+    # "{posonlyarg}, /") by lookup in the wrapper's "*args" dictionary.
+    ArgKind.POSITIONAL_ONLY: f'''
+    # If this positional-only parameter was passed...
+    if {VAR_NAME_ARGS_LEN} > {{arg_index}}:
+        # Localize this positional-only parameter.
+        {VAR_NAME_PITH_ROOT} = args[{{arg_index}}]''',
+
+    # Snippet localizing any positional or keyword parameter as follows:
+    #
+    # * If this parameter's 0-based index (in the parameter list of the
+    #   decorated callable's signature) does *NOT* exceed the number of
+    #   positional parameters passed to the wrapper function, localize this
+    #   positional parameter from the wrapper's variadic "*args" tuple.
+    # * Else if this parameter's name is in the dictionary of keyword
+    #   parameters passed to the wrapper function, localize this keyword
+    #   parameter from the wrapper's variadic "*kwargs" tuple.
+    # * Else, this parameter is unpassed. In this case, localize this parameter
+    #   as a placeholder value guaranteed to *NEVER* be passed to any wrapper
+    #   function: the private "__beartypistry" singleton passed to this wrapper
+    #   function as a hidden default parameter and thus accessible here. While
+    #   we could pass a "__beartype_sentinel" parameter to all wrapper
+    #   functions defaulting to "object()" and then use that here instead,
+    #   doing so would slightly reduce efficiency for no tangible gain. *shrug*
+    ArgKind.POSITIONAL_OR_KEYWORD: f'''
+    # Localize this positional or keyword parameter if passed *OR* to the
+    # sentinel "__beartype_raise_exception" guaranteed to never be passed.
+    {VAR_NAME_PITH_ROOT} = (
+        args[{{arg_index}}] if {VAR_NAME_ARGS_LEN} > {{arg_index}} else
+        kwargs.get({{arg_name!r}}, {ARG_NAME_GET_VIOLATION})
+    )
+
+    # If this parameter was passed...
+    if {VAR_NAME_PITH_ROOT} is not {ARG_NAME_GET_VIOLATION}:''',
+
+    # Snippet localizing any keyword-only parameter (e.g., "*, {kwarg}") by
+    # lookup in the wrapper's variadic "**kwargs" dictionary. (See above.)
+    ArgKind.KEYWORD_ONLY: f'''
+    # Localize this keyword-only parameter if passed *OR* to the sentinel value
+    # "__beartype_raise_exception" guaranteed to never be passed.
+    {VAR_NAME_PITH_ROOT} = kwargs.get({{arg_name!r}}, {ARG_NAME_GET_VIOLATION})
+
+    # If this parameter was passed...
+    if {VAR_NAME_PITH_ROOT} is not {ARG_NAME_GET_VIOLATION}:''',
+
+    # Snippet iteratively localizing all variadic positional parameters.
+    ArgKind.VAR_POSITIONAL: f'''
+    # For all passed variadic positional parameters...
+    for {VAR_NAME_PITH_ROOT} in args[{{arg_index!r}}:]:''',
+
+    #FIXME: Probably impossible to implement under the standard decorator
+    #paradigm, sadly. This will have to wait for us to fundamentally revise
+    #our signature generation algorithm.
+    # # Snippet iteratively localizing all variadic keyword parameters.
+    # ArgKind.VAR_KEYWORD: f'''
+    # # For all passed variadic keyword parameters...
+    # for {VAR_NAME_PITH_ROOT} in kwargs[{{arg_index!r}}:]:''',
+}
+'''
+Dictionary mapping from the type of each callable parameter supported by the
+:func:`beartype.beartype` decorator to a code snippet localizing that callable's
+next parameter to be type-checked.
+'''
+
+# ....................{ CODE ~ return ~ check              }....................
+CODE_RETURN_CHECK_PREFIX = f'''
+    # Call this function with all passed parameters and localize the value
+    # returned from this call.
+    {VAR_NAME_PITH_ROOT} = {{func_call_prefix}}{ARG_NAME_FUNC}(*args, **kwargs)
+
+    # Noop required to artificially increase indentation level. Note that
+    # CPython implicitly optimizes this conditional away. Isn't that nice?
+    if True:'''
+'''
+Code snippet calling the decorated callable and localizing the value returned by
+that call.
+
+Note that this snippet intentionally terminates on a noop increasing the
+indentation level, enabling subsequent type-checking code to effectively ignore
+indentation level and thus uniformly operate on both:
+
+* Parameters localized via values of the
+  :data:`PARAM_KIND_TO_PEP_CODE_LOCALIZE` dictionary.
+* Return values localized via this snippet.
+
+See Also
+--------
+https://stackoverflow.com/a/18124151/2809027
+    Bytecode disassembly demonstrating that CPython optimizes away the spurious
+   ``if True:`` conditional hardcoded into this snippet.
+'''
+
+
+CODE_RETURN_CHECK_SUFFIX = f'''
+    return {VAR_NAME_PITH_ROOT}'''
+'''
+Code snippet returning from the wrapper function the successfully type-checked
+value returned from the decorated callable.
+'''
+
+# ....................{ CODE ~ return ~ check ~ noreturn   }....................
+#FIXME: *FALSE.* The following comment is entirely wrong, sadly. Although that
+#comment does, in fact, apply to asynchronous generators, that comment does
+#*NOT* apply to coroutines. PEP 484 stipulates that the returns of coroutines
+#are annotated in the exact same standard way as the returns of synchronous
+#callables are annotated: e.g.,
+#   # This is valid, but @beartype currently fails to support this.
+#   async def muh_coroutine() -> typing.NoReturn:
+#       await asyncio.sleep(0)
+#       raise ValueError('Dude, who stole my standards compliance?')
+#
+#Generalize this snippet to contain a "{{func_call_prefix}}" substring prefixing
+#the "{ARG_NAME_FUNC}(*args, **kwargs)" call, please.
+
+# Unlike above, this snippet intentionally omits the "{{func_call_prefix}}"
+# substring prefixing the "{ARG_NAME_FUNC}(*args, **kwargs)" call. Why? Because
+# callables whose returns are annotated by "typing.NoReturn" *MUST* necessarily
+# be synchronous (rather than asynchronous) and thus require no such prefix.
+# Why? Because the returns of asynchronous callables are either unannotated
+# *OR* annotated by either "Coroutine[...]" *OR* "AsyncGenerator[...]" type
+# hints. Since "typing.NoReturn" is neither, "typing.NoReturn" *CANNOT*
+# annotate the returns of asynchronous callables. The implication then follows.
+PEP484_CODE_CHECK_NORETURN = f'''
+    # Call this function with all passed parameters and localize the value
+    # returned from this call.
+    {VAR_NAME_PITH_ROOT} = {{func_call_prefix}}{ARG_NAME_FUNC}(*args, **kwargs)
+
+    # Since this function annotated by "typing.NoReturn" successfully returned a
+    # value rather than raising an exception or halting the active Python
+    # interpreter, unconditionally raise an exception.
+    #
+    # Noop required to artificially increase indentation level. Note that
+    # CPython implicitly optimizes this conditional away. Isn't that nice?
+    if True'''
+'''
+:pep:`484`-compliant code snippet calling the decorated callable annotated by
+the :attr:`typing.NoReturn` singleton and raising an exception if this call
+successfully returned a value rather than raising an exception or halting the
+active Python interpreter.
+'''
+
+# ....................{ CODE ~ return ~ uncheck            }....................
+CODE_RETURN_UNCHECKED = f'''
+    # Call this function with all passed parameters and return the value
+    # returned from this call.
+    return {{func_call_prefix}}{ARG_NAME_FUNC}(*args, **kwargs)'''
+'''
+Code snippet calling the decorated callable *without* type-checking the value
+returned by that call (if any).
+'''
+
+# ..................{ FORMATTERS                             }..................
+# str.format() methods, globalized to avoid inefficient dot lookups elsewhere.
+# This is an absurd micro-optimization. *fight me, github developer community*
+CODE_RETURN_UNCHECKED_format: Callable = CODE_RETURN_UNCHECKED.format
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/api/utilapibeartype.py
@@ -0,0 +1,111 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **beartype-generated wrapper function utilities** (i.e., callables
+specifically applicable to wrapper functions generated by the
+:func:`beartype.beartype` decorator for beartype-decorated callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._util.func.pep.utilpep484func import (
+    is_func_pep484_notypechecked)
+from beartype._util.func.utilfuncget import get_func_annotations_or_none
+from beartype._util.api.utilapisphinx import is_sphinx_autodocing
+from beartype._util.py.utilpyinterpreter import is_python_optimized
+from collections.abc import Callable
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_func_unbeartypeable(func: Callable) -> bool:
+    '''
+    :data:`True` only if the passed callable is **unbeartypeable** (i.e., if the
+    :func:`beartype.beartype` decorator should preserve that callable as is by
+    reducing to the identity decorator rather than wrap that callable with
+    constant-time type-checking).
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if that callable is unbeartypeable.
+    '''
+
+    # Return true only if either...
+    return (
+        # That callable is unannotated *OR*...
+        get_func_annotations_or_none(func) is None or
+        # That callable is decorated by the @typing.no_type_check decorator
+        # defining this dunder instance variable on this callable *OR*...
+        is_func_pep484_notypechecked(func) or
+        # That callable is a @beartype-specific wrapper previously generated by
+        # this decorator *OR*...
+        is_func_beartyped(func) or
+        # The active Python process was optimized *AFTER* process invocation
+        # time (e.g., in an interactive REPL by the external user manually
+        # setting the ${PYTHONOPTIMIZED} environment variable to a non-zero
+        # integer) *OR*...
+        is_python_optimized() or
+        # Sphinx is currently autogenerating documentation (i.e., if this
+        # decorator has been called from a Python call stack invoked by the
+        # "autodoc" extension bundled with the optional third-party build-time
+        # "sphinx" package)...
+        #
+        # Why? Because of mocking. When @beartype-decorated callables are
+        # annotated with one more classes mocked by "autodoc_mock_imports",
+        # @beartype frequently raises exceptions at decoration time. Why?
+        # Because mocking subverts our assumptions and expectations about
+        # classes used as annotations.
+        is_sphinx_autodocing()
+    )
+
+
+def is_func_beartyped(func: Callable) -> bool:
+    '''
+    :data:`True` only if the passed callable is a **beartype-generated wrapper
+    function** (i.e., function dynamically generated by the
+    :func:`beartype.beartype` decorator for a user-defined callable decorated by
+    that decorator, wrapping that callable with constant-time type-checking).
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if that callable is a beartype-generated wrapper
+        function.
+    '''
+
+    # Return true only if this callable is a @beartype-specific wrapper
+    # previously generated by this decorator.
+    return hasattr(func, '__beartype_wrapper')
+
+# ....................{ SETTERS                            }....................
+def set_func_beartyped(func: Callable) -> None:
+    '''
+    Declare the passed callable to be a **beartype-generated wrapper function**
+    (i.e., function dynamically generated by the :func:`beartype.beartype`
+    decorator for a user-defined callable decorated by that decorator, wrapping
+    that callable with constant-time type-checking).
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be modified.
+    '''
+
+    # Declare this callable to be generated by @beartype, which tests for the
+    # existence of this attribute above to avoid re-decorating callables
+    # already decorated by @beartype by efficiently reducing to a noop.
+    func.__beartype_wrapper = True  # type: ignore[attr-defined]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/api/utilapicontextlib.py
@@ -0,0 +1,102 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :mod:`contextlib` utilities (i.e., low-level callables handling the
+standard :mod:`contextlib` module).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+)
+from beartype._data.hint.datahintfactory import TypeGuard
+from beartype._util.func.utilfunccodeobj import (
+    get_func_codeobj_or_none,
+    get_func_codeobj_basename,
+)
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_MOST_3_10
+from collections.abc import (
+    Callable,
+    # Generator,
+)
+
+# ....................{ TESTERS                            }....................
+def is_func_contextlib_contextmanager(func: Any) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is a
+    :func:`contextlib.contextmanager`-based **isomorphic decorator closure**
+    (i.e., closure both defined and returned by the standard
+    :func:`contextlib.contextmanager` decorator where that closure
+    isomorphically preserves both the number and types of all passed parameters
+    and returns by accepting only a variadic positional argument and variadic
+    keyword argument).
+
+    This tester enables callers to detect when a user-defined callable has been
+    decorated by :func:`contextlib.contextmanager` and thus has a mismatch
+    between the type hints annotating that decorated callable and the type of
+    the object created and returned by that decorated callable.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a
+        :func:`contextlib.contextmanager`-based isomorphic decorator closure.
+
+    See Also
+    --------
+    beartype._data.func.datafunc.CONTEXTLIB_CONTEXTMANAGER_CO_NAME_QUALNAME
+        Further discussion.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import is_func_closure
+
+    # If either...
+    if (
+        # The active Python interpreter targets Python < 3.10 and thus fails to
+        # define the "co_qualname" attribute on code objects required to
+        # robustly implement this test *OR*...
+        IS_PYTHON_AT_MOST_3_10 or
+        # The passed callable is *NOT* a closure...
+        not is_func_closure(func)
+    ):
+        # Then immediately return false.
+        return False
+    # Else, that callable is a closure.
+
+    # Code object underlying that callable as is (rather than possibly unwrapped
+    # to another code object entirely) if that callable is pure-Python *OR*
+    # "None" otherwise (i.e., if that callable is C-based).
+    func_codeobj = get_func_codeobj_or_none(func)
+
+    # If that callable is C-based, immediately return false.
+    if func_codeobj is None:
+        return False
+    # Else, that callable is pure-Python.
+
+    # Defer heavyweight tester-specific imports with potential side effects --
+    # notably, increased costs to space and time complexity.
+    from beartype._data.module.datamodcontextlib import (
+        CONTEXTLIB_CONTEXTMANAGER_CODEOBJ_NAME)
+
+    # Fully-qualified name of that code object.
+    func_codeobj_name = get_func_codeobj_basename(func_codeobj)
+
+    # Return true only if the fully-qualified name of that code object is that
+    # of the isomorphic decorator closure created and returned by the standard
+    # @contextlib.contextmanager decorator.
+    #
+    # Note that we *COULD* technically also explicitly test whether that
+    # callable satisfies the is_func_wrapper_isomorphic() tester, but that
+    # there's no benefit and a minor efficiency cost  to doing so.
+    return func_codeobj_name == CONTEXTLIB_CONTEXTMANAGER_CODEOBJ_NAME
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/api/utilapifunctools.py
@@ -0,0 +1,249 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :mod:`functools` utilities (i.e., low-level callables handling the
+standard :mod:`functools` module).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import (
+    Any,
+    Tuple,
+)
+from beartype._cave._cavefast import (
+    CallableFunctoolsLruCacheType,
+    CallableFunctoolsPartialType,
+)
+from beartype._data.hint.datahintfactory import TypeGuard
+from beartype._data.hint.datahinttyping import (
+    DictStrToAny,
+    TypeException,
+)
+from collections.abc import Callable
+
+# ....................{ TESTERS                            }....................
+def is_func_functools_lru_cache(func: Any) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is a
+    :func:`functools.lru_cache`-memoized **pseudo-callable** (i.e., low-level
+    C-based callable object both created and returned by the standard
+    :func:`functools.lru_cache` decorator).
+
+    This tester enables callers to detect when a user-defined callable has been
+    decorated by the :func:`functools.lru_cache` decorator, which creates
+    low-level C-based callable objects requiring special handling elsewhere.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a
+        :func:`functools.lru_cache`-memoized callable.
+    '''
+
+    # Defer heavyweight tester-specific imports with potential side effects --
+    # notably, increased costs to space and time complexity.
+
+    # Return true only if the type of that callable is the low-level C-based
+    # private type of all objects created and returned by the standard
+    # @functools.lru_cache decorator.
+    return isinstance(func, CallableFunctoolsLruCacheType)
+
+
+def is_func_functools_partial(func: Any) -> TypeGuard[
+    CallableFunctoolsPartialType]:
+    '''
+    :data:`True` only if the passed object is a **partial** (i.e., pure-Python
+    callable :class:`functools.partial` object wrapping a possibly C-based
+    callable).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a
+        :func:`functools.partial`-wrapped callable.
+    '''
+
+    # Return true only if the type of that callable is the high-level
+    # pure-Python public type of all objects created and returned by the
+    # standard functools.partial() factory.
+    return isinstance(func, CallableFunctoolsPartialType)
+
+# ....................{ GETTERS                            }....................
+def get_func_functools_partial_args(
+    func: CallableFunctoolsPartialType) -> Tuple[tuple, DictStrToAny]:
+    '''
+    2-tuple ``(args, kwargs)`` providing the positional and keyword parameters
+    with which the passed **partial** (i.e., pure-Python callable
+    :class:`functools.partial` object directly wrapping this possibly C-based
+    callable) was originally partialized.
+
+    Parameters
+    ----------
+    func : CallableFunctoolsPartialType
+        Partial to be inspected.
+
+    Returns
+    -------
+    Tuple[tuple, DictStrToAny]
+        2-tuple ``(args, kwargs)`` such that:
+
+        * ``args`` is the tuple of the zero or more positional parameters passed
+          to the callable partialized by this partial.
+        * ``kwargs`` is the dictionary mapping from the name to value of the
+          zero or more keyword parameters passed to the callable partialized by
+          this partial.
+    '''
+    assert isinstance(func, CallableFunctoolsPartialType), (
+        f'{repr(func)} not "function.partial"-wrapped callable.')
+
+    # Return a 2-tuple providing the positional and keyword parameters with
+    # which this partial was originally partialized.
+    return (func.args, func.keywords)
+
+
+def get_func_functools_partial_args_flexible_len(
+    # Mandatory parameters.
+    func: CallableFunctoolsPartialType,
+
+    # Optional parameters.
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> int:
+    '''
+    Number of **flexible parameters** (i.e., parameters passable as either
+    positional or keyword arguments but *not* positional-only, keyword-only,
+    variadic, or other more constrained kinds of parameters) accepted by the
+    passed **partial** (i.e., pure-Python callable :class:`functools.partial`
+    object directly wrapping this possibly C-based callable).
+
+    Specifically, this getter transparently returns the total number of flexible
+    parameters accepted by the lower-level callable wrapped by this partial
+    minus the number of flexible parameters partialized away by this partial.
+
+    Parameters
+    ----------
+    func : CallableFunctoolsPartialType
+        Partial to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function.
+        Defaults to :data:`True` for safety. See :func:`.get_func_codeobj` for
+        further commentary.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the message of any exception raised in
+        the event of a fatal error. Defaults to the empty string.
+
+    Returns
+    -------
+    int
+        Number of flexible parameters accepted by this callable.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* pure-Python.
+    '''
+    assert isinstance(func, CallableFunctoolsPartialType), (
+        f'{repr(func)} not "function.partial"-wrapped callable.')
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.arg.utilfuncargget import (
+        get_func_args_flexible_len)
+
+    # Pure-Python wrappee callable wrapped by that partial.
+    wrappee = unwrap_func_functools_partial_once(func)
+
+    # Positional and keyword parameters implicitly passed by this partial to
+    # this wrappee.
+    partial_args, partial_kwargs = get_func_functools_partial_args(func)
+
+    # Number of flexible parameters accepted by this wrappee.
+    #
+    # Note that this recursive function call is guaranteed to immediately bottom
+    # out and thus be safe. Why? Because a partial *CANNOT* wrap itself, because
+    # a partial has yet to be defined when the functools.partial.__init__()
+    # method defining that partial is called. Technically, the caller *COULD*
+    # violate sanity by directly interfering with the "func" instance variable
+    # of this partial after instantiation. Pragmatically, a malicious edge case
+    # like that is unlikely in the extreme. You are now reading this comment
+    # because this edge case just blew up in your face, aren't you!?!? *UGH!*
+    wrappee_args_flexible_len = get_func_args_flexible_len(
+        func=wrappee,
+        is_unwrap=is_unwrap,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # Number of flexible parameters passed by this partial to this wrappee.
+    partial_args_flexible_len = len(partial_args) + len(partial_kwargs)
+
+    # Number of flexible parameters accepted by this wrappee minus the number of
+    # flexible parameters passed by this partial to this wrappee.
+    func_args_flexible_len = (
+        wrappee_args_flexible_len - partial_args_flexible_len)
+
+    # If this number is negative, the caller maliciously defined an invalid
+    # partial passing more flexible parameters than this wrappee accepts. In
+    # this case, raise an exception.
+    #
+    # Note that the "functools.partial" factory erroneously allows callers to
+    # define invalid partials passing more flexible parameters than their
+    # wrappees accept. Ergo, validation is required to guarantee sanity.
+    if func_args_flexible_len < 0:
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} passes '
+            f'{partial_args_flexible_len} parameter(s) to '
+            f'{repr(wrappee)} accepting only '
+            f'{wrappee_args_flexible_len} parameter(s) '
+            f'(i.e., {partial_args_flexible_len} > '
+            f'{wrappee_args_flexible_len}).'
+        )
+    # Else, this number is non-negative. The caller correctly defined a valid
+    # partial passing no more flexible parameters than this wrappee accepts.
+
+    # Return this number.
+    return func_args_flexible_len
+
+# ....................{ UNWRAPPERS                         }....................
+def unwrap_func_functools_partial_once(
+    func: CallableFunctoolsPartialType) -> Callable:
+    '''
+    Possibly C-based callable directly wrapped by the passed **partial** (i.e.,
+    pure-Python callable :class:`functools.partial` object directly wrapping
+    this possibly C-based callable).
+
+    Parameters
+    ----------
+    func : CallableFunctoolsPartialType
+        Partial to be unwrapped.
+
+    Returns
+    -------
+    Callable
+        Possibly C-based callable directly wrapped by this partial.
+    '''
+    assert isinstance(func, CallableFunctoolsPartialType), (
+        f'{repr(func)} not "function.partial"-wrapped callable.')
+
+    # Return the public "func" instance variable of this partial wrapper as is.
+    return func.func
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/api/utilapisphinx.py
@@ -0,0 +1,81 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Sphinx utilities** (i.e., low-level callables handling the
+third-party :mod:`sphinx` package as an optional runtime dependency of this
+project).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To prevent this project from accidentally requiring third-party
+# packages as mandatory runtime dependencies, avoid importing from *ANY* such
+# package via a module-scoped import. These imports should be isolated to the
+# bodies of callables declared below.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype._util.func.utilfuncframe import iter_frames
+from sys import modules as module_imported_names
+
+# ....................{ TESTERS                            }....................
+def is_sphinx_autodocing() -> bool:
+    '''
+    :data:`True` only if Sphinx is currently **autogenerating documentation**
+    (i.e., if this function has been called from a Python call stack invoked by
+    the ``autodoc`` extension bundled with the optional third-party build-time
+    :mod:`sphinx` package).
+    '''
+
+    # If the "autodoc" extension has *NOT* been imported, Sphinx by definition
+    # *CANNOT* be autogenerating documentation. In this case, return false.
+    #
+    # Note this technically constitutes an optional (albeit pragmatically
+    # critical) optimization. This test is O(1) with negligible constants,
+    # whereas the additional test below is O(n) with non-negligible constants.
+    # Ergo, this efficient test short-circuits the inefficient test below.
+    if _SPHINX_AUTODOC_SUBPACKAGE_NAME not in module_imported_names:
+        return False
+    # Else, the "autodoc" extension has been imported. Since this does *NOT*
+    # conclusively imply that Sphinx is currently autogenerating documentation,
+    # further testing is required to avoid returning false positives (and thus
+    # erroneously reducing @beartype to a noop, which would be horrifying).
+    #
+    # Specifically, we iteratively search up the call stack for a stack frame
+    # originating from the "autodoc" extension. If we find such a stack frame,
+    # Sphinx is currently autogenerating documentation; else, Sphinx is not.
+
+    #FIXME: Refactor this to leverage a genuinely valid working solution
+    #hopefully provided out-of-the-box by some hypothetical new bleeding-edge
+    #version of Sphinx *AFTER* they resolve our feature request for this:
+    #    https://github.com/sphinx-doc/sphinx/issues/9805
+
+    # For each stack frame on the call stack, ignoring the stack frame
+    # encapsulating the call to this tester...
+    for frame in iter_frames(func_stack_frames_ignore=1):
+        # Fully-qualified name of this scope's module if this scope defines
+        # this name *OR* "None" otherwise.
+        frame_module_name = frame.f_globals.get('__name__')
+        # print(f'Visiting frame (module: "{func_frame_module_name}")...')
+
+        # If this scope's module is the "autodoc" extension, Sphinx is
+        # currently autogenerating documentation. In this case, return true.
+        if (
+            frame_module_name and
+            frame_module_name.startswith(_SPHINX_AUTODOC_SUBPACKAGE_NAME)
+        ):
+            return True
+        # Else, this scope's module is *NOT* the "autodoc" extension.
+
+    # Else, *NO* scope's module is the "autodoc" extension. Return false.
+    return False
+
+# ....................{ PRIVATE ~ magic                    }....................
+_SPHINX_AUTODOC_SUBPACKAGE_NAME = 'sphinx.ext.autodoc'
+'''
+Fully-qualified name of the subpackage providing the ``autodoc`` extension
+bundled with Sphinx.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/api/utilapityping.py
@@ -0,0 +1,506 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **typing module** utilities (i.e., callables dynamically testing
+and importing attributes declared at module scope by either the standard
+:mod:`typing` or third-party :mod:`typing_extensions` modules).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeModuleAttributeNotFoundWarning
+from beartype.roar._roarexc import _BeartypeUtilModuleException
+from beartype.typing import (
+    Any,
+    Iterable,
+    Union,
+)
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.module.datamodtyping import TYPING_MODULE_NAMES
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.error.utilerrwarn import issue_warning
+from beartype._util.module.utilmodimport import import_module_attr_or_none
+from collections.abc import Iterable as IterableABC
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_typing_attr(
+    # Mandatory parameters.
+    typing_attr_basename: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+) -> bool:
+    '''
+    :data:`True` only if a **typing attribute** (i.e., object declared at module
+    scope by either the :mod:`typing` or :mod:`typing_extensions` modules) with
+    the passed unqualified name is importable from one or more of these
+    modules.
+
+    This function is effectively memoized for efficiency.
+
+    Parameters
+    ----------
+    typing_attr_basename : str
+        Unqualified name of the attribute to be imported from a typing module.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if the :mod:`typing` or :mod:`typing_extensions`
+        modules declare an attribute with this name.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+
+    Raises
+    ------
+    exception_cls
+        If this name is syntactically invalid.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If any of these modules raise module-scoped exceptions at importation
+        time. That said, the :mod:`typing` and :mod:`typing_extensions` modules
+        are scrupulously tested and thus unlikely to raise such exceptions.
+    '''
+
+    # Return true only if an attribute with this name is importable from either
+    # the "typing" *OR* "typing_extensions" modules.
+    #
+    # Note that positional rather than keyword arguments are intentionally
+    # passed to optimize memoization efficiency.
+    return import_typing_attr_or_none(
+        typing_attr_basename, exception_cls) is not None
+
+# ....................{ IMPORTERS                          }....................
+def import_typing_attr(
+    # Mandatory parameters.
+    typing_attr_basename: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+) -> Any:
+    '''
+    Dynamically import and return the **typing attribute** (i.e., object
+    declared at module scope by either the :mod:`typing` or
+    :mod:`typing_extensions` modules) with the passed unqualified name if
+    importable from one or more of these modules *or* raise an exception
+    otherwise (i.e., if this attribute is *not* importable from these modules).
+
+    This function is effectively memoized for efficiency.
+
+    Parameters
+    ----------
+    typing_attr_basename : str
+        Unqualified name of the attribute to be imported from a typing module.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+
+    Returns
+    -------
+    object
+        Attribute with this name dynamically imported from a typing module.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * This name is syntactically invalid.
+        * Neither the :mod:`typing` nor :mod:`typing_extensions` modules
+          declare an attribute with this name.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If any of these modules raise module-scoped exceptions at importation
+        time. That said, the :mod:`typing` and :mod:`typing_extensions` modules
+        are scrupulously tested and thus unlikely to raise such exceptions.
+
+    See Also
+    --------
+    :func:`beartype._util.module.utilmodimport.import_module_typing_any_attr_or_none`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodtest import is_module
+
+    # Attribute with this name imported from either the "typing" or
+    # "typing_extensions" modules if one or more of these modules declare this
+    # attribute *OR* "None" otherwise.
+    #
+    # Note that positional rather than keyword arguments are intentionally
+    # passed to optimize memoization efficiency.
+    typing_attr = import_typing_attr_or_none(
+        typing_attr_basename, exception_cls)
+
+    # If none of these modules declare this attribute...
+    if typing_attr is None:
+        # Substrings prefixing and suffixing exception messages raised below.
+        EXCEPTION_PREFIX = (
+            f'Typing attributes "typing.{typing_attr_basename}" and '
+            f'"typing_extensions.{typing_attr_basename}" not found. '
+        )
+        EXCEPTION_SUFFIX = (
+            'We apologize for the inconvenience and hope you had a '
+            'great dev cycle flying with Air Beartype, '
+            '"Your Grizzled Pal in the Friendly Skies."'
+        )
+
+        # If the "typing_extensions" module is importable, raise an
+        # appropriate exception.
+        if is_module('typing_extensions'):
+            raise exception_cls(
+                f'{EXCEPTION_PREFIX} Please either '
+                f'(A) update the "typing_extensions" package or '
+                f'(B) update to a newer Python version. {EXCEPTION_SUFFIX}'
+            )
+        # Else, the "typing_extensions" module is unimportable. In this
+        # case, raise an appropriate exception.
+        else:
+            raise exception_cls(
+                f'{EXCEPTION_PREFIX} Please either '
+                f'(A) install the "typing_extensions" package or '
+                f'(B) update to a newer Python version. {EXCEPTION_SUFFIX}'
+            )
+    # Else, one or more of these modules declare this attribute.
+
+    # Return this attribute.
+    return typing_attr
+
+
+#FIXME: Unit test us up, please.
+def import_typing_attr_or_none(
+    # Mandatory parameters.
+    typing_attr_basename: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+) -> Any:
+    '''
+    Dynamically import and return the **typing attribute** (i.e., object
+    declared at module scope by either the :mod:`typing` or
+    :mod:`typing_extensions` modules) with the passed unqualified name if
+    importable from one or more of these modules *or* :data:`None` otherwise
+    otherwise (i.e., if this attribute is *not* importable from these modules).
+
+    This function is effectively memoized for efficiency.
+
+    Parameters
+    ----------
+    typing_attr_basename : str
+        Unqualified name of the attribute to be imported from a typing module.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+
+    Returns
+    -------
+    object
+        Attribute with this name dynamically imported from a typing module.
+
+    Raises
+    ------
+    exception_cls
+        If this name is syntactically invalid.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If any of these modules raise module-scoped exceptions at importation
+        time. That said, the :mod:`typing` and :mod:`typing_extensions` modules
+        are scrupulously tested and thus unlikely to raise exceptions.
+
+    See Also
+    --------
+    :func:`import_typing_attr_or_fallback`
+        Further details.
+    '''
+
+    # One-liners in the rear view mirror may be closer than they appear.
+    #
+    # Note that parameters are intentionally passed positionally rather than by
+    # keyword for memoization efficiency.
+    return import_typing_attr_or_fallback(
+        typing_attr_basename, None, exception_cls)
+
+
+#FIXME: Unit test us up, please.
+#FIXME: Leverage above, please.
+@callable_cached
+def import_typing_attr_or_fallback(
+    # Mandatory parameters.
+    typing_attr_basename: str,
+    fallback: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+) -> Any:
+    '''
+    Dynamically import and return the **typing attribute** (i.e., object
+    declared at module scope by either the :mod:`typing` or
+    :mod:`typing_extensions` modules) with the passed unqualified name if
+    importable from one or more of these modules *or* the passed fallback
+    otherwise otherwise (i.e., if this attribute is *not* importable from these
+    modules).
+
+    Specifically, this function (in order):
+
+    #. If the official :mod:`typing` module bundled with the active Python
+       interpreter declares that attribute, dynamically imports and returns
+       that attribute from that module.
+    #. Else if the third-party (albeit quasi-official) :mod:`typing_extensions`
+       module requiring external installation under the active Python
+       interpreter declares that attribute, dynamically imports and returns
+       that attribute from that module.
+    #. Else, returns the passed fallback value.
+
+    This function is memoized for efficiency.
+
+    Parameters
+    ----------
+    typing_attr_basename : str
+        Unqualified name of the attribute to be imported from a typing module.
+    fallback : object
+        Arbitrary value to be returned as a last-ditch fallback if *no* typing
+        module declares this attribute.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+
+    Returns
+    -------
+    object
+        Attribute with this name dynamically imported from a typing module.
+
+    Raises
+    ------
+    exception_cls
+        If this name is syntactically invalid.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If any of these modules raise module-scoped exceptions at importation
+        time. That said, the :mod:`typing` and :mod:`typing_extensions` modules
+        are scrupulously tested and thus unlikely to raise exceptions.
+    '''
+
+    # Attribute with this name imported from the "typing" module if that module
+    # declares this attribute *OR* "None" otherwise.
+    typing_attr = import_module_attr_or_none(
+        attr_name=f'typing.{typing_attr_basename}',
+        exception_cls=exception_cls,
+        exception_prefix='Typing attribute ',
+    )
+
+    # If the "typing" module does *NOT* declare this attribute...
+    if typing_attr is None:
+        # Attribute with this name imported from the "typing_extensions" module
+        # if that module declares this attribute *OR* "None" otherwise.
+        typing_attr = import_module_attr_or_none(
+            attr_name=f'typing_extensions.{typing_attr_basename}',
+            exception_cls=exception_cls,
+            exception_prefix='Typing attribute ',
+        )
+
+        # If the "typing_extensions" module also does *NOT* declare this
+        # attribute, fallback to the passed fallback value.
+        if typing_attr is None:
+            typing_attr = fallback
+        # Else, the "typing_extensions" module declares this attribute.
+    # Else, the "typing" module declares this attribute.
+
+    # Return either this attribute if one or more of these modules declare this
+    # attribute *OR* this fallback otherwise.
+    return typing_attr
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+@callable_cached
+def get_typing_attrs(typing_attr_basename: str) -> frozenset:
+    '''
+    Frozen set of all attributes with the passed unqualified basename declared
+    by all importable typing modules, silently ignoring those modules failing to
+    declare this attribute.
+
+    This getter intentionally returns a set rather than a list. Why? Duplicates.
+    The third-party :mod:`typing_extensions` module duplicates *all* type hint
+    factories implemented by the standard :mod:`typing` module under the most
+    recently released version of Python.
+
+    This getter is memoized for efficiency.
+
+    Attributes
+    ----------
+    typing_attr_basename : str
+        Unqualified name of the attribute to be dynamically imported from
+        each typing module.
+
+    Yields
+    ------
+    set
+        Set of all attributes with the passed unqualified basename declared by
+        all importable typing modules.
+    '''
+    assert isinstance(typing_attr_basename, str), (
+        f'{repr(typing_attr_basename)} not string.')
+
+    # Set of all importable attributes to be returned by this getter.
+    typing_attrs: set = set()
+
+    # For the fully-qualified name of each quasi-standard typing module...
+    for typing_module_name in TYPING_MODULE_NAMES:
+        # Attribute with this name dynamically imported from that module if
+        # that module defines this attribute *OR* "None" otherwise.
+        typing_attr = import_module_attr_or_none(
+            f'{typing_module_name}.{typing_attr_basename}')
+
+        # If that module fails to define this attribute, silently continue to
+        # the next module.
+        if typing_attr is None:
+            continue
+        # Else, that module declares this attribute.
+
+        # Append this attribute to this list.
+        typing_attrs.add(typing_attr)
+
+    # Return this set, coerced into a frozen set for caching purposes.
+    return frozenset(typing_attrs)
+
+# ....................{ ITERATORS                          }....................
+#FIXME: Replace *ALL* calls to this by calls to get_typing_attrs(), please.
+#FIXME: Currently unused but preserved for posterity. Consider excising, please.
+def iter_typing_attrs(
+    # Mandatory parameters.
+    typing_attr_basenames: Union[str, Iterable[str]],
+
+    # Optional parameters.
+    is_warn: bool = False,
+    typing_module_names: Iterable[str] = TYPING_MODULE_NAMES,
+) -> IterableABC:
+    '''
+    Generator iteratively yielding all attributes with the passed basename
+    declared by the quasi-standard typing modules with the passed
+    fully-qualified names, silently ignoring those modules failing to declare
+    such an attribute.
+
+    Attributes
+    ----------
+    typing_attr_basenames : Union[str, Iterable[str]]
+        Either:
+
+        * Unqualified name of the attribute to be dynamically imported from
+          each typing module, in which case either:
+
+          * If the currently iterated typing module defines this attribute,
+            this generator yields this attribute imported from that module.
+          * Else, this generator silently ignores that module.
+        * Iterable of one or more such names, in which case either:
+
+          * If the currently iterated typing module defines *all* attributes,
+            this generator yields a tuple whose items are these attributes
+            imported from that module (in the same order).
+          * Else, this generator silently ignores that module.
+    is_warn : bool
+        :data:`True` only if emitting non-fatal warnings for typing modules
+        failing to define all passed attributes. If ``typing_module_names`` is
+        passed, this parameter should typically also be passed as :data:`True`
+        for safety. Defaults to :data:`False`.
+    typing_module_names: Iterable[str]
+        Iterable of the fully-qualified names of all typing modules to
+        dynamically import this attribute from. Defaults to
+        :data:`.TYPING_MODULE_NAMES`.
+
+    Yields
+    ------
+    Union[object, Tuple[object, ...]]
+        Either:
+
+        * If passed only an attribute basename, the attribute with that
+          basename declared by each typing module.
+        * If passed an iterable of one or more attribute basenames, a tuple
+          whose items are the attributes with those basenames (in the same
+          order) declared by each typing module.
+    '''
+    assert isinstance(is_warn, bool), f'{is_warn} not boolean.'
+    assert isinstance(typing_attr_basenames, (str, IterableABC)), (
+        f'{typing_attr_basenames} not string.')
+    assert typing_attr_basenames, '"typing_attr_basenames" empty.'
+    assert isinstance(typing_module_names, IterableABC), (
+        f'{repr(typing_module_names)} not iterable.')
+    assert typing_module_names, '"typing_module_names" empty.'
+    assert all(
+        isinstance(typing_module_name, str)
+        for typing_module_name in typing_module_names
+    ), f'One or more {typing_module_names} items not strings.'
+
+    # If passed an attribute basename, pack this into a tuple containing only
+    # this basename for ease of use.
+    if isinstance(typing_attr_basenames, str):
+        typing_attr_basenames = (typing_attr_basenames,)
+    # Else, an iterable of attribute basenames was passed. In this case...
+    else:
+        assert all(
+            isinstance(typing_attr_basename, str)
+            for typing_attr_basename in typing_attr_basenames
+        ), f'One or more {typing_attr_basenames} items not strings.'
+    # In either case, this parameter is now a tuple of attribute basenames.
+
+    # List of all imported attributes to be yielded from each iteration of the
+    # generator implicitly returned by this generator function.
+    typing_attrs: list = []
+
+    # For the fully-qualified name of each quasi-standard typing module...
+    for typing_module_name in typing_module_names:
+        # Clear this list *BEFORE* appending to this list below.
+        typing_attrs.clear()
+
+        # For the basename of each attribute to be imported from that module...
+        for typing_attr_basename in typing_attr_basenames:
+            # Fully-qualified name of this attribute declared by that module.
+            typing_attr_name = f'{typing_module_name}.{typing_attr_basename}'
+
+            # Attribute with this name dynamically imported from that module if
+            # that module defines this attribute *OR* "None" otherwise.
+            typing_attr = import_module_attr_or_none(typing_attr_name)
+
+            # If that module fails to define this attribute...
+            if typing_attr is None:
+                # If emitting non-fatal warnings, do so.
+                if is_warn:
+                    issue_warning(
+                        cls=BeartypeModuleAttributeNotFoundWarning,
+                        message=(
+                            f'Ignoring undefined typing attribute '
+                            f'"{typing_attr_name}"...'
+                        ),
+                    )
+                # Else, silently reduce to a noop.
+
+                # Continue to the next module.
+                break
+            # Else, that module declares this attribute.
+
+            # Append this attribute to this list.
+            typing_attrs.append(typing_attr)
+        # If that module declares *ALL* attributes...
+        else:
+            # If exactly one attribute name was passed, yield this attribute as
+            # is (*WITHOUT* packing this attribute into a tuple).
+            if len(typing_attrs) == 1:
+                yield typing_attrs[0]
+            # Else, two or more attribute names were passed. In this case, yield
+            # these attributes as a tuple.
+            else:
+                yield tuple(typing_attrs)
+        # Else, that module failed to declare one or more attributes. In this
+        # case, silently continue to the next module.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/ast/utilastget.py
@@ -0,0 +1,110 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) getters** (i.e., low-level callables
+acquiring various properties of various nodes in the currently visited AST).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    AST,
+    Module,
+    dump as ast_dump,
+    parse as ast_parse,
+)
+from beartype.roar._roarexc import _BeartypeUtilAstException
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+
+# ....................{ GETTERS ~ node                     }....................
+#FIXME: Unit test us up, please.
+def get_node_repr_indented(node: AST) -> str:
+    '''
+    Human-readable string pretty-printing the contents of the passed abstract
+    syntax tree (AST), complete with readable indentation.
+
+    Parameters
+    ----------
+    node : AST
+        AST to be pretty-printed.
+
+    Returns
+    -------
+    str
+        Human-readable string pretty-printing the contents of this AST.
+    '''
+    assert isinstance(node, AST), f'{repr(node)} not AST.'
+
+    # Return either...
+    return (
+        # If the active Python interpreter targets Python >= 3.9, the
+        # pretty-printed contents of this AST. Sadly, the "indent=4" parameter
+        # pretty-printing this AST was first introduced by Python 3.9.
+        ast_dump(node, indent=4)  # type: ignore[call-arg]
+        if IS_PYTHON_AT_LEAST_3_9 else
+        # Else, the active Python interpreter targets Python < 3.9. In this
+        # case, the non-pretty-printed contents of this AST as a single line.
+        ast_dump(node)
+    )
+
+# ....................{ GETTERS ~ node                     }....................
+#FIXME: Unit test us up, please. When we do, remove the "pragma: no cover" from
+#the body of this getter below.
+def get_code_child_node(code: str) -> AST:
+    '''
+    Abstract syntax tree (AST) node parsed from the passed (presumably)
+    triple-quoted string defining a single child object.
+
+    This function is principally intended to be called from our test suite as a
+    convenient means of "parsing" triple-quoted strings into AST nodes.
+
+    Caveats
+    -------
+    **This function assumes that this string defines only a single child
+    object.** If this string defines either no *or* two or more child objects,
+    an exception is raised.
+
+    Parameters
+    ----------
+    code : str
+        Triple-quoted string defining a single child object.
+
+    Returns
+    -------
+    AST
+        AST node encapsulating the object defined by this string.
+
+    Raises
+    -------
+    _BeartypeUtilAstException
+        If this string defines either no *or* two or more child objects.
+    '''
+    assert isinstance(code, str), f'{repr(code)} not string.'
+
+    # "ast.Module" AST tree parsed from this string.
+    node_module = ast_parse(code)
+
+    # If this node is *NOT* actually a module node, raise an exception.
+    if not isinstance(node_module, Module):  # pragma: no cover
+        raise _BeartypeUtilAstException(
+            f'{repr(node_module)} not AST module node.')
+    # Else, this node is a module node.
+
+    # List of all direct child nodes of this parent module name.
+    nodes_child = node_module.body
+
+    # If this module node contains either no *OR* two or more child nodes, raise
+    # an exception.
+    if len(nodes_child) != 1:  # pragma: no cover
+        raise _BeartypeUtilAstException(
+            f'Python code {repr(code)} defines '
+            f'{len(nodes_child)} != 1 child objects.'
+        )
+    # Else, this module node contains exactly one child node.
+
+    # Return this child node.
+    return nodes_child[0]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/ast/utilastmake.py
@@ -0,0 +1,486 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) factories** (i.e., low-level callables
+creating and returning various types of nodes, typically for inclusion in the
+currently visited AST).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    AST,
+    Attribute,
+    Call,
+    Constant,
+    Expr,
+    FormattedValue,
+    ImportFrom,
+    Name,
+    alias,
+    keyword,
+)
+from beartype.roar import BeartypeClawImportAstException
+from beartype.typing import (
+    List,
+    Optional,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.ast.dataast import (
+    NODE_CONTEXT_LOAD,
+    NODE_CONTEXT_STORE,
+)
+from beartype._data.hint.datahinttyping import NodesList
+from beartype._data.kind.datakindsequence import LIST_EMPTY
+from beartype._util.ast.utilastmunge import copy_node_metadata
+
+# ....................{ FACTORIES                          }....................
+#FIXME: Unit test us up, please.
+def make_node_importfrom(
+    # Mandatory parameters.
+    module_name: str,
+    source_attr_name: str,
+    node_sibling: AST,
+
+    # Optional parameters.
+    target_attr_name: Optional[str] = None,
+) -> ImportFrom:
+    '''
+    Create and return a new **import-from abstract syntax tree (AST) node**
+    (i.e., node encapsulating an import statement of the alias-style format
+    ``from {module_name} import {attr_name}``) importing the attribute with the
+    passed source name from the module with the passed name into the currently
+    visited module as a new attribute with the passed target name.
+
+    Parameters
+    ----------
+    module_name : str
+        Fully-qualified name of the module to import this attribute from.
+    source_attr_name : str
+        Unqualified basename of the attribute to import from this module.
+    target_attr_name : Optional[str]
+        Either:
+
+        * If this attribute is to be imported into the currently visited module
+          under a different unqualified basename, that basename.
+        * If this attribute is to be imported into the currently visited module
+          under the same unqualified basename as ``source_attr_name``,
+          :data:`None`.
+
+        Defaults to :data:`None`.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    Returns
+    -------
+    ImportFrom
+        Import-from node importing this attribute from this module.
+    '''
+    assert isinstance(module_name, str), f'{repr(module_name)} not string.'
+    assert isinstance(source_attr_name, str), (
+        f'{repr(source_attr_name)} not string.')
+    assert isinstance(target_attr_name, NoneTypeOr[str]), (
+        f'{repr(target_attr_name)} neither string nor "None".')
+
+    # Node encapsulating the name of the attribute to import from this module,
+    # defined as either...
+    node_importfrom_name = (
+        # If this attribute is to be imported into the currently visited module
+        # under a different basename, do so;
+        alias(name=source_attr_name, asname=target_attr_name)
+        if target_attr_name else
+        # Else, this attribute is to be imported into the currently visited
+        # module under the same basename. In this case, do so.
+        alias(name=source_attr_name)
+    )
+
+    # Node encapsulating the name of the module to import this attribute from.
+    node_importfrom = ImportFrom(
+        module=module_name,
+        names=[node_importfrom_name],
+        # Force an absolute import for safety (i.e., prohibit relative imports).
+        level=0,
+    )
+
+    # Copy all source code metadata (e.g., line numbers) from this sibling node
+    # onto these new nodes.
+    copy_node_metadata(
+        node_src=node_sibling, node_trg=(node_importfrom, node_importfrom_name))
+
+    # Return this import-from node.
+    return node_importfrom
+
+# ....................{ FACTORIES ~ attribute              }....................
+#FIXME: Unit test us up, please.
+def make_node_object_attr_load(
+    # Mandatory parameters.
+    attr_name: str,
+    node_sibling: AST,
+
+    # Optional parameters.
+    node_obj: Optional[AST] = None,
+    obj_name: Optional[str] = None,
+) -> Attribute:
+    '''
+    Create and return a new **object attribute access abstract syntax tree (AST)
+    node** (i.e., node encapsulating an access of an object attribute) of the
+    passed object with the passed attribute name.
+
+    Note that exactly one of the ``node_obj`` and ``obj_name`` parameters *must*
+    be passed. If neither or both of these parameters are passed, an exception
+    is raised.
+
+    Parameters
+    ----------
+    attr_name : str
+        Unqualified basename of the attribute of this object to be accessed.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+    node_obj : Optional[AST]
+        Either:
+
+        * If the caller prefers supplying the name node accessing the parent
+          object to load this attribute from, that node.
+        * Else, :data:`None`. In this case, the caller *must* pass the
+          ``obj_name`` parameter.
+
+        Defaults to :data:`None`.
+    obj_name : Optional[str]
+        Either:
+
+        * If the caller prefers supplying the unqualified basename of the parent
+          object to load this attribute from in the current lexical scope,
+          that basename.
+        * Else, :data:`None`. In this case, the caller *must* pass the
+          ``node_obj`` parameter.
+
+        Defaults to :data:`None`.
+
+    Returns
+    -------
+    Attribute
+        Object attribute node accessing this attribute of this object.
+
+    Raises
+    ------
+    BeartypeClawImportAstException
+        If either:
+
+        * Neither the ``node_obj`` nor ``obj_name`` parameters are passed.
+        * Both of the ``node_obj`` and ``obj_name`` parameters are passed.
+    '''
+    assert isinstance(attr_name, str), f'{repr(attr_name)} not string.'
+
+    # If the caller passed *NO* name node accessing the parent object to load
+    # this attribute from...
+    if not node_obj:
+        # If the caller also passed *NO* unqualified basename of that object,
+        # raise an exception.
+        if not obj_name:
+            raise BeartypeClawImportAstException(
+                f'Attribute "{attr_name}" parent object undefined '
+                f'(i.e., neither "node_obj" nor "obj_name" parameters passed).'
+            )
+        # Else, the caller also passed the unqualified basename of that object.
+
+        # Child node accessing that object with this basename.
+        node_obj = make_node_name_load(name=obj_name, node_sibling=node_sibling)
+    # Else, the caller passed a name node accessing that object.
+    #
+    # If the caller also passed the unqualified basename of that object, raise
+    # an exception.
+    elif obj_name:
+        raise BeartypeClawImportAstException(
+            f'Attribute "{attr_name}" parent object overly defined '
+            f'(i.e., both "node_obj" and "obj_name" parameters passed).'
+        )
+    # Else, the caller passed *NO* unqualified basename of that object.
+    #
+    # In any case, the "node_obj" variable is now the desired object node.
+    assert isinstance(node_obj, AST), (
+        f'{repr(node_obj)} not AST node.')
+
+    # Object attribute node accessing this attribute of this object.
+    node_attribute_load = Attribute(
+        value=node_obj, attr=attr_name, ctx=NODE_CONTEXT_LOAD)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_attribute_load)
+
+    # Return this node.
+    return node_attribute_load
+
+# ....................{ FACTORIES ~ call                   }....................
+#FIXME: Unit test us up, please.
+def make_node_call_expr(*args, node_sibling: AST, **kwargs) -> Expr:
+    '''
+    Create and return a new **callable call expression abstract syntax tree
+    (AST) node** (i.e., node encapsulating a Python expression expressing a call
+    to an arbitrary function or method) calling the function or method with the
+    passed name, positional arguments, and keyword arguments.
+
+    Parameters
+    ----------
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    All remaining passed positional and keyword parameters are passed to the
+    lower-level :func:`.make_node_call` factory function as is.
+
+    Returns
+    -------
+    Expr
+        Expression node calling this callable with these parameters.
+    '''
+
+    # Child node calling this callable.
+    node_func_call = make_node_call(*args, node_sibling=node_sibling, **kwargs)  # type: ignore[misc]
+
+    # Child node expressing this call as a Python expression.
+    node_func = Expr(node_func_call)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_func)
+
+    # Return this expression node.
+    return node_func
+
+
+#FIXME: Unit test us up, please.
+def make_node_call(
+    # Mandatory parameters.
+    func_name: str,
+    node_sibling: AST,
+
+    # Optional parameters.
+    nodes_args: NodesList = LIST_EMPTY,
+    nodes_kwargs: List[keyword] = LIST_EMPTY,
+) -> Call:
+    '''
+    Create and return a new **callable call abstract syntax tree (AST) node**
+    (i.e., node encapsulating a call to an arbitrary function or method)
+    calling the function or method with the passed name, positional arguments,
+    and keyword arguments.
+
+    Parameters
+    ----------
+    func_name : str
+        Fully-qualified name of the module to import this attribute from.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+    nodes_args : NodesList, optional
+        List of zero or more **positional parameter AST nodes** comprising the
+        tuple of all positional parameters to be passed to this call. Defaults
+        to the empty list.
+    nodes_kwargs : NodesList, optional
+        List of zero or more **keyword parameter AST nodes** comprising the
+        dictionary of all keyword parameters to be passed to this call. Defaults
+        to the empty list.
+
+    Returns
+    -------
+    Call
+        Callable call node calling this callable with these parameters.
+    '''
+    assert isinstance(nodes_args, list), f'{repr(nodes_args)} not list.'
+    assert isinstance(nodes_kwargs, list), f'{repr(nodes_kwargs)} not list.'
+    assert all(
+        isinstance(node_args, AST) for node_args in nodes_args), (
+        f'{repr(nodes_args)} not list of AST nodes.')
+    assert all(
+        isinstance(node_kwargs, keyword) for node_kwargs in nodes_kwargs), (
+        f'{repr(nodes_kwargs)} not list of keyword nodes.')
+
+    # Child node referencing the callable to be called.
+    node_func_name = make_node_name_load(
+        name=func_name, node_sibling=node_sibling)
+
+    # Child node calling this callable.
+    node_func_call = Call(
+        func=node_func_name,
+        args=nodes_args,
+        keywords=nodes_kwargs,
+    )
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_func_call)
+
+    # Return this call node.
+    return node_func_call
+
+# ....................{ FACTORIES ~ call : arg             }....................
+#FIXME: Unit test us up, please.
+def make_node_kwarg(
+    kwarg_name: str, kwarg_value: AST, node_sibling: AST) -> keyword:
+    '''
+    Create and return a new **keyword argument abstract syntax tree (AST) node**
+    (i.e., node encapsulating a keyword argument of a call to an arbitrary
+    function or method) passing the keyword argument with the passed name and
+    value to some parent node encapsulating a call to some function or method.
+
+    Parameters
+    ----------
+    kwarg_name : str
+        Name of this keyword argument.
+    kwarg_value : AST
+        Node passing the value of this keyword argument.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    Returns
+    -------
+    keyword
+        Keyword node passing a keyword argument with this name and value.
+    '''
+    assert isinstance(kwarg_name, str), f'{repr(kwarg_name)} not string.'
+    assert isinstance(kwarg_value, AST), f'{repr(kwarg_value)} not AST node.'
+
+    # Child node encapsulating this keyword argument.
+    node_kwarg = keyword(arg=kwarg_name, value=kwarg_value)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_kwarg)
+
+    # Return this expression node.
+    return node_kwarg
+
+# ....................{ FACTORIES ~ literal : string       }....................
+#FIXME: Unit test us up, please.
+def make_node_str(text: str, node_sibling: AST) -> Constant:
+    '''
+    Create and return a new **string literal abstract syntax tree
+    (AST) node** (i.e., node encapsulating the passed string).
+
+    Parameters
+    ----------
+    text : str
+        String literal to be encapsulated in a new node.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    Returns
+    -------
+    Constant
+        String literal node encapsulating this string.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Child node encapsulating this string.
+    node_str = Constant(value=text)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_str)
+
+    # Return this string literal node.
+    return node_str
+
+# ....................{ FACTORIES ~ literal : f-string     }....................
+#FIXME: Unit test us up, please.
+def make_node_fstr_field(node_expr: AST, node_sibling: AST) -> FormattedValue:
+    '''
+    Create and return a new **f-string formatting field abstract syntax tree
+    (AST) node** (i.e., node embedding the substring created and returned by the
+    evaluation of the passed arbitrary expression in some parent node
+    encapsulating an f-string embedding this field).
+
+    This factory function creates substrings resembling ``{some_fstr_field}`` in
+    larger f-strings resembling ``f'This is {some_fstr_field}, isn't it?'``.
+
+    Caveats
+    -------
+    This field assumes *no* suffixing ``!``-prefixed conversion (e.g., "!a",
+    "!r", "!s"). Thankfully, those conversions are only syntactic sugar for more
+    human-readable builtins (e.g., ``repr()``, ``str()``). Ergo, this caveat
+    does *not* actually constitute a hard constraint. Just prefer the builtins.
+
+    Parameters
+    ----------
+    node_expr : AST
+        Formatting field to be embedded in some parent f-string node.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    Returns
+    -------
+    Name
+        Name node accessing this attribute in the current lexical scope.
+    '''
+    assert isinstance(node_expr, AST), f'{repr(node_expr)} not AST node.'
+
+    # Child node encapsulating a formatting field "{node_expr.value}" in some
+    # parent node encapsulating an f-string embedding this field. For unknown
+    # reasons, the standard "ast" module requires that the "conversion"
+    # parameter be passed as a non-standard magic integer constant. Whatevahs!
+    node_fstr_field = FormattedValue(value=node_expr, conversion=-1)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_fstr_field)
+
+    # Return this f-string field node.
+    return node_fstr_field
+
+# ....................{ FACTORIES ~ name                   }....................
+#FIXME: Unit test us up.
+def make_node_name_load(name: str, node_sibling: AST) -> Name:
+    '''
+    Create and return a new **attribute access abstract syntax tree (AST) node**
+    (i.e., node encapsulating an access of an attribute) in the current lexical
+    scope with the passed name.
+
+    Parameters
+    ----------
+    name : str
+        Fully-qualified name of the attribute to be accessed.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    Returns
+    -------
+    Name
+        Name node accessing this attribute in the current lexical scope.
+    '''
+    assert isinstance(name, str), f'{repr(name)} not string.'
+
+    # Child node accessing this attribute in the current lexical scope.
+    node_name = Name(name, ctx=NODE_CONTEXT_LOAD)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_name)
+
+    # Return this child node.
+    return node_name
+
+
+#FIXME: Unit test us up.
+def make_node_name_store(name: str, node_sibling: AST) -> Name:
+    '''
+    Create and return a new **attribute assignment abstract syntax tree (AST)
+    node** (i.e., node encapsulating an assignment of an attribute) in the
+    current lexical scope with the passed name.
+
+    Parameters
+    ----------
+    name : str
+        Fully-qualified name of the attribute to be assigned.
+    node_sibling : AST
+        Sibling node to copy source code metadata from.
+
+    Returns
+    -------
+    Name
+        Name node assigning this attribute in the current lexical scope.
+    '''
+    assert isinstance(name, str), f'{repr(name)} not string.'
+
+    # Child node assigning this attribute in the current lexical scope.
+    node_name = Name(name, ctx=NODE_CONTEXT_STORE)
+
+    # Copy source code metadata from this sibling node onto this new node.
+    copy_node_metadata(node_src=node_sibling, node_trg=node_name)
+
+    # Return this child node.
+    return node_name
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/ast/utilastmunge.py
@@ -0,0 +1,108 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **abstract syntax tree (AST) mungers** (i.e., low-level callables
+modifying various properties of various nodes in the currently visited AST).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import AST
+from beartype.typing import (
+    Iterable,
+    Union,
+)
+
+# ....................{ COPIERS                            }....................
+#FIXME: Unit test us up, please.
+def copy_node_metadata(
+    node_src: AST, node_trg: Union[AST, Iterable[AST]]) -> None:
+    '''
+    Copy all **source code metadata** (i.e., beginning and ending line and
+    column numbers) from the passed source abstract syntax tree (AST) node onto
+    the passed target AST node(s).
+
+    This function is an efficient alternative to:
+
+    * The extremely inefficient (albeit still useful)
+      :func:`ast.fix_missing_locations` function.
+    * The mildly inefficient (and mostly useless) :func:`ast.copy_location`
+      function.
+
+    The tradeoffs are as follows:
+
+    * :func:`ast.fix_missing_locations` is :math:`O(n)` time complexity for
+      :math:`n` the number of AST nodes across the entire AST tree, but requires
+      only a single trivial call and is thus considerably more "plug-and-play"
+      than this function.
+    * This function is :math:`O(1)` time complexity irrespective of the size of
+      the AST tree, but requires one still mostly trivial call for each
+      synthetic AST node inserted into the AST tree by the
+      :class:`BeartypeNodeTransformer` above.
+
+    Caveats
+    -------
+    **This function should only be passed nodes that support code metadata.**
+    Although *most* nodes do, some nodes do not. Why? Because they are *not*
+    actually nodes; they simply masquerade as nodes in documentation for the
+    standard :mod:`ast` module, which inexplicably makes *no* distinction
+    between the two. These pseudo-nodes include:
+
+    * :class:`ast.Del` nodes.
+    * :class:`ast.Load` nodes.
+    * :class:`ast.Store` nodes.
+
+    Indeed, this observation implies that these pseudo-nodes may be globalized
+    as singletons for efficient reuse throughout our AST generation algorithms.
+
+    Lastly, note that nodes may be differentiated from pseudo-nodes by passing
+    the call to the :func:`ast.dump` function in the code snippet presented in
+    the docstring for the :class:`BeartypeNodeTransformer` class an additional
+    ``include_attributes=True`` parameter: e.g.,
+
+    .. code-block:: python
+
+       print(ast.dump(ast.parse(CODE), indent=4, include_attributes=True))
+
+    Actual nodes have code metadata printed for them; pseudo-nodes do *not*.
+
+    Parameters
+    ----------
+    node_src : AST
+        Source AST node to copy source code metadata from.
+    node_trg : Union[AST, Iterable[AST]]
+        Either:
+
+        * A single target AST node to copy source code metadata onto.
+        * An iterable of zero or more target AST nodes to copy source code
+          metadata onto.
+
+    See Also
+    --------
+    :func:`ast.copy_location`
+        Less efficient analogue of this function running in :math:`O(k)` time
+        complexity for :math:`k` the number of types of source code metadata.
+        Typically, :math:`k == 4`.
+    '''
+    assert isinstance(node_src, AST), f'{repr(node_src)} not AST node.'
+
+    # If passed only a single target node, wrap this node in a 1-tuple
+    # containing only this node for simplicity.
+    if isinstance(node_trg, AST):
+        node_trg = (node_trg,)
+    # In either case, "node_trg" is now an iterable of target nodes.
+
+    # For each passed target node...
+    for node_trg_cur in node_trg:
+        assert isinstance(node_trg_cur, AST), (
+            f'{repr(node_trg_cur)} not AST node.')
+
+        # Copy all source code metadata from this source to target node.
+        node_trg_cur.lineno         = node_src.lineno
+        node_trg_cur.col_offset     = node_src.col_offset
+        node_trg_cur.end_lineno     = node_src.end_lineno  # type: ignore[attr-defined]
+        node_trg_cur.end_col_offset = node_src.end_col_offset  # type: ignore[attr-defined]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/ast/utilasttest.py
@@ -0,0 +1,146 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) testers** (i.e., low-level callables
+testing various properties of various nodes in the currently visited AST).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.datahinttyping import NodeCallable
+
+# ....................{ TESTERS                            }....................
+def is_node_callable_typed(node: NodeCallable) -> bool:
+    '''
+    :data:`True` only if the passed **callable node** (i.e., node signifying the
+    definition of a pure-Python function or method) is **typed** (i.e.,
+    annotated by a return type hint and/or one or more parameter type hints).
+
+    Parameters
+    ----------
+    node : NodeCallable
+        Callable node to be tested.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this callable node is typed.
+    '''
+
+    # Note that this algorithm is intentionally implemented in an unintuitive
+    # order so as to increase the likelihood of efficiently deciding this
+    # problem in best-case O(1) time. Specifically:
+    # * It is most efficient to test whether that callable is annotated by a
+    #   return type hint.
+    # * It is next-most efficient to test whether that callable accepts a
+    #   variadic positional or keyword argument annotated by a type hint.
+    # * It is least efficient to test whether that callable accepts a
+    #   non-variadic parameter annotated by a type hint, as doing so requires
+    #   O(n) iteration for "n" the number of such arguments.
+    #
+    # Lastly, note that we could naively avoid doing this entirely and instead
+    # unconditionally decorate *ALL* callables by @beartype -- in which case
+    # @beartype would simply reduce to a noop for untyped callables annotated by
+    # *NO* type hints. Technically, that works. Pragmatically, that would almost
+    # certainly be slower than the current approach under the common assumption
+    # that any developer annotating one or more non-variadic parameters of a
+    # callable would also annotate the return of that callable -- in which case
+    # this detection reduces to O(1) time complexity. Even where this is *NOT*
+    # the case, however, this is still almost certainly slightly faster or of an
+    # equivalent speed to the naive approach. Why? Because treating untyped
+    # callables as typed would needlessly:
+    # * Increase space complexity by polluting this AST with needlessly many
+    #   "Name" child nodes performing untyped @beartype decorations.
+    # * Increase time complexity by instantiating, initializing, and inserting
+    #   (the three dread i's) those nodes.
+    #
+    # Admittedly, this approach is *CONSIDERABLY* slower for untyped callables,
+    # where this detection exhibits worst-case O(n) time complexity. In theory,
+    # the "beartype.claw" API that calls this tester function once per callable
+    # should *NEVER* be applied to untyped callables. In practice, that API
+    # almost certainly will be. We (largely) consider that the responsibility of
+    # the caller, however. Beartype can't be faulted for optimizing for the
+    # ideal case of well-typed packages... *CAN IT*!?!? o_O
+
+    # If the return of that callable is typed, that callable is typed. In this
+    # case, immediately and efficiently return true.
+    if node.returns:
+        return True
+    # Else, the return of that callable is untyped.
+
+    # Child arguments node of all arguments accepted by that callable.
+    node_arg_nodes = node.args
+
+    # If either...
+    #
+    # Note that PEP 484-compliant typed variadic positional arguments (e.g.,
+    # "*args: str") are considerably more common than PEP 692-compliant typed
+    # variadic keyword arguments (e.g., "**kwargs: SomeTypedDict", where
+    # "SomeTypedDict" is a user-defined "typing.TypedDict" subclass). Ergo, we
+    # intentionally detect typed variadic positional arguments *BEFORE* typed
+    # variadic keyword arguments.
+    if (
+        (
+            # That callable accepts a variadic positional argument *AND*...
+            node_arg_nodes.vararg and
+            # That parameter is typed...
+            node_arg_nodes.vararg.annotation
+        # *OR*...
+        ) or
+        (
+            # That callable accepts a variadic keyword argument *AND*...
+            node_arg_nodes.kwarg and
+            # That parameter is typed...
+            node_arg_nodes.kwarg.annotation
+        )
+    # That callable is typed. In this case, return true.
+    ):
+        return True
+    # Else, that callable is still possibly untyped.
+
+    # Fallback to deciding whether that callable accepts one or more typed
+    # non-variadic parameters. Since doing is considerably more computationally
+    # expensive, we do so *ONLY* as needed.
+    #
+    # Note that manual iteration is considerably more efficient than more
+    # syntactically concise any() and all() generator expressions.
+    #
+    # Specifically, if that callable accepts non-variadic flexible parameters...
+    if node_arg_nodes.args:
+        # For each non-variadic flexible parameter...
+        for node_arg_nonvar in node_arg_nodes.args:
+            # If this parameter is typed, that callable is typed. In this case,
+            # return true.
+            if node_arg_nonvar.annotation:
+                return True
+            # Else, this parameter is untyped. Continue to the next.
+    # Else, that callable is still possibly untyped.
+
+    # If that callable accepts non-variadic keyword-only parameters...
+    if node_arg_nodes.kwonlyargs:
+        # For each non-variadic keyword-only parameter...
+        for node_arg_nonvar in node_arg_nodes.kwonlyargs:
+            # If this parameter is typed, that callable is typed. In this case,
+            # return true.
+            if node_arg_nonvar.annotation:
+                return True
+            # Else, this parameter is untyped. Continue to the next.
+    # Else, that callable is still possibly untyped.
+
+    # If that callable accepts non-variadic positional-only parameters...
+    if node_arg_nodes.posonlyargs:
+        # For each non-variadic positional-only parameter...
+        for node_arg_nonvar in node_arg_nodes.posonlyargs:
+            # If this parameter is typed, that callable is typed. In this case,
+            # return true.
+            if node_arg_nonvar.annotation:
+                return True
+            # Else, this parameter is untyped. Continue to the next.
+    # Else, that callable is now known to be untyped.
+
+    # Return false.
+    return False
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/map/utilmapbig.py
@@ -0,0 +1,247 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **unbounded cache** utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Callable,
+    Dict,
+    Union,
+)
+from beartype._util.utilobject import SENTINEL
+from collections.abc import Hashable
+from contextlib import AbstractContextManager
+from threading import Lock
+
+# ....................{ CLASSES                            }....................
+#FIXME: Submit back to StackOverflow, preferably under this question:
+#    https://stackoverflow.com/questions/1312331/using-a-global-dictionary-with-threads-in-python
+class CacheUnboundedStrong(object):
+    '''
+    **Thread-safe strongly unbounded cache** (i.e., mapping of unlimited size
+    from strongly referenced arbitrary keys onto strongly referenced arbitrary
+    values, whose methods are guaranteed to behave thread-safely).
+
+    Design
+    ------
+    Cache implementations typically employ weak references for safety. Employing
+    strong references invites memory leaks by preventing objects *only*
+    referenced by the cache (cache-only objects) from being garbage-collected.
+    Nonetheless, this cache intentionally employs strong references to persist
+    these cache-only objects across calls to callables decorated with
+    :func:`beartype.beartype`. In theory, caching an object under a weak
+    reference would result in immediate garbage-collection; with *no* external
+    strong referents, that object would be garbage-collected with all other
+    short-lived objects in the first generation (i.e., generation 0).
+
+    This cache intentionally does *not* adhere to standard mapping semantics by
+    subclassing a standard mapping API (e.g., :class:`dict`,
+    :class:`collections.abc.MutableMapping`). Standard mapping semantics are
+    sufficiently low-level as to invite race conditions between competing
+    threads concurrently contesting the same instance of this class. For
+    example, consider the following standard non-atomic logic for caching a new
+    key-value into this cache:
+
+    .. code-block:: python
+
+       if key not in cache:    # <-- If a context switch happens immediately
+                               # <-- after entering this branch, bad stuff!
+           cache[key] = value  # <-- We may overwrite another thread's work.
+
+    Attributes
+    ----------
+    _key_to_value : dict[Hashable, object]
+        Internal **backing store** (i.e., thread-unsafe dictionary of unlimited
+        size mapping from strongly referenced arbitrary keys onto strongly
+        referenced arbitrary values).
+    _key_to_value_get : Callable
+        The :meth:`self._key_to_value.get` method, classified for efficiency.
+    _key_to_value_set : Callable
+        The :meth:`self._key_to_value.__setitem__` dunder method, classified
+        for efficiency.
+    _lock : AbstractContextManager
+        **Instance-specific thread lock** (i.e., low-level thread locking
+        mechanism implemented as a highly efficient C extension, defined as an
+        instance variable for non-reentrant reuse by the public API of this
+        class). Although CPython, the canonical Python interpreter, *does*
+        prohibit conventional multithreading via its Global Interpreter Lock
+        (GIL), CPython still coercively preempts long-running threads at
+        arbitrary execution points. Ergo, multithreading concerns are *not*
+        safely ignorable -- even under CPython.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # @beartype decorations. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_key_to_value',
+        '_key_to_value_get',
+        '_key_to_value_set',
+        '_lock',
+    )
+
+    # ..................{ INITIALIZER                        }..................
+    def __init__(
+        self,
+
+        # Optional parameters.
+        lock_type: Union[type, Callable[[], object]] = Lock,
+    ) -> None:
+        '''
+        Initialize this cache to an empty cache.
+
+        Parameters
+        ----------
+        lock_type : Union[type, Callable[[], object]]
+            Type of thread-safe lock to internally use. Defaults to
+            :class:`Lock` (i.e., the type of the standard non-reentrant lock)
+            for efficiency.
+        '''
+
+        # Initialize all instance variables.
+        self._key_to_value: Dict[Hashable, object] = {}
+        self._key_to_value_get = self._key_to_value.get
+        self._key_to_value_set = self._key_to_value.__setitem__
+        self._lock: AbstractContextManager = lock_type()  # type: ignore[assignment]
+
+    # ..................{ GETTERS                            }..................
+    def cache_or_get_cached_value(
+        self,
+
+        # Mandatory parameters.
+        key: Hashable,
+        value: object,
+
+        # Hidden parameters, localized for negligible efficiency.
+        _SENTINEL=SENTINEL,
+    ) -> object:
+        '''
+        **Statically** (i.e., non-dynamically, rather than "statically" in the
+        different semantic sense of "static" methods) associate the passed key
+        with the passed value if this cache has yet to cache this key (i.e., if
+        this method has yet to be passed this key) and, in any case, return the
+        value associated with this key.
+
+        Parameters
+        ----------
+        key : Hashable
+            **Key** (i.e., arbitrary hashable object) to return the associated
+            value of.
+        value : object
+            **Value** (i.e., arbitrary object) to associate with this key if
+            this key has yet to be associated with any value.
+
+        Returns
+        ----------
+        object
+            **Value** (i.e., arbitrary object) associated with this key.
+        '''
+        # assert isinstance(key, Hashable), f'{repr(key)} unhashable.'
+
+        # Thread-safely (but non-reentrantly)...
+        with self._lock:
+            # Value previously cached under this key if any *OR* the sentinel
+            # placeholder otherwise.
+            value_old = self._key_to_value_get(key, _SENTINEL)
+
+            # If this key has already been cached, return this value as is.
+            if value_old is not _SENTINEL:
+                return value_old
+            # Else, this key has yet to be cached.
+
+            # Cache this key with this value.
+            self._key_to_value_set(key, value)
+
+            # Return this value.
+            return value
+
+
+    #FIXME: Unit test us up.
+    #FIXME: Generalize to accept a new mandatory "arg: object" parameter and
+    #then pass rather than forcefully passing the passed key. \o/
+    def cache_or_get_cached_func_return_passed_arg(
+        self,
+
+        # Mandatory parameters.
+        key: Hashable,
+        value_factory: Callable[[object], object],
+        arg: object,
+
+        # Hidden parameters, localized for negligible efficiency.
+        _SENTINEL=SENTINEL,
+    ) -> object:
+        '''
+        Dynamically associate the passed key with the value returned by the
+        passed **value factory** (i.e., caller-defined function accepting this
+        key and returning the value to be associated with this key) if this
+        cache has yet to cache this key (i.e., if this method has yet to be
+        passed this key) and, in any case, return the value associated with
+        this key.
+
+        Caveats
+        ----------
+        **This value factory must not recursively call this method.** For
+        efficiency, this cache is internally locked through a non-reentrant
+        rather than reentrant thread lock. If this value factory accidentally
+        recursively calls this method, the active thread will be indefinitely
+        locked. Welcome to the risky world of high-cost efficiency gains.
+
+        Parameters
+        ----------
+        key : Hashable
+            **Key** (i.e., arbitrary hashable object) to return the associated
+            value of.
+        value_factory : Callable[[object], object]
+            **Value factory** (i.e., caller-defined function accepting the
+            passed ``arg`` object and dynamically returning the value to be
+            associated with this key).
+        arg : object
+            Arbitrary object to be passed as is to this value factory.
+
+        Returns
+        ----------
+        object
+            **Value** (i.e., arbitrary object) associated with this key.
+        '''
+        # assert isinstance(key, Hashable), f'{repr(key)} unhashable.'
+        # assert callable(value_factory), f'{repr(value_factory)} uncallable.'
+
+        # Thread-safely (but non-reentrantly)...
+        with self._lock:
+            # Value previously cached under this key if any *OR* the sentinel
+            # placeholder otherwise.
+            value_old = self._key_to_value_get(key, _SENTINEL)
+
+            # If this key has already been cached, return this value as is.
+            if value_old is not _SENTINEL:
+                return value_old
+            # Else, this key has yet to be cached.
+
+            # Value created by this factory function, localized for negligible
+            # efficiency to avoid the unnecessary subsequent dictionary lookup.
+            value = value_factory(arg)
+
+            # Cache this key with this value.
+            self._key_to_value_set(key, value)
+
+            # Return this value.
+            return value
+
+    # ..................{ CLEARERS                           }..................
+    #FIXME: Unit test us up, please.
+    def clear(self) -> None:
+        '''
+        Clear (i.e., empty) this cache.
+        '''
+
+        # Clear your head and be at peace, one-liner.
+        self._key_to_value.clear()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/map/utilmaplru.py
@@ -0,0 +1,247 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Least Recently Used (LRU) cache** utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: The current "CacheLruStrong" implementation is overly low-level and
+#thus fundamentally *THREAD-UNSAFE.* The core issue here is that the current
+#approach encourages callers to perform thread-unsafe logic resembling:
+#   if key not in lru_dict:  # <-- if a context switch happens here, bad stuff
+#       lru_dict[key] = value
+#
+#For thread-safety, the entire "CacheLruStrong" class *MUST* be rethought along
+#the manner of the comparable "utilmapbig.CacheUnboundedStrong" class. Notably:
+#* "CacheLruStrong" class should *NOT* directly subclass "dict" but instead
+#  simply contain a "_dict" instance.
+#* Thread-unsafe dunder methods (particularly the "__setitem__" method) should
+#  probably *NOT* be defined at all. Yeah, we know.
+#* A new CacheLruStrong.cache_entry() method resembling the existing
+#  CacheUnboundedStrong.cache_entry() method should be declared.
+#* Indeed, we should (arguably) declare a new "CacheStrongABC" base class to
+#  provide a common API here -- trivializing switching between different
+#  caching strategies implemented by concrete subclasses.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCacheLruException
+from beartype.typing import Hashable
+from threading import Lock
+
+# ....................{ CLASSES                            }....................
+class CacheLruStrong(dict):
+    '''
+    **Thread-safe strong Least Recently Used (LRU) cache** (i.e., mapping
+    limited to some maximum capacity of strongly referenced arbitrary keys
+    mapped onto strongly referenced arbitrary values, whose methods are
+    guaranteed to behave thread-safely).
+
+    Design
+    ------
+    Cache implementations typically employ weak references for safety.
+    Employing strong references invites memory leaks by preventing objects
+    *only* referenced by the cache (cache-only objects) from being
+    garbage-collected. Nonetheless, this cache intentionally employs strong
+    references to persist these cache-only objects across calls to callables
+    decorated with :func:`beartype.beartype`. In theory, caching an object
+    under a weak reference would result in immediate garbage-collection as,
+    with no external strong referents, the object would get collected with all
+    other short-lived objects in the first generation (i.e., generation 0).
+
+    Note that:
+
+    * The equivalent LRU cache employing weak references to keys and/or values
+      may be trivially implemented by swapping this classes inheritance from
+      the builtin :class:`dict` to either of the builtin
+      :class:`weakref.WeakKeyDictionary` or
+      :class:`weakref.WeakValueDictionary`.
+    * The standard example of a cache-only object is a container iterator
+      (e.g., :meth:`dict.items`).
+
+    Attributes
+    ----------
+    _size : int
+        **Cache capacity** (i.e., maximum number of key-value pairs persisted
+        by this cache).
+    _lock : Lock
+        **Non-reentrant instance-specific thread lock** (i.e., low-level thread
+        locking mechanism implemented as a highly efficient C extension,
+        defined as an instance variable for non-reentrant reuse by the public
+        API of this class). Although CPython, the canonical Python interpreter,
+        *does* prohibit conventional multithreading via its Global Interpreter
+        Lock (GIL), CPython still coercively preempts long-running threads at
+        arbitrary execution points. Ergo, multithreading concerns are *not*
+        safely ignorable -- even under CPython.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_size',
+        '_lock',
+    )
+
+    # ..................{ DUNDERS                            }..................
+    def __init__(self, size: int) -> None:
+        '''
+        Initialize this cache to an empty cache with a capacity of this size.
+
+        Parameters
+        ----------
+        size : int
+            **Cache capacity** (i.e., maximum number of key-value pairs held in
+            this cache).
+
+        Raises
+        ------
+        _BeartypeUtilCacheLruException:
+            If the capacity is *not* an integer or its a **non-positive
+            integer** (i.e. less than 1).
+        '''
+
+        super().__init__()
+
+        if not isinstance(size, int):
+            raise _BeartypeUtilCacheLruException(
+                f'LRU cache capacity {repr(size)} not integer.')
+        elif size < 1:
+            raise _BeartypeUtilCacheLruException(
+                f'LRU cache capacity {size} not positive.')
+
+        self._size = size
+        self._lock = Lock()
+
+
+    def __getitem__(
+        self,
+        key: Hashable,
+
+        # Superclass methods efficiently localized as default parameters.
+        __contains = dict.__contains__,  # pyright: ignore
+        __getitem = dict.__getitem__,  # pyright: ignore
+        __delitem = dict.__delitem__,  # pyright: ignore
+        __pushitem = dict.__setitem__,  # pyright: ignore
+    ) -> object:
+        '''
+        Return an item previously cached under the passed key *or* raise an
+        exception otherwise.
+
+        This implementation is *practically* identical to
+        :meth:`self.__contains__` except we return an arbitrary object rather
+        than a boolean.
+
+        Parameters
+        ----------
+        key : Hashable
+            Arbitrary hashable key to retrieve the cached value of.
+
+        Returns
+        -------
+        object
+            Arbitrary value cached under this key.
+
+        Raises
+        ------
+        TypeError
+            If this key is not hashable.
+        KeyError
+            If this key isn't cached.
+        '''
+
+        with self._lock:
+            # Reset this key if it exists.
+            if __contains(self, key):
+                val = __getitem(self, key)
+                __delitem(self, key)
+                __pushitem(self, key, val)
+                return val
+
+            raise KeyError(f'Key Error: {key}')
+
+
+    def __setitem__(
+        self,
+        key: Hashable,
+        value: object,
+
+        # Superclass methods efficiently localized as default parameters.
+        __contains = dict.__contains__,  # pyright: ignore
+        __delitem = dict.__delitem__,  # pyright: ignore
+        __pushitem = dict.__setitem__,  # pyright: ignore
+        __iter = dict.__iter__,  # pyright: ignore
+        __len = dict.__len__,  # pyright: ignore
+    ) -> None:
+        '''
+        Cache this key-value pair while preserving size constraints.
+
+        Parameters
+        ----------
+        key : Hashable
+            Arbitrary hashable key to cache this value to.
+        value : object
+            Arbitrary value to be cached under this key.
+
+        Raises
+        ------
+        TypeError
+            If this key is not hashable.
+        '''
+
+        with self._lock:
+            if __contains(self, key):
+                __delitem(self, key)
+            __pushitem(self, key, value)
+
+            # Prune this cache.
+            if __len(self) > self._size:
+                __delitem(self, next(__iter(self)))
+
+
+    def __contains__(
+        self,
+        key: Hashable,
+
+        # Superclass methods efficiently localized as default parameters.
+        __contains = dict.__contains__,  # pyright: ignore
+        __getitem = dict.__getitem__,  # pyright: ignore
+        __delitem = dict.__delitem__,  # pyright: ignore
+        __pushitem = dict.__setitem__,  # pyright: ignore
+     ) -> bool:
+        '''
+        Return a boolean indicating whether this key is cached.
+
+        If this key is cached, this method implicitly refreshes this key by
+        popping and pushing this key back onto the top of this cache.
+
+        Parameters
+        ----------
+        key : Hashable
+            Arbitrary hashable key to detect the existence of.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this key is cached.
+
+        Raises
+        ----------
+        TypeError
+            If this key is unhashable.
+        '''
+
+        with self._lock:
+            if __contains(self, key):
+                val = __getitem(self, key)
+                __delitem(self, key)
+                __pushitem(self, key, val)
+                return True
+
+            return False
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/pool/utilcachepool.py
@@ -0,0 +1,300 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **key pool type** (i.e., object caching class implemented as a
+dictionary of lists of arbitrary objects to be cached, where objects cached to
+the same list are typically of the same type).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Conditionally pass "is_debug=True" to the KeyPool.{acquire,release}()
+#methods defined below when the "BeartypeConfig.is_debug" parameter is "True"
+#for the current call to the @beartype decorator, please.
+
+#FIXME: Optimize the KeyPool.{acquire,release}() methods defined below. Rather
+#than unconditionally wrapping the bodies of each in a thread-safe
+#"self._thread_lock" context manager, we might be able to leverage the GIL by
+#only doing so "if threading.active_count():". Profile us up, please.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCachedKeyPoolException
+from beartype.typing import (
+    Dict,
+    Union,
+)
+from collections import defaultdict
+from collections.abc import Callable, Hashable
+from threading import Lock
+
+# ....................{ CLASSES                            }....................
+class KeyPool(object):
+    '''
+    Thread-safe **key pool** (i.e., object cache implemented as a dictionary of
+    lists of arbitrary objects to be cached, where objects cached to the same
+    list are typically of the same type).
+
+    Key pools are thread-safe by design and thus safely usable as module-scoped
+    globals accessed from module-scoped callables.
+
+    Attributes
+    ----------
+    _key_to_pool : defaultdict
+        Dictionary mapping from an **arbitrary key** (i.e., hashable object) to
+        corresponding **pool** (i.e., list of zero or more arbitrary objects
+        referred to as "pool items" cached under that key). For both efficiency
+        and simplicity, this dictionary is defined as a :class:`defaultdict`
+        implicitly initializing missing keys on initial access to the empty
+        list.
+    _pool_item_id_to_is_acquired : dict
+        Dictionary mapping from the unique object identifier of a **pool item**
+        (i.e., arbitrary object cached under a pool of the :attr:`_key_to_pool`
+        ditionary) to a boolean that is either:
+
+        * :data:`True` if that item is currently **acquired** (i.e., most
+          recently returned by a call to the :meth:`acquire` method).
+        * :data:`False` if that item is currently **released** (i.e., most
+          recently passed to a call to the :meth:`release` method).
+    _pool_item_maker : Callable
+        Caller-defined factory callable internally called by the
+        :meth:`acquire` method on attempting to acquire a non-existent object
+        from an **empty pool. See :meth:`__init__` for further details.
+    _thread_lock : Lock
+        **Non-reentrant instance-specific thread lock** (i.e., low-level thread
+        locking mechanism implemented as a highly efficient C extension,
+        defined as an instance variable for non-reentrant reuse by the public
+        API of this class). Although CPython, the canonical Python interpreter,
+        *does* prohibit conventional multithreading via its Global Interpreter
+        Lock (GIL), CPython still coercively preempts long-running threads at
+        arbitrary execution points. Ergo, multithreading concerns are *not*
+        safely ignorable -- even under CPython.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # @beartype decorations. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_key_to_pool',
+        '_pool_item_id_to_is_acquired',
+        '_pool_item_maker',
+        '_thread_lock',
+    )
+
+    # ..................{ INITIALIZER                        }..................
+    def __init__(
+        self,
+        item_maker: Union[type, Callable],
+    ) -> None:
+        '''
+        Initialize this key pool with the passed factory callable.
+
+        Parameters
+        ----------
+        item_maker : Union[type, Callable[[Hashable,], Any]]
+            Caller-defined factory callable internally called by the
+            :meth:`acquire` method on attempting to acquire a non-existent
+            object from an **empty pool** (i.e., either a missing key *or* an
+            empty list of an existing key of the underlying
+            :attr:`_key_to_pool` dictionary). That method initializes the empty
+            pool in question by calling this factory with the key associated
+            with that pool and appending the object created and returned by
+            this factory to that pool. This factory is thus expected to have a
+            signature resembling:
+
+            .. code-block:: python
+
+               from collections.abc import Hashable
+               def item_maker(key: Hashable) -> object: ...
+        '''
+        assert callable(item_maker), f'{repr(item_maker)} not callable.'
+
+        # Classify these parameters as instance variables.
+        self._pool_item_maker = item_maker
+
+        # Initialize all remaining instance variables.
+        #
+        # Note that "defaultdict" instances *MUST* be initialized with
+        # positional rather than keyword parameters. For unknown reasons,
+        # initializing such an instance with a keyword parameter causes that
+        # instance to silently behave like a standard dictionary instead: e.g.,
+        #
+        #     >>> dd = defaultdict(default_factory=list)
+        #     >>> dd['ee']
+        #     KeyError: 'ee'
+        self._key_to_pool: Dict[Hashable, list] = defaultdict(list)
+        self._pool_item_id_to_is_acquired: Dict[int, bool] = {}
+        self._thread_lock = Lock()
+
+    # ..................{ METHODS                            }..................
+    def acquire(
+        self,
+
+        # Optional parameters.
+        key: Hashable = None,
+        is_debug: bool = False,
+    ) -> object:
+        '''
+        Acquire an arbitrary object associated with the passed **arbitrary
+        key** (i.e., hashable object).
+
+        Specifically, this method tests whether there exists a non-empty list
+        previously associated with this key. If so, this method pops the last
+        item from that list and returns that item; else (i.e., if there either
+        exists no such list or such a list exists but is empty), this method
+        effectively (in order):
+
+        #. If no such list exists, create a new empty list associated with
+           this key.
+        #. Create a new object to be returned by calling the user-defined
+           :meth:`_pool_item_maker` factory callable.
+        #. Append this object to this list.
+        #. Add/Update acquisition state of the object to True
+        #. Returns this object.
+
+        Parameters
+        ----------
+        key : Optional[HashableType]
+            Hashable object associated with the pool item to be acquired.
+            Defaults to ``None``.
+        is_debug : bool, optional
+            ``True`` only if enabling inefficient debugging logic. Notably,
+            enabling this option notes this item to have now been acquired.
+            Defaults to ``False``.
+
+        Returns
+        ----------
+        object
+            Pool item associated with this hashable object.
+
+        Raises
+        ----------
+        TypeError
+            If this key is unhashable and thus *not* a key.
+        '''
+
+        # In a thread-safe manner...
+        with self._thread_lock:
+            #FIXME: This logic can *PROBABLY* be optimized into:
+            #    if not is_debug:
+            #        try:
+            #            return self._key_to_pool[key].pop()
+            #        except IndexError:
+            #            return self._pool_item_maker(key)
+            #    else:
+            #        try:
+            #            pool_item = self._key_to_pool[key].pop()
+            #        except IndexError:
+            #            pool_item = self._pool_item_maker(key)
+            #
+            #        # Record this item to have now been acquired.
+            #        self._pool_item_id_to_is_acquired[id(pool_item)] = True
+            #
+            #        return pool_item
+            #
+            #That said, this introduces additional complexity that will require
+            #unit testing. So, only do so if the above is actually profiled as
+            #being faster. It almost certainly is, but let's be certain please.
+
+            # List associated with this key.
+            #
+            # If this is the first access of this key, this "defaultdict"
+            # implicitly creates a new list and associates this key with that
+            # list; else, this is the list previously associated with this key.
+            #
+            # Note that this statement implicitly raises a "TypeError"
+            # exception if this key is unhashable, which is certainly more
+            # efficient than our explicitly validating this constraint.
+            pool = self._key_to_pool[key]
+
+            # Pool item associated with this key, defined as either...
+            pool_item = (
+                # The last item popped (i.e., removed) from this list...
+                pool.pop()
+                # If the list associated with this key is non-empty (i.e., this
+                # method has been called less frequently than the corresponding
+                # release() method for this key);
+                if pool else
+                # Else, the list associated with this key is empty (i.e., this
+                # method has been called more frequently than the release()
+                # method for this key). In this case, an arbitrary object
+                # associated with this key.
+                self._pool_item_maker(key)
+            )
+
+            # If debugging, record this item to have now been acquired.
+            if is_debug:
+                self._pool_item_id_to_is_acquired[id(pool_item)] = True
+
+            # Return this item.
+            return pool_item
+
+
+    def release(
+        self,
+
+        # Mandatory parameters.
+        item: object,
+
+        # Optional parameters.
+        key: Hashable = None,
+        is_debug: bool = False,
+    ) -> None:
+        '''
+        Release the passed object acquired by a prior call to the
+        :meth:`acquire` method passed the same passed **arbitrary key** (i.e.,
+        hashable object).
+
+        Specifically, this method tests whether there exists a list
+        previously associated with this key. If not, this method creates a new
+        empty list associated with this key. In either case, this method then
+        appends this object to this list.
+
+        Parameters
+        ----------
+        item : object
+            Arbitrary object previously associated with this key.
+        key : Optional[HashableType]
+            Hashable object previously associated with this pool item. Defaults
+            to ``None``.
+        is_debug : bool, optional
+            ``True`` only if enabling inefficient debugging logic. Notably,
+            enabling this option raises an exception if this item was *not*
+            previously acquired. Defaults to ``False``.
+
+        Raises
+        ----------
+        TypeError
+            If this key is unhashable (i.e. *not* a key).
+        _BeartypeUtilCachedKeyPoolException
+            If debugging *and* this pool item was not acquired (i.e., returned
+            by a prior call to the :meth:`acquire` method), in which case this
+            item is ineligible for release.
+        '''
+
+        # In a thread-safe manner...
+        with self._thread_lock:
+            # If debugging...
+            if is_debug:
+                # Integer uniquely identifying this previously acquired pool
+                # item.
+                item_id = id(item)
+
+                # If this item was *NOT* previously acquired, raise an
+                # exception.
+                if not self._pool_item_id_to_is_acquired.get(item_id, False):
+                    raise _BeartypeUtilCachedKeyPoolException(
+                        f'Unacquired key pool item {repr(item)} '
+                        f'not releasable.'
+                    )
+
+                # Record this item to have now been released.
+                self._pool_item_id_to_is_acquired[item_id] = False
+
+            # Append this item to the pool associated with this key.
+            self._key_to_pool[key].append(item)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/pool/utilcachepoollistfixed.py
@@ -0,0 +1,376 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Fixed list pool** (i.e., submodule whose thread-safe API caches previously
+instantiated :class:`list` subclasses constrained to fixed lengths defined at
+instantiation time of various lengths for space- and time-efficient reuse
+by the :func:`beartype.beartype` decorator across decoration calls).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Consider submitting the "FixedList" type as a relevant StackOverflow
+#answer here:
+#    https://stackoverflow.com/questions/10617045/how-to-create-a-fix-size-list-in-python
+#    https://stackoverflow.com/questions/51558015/implementing-efficient-fixed-size-fifo-in-python
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCachedFixedListException
+from beartype.typing import NoReturn
+from beartype._util.cache.pool.utilcachepool import KeyPool
+from beartype._util.text.utiltextrepr import represent_object
+
+# ....................{ CONSTANTS                          }....................
+FIXED_LIST_SIZE_MEDIUM = 256
+'''
+Reasonably large length to constrain acquired and released fixed lists to.
+
+This constant is intended to be passed to the :func:`.acquire_fixed_list`
+function, which then returns a fixed list of this length suitable for use in
+contexts requiring a "reasonably large" list -- where "reasonably" and "large"
+are both subjective but *should* cover 99.9999% of use cases in this codebase.
+'''
+
+# ....................{ CLASSES                            }....................
+class FixedList(list):
+    '''
+    **Fixed list** (i.e., :class:`list` constrained to a fixed length defined
+    at instantiation time).**
+
+    A fixed list is effectively a mutable tuple. Whereas a tuple is immutable
+    and thus prohibits changes to its contained items, a fixed list is mutable
+    and thus *permits* changes to its contained items.
+
+    Design
+    ------
+    This list enforces this constraint by overriding *all* :class:`list` dunder
+    and standard methods that would otherwise modify the length of this list
+    (e.g., :meth:`list.__delitem__`, :meth:`list.append`) to instead
+    unconditionally raise an :class:`._BeartypeUtilCachedFixedListException`
+    exception.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently
+    # called @beartype decorations. Slotting has been shown to reduce read and
+    # write costs by approximately ~10%, which is non-trivial.
+    __slots__ = ()
+
+    # ..................{ INITIALIZER                        }..................
+    def __init__(
+        self,
+
+        # Mandatory parameters.
+        size: int,
+
+        # Optional parameters.
+        obj_init: object = None,
+    ) -> None:
+        '''
+        Initialize this fixed list to the passed length and all items of this
+        fixed list to the passed initialization object.
+
+        Parameters
+        ----------
+        size : IntType
+            Length to constrain this fixed list to.
+        obj_init : object, optional
+            **Initialization object** (i.e., object to be unilaterally assigned
+            to *all* indices of this fixed list). Defaults to :data:`None`.
+
+        Raises
+        ------
+        _BeartypeUtilCachedFixedListException
+            If this length is either not an integer *or* is but is
+            **non-positive** (i.e., is less than or equal to 0).
+        '''
+
+        # If this length is *NOT* an integer, raise an exception.
+        if not isinstance(size, int):
+            raise _BeartypeUtilCachedFixedListException(
+                f'Fixed list length {repr(size)} not integer.')
+        # Else, this length is an integer.
+        #
+        # If this length is non-positive, raise an exception.
+        elif size <= 0:
+            raise _BeartypeUtilCachedFixedListException(
+                f'Fixed list length {size} <= 0.')
+        # Else, this length is positive.
+
+        # Make it so with the standard Python idiom for preallocating list
+        # space -- which, conveniently, is also the optimally efficient means
+        # of doing so. See also the timings in this StackOverflow answer:
+        #     https://stackoverflow.com/a/10617221/2809027
+        super().__init__([obj_init]*size)
+
+    # ..................{ GOOD ~ non-dunders                 }..................
+    # Permit non-dunder methods preserving list length but otherwise requiring
+    # overriding.
+
+    def copy(self) -> 'FixedList':
+
+        # Nullified fixed list of the same length as this fixed list.
+        list_copy = FixedList(len(self))
+
+        # Slice over the nullified contents of this copy with those of this
+        # fixed list.
+        list_copy[:] = self
+
+        # Return this copy.
+        return list_copy
+
+    # ..................{ BAD ~ dunders                      }..................
+    # Prohibit dunder methods modifying list length by overriding these methods
+    # to raise exceptions.
+
+    def __delitem__(self, index) -> NoReturn:
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} index {repr(index)} not deletable.')
+
+
+    def __iadd__(self, value) -> NoReturn:  # type: ignore[misc]
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not addable by {represent_object(value)}.')
+
+
+    def __imul__(self, value) -> NoReturn:  # type: ignore[misc]
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not multipliable by {represent_object(value)}.')
+
+    # ..................{ BAD ~ dunders : setitem            }..................
+    #FIXME: Great idea, if efficiency didn't particularly matter. Since
+    #efficiency is the entire raison d'etre of this class, however, this method
+    #has been temporarily and probably permanently disabled. Extensive
+    #profiling has shown this single method to substantially cost us elsewhere.
+    #Moreover, this method is only relevant in the context of preventing
+    #external callers who are *NOT* us from violating class constraints. No
+    #external callers exist, though! We are it. Since we know better, we won't
+    #violate class constraints by changing fixed list length with slicing.
+    #Moreover, it's unlikely we ever even assign list slices anywhere. *sigh*
+
+    # def __setitem__(self, index, value):
+    #
+    #     # If these parameters indicate an external attempt to change the length
+    #     # of this fixed length with slicing, raise an exception.
+    #     self._die_if_slice_len_ne_value_len(index, value)
+    #
+    #     # If this index is a tuple of 0-based indices and slice objects...
+    #     if isinstance(index, Iterable):
+    #         # For each index or slice in this tuple...
+    #         for subindex in index:
+    #             # If these parameters indicate an external attempt to change
+    #             # the length of this fixed length with slicing, raise an
+    #             # exception.
+    #             self._die_if_slice_len_ne_value_len(subindex, value)
+    #
+    #     # Else, this list is either not being sliced or is but is being set to
+    #     # an iterable of the same length as that slice. In either case, this
+    #     # operation preserves the length of this list and is thus acceptable.
+    #     return super().__setitem__(index, value)
+
+
+    #FIXME: Disabled as currently only called by __setitem__(). *sigh*
+    # def _die_if_slice_len_ne_value_len(self, index, value) -> None:
+    #     '''
+    #     Raise an exception only if the passed parameters when passed to the
+    #     parent :meth:`__setitem__` dunder method signify an external attempt to
+    #     change the length of this fixed length with slicing.
+    #
+    #     This function is intended to be called by the :meth:`__setitem__`
+    #     dunder method to validate the passed parameters.
+    #
+    #     Parameters
+    #     ----------
+    #     index
+    #         0-based index, slice object, or tuple of 0-based indices and slice
+    #         objects to index this fixed list with.
+    #     value
+    #         Object to set this index(s) of this fixed list to.
+    #
+    #     Raises
+    #     ----------
+    #     _BeartypeUtilCachedFixedListException
+    #         If this index is a **slice object** (i.e., :class:`slice` instance
+    #         underlying slice syntax) and this value is either:
+    #
+    #         * **Unsized** (i.e., unsupported by the :func:`len` builtin).
+    #         * Sized but has a length differing from that of this fixed list.
+    #     '''
+    #
+    #     # If this index is *NOT* a slice, silently reduce to a noop.
+    #     if not isinstance(index, slice):
+    #         return
+    #     # Else, this index is a slice.
+    #     #
+    #     # If this value is *NOT* a sized container, raise an exception.
+    #     elif not isinstance(value, Sized):
+    #         raise _BeartypeUtilCachedFixedListException(
+    #             f'{self._label} slice {repr(index)} not settable to unsized '
+    #             f'{represent_object(value)}.'
+    #         )
+    #     # Else, this value is a sized container.
+    #
+    #     # 0-based first and one-past-the-last indices sliced by this slice.
+    #     start, stop_plus_one, _ = index.indices(len(self))
+    #
+    #     # Number of items of this fixed list sliced by this slice. By
+    #     # definition, this is guaranteed to be a non-negative integer.
+    #     slice_len = stop_plus_one - start
+    #
+    #     # Number of items of this sized container to set this slice to.
+    #     value_len = len(value)
+    #
+    #     # If these two lengths differ, raise an exception.
+    #     if slice_len != value_len:
+    #         raise _BeartypeUtilCachedFixedListException(
+    #             f'{self._label} slice {repr(index)} of length {slice_len} not '
+    #             f'settable to {represent_object(value)} of differing '
+    #             f'length {value_len}.'
+    #         )
+
+    # ..................{ BAD ~ non-dunders                  }..................
+    # Prohibit non-dunder methods modifying list length by overriding these
+    # methods to raise exceptions.
+
+    def append(self, obj) -> NoReturn:
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not appendable by {represent_object(obj)}.')
+
+
+    def clear(self) -> NoReturn:
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not clearable.')
+
+
+    def extend(self, obj) -> NoReturn:
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not extendable by {represent_object(obj)}.')
+
+
+    def pop(self, *args) -> NoReturn:
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not poppable.')
+
+
+    def remove(self, *args) -> NoReturn:
+        raise _BeartypeUtilCachedFixedListException(
+            f'{self._label} not removable.')
+
+    # ..................{ PRIVATE ~ property                 }..................
+    # Read-only properties intentionally prohibiting mutation.
+
+    @property
+    def _label(self) -> str:
+        '''
+        Human-readable representation of this fixed list trimmed to a
+        reasonable length.
+
+        This string property is intended to be interpolated into exception
+        messages and should probably *not* be called in contexts where
+        efficiency is a valid concern.
+        '''
+
+        # One-liners for magnanimous pusillanimousness.
+        return f'Fixed list {represent_object(self)}'
+
+# ....................{ PRIVATE ~ factories                }....................
+_fixed_list_pool = KeyPool(item_maker=FixedList)
+'''
+Thread-safe **fixed list pool** (i.e., :class:`.KeyPool` singleton caching
+previously instantiated :class:`FixedList` instances of various lengths).
+
+Caveats
+-------
+**Avoid accessing this private singleton externally.** Instead, call the public
+:func:`.acquire_fixed_list` and :func:`.release_fixed_list` functions, which
+efficiently validate both input *and* output to conform to sane expectations.
+'''
+
+# ....................{ (ACQUIRERS|RELEASERS)              }....................
+def acquire_fixed_list(size: int) -> FixedList:
+    '''
+    Acquire an arbitrary **fixed list** (i.e., :class:`list` constrained to a
+    fixed length defined at instantiation time) with the passed length.
+
+    Caveats
+    -------
+    **The contents of this list are arbitrary.** Callers should make *no*
+    assumptions as to this list's initial items, but should instead reinitialize
+    this list immediately after acquiring this list with standard list slice
+    syntax: e.g.,
+
+    .. code-block:: pycon
+
+       >>> from beartype._util.cache.pool.utilcachepoollistfixed import (
+       ...     acquire_fixed_list)
+       >>> fixed_list = acquire_fixed_list(size=5)
+       >>> fixed_list[:] = ('Dirty', 'Deads', 'Done', 'Dirt', 'Cheap',)
+
+    Parameters
+    ----------
+    size : int
+        Length to constrain the fixed list to be acquired to.
+
+    Returns
+    -------
+    FixedList
+        Arbitrary fixed list with this length.
+
+    Raises
+    ------
+    _BeartypeUtilCachedFixedListException
+        If this length is either not an integer *or* is but is **non-positive**
+        (i.e., is less than or equal to 0).
+    '''
+    # Note that the FixedList.__init__() method already validates this "size"
+    # parameter to be an integer.
+
+    # Thread-safely acquire a fixed list of this length.
+    fixed_list = _fixed_list_pool.acquire(size)
+    assert isinstance(fixed_list, FixedList), (
+        f'{repr(fixed_list)} not fixed list.')
+
+    # Return this list.
+    return fixed_list
+
+
+def release_fixed_list(fixed_list: FixedList) -> None:
+    '''
+    Release the passed fixed list acquired by a prior call to the
+    :func:`acquire_fixed_list` function.
+
+    Caveats
+    -------
+    **This list is not safely accessible after calling this function.** Callers
+    should make *no* attempts to read, write, or otherwise access this list, but
+    should instead nullify *all* variables referring to this list immediately
+    after releasing this list (e.g., by setting these variables to the
+    :data:`None` singleton *or* by deleting these variables): e.g.,
+
+    .. code-block:: pycon
+
+       >>> from beartype._util.cache.pool.utilcachepoollistfixed import (
+       ...     acquire_fixed_list, release_fixed_list)
+       >>> fixed_list = acquire_fixed_list(size=7)
+       >>> fixed_list[:] = ('If', 'You', 'Want', 'Blood', "You've", 'Got', 'It',)
+       >>> release_fixed_list(fixed_list)
+       # Either do this...
+       >>> fixed_list = None
+       # Or do this.
+       >>> del fixed_list
+
+    Parameters
+    ----------
+    fixed_list : FixedList
+        Previously acquired fixed list to be released.
+    '''
+    assert isinstance(fixed_list, FixedList), (
+        f'{repr(fixed_list)} not fixed list.')
+
+    # Thread-safely release this fixed list.
+    _fixed_list_pool.release(key=len(fixed_list), item=fixed_list)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/pool/utilcachepoolobjecttyped.py
@@ -0,0 +1,111 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Typed object pool** (i.e., submodule whose thread-safe API caches previously
+instantiated objects of arbitrary types for space- and time-efficient reuse by
+the :func:`beartype.beartype` decorator across decoration calls).
+
+This private submodule is *not* intended for importation by downstream callers.
+
+Caveats
+----------
+**This submodule only pools objects defining an** ``__init__()`` **method
+accepting no parameters.** Why? Because this submodule unconditionally pools
+all objects of the same types under those types. This submodule provides *no*
+mechanism for pooling objects of the same types under different parameters
+instantiated with those parameters and thus only implements a coarse- rather
+than fine-grained object cache. If insufficient, consider defining a new
+submodule implementing a fine-grained object cache unique to those objects. For
+example:
+
+* This submodule unconditionally pools all instances of the
+  :class:`beartype._check.checkcall.BeartypeCall` class under that type.
+* The parallel :mod:`beartype._util.cache.pool.utilcachepoollistfixed`
+  submodule conditionally pools every instance of the
+  :class:`beartype._util.cache.pool.utilcachepoollistfixed.FixedList` class of
+  the same length under that length.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCachedObjectTypedException
+from beartype.typing import Any
+from beartype._util.cache.pool.utilcachepool import KeyPool
+
+# ....................{ SINGLETONS ~ private               }....................
+_object_typed_pool = KeyPool(item_maker=lambda cls: cls())
+'''
+Thread-safe **typed object pool** (i.e., :class:`KeyPool` singleton caching
+previously instantiated objects of the same types under those types).
+
+Caveats
+----------
+**Avoid accessing this private singleton externally.** Instead, call the public
+:func:`acquire_object_typed` and :func:`release_object_typed` functions, which
+efficiently validate both input *and* output to conform to sane expectations.
+'''
+
+# ....................{ (ACQUIRERS|RELEASERS)              }....................
+def acquire_object_typed(cls: type) -> Any:
+    '''
+    Acquire an arbitrary object of the passed type.
+
+    Caveats
+    ----------
+    **The contents of this object are arbitrary.** Callers should make *no*
+    assumptions as to this object's state, but should instead reinitialize this
+    object immediately after acquiring this object.
+
+    Parameters
+    ----------
+    cls : type
+        Type of the object to be acquired.
+
+    Returns
+    ----------
+    object
+        Arbitrary object of this type.
+
+    Raises
+    ----------
+    _BeartypeUtilCachedObjectTypedException
+        If this type is *not* actually a type.
+    '''
+
+    # If this type is *NOT* actually a type, raise an exception.
+    if not isinstance(cls, type):
+        raise _BeartypeUtilCachedObjectTypedException(
+            '{!r} not a class.'.format(cls))
+
+    # Thread-safely acquire an object of this type.
+    object_typed = _object_typed_pool.acquire(cls)
+    assert isinstance(object_typed, cls), (
+        '{!r} not a {!r}.'.format(object_typed, cls))
+
+    # Return this object.
+    return object_typed
+
+
+def release_object_typed(obj: Any) -> None:
+    '''
+    Release the passed object acquired by a prior call to the
+    :func:`acquire_object_typed` function.
+
+    Caveats
+    ----------
+    **This object is not safely accessible after calling this function.**
+    Callers should make *no* attempts to read, write, or otherwise access this
+    object, but should instead nullify *all* variables referring to this object
+    immediately after releasing this object (e.g., by setting these variables
+    to the ``None`` singleton *or* by deleting these variables).
+
+    Parameters
+    ----------
+    obj : object
+        Previously acquired object to be released.
+    '''
+
+    # Thread-safely release this object.
+    _object_typed_pool.release(key=obj.__class__, item=obj)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/utilcachecall.py
@@ -0,0 +1,670 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable caching utilities** (i.e., low-level callables
+performing general-purpose memoization of function and method calls).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Generalize @callable_cached to revert to the body of the
+#@beartype._util.type.decorator.decmemo.func_cached decorator when the passed
+#callable accepts *NO* parameters, which can be trivially decided by inspecting
+#the code object of this callable. Why do this? Because the @func_cached
+#decorator is *INSANELY* fast for this edge case -- substantially faster than
+#the current general-purpose @callable_cached approach.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableCachedException
+from beartype.typing import Dict
+from beartype._data.hint.datahinttyping import CallableT
+from beartype._util.func.arg.utilfuncargtest import (
+    die_unless_func_args_len_flexible_equal,
+    is_func_arg_variadic,
+)
+from beartype._util.text.utiltextlabel import label_callable
+from beartype._util.utilobject import SENTINEL
+from functools import wraps
+
+# ....................{ DECORATORS ~ callable              }....................
+def callable_cached(func: CallableT) -> CallableT:
+    '''
+    **Memoize** (i.e., efficiently re-raise all exceptions previously raised by
+    the decorated callable when passed the same parameters (i.e., parameters
+    that evaluate as equals) as a prior call to that callable if any *or* return
+    all values previously returned by that callable otherwise rather than
+    inefficiently recalling that callable) the passed callable.
+
+    Specifically, this decorator (in order):
+
+    #. Creates:
+
+       * A local dictionary mapping parameters passed to this callable with the
+         values returned by this callable when passed those parameters.
+       * A local dictionary mapping parameters passed to this callable with the
+         exceptions raised by this callable when passed those parameters.
+
+    #. Creates and returns a closure transparently wrapping this callable with
+       memoization. Specifically, this wrapper (in order):
+
+       #. Tests whether this callable has already been called at least once
+          with the passed parameters by lookup of those parameters in these
+          dictionaries.
+       #. If this callable previously raised an exception when passed these
+          parameters, this wrapper re-raises the same exception.
+       #. Else if this callable returned a value when passed these parameters,
+          this wrapper re-returns the same value.
+       #. Else, this wrapper:
+
+          #. Calls that callable with those parameters.
+          #. If that call raised an exception:
+
+             #. Caches that exception with those parameters in that dictionary.
+             #. Raises that exception.
+
+          #. Else:
+
+             #. Caches the value returned by that call with those parameters in
+                that dictionary.
+             #. Returns that value.
+
+    Caveats
+    -------
+    **The decorated callable must accept no keyword parameters.** While this
+    decorator previously memoized keyword parameters, doing so incurred
+    significant performance penalties defeating the purpose of caching. This
+    decorator now intentionally memoizes *only* positional parameters.
+
+    **The decorated callable must accept no variadic positional parameters.**
+    While memoizing variadic parameters would of course be feasible, this
+    decorator has yet to implement support for doing so.
+
+    **The decorated callable should not be a property method** (i.e., either a
+    property getter, setter, or deleter subsequently decorated by the
+    :class:`property` decorator). Technically, this decorator *can* be used to
+    memoize property methods; pragmatically, doing so would be sufficiently
+    inefficient as to defeat the intention of memoizing in the first place.
+
+    Efficiency
+    ----------
+    For efficiency, consider calling the decorated callable with only:
+
+    * **Hashable** (i.e., immutable) arguments. While technically supported,
+      every call to the decorated callable passed one or more unhashable
+      arguments (e.g., mutable containers like lists and dictionaries) will
+      silently *not* be memoized. Equivalently, only calls passed only hashable
+      arguments will be memoized. This flexibility enables decorated callables
+      to accept unhashable PEP-compliant type hints. Although *all*
+      PEP-noncompliant and *most* PEP-compliant type hints are hashable, some
+      sadly are not. These include:
+
+      * :pep:`585`-compliant type hints subscripted by one or more unhashable
+        objects (e.g., ``collections.abc.Callable[[], str]``, the `PEP
+        585`_-compliant type hint annotating piths accepting callables
+        accepting no parameters and returning strings).
+      * :pep:`586`-compliant type hints subscripted by an unhashable object
+        (e.g., ``typing.Literal[[]]``, a literal empty list).
+      * :pep:`593`-compliant type hints subscripted by one or more unhashable
+        objects (e.g., ``typing.Annotated[typing.Any, []]``, the
+        :attr:`typing.Any` singleton annotated by an empty list).
+
+    **This decorator is intentionally not implemented in terms of the stdlib**
+    :func:`functools.lru_cache` **decorator,** as that decorator is inefficient
+    in the special case of unbounded caching with ``maxsize=None``. Why? Because
+    that decorator insists on unconditionally recording irrelevant statistics
+    like cache misses and hits. While bounding the number of cached values is
+    advisable in the general case (e.g., to avoid exhausting memory merely for
+    optional caching), parameters and returns cached by this package are
+    sufficiently small in size to render such bounding irrelevant.
+
+    Consider the
+    :func:`beartype._util.hint.pep.utilpeptest.is_hint_pep_type_typing`
+    function, for example. Each call to that function only accepts a single
+    class and returns a boolean. Under conservative assumptions of 4 bytes of
+    storage per class reference and 4 byte of storage per boolean reference,
+    each call to that function requires caching at most 8 bytes of storage.
+    Again, under conservative assumptions of at most 1024 unique type
+    annotations for the average downstream consumer, memoizing that function in
+    full requires at most 1024 * 8 == 8096 bytes or ~8Kb of storage. Clearly,
+    8Kb of overhead is sufficiently negligible to obviate any space concerns
+    that would warrant an LRU cache in the first place.
+
+    Parameters
+    ----------
+    func : CallableT
+        Callable to be memoized.
+
+    Returns
+    -------
+    CallableT
+        Closure wrapping this callable with memoization.
+
+    Raises
+    ------
+    _BeartypeUtilCallableCachedException
+        If this callable accepts a variadic positional parameter (e.g.,
+        ``*args``).
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize against the @method_cached_arg_by_id decorator
+    # below. For speed, this decorator violates DRY by duplicating logic.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Dictionary mapping a tuple of all flattened parameters passed to each
+    # prior call of the decorated callable with the value returned by that call
+    # if any (i.e., if that call did *NOT* raise an exception).
+    args_flat_to_return_value: Dict[tuple, object] = {}
+
+    # get() method of this dictionary, localized for efficiency.
+    args_flat_to_return_value_get = args_flat_to_return_value.get
+
+    # Dictionary mapping a tuple of all flattened parameters passed to each
+    # prior call of the decorated callable with the exception raised by that
+    # call if any (i.e., if that call raised an exception).
+    args_flat_to_exception: Dict[tuple, Exception] = {}
+
+    # get() method of this dictionary, localized for efficiency.
+    args_flat_to_exception_get = args_flat_to_exception.get
+
+    @wraps(func)
+    def _callable_cached(*args):
+        f'''
+        Memoized variant of the {func.__name__}() callable.
+
+        See Also
+        --------
+        :func:`callable_cached`
+            Further details.
+        '''
+
+        # Object representing all passed positional arguments to be used as the
+        # key of various memoized dictionaries, defined as either...
+        args_flat = (
+            # If passed only one positional argument, minimize space consumption
+            # by flattening this tuple of only that argument into that argument.
+            # Since tuple items are necessarily hashable, this argument is
+            # necessarily hashable and thus permissible as a dictionary key;
+            args[0]
+            if len(args) == 1 else
+            # Else, one or more positional arguments are passed. In this case,
+            # reuse this tuple as is.
+            args
+        )
+
+        # Attempt to...
+        try:
+            # Exception raised by a prior call to the decorated callable when
+            # passed these parameters *OR* the sentinel placeholder otherwise
+            # (i.e., if this callable either has yet to be called with these
+            # parameters *OR* has but failed to raise an exception).
+            #
+            # Note that:
+            # * This statement raises a "TypeError" exception if any item of
+            #   this flattened tuple is unhashable.
+            # * A sentinel placeholder (e.g., "SENTINEL") is *NOT* needed here.
+            #   The values of the "args_flat_to_exception" dictionary are
+            #   guaranteed to *ALL* be exceptions. Since "None" is *NOT* an
+            #   exception, disambiguation between "None" and valid dictionary
+            #   values is *NOT* needed here. Although a sentinel placeholder
+            #   could still be employed, doing so would slightly reduce
+            #   efficiency for *NO* real-world gain.
+            exception = args_flat_to_exception_get(args_flat)
+
+            # If this callable previously raised an exception when called with
+            # these parameters, re-raise the same exception.
+            if exception:
+                raise exception  # pyright: ignore[reportGeneralTypeIssues]
+            # Else, this callable either has yet to be called with these
+            # parameters *OR* has but failed to raise an exception.
+
+            # Value returned by a prior call to the decorated callable when
+            # passed these parameters *OR* a sentinel placeholder otherwise
+            # (i.e., if this callable has yet to be passed these parameters).
+            return_value = args_flat_to_return_value_get(
+                args_flat, SENTINEL)
+
+            # If this callable has already been called with these parameters,
+            # return the value returned by that prior call.
+            if return_value is not SENTINEL:
+                return return_value
+            # Else, this callable has yet to be called with these parameters.
+
+            # Attempt to...
+            try:
+                # Call this parameter with these parameters and cache the value
+                # returned by this call to these parameters.
+                return_value = args_flat_to_return_value[args_flat] = func(
+                    *args)
+            # If this call raised an exception...
+            except Exception as exception:
+                # Cache this exception to these parameters.
+                args_flat_to_exception[args_flat] = exception
+
+                # Re-raise this exception.
+                raise exception
+        # If one or more objects either passed to *OR* returned from this call
+        # are unhashable, perform this call as is *WITHOUT* memoization. While
+        # non-ideal, stability is better than raising a fatal exception.
+        except TypeError:
+            #FIXME: If testing, emit a non-fatal warning or possibly even raise
+            #a fatal exception. In either case, we want our test suite to notify
+            #us about this.
+            return func(*args)
+
+        # Return this value.
+        return return_value
+
+    # Return this wrapper.
+    return _callable_cached  # type: ignore[return-value]
+
+# ....................{ DECORATORS ~ method                }....................
+def method_cached_arg_by_id(func: CallableT) -> CallableT:
+    '''
+    **Memoize** (i.e., efficiently re-raise all exceptions previously raised by
+    the decorated method when passed the same *exact* parameters (i.e.,
+    parameters whose object IDs are equals) as a prior call to that method if
+    any *or* return all values previously returned by that method otherwise
+    rather than inefficiently recalling that method) the passed method.
+
+    Caveats
+    -------
+    **This decorator is only intended to decorate bound methods** (i.e., either
+    class or instance methods bound to a class or instance). This decorator is
+    *not* intended to decorate functions or static methods.
+
+    **This decorator is only intended to decorate a method whose sole argument
+    is guaranteed to be a memoized singleton** (e.g.,
+    :class:`beartype.door.TypeHint` singleton). In this case, the object
+    identifier of that argument uniquely identifies that argument across *all*
+    calls to that method -- enabling this decorator to memoize that method.
+    Conversely, if that argument is *not* guaranteed to be a memoized singleton,
+    this decorator will fail to memoize that method while wasting considerable
+    space and time attempting to do so. In short, care is warranted.
+
+    This decorator is a micro-optimized variant of the more general-purpose
+    :func:`callable_cached` decorator, which should be preferred in most cases.
+    This decorator mostly exists for one specific edge case that the
+    :func:`callable_cached` decorator *cannot* by definition support:
+    user-defined classes implementing the ``__eq__`` dunder method to internally
+    call another method decorated by :func:`callable_cached` accepting an
+    instance of the same class. This design pattern appears astonishingly
+    frequently, including in our prominent :class:`beartype.door.TypeHint`
+    class. This edge case provokes infinite recursion. Consider this
+    minimal-length example (MLE) exhibiting the issue:
+
+    .. code-block:: python
+
+       from beartype._util.cache.utilcachecall import callable_cached
+
+       class MuhClass(object):
+           def __eq__(self, other: object) -> bool:
+               return isinstance(other, MuhClass) and self._is_equal(other)
+
+           @callable_cached
+           def _is_equal(self, other: 'MuhClass') -> bool:
+               return True
+
+    :func:`callable_cached` internally caches the ``other`` argument passed to
+    the ``_is_equal()`` method as keys of various internal dictionaries. When
+    passed the same ``other`` argument, subsequent calls to that method lookup
+    that ``other`` argument in those dictionaries. Since dictionary lookups
+    implicitly call the ``other.__eq__()`` method to resolve key collisions
+    *and* since the ``__eq__()`` method has been overridden in terms of the
+    ``_is_equal()`` method, infinite recursion results.
+
+    This decorator circumvents this issue by internally looking up the object
+    identifier of the passed argument rather than that argument itself, which
+    then avoids implicitly calling the ``__eq__()`` method of that argument.
+
+    Parameters
+    ----------
+    func : CallableT
+        Callable to be memoized.
+
+    Returns
+    -------
+    CallableT
+        Closure wrapping this callable with memoization.
+
+    Raises
+    ------
+    _BeartypeUtilCallableCachedException
+        If this callable accepts either:
+
+        * *No* parameters.
+        * Two or more parameters.
+        * A variadic positional parameter (e.g., ``*args``).
+
+    See Also
+    --------
+    :func:`callable_cached`
+        Further details.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfuncwrap import unwrap_func_all
+
+    # Lowest-level wrappee callable wrapped by this wrapper callable.
+    func_wrappee = unwrap_func_all(func)
+
+    # If this wrappee accepts either zero, one, *OR* three or more flexible
+    # parameters (i.e., parameters passable as either positional or keyword
+    # arguments), raise an exception.
+    die_unless_func_args_len_flexible_equal(
+        func=func_wrappee,
+        func_args_len_flexible=2,
+        exception_cls=_BeartypeUtilCallableCachedException,
+        # Avoid unnecessary callable unwrapping as a negligible optimization.
+        is_unwrap=False,
+    )
+    # Else, this wrappee accepts exactly one flexible parameter.
+
+    # If this wrappee accepts variadic arguments, raise an exception.
+    if is_func_arg_variadic(func_wrappee):
+        raise _BeartypeUtilCallableCachedException(
+            f'@method_cached_arg_by_id {label_callable(func)} '
+            f'variadic arguments uncacheable.'
+        )
+    # Else, this wrappee accepts *NO* variadic arguments.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize against the @callable_cached decorator above. For
+    # speed, this decorator violates DRY by duplicating logic.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Dictionary mapping a tuple of all flattened parameters passed to each
+    # prior call of the decorated callable with the value returned by that call
+    # if any (i.e., if that call did *NOT* raise an exception).
+    args_flat_to_return_value: Dict[tuple, object] = {}
+
+    # get() method of this dictionary, localized for efficiency.
+    args_flat_to_return_value_get = args_flat_to_return_value.get
+
+    # Dictionary mapping a tuple of all flattened parameters passed to each
+    # prior call of the decorated callable with the exception raised by that
+    # call if any (i.e., if that call raised an exception).
+    args_flat_to_exception: Dict[tuple, Exception] = {}
+
+    # get() method of this dictionary, localized for efficiency.
+    args_flat_to_exception_get = args_flat_to_exception.get
+
+    @wraps(func)
+    def _method_cached(self_or_cls, arg):
+        f'''
+        Memoized variant of the {func.__name__}() callable.
+
+        See Also
+        --------
+        :func:`callable_cached`
+            Further details.
+        '''
+
+        # Object identifiers of the sole positional parameters passed to the
+        # decorated method.
+        args_flat = (id(self_or_cls), id(arg))
+
+        # Attempt to...
+        try:
+            # Exception raised by a prior call to the decorated callable when
+            # passed these parameters *OR* the sentinel placeholder otherwise
+            # (i.e., if this callable either has yet to be called with these
+            # parameters *OR* has but failed to raise an exception).
+            #
+            # Note that:
+            # * This statement raises a "TypeError" exception if any item of
+            #   this flattened tuple is unhashable.
+            # * A sentinel placeholder (e.g., "SENTINEL") is *NOT* needed here.
+            #   The values of the "args_flat_to_exception" dictionary are
+            #   guaranteed to *ALL* be exceptions. Since "None" is *NOT* an
+            #   exception, disambiguation between "None" and valid dictionary
+            #   values is *NOT* needed here. Although a sentinel placeholder
+            #   could still be employed, doing so would slightly reduce
+            #   efficiency for *NO* real-world gain.
+            exception = args_flat_to_exception_get(args_flat)
+
+            # If this callable previously raised an exception when called with
+            # these parameters, re-raise the same exception.
+            if exception:
+                raise exception  # pyright: ignore[reportGeneralTypeIssues]
+            # Else, this callable either has yet to be called with these
+            # parameters *OR* has but failed to raise an exception.
+
+            # Value returned by a prior call to the decorated callable when
+            # passed these parameters *OR* a sentinel placeholder otherwise
+            # (i.e., if this callable has yet to be passed these parameters).
+            return_value = args_flat_to_return_value_get(
+                args_flat, SENTINEL)
+
+            # If this callable has already been called with these parameters,
+            # return the value returned by that prior call.
+            if return_value is not SENTINEL:
+                return return_value
+            # Else, this callable has yet to be called with these parameters.
+
+            # Attempt to...
+            try:
+                # Call this parameter with these parameters and cache the value
+                # returned by this call to these parameters.
+                return_value = args_flat_to_return_value[args_flat] = func(
+                    self_or_cls, arg)
+            # If this call raised an exception...
+            except Exception as exception:
+                # Cache this exception to these parameters.
+                args_flat_to_exception[args_flat] = exception
+
+                # Re-raise this exception.
+                raise exception
+        # If one or more objects either passed to *OR* returned from this call
+        # are unhashable, perform this call as is *WITHOUT* memoization. While
+        # non-ideal, stability is better than raising a fatal exception.
+        except TypeError:
+            #FIXME: If testing, emit a non-fatal warning or possibly even raise
+            #a fatal exception. In either case, we want our test suite to notify
+            #us about this.
+            return func(self_or_cls, arg)
+
+        # Return this value.
+        return return_value
+
+    # Return this wrapper.
+    return _method_cached  # type: ignore[return-value]
+
+# ....................{ DECORATORS ~ property              }....................
+def property_cached(func: CallableT) -> CallableT:
+    '''
+    **Memoize** (i.e., efficiently cache and return all previously returned
+    values of the passed property method as well as all previously raised
+    exceptions of that method previously rather than inefficiently recalling
+    that method) the passed **property method method** (i.e., either a property
+    getter, setter, or deleter subsequently decorated by the :class:`property`
+    decorator).
+
+    On the first access of a property decorated with this decorator (in order):
+
+    #. The passed method implementing this property is called.
+    #. The value returned by this property is internally cached into a private
+       attribute of the object to which this method is bound.
+    #. This value is returned.
+
+    On each subsequent access of this property, this cached value is returned as
+    is *without* calling the decorated method. Hence, the decorated method is
+    called at most once for each object exposing this property.
+
+    Caveats
+    -------
+    **This decorator must be preceded by an explicit usage of the standard**
+    :class:`property` **decorator.** Although this decorator could be trivially
+    refactored to automatically decorate the returned property method by the
+    :class:`property` decorator, doing so would violate static type-checking
+    expectations -- introducing far more issues than it would solve.
+
+    **This decorator should always be preferred over the standard**
+    :func:`functools.cached_property` **decorator available under Python >=
+    3.8.** This decorator is substantially more efficient in both space and time
+    than that decorator -- which is, of course, the entire point of caching.
+
+    **This decorator does not destroy bound property methods.** Technically, the
+    most efficient means of caching a property value into an instance is to
+    replace the property method currently bound to that instance with an
+    instance variable initialized to that value (e.g., as documented by this
+    `StackOverflow answer`_). Since a property should only ever be treated as an
+    instance variable, there superficially exists little harm in dynamically
+    changing the type of the former to the latter. Sadly, doing so introduces
+    numerous subtle issues with *no* plausible workaround. Notably, replacing
+    property methods by instance variables:
+
+    * Permits callers to erroneously set **read-only properties** (i.e.,
+      properties lacking setter methods), a profound violation of one of the
+      principle use cases for properties.
+    * Prevents pickling logic elsewhere from automatically excluding cached
+      property values, forcing these values to *always* be pickled to disk.
+      This is bad. Cached property values are *always* safely recreatable in
+      memory (and hence need *not* be pickled) and typically space-consumptive
+      in memory (and hence best *not* pickled). The slight efficiency gain from
+      replacing property methods by instance variables is hardly worth the
+      significant space loss from pickling these variables.
+
+    .. _StackOverflow answer:
+        https://stackoverflow.com/a/36684652/2809027
+
+    Parameters
+    ----------
+    func : CallableT
+        Property method to be memoized.
+
+    Returns
+    -------
+    CallableT
+        Dynamically generated function wrapping this property with memoization.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+
+    # Name of the private instance variable to which this decorator caches the
+    # value returned by the decorated property method.
+    property_var_name = (
+        _PROPERTY_CACHED_VAR_NAME_PREFIX + func.__name__)
+
+    # Raw string of Python statements comprising the body of this wrapper.
+    #
+    # Note that this implementation intentionally avoids calling our
+    # higher-level beartype._util.func.utilfuncmake.make_func() factory function
+    # for dynamically generating functions. Although this implementation could
+    # certainly be refactored in terms of that factory, doing so would
+    # needlessly reduce debuggability and portability for *NO* tangible gain.
+    func_body = _PROPERTY_CACHED_CODE.format(
+        property_var_name=property_var_name)
+
+    # Dictionary mapping from local attribute names to values. For efficiency,
+    # only attributes required by the body of this wrapper are copied from the
+    # current namespace. (See below.)
+    local_attrs = {'__property_method': func}
+
+    # Dynamically define this wrapper as a closure of this decorator. For
+    # obscure and presumably uninteresting reasons, Python fails to locally
+    # declare this closure when the locals() dictionary is passed; to capture
+    # this closure, a local dictionary must be passed instead.
+    exec(func_body, globals(), local_attrs)
+
+    # Return this wrapper method.
+    return local_attrs['property_method_cached']
+
+# ....................{ PRIVATE ~ constants : var          }....................
+_CALLABLE_CACHED_VAR_NAME_PREFIX = '__beartype_cached__'
+'''
+Substring prefixing the names of all private instance variables to which all
+caching decorators (e.g., :func:`property_cached`) cache values returned by
+decorated callables.
+
+This prefix:
+
+* Guarantees uniqueness across *all* instances -- including those instantiated
+  from official Python and unofficial third-party classes and those internally
+  defined by this application. Doing so permits logic elsewhere (e.g., pickling
+  filtering) to uniquely match and act upon these variables.
+* Is intentionally prefixed by double rather than single underscores (i.e.,
+  ``"__"`` rather than ``"_"``), ensuring that our
+  :meth:`beartype._check.forward.reference.fwdrefmeta.BeartypeForwardRefMeta.__getattr__`
+  dunder method ignores the private instance variables cached by our cached
+  :meth:`beartype._check.forward.reference.fwdrefmeta.BeartypeForwardRefMeta.__type_beartype__`
+  property.
+'''
+
+
+_FUNCTION_CACHED_VAR_NAME = (
+    f'{_CALLABLE_CACHED_VAR_NAME_PREFIX}function_value')
+'''
+Name of the private instance variable to which the :func:`func_cached`
+decorator statically caches the value returned by the decorated function.
+'''
+
+
+_PROPERTY_CACHED_VAR_NAME_PREFIX = (
+    f'{_CALLABLE_CACHED_VAR_NAME_PREFIX}property_')
+'''
+Substring prefixing the names of all private instance variables to which the
+:func:`property_cached` decorator dynamically caches the value returned by the
+decorated property method.
+'''
+
+# ....................{ PRIVATE ~ constants : code         }....................
+_PROPERTY_CACHED_CODE = '''
+@wraps(__property_method)
+def property_method_cached(self, __property_method=__property_method):
+    try:
+        return self.{property_var_name}
+    except AttributeError:
+        self.{property_var_name} = __property_method(self)
+        return self.{property_var_name}
+'''
+'''
+Raw string of Python statements comprising the body of the wrapper function
+dynamically generated by the :func:`property_cached` decorator.
+
+These statements include (in order):
+
+* A :mod:`functools.wraps` decoration propagating the name, docstring, and other
+  identifying metadata of the original function to this wrapper.
+* A private ``__property_method`` parameter set to the underlying property
+  getter method. In theory, the ``func`` parameter passed to the
+  :func:`property_cached` decorator should be accessible as a closure-style
+  local in this code. For unknown reasons (presumably, a subtle bug in the
+  :func:`exec` builtin), this is not the case. Instead, a closure-style local
+  must be simulated by passing the ``func`` parameter to this function at
+  function definition time as the default value of an arbitrary parameter.
+
+Design
+------
+While there exist numerous alternative implementations for caching properties,
+the approach implemented below has been profiled to be the most efficient.
+Alternatives include (in order of decreasing efficiency):
+
+* Dynamically getting and setting a property-specific key-value pair of the
+  internal dictionary for the current object, timed to be approximately 1.5
+  times as slow as exception handling: e.g.,
+
+.. code-block:: python
+   if not {property_name!r} in self.__dict__:
+       self.__dict__[{property_name!r}] = __property_method(self)
+   return self.__dict__[{property_name!r}]
+
+* Dynamically getting and setting a property-specific attribute of the current
+  object (e.g., the internal dictionary for the current object), timed to be
+  approximately 1.5 times as slow as exception handling: e.g.,
+
+.. code-block:: python
+   if not hasattr(self, {property_name!r}):
+       setattr(self, {property_name!r}, __property_method(self))
+   return getattr(self, {property_name!r})
+'''
+
+
+#FIXME: Uncomment to debug memoization-specific issues. *sigh*
+# def callable_cached(func: _CallableT) -> _CallableT: return func
+# def property_cached(func: _CallableT) -> _CallableT: return func
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cache/utilcachemeta.py
@@ -0,0 +1,79 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **caching metaclasses** (i.e., classes performing general-purpose
+memoization of classes that declare the former to be their metaclasses).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Type
+from beartype._data.hint.datahinttyping import T
+from beartype._util.cache.utilcachecall import callable_cached
+
+# ....................{ METACLASSES                        }....................
+class BeartypeCachingMeta(type):
+    '''
+    **Caching metaclass** (i.e., metaclass caching immutable instances of
+    classes whose metaclasses are this metaclass, cached via the positional
+    arguments instantiating those classes).
+
+    This metaclass is superior to the usual approach of caching immutable
+    objects: overriding the ``__new__`` method to conditionally create a new
+    instance of that class only if an instance has *not* already been created
+    with the passed positional arguments. Why? Because that approach unavoidably
+    re-calls the ``__init__`` method of a previously initialized instance on
+    each instantiation of that class -- which is clearly harmful, especially
+    where immutability is concerned.
+
+    This metaclass instead guarantees that the ``__init__`` method of an
+    instance is only called once on the first instantiation of that instance.
+
+    Caveats
+    ----------
+    **This metaclass assumes immutability.** Ideally, instances of classes whose
+    metaclasses are this metaclass should be **immutable** (i.e., frozen). Where
+    this is *not* the case, the behaviour of this metaclass is undefined.
+
+    **This metaclass prohibits keyword arguments.** ``__init__`` methods of
+    classes whose metaclass is this metaclass must accept *only* positional
+    arguments. Why? Efficiency, the entire point of caching. While feasible,
+    permitting ``__init__`` methods to also accept keyword arguments would be
+    sufficiently slow as to entirely defeat the point of caching. That's bad.
+
+    See Also
+    ----------
+    https://stackoverflow.com/a/8665179/2809027
+        StackOverflow answers strongly inspiring this implementation.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    @callable_cached
+    def __call__(cls: Type[T], *args) -> T:  # type: ignore[reportIncompatibleMethodOverride]
+        '''
+        Instantiate the passed class with the passed positional arguments if
+        this is the first instantiation of this class passed these arguments
+        *or* simply return the previously instantiated instance of this class
+        otherwise (i.e., if this is a subsequent instantiation of this class
+        re-passed these same arguments).
+
+        Caveats
+        ----------
+        This method intentionally accepts *only* positional arguments. See the
+        metaclass docstring for further details.
+
+        Parameters
+        ----------
+        cls : type
+            Class whose class is this metaclass.
+
+        All remaining parameters are passed as is to the superclass
+        :meth:`type.__call__` method.
+        '''
+
+        # Bear witness to the terrifying power of @callable_cached.
+        return super().__call__(*args)  # type: ignore[misc]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cls/pep/utilpep3119.py
@@ -0,0 +1,754 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`3119`-compliant **class detectors** (i.e., callables
+validating and testing various properties of arbitrary classes standardized by
+:pep:`3119`).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep3119Exception
+from beartype.typing import Callable
+from beartype._data.hint.datahinttyping import (
+    TypeException,
+    TypeOrTupleTypes,
+)
+
+# ....................{ RAISERS ~ instance                 }....................
+def die_unless_object_isinstanceable(
+    # Mandatory parameters.
+    obj: TypeOrTupleTypes,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep3119Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is
+    **isinstanceable** (i.e., valid as the second parameter to the
+    :func:`isinstance` builtin).
+
+    Specifically, this function raises an exception unless this object is
+    either:
+
+    * An **isinstanceable class** (i.e., class whose metaclass does *not* define
+      an ``__instancecheck__()`` dunder method that raises a :exc:`TypeError`
+      exception).
+    * Tuple of one or more isinstanceable classes.
+    * A :pep:`604`-compliant **new union** (i.e., objects created by expressions
+      of the form ``{type1} | {type2} | ... | {typeN}``) under Python >= 3.10.
+      By definition, *all* new unions are isinstanceable.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be validated.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`.BeartypeDecorHintPep3119Exception`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this object is neither:
+
+        * An isinstanceable class.
+        * A tuple containing only isinstanceable classes.
+        * A :pep:`604`-compliant new union.
+    '''
+
+    # Defer to this lower-level general-purpose raiser.
+    _die_if_object_uncheckable(
+        obj=obj,
+        obj_pith=None,
+        obj_raiser=die_unless_type_isinstanceable,
+        obj_tester=isinstance,  # type: ignore[arg-type]
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+
+def die_unless_type_isinstanceable(
+    # Mandatory parameters.
+    cls: type,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep3119Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is an
+    **isinstanceable class** (i.e., class whose metaclass does *not* define an
+    ``__instancecheck__()`` dunder method that raises a :exc:`TypeError`
+    exception).
+
+    Classes that are *not* isinstanceable include most PEP-compliant type
+    hints, notably:
+
+    * **Generic aliases** (i.e., subscriptable classes overriding the
+      ``__class_getitem__()`` class dunder method standardized by :pep:`560`
+      subscripted by an arbitrary object) under Python >= 3.9, whose
+      metaclasses define an ``__instancecheck__()`` dunder method to
+      unconditionally raise an exception. Generic aliases include:
+
+      * :pep:`484`-compliant **subscripted generics.**
+      * :pep:`585`-compliant type hints.
+
+    * User-defined classes whose metaclasses define an ``__instancecheck__()``
+      dunder method to unconditionally raise an exception, including:
+
+      * :pep:`544`-compliant protocols *not* decorated by the
+        :func:`typing.runtime_checkable` decorator.
+
+    Motivation
+    ----------
+    When a class whose metaclass defines an ``__instancecheck__()`` dunder
+    method is passed as the second parameter to the :func:`isinstance` builtin,
+    that builtin defers to that method rather than testing whether the first
+    parameter passed to that builtin is an instance of that class. If that
+    method raises an exception, that builtin raises the same exception,
+    preventing callers from deciding whether arbitrary objects are instances
+    of that class. For brevity, we refer to that class as "non-isinstanceable."
+
+    Most classes are isinstanceable, because deciding whether arbitrary objects
+    are instances of those classes is a core prerequisite for object-oriented
+    programming. Most classes that are also PEP-compliant type hints, however,
+    are *not* isinstanceable, because they're *never* intended to be
+    instantiated into objects (and typically prohibit instantiation in various
+    ways); they're only intended to be referenced as type hints annotating
+    callables, an arguably crude form of callable markup.
+
+    :mod:`beartype`-decorated callables typically check the types of arbitrary
+    objects at runtime by passing those objects and types as the first and
+    second parameters to the :func:`isinstance` builtin. If those types are
+    non-isinstanceable, those type-checks will typically raise
+    non-human-readable exceptions (e.g., ``"TypeError: isinstance() argument 2
+    cannot be a parameterized generic"`` for :pep:`585`-compliant type hints).
+    This is non-ideal both because those exceptions are non-human-readable *and*
+    because those exceptions are raised at call rather than decoration time,
+    where users expect the :func:`beartype.beartype` decorator to raise
+    exceptions for erroneous type hints.
+
+    Thus the existence of this function, which the :func:`beartype.beartype`
+    decorator calls to validate the usability of type hints that are classes
+    *before* checking objects against those classes at call time.
+
+    Caveats
+    -------
+    **This function considers all classes whose metaclasses define
+    ``__instancecheck__()`` dunder methods that raise exceptions other than**
+    :exc:`TypeError` **to be isinstanceable.** This function *only* considers
+    classes whose metaclasses define ``__instancecheck__()`` dunder methods that
+    raise :exc:`TypeError` exceptions to be non-isinstanceable; all other
+    classes are isinstanceable.
+
+    Ideally, this function would consider any class whose metaclass defines an
+    ``__instancecheck__()`` dunder method that raises any exception (rather than
+    merely a :exc:`TypeError` exception) to be non-isinstanceable.
+    Pragmatically, doing so would raise false positives in common edge cases --
+    and previously did so, in fact, which is why we no longer do so.
+
+    In particular, the metaclass of the passed class may *not* necessarily be
+    fully initialized at the early time that this function is called (typically,
+    at :func:`beartype.beartype` decoration time). If this is the case, then
+    eagerly passing that class to :func:`isinstance` is likely to raise an
+    exception. For example, doing so raises an :exc:`AttributeError` when the
+    ``__instancecheck__()`` dunder method defined by that metaclass references
+    an external attribute that has yet to be defined:
+
+    .. code-block:: python
+
+       from beartype import beartype
+
+       class MetaFoo(type):
+           def __instancecheck__(cls, other):
+               return g()
+
+       class Foo(metaclass=MetaFoo):
+           pass
+
+       # @beartype transitively calls this function to validate that "Foo" is
+       # isinstanceable. However, since g() has yet to be defined at this time,
+       # doing so raises an "AttributeError" exception despite this logic
+       # otherwise being sound.
+       @beartype
+       def f(x: Foo):
+           pass
+
+       def g():
+           return True
+
+    This function thus constrains itself to merely the :exc:`TypeError`
+    exception, which all non-isinstanceable classes defined by the standard
+    :mod:`typing` module unconditionally raise. This suggests that there is
+    currently an unambiguous one-to-one mapping between non-isinstanceable
+    classes and classes whose metaclass ``__instancecheck__()`` dunder methods
+    raise :exc:`TypeError` exceptions. May this mapping hold true forever!
+
+    Parameters
+    ----------
+    cls : object
+        Object to be validated.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`.BeartypeDecorHintPep3119Exception`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this object is *not* an isinstanceable class.
+
+    See Also
+    --------
+    :func:`.die_unless_type_isinstanceable`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.cls.utilclstest import die_unless_type
+
+    # If this object is *NOT* a class, raise an exception.
+    die_unless_type(
+        cls=cls,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this object is a class.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the is_type_isinstanceable() tester.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Attempt to pass this class as the second parameter to isinstance().
+    try:
+        isinstance(None, cls)  # type: ignore[arg-type]
+    # If doing so raised a "TypeError" exception, this class is *NOT*
+    # isinstanceable. In this case, raise a human-readable exception.
+    #
+    # See the docstring for further discussion.
+    except TypeError as exception:
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not exception class.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        #FIXME: Uncomment after we uncover why doing so triggers an
+        #infinite circular exception chain when "hint" is a "GenericAlias".
+        #It's clearly the is_hint_pep544_protocol() call, but why? In any
+        #case, the simplest workaround would just be to inline the logic of
+        #is_hint_pep544_protocol() here directly. Yes, we know. *shrug*
+
+        # # Human-readable exception message to be raised as either...
+        # exception_message = (
+        #     # If this class is a PEP 544-compliant protocol, a message
+        #     # documenting this exact issue and how to resolve it;
+        #     (
+        #         f'{exception_prefix}PEP 544 protocol {hint} '
+        #         f'uncheckable at runtime (i.e., '
+        #         f'not decorated by @typing.runtime_checkable).'
+        #     )
+        #     if is_hint_pep544_protocol(hint) else
+        #     # Else, a fallback message documenting this general issue.
+        #     (
+        #         f'{exception_prefix}type {hint} uncheckable at runtime (i.e., '
+        #         f'not passable as second parameter to isinstance() '
+        #         f'due to raising "{exception}" from metaclass '
+        #         f'__instancecheck__() method).'
+        #     )
+        # )
+
+        # Exception message to be raised.
+        exception_message = (
+            f'{exception_prefix}{repr(cls)} uncheckable at runtime '
+            f'(i.e., not passable as second parameter to isinstance(), '
+            f'due to raising "{exception.__class__.__name__}: {exception}" '
+            f'from metaclass __instancecheck__() method).'
+        )
+
+        # Raise this exception chained onto this lower-level exception.
+        raise exception_cls(exception_message) from exception
+    # If doing so raised any exception *OTHER* than a "TypeError" exception,
+    # this class may or may not be isinstanceable. Since we have no means of
+    # differentiating the two, we err on the side of caution. Avoid returning a
+    # false negative by quietly ignoring this exception.
+    except Exception:
+        pass
+
+# ....................{ RAISERS ~ subclass                 }....................
+def die_unless_object_issubclassable(
+    # Mandatory parameters.
+    obj: TypeOrTupleTypes,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep3119Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is
+    **issubclassable** (i.e., valid as the second parameter to the
+    :func:`issubclass` builtin).
+
+    Specifically, this function raises an exception unless this object is
+    either:
+
+    * An **issubclassable class** (i.e., class whose metaclass does *not* define
+      an ``__subclasscheck__()`` dunder method that raises a :exc:`TypeError`
+      exception).
+    * Tuple of one or more issubclassable classes.
+    * A :pep:`604`-compliant **new union** (i.e., objects created by expressions
+      of the form ``{type1} | {type2} | ... | {typeN}``) under Python >= 3.10.
+      By definition, *all* new unions are issubclassable.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be validated.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`.BeartypeDecorHintPep3119Exception`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this object is neither:
+
+        * An issubclassable class.
+        * A tuple containing only issubclassable classes.
+        * A :pep:`604`-compliant new union.
+    '''
+
+    # Defer to this lower-level general-purpose raiser.
+    _die_if_object_uncheckable(
+        obj=obj,
+        obj_pith=type,
+        obj_raiser=die_unless_type_issubclassable,
+        obj_tester=issubclass,  # type: ignore[arg-type]
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+
+def die_unless_type_issubclassable(
+    # Mandatory parameters.
+    cls: type,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep3119Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is an
+    **issubclassable class** (i.e., class whose metaclass does *not* define a
+    ``__subclasscheck__()`` dunder method that raise a :exc:`TypeError`
+    exception).
+
+    Classes that are *not* issubclassable include most PEP-compliant type
+    hints, notably:
+
+    * **Generic aliases** (i.e., subscriptable classes overriding the
+      ``__class_getitem__()`` class dunder method standardized by :pep:`560`
+      subscripted by an arbitrary object) under Python >= 3.9, whose
+      metaclasses define an ``__subclasscheck__()`` dunder method to
+      unconditionally raise an exception. Generic aliases include:
+
+      * :pep:`484`-compliant **subscripted generics.**
+      * :pep:`585`-compliant type hints.
+
+    * User-defined classes whose metaclasses define a ``__subclasscheck__()``
+      dunder method to unconditionally raise an exception, including:
+
+      * :pep:`544`-compliant protocols *not* decorated by the
+        :func:`typing.runtime_checkable` decorator.
+
+    Motivation
+    ----------
+    See also the "Motivation" and "Caveats" sections of the
+    :func:`die_unless_type_isinstanceable` docstring for further discussion,
+    substituting:
+
+    * ``__instancecheck__()`` for ``__subclasscheck__()``.
+    * :func:`isinstance` for :func:`issubclass`.
+
+    Parameters
+    ----------
+    cls : object
+        Object to be validated.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep3119Exception`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this object is *not* an issubclassable class.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.cls.utilclstest import die_unless_type
+
+    # If this hint is *NOT* a class, raise an exception.
+    die_unless_type(
+        cls=cls,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this hint is a class.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the is_type_issubclassable() tester.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Attempt to pass this class as the second parameter to issubclass().
+    try:
+        issubclass(type, cls)  # type: ignore[arg-type]
+    # If doing so raised a "TypeError" exception, this class is *NOT*
+    # issubclassable. In this case, raise a human-readable exception.
+    #
+    # See the die_unless_type_isinstanceable() docstring for details.
+    except TypeError as exception:
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not exception class.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Exception message to be raised.
+        exception_message = (
+            f'{exception_prefix}{repr(cls)} uncheckable at runtime '
+            f'(i.e., not passable as second parameter to issubclass(), '
+            f'due to raising "{exception.__class__.__name__}: {exception}" '
+            f'from metaclass __subclasscheck__() method).'
+        )
+
+        # Raise this exception chained onto this lower-level exception.
+        raise exception_cls(exception_message) from exception
+    # If doing so raised any exception *OTHER* than a "TypeError" exception,
+    # this class may or may not be issubclassable. Since we have no means of
+    # differentiating the two, we err on the side of caution. Avoid returning a
+    # false negative by quietly ignoring this exception.
+    except Exception:
+        pass
+
+# ....................{ TESTERS                            }....................
+def is_type_isinstanceable(cls: object) -> bool:
+    '''
+    :data:`True` only if the passed object is an **isinstanceable class** (i.e.,
+    class whose metaclass does *not* define an ``__instancecheck__()`` dunder
+    method that raises a :exc:`TypeError` exception).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). Although the implementation does *not*
+    trivially reduce to an efficient one-liner, the inefficient branch of this
+    implementation *only* applies to erroneous edge cases resulting in raised
+    exceptions and is thus largely ignorable.
+
+    Caveats
+    -------
+    **This tester may return false positives in unlikely edge cases.**
+    Internally, this tester tests whether this class is isinstanceable by
+    detecting whether passing the :data:`None` singleton and this class to the
+    :func:`isinstance` builtin raises a :exc:`TypeError` exception. If that call
+    raises *no* exception, this class is probably but *not* necessarily
+    isinstanceable. Since the metaclass of this class could define an
+    ``__instancecheck__()`` dunder method to conditionally raise exceptions
+    *except* when passed the :data:`None` singleton, there exists *no* perfect
+    means of deciding whether an arbitrary class is fully isinstanceable in the
+    general sense. Since most classes that are *not* isinstanceable are
+    unconditionally isinstanceable (i.e., the metaclasses of those classes
+    define an ``__instancecheck__()`` dunder method to unconditionally raise
+    exceptions), this distinction is generally meaningless in the real world.
+    This test thus generally suffices.
+
+    Parameters
+    ----------
+    cls : object
+        Object to be tested.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an isinstanceable class.
+
+    See Also
+    --------
+    :func:`.die_unless_type_isinstanceable`
+        Further details.
+    '''
+
+    # If this object is *NOT* a class, immediately return false.
+    if not isinstance(cls, type):
+        return False
+    # Else, this object is a class.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with die_unless_type_isinstanceable().
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Attempt to pass this class as the second parameter to the isinstance()
+    # builtin to decide whether or not this class is safely usable as a
+    # standard class or not.
+    #
+    # Note that this leverages an EAFP (i.e., "It is easier to ask forgiveness
+    # than permission") approach and thus imposes a minor performance penalty,
+    # but that there exists *NO* faster alternative applicable to arbitrary
+    # user-defined classes, whose metaclasses may define an __instancecheck__()
+    # dunder method to raise exceptions and thus prohibit being passed as the
+    # second parameter to the isinstance() builtin, the primary means employed
+    # by @beartype wrapper functions to check arbitrary types.
+    try:
+        isinstance(None, cls)  # type: ignore[arg-type]
+
+        # If the prior function call raised *NO* exception, this class is
+        # probably but *NOT* necessarily isinstanceable. Return true.
+    # If the prior function call raised a "TypeError" exception, this class is
+    # *NOT* isinstanceable. In this case, return false.
+    except TypeError:
+        return False
+    # If the prior function call raised any exception *OTHER* than a "TypeError"
+    # exception, this class may or may not be isinstanceable. Since we have no
+    # means of differentiating the two, we err on the side of caution. Avoid
+    # returning a false negative by safely returning true.
+    except Exception:
+        return True
+
+    # Look. Just do it. *sigh*
+    return True
+
+
+def is_type_issubclassable(cls: object) -> bool:
+    '''
+    :data:`True` only if the passed object is either an **issubclassable class**
+    (i.e., class whose metaclass does *not* define a ``__subclasscheck__()``
+    dunder method that raises a :exc:`TypeError` exception) *or* tuple
+    containing only issubclassable classes.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). Although the implementation does *not*
+    trivially reduce to an efficient one-liner, the inefficient branch of this
+    implementation *only* applies to erroneous edge cases resulting in raised
+    exceptions and is thus largely ignorable.
+
+    Caveats
+    -------
+    See also the "Caveats" sections of the
+    :func:`.is_type_isinstanceable` docstring for further discussion,
+    substituting:
+
+    * ``__instancecheck__()`` for ``__subclasscheck__()``.
+    * :func:`isinstance` for :func:`issubclass`.
+
+    Parameters
+    ----------
+    cls : object
+        Object to be tested.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is either:
+
+        * An issubclassable class.
+        * A tuple containing only issubclassable classes.
+
+    See Also
+    --------
+    :func:`.die_unless_type_issubclassable`
+        Further details.
+    '''
+
+    # If this object is *NOT* a class, immediately return false.
+    if not isinstance(cls, type):
+        return False
+    # Else, this object is a class.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with die_unless_type_issubclassable().
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Attempt to pass this class as the second parameter to the issubclass()
+    # builtin to decide whether or not this class is safely usable as a
+    # standard class or not.
+    #
+    # Note that this leverages an EAFP (i.e., "It is easier to ask forgiveness
+    # than permission") approach and thus imposes a minor performance penalty,
+    # but that there exists *NO* faster alternative applicable to arbitrary
+    # user-defined classes, whose metaclasses may define a __subclasscheck__()
+    # dunder method to raise exceptions and thus prohibit being passed as the
+    # second parameter to the issubclass() builtin, the primary means employed
+    # by @beartype wrapper functions to check arbitrary types.
+    try:
+        issubclass(type, cls)  # type: ignore[arg-type]
+
+        # If the prior function call raised *NO* exception, this class is
+        # probably but *NOT* necessarily issubclassable. Return true.
+    # If the prior function call raised a "TypeError" exception, this class is
+    # *NOT* issubclassable. In this case, return false.
+    except TypeError:
+        return False
+    # If the prior function call raised any exception *OTHER* than a "TypeError"
+    # exception, this class may or may not be issubclassable. Since we have no
+    # means of differentiating the two, we err on the side of caution. Avoid
+    # returning a false negative by safely returning true.
+    except Exception:
+        pass
+
+    # Look. Just do it. *sigh*
+    return True
+
+# ....................{ PRIVATE ~ raisers                  }....................
+def _die_if_object_uncheckable(
+    obj: TypeOrTupleTypes,
+    obj_pith: object,
+    obj_raiser: Callable,
+    obj_tester: Callable[[object, TypeOrTupleTypes], bool],
+    exception_cls: TypeException,
+    exception_prefix: str,
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is
+    **runtime-checkable** (i.e., valid as the second parameter to either the
+    :func:`isinstance` or :func:`issubclass` builtins) according to the passed
+    object tester and raiser.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be validated.
+    obj_pith : object
+        Object guaranteed to satisfy the ``obj_tester`` callable when ``obj`` is
+        runtime-typecheckable (i.e., when ``obj_tester`` is called as
+        ``obj_tester(obj_pith, obj)``).
+    obj_raiser : Callable
+        Callable raising an exception unless this object is runtime-checkable
+        according to this predicate, which should be either:
+
+        * :func:`.die_unless_type_isinstanceable`.
+        * :func:`.die_unless_type_issubclassable`.
+    obj_tester : Callable[[object, TypeOrTupleTypes], bool]
+        Callable returning :data:`True` only if this object is runtime-checkable
+        according to this predicate, which should be either:
+
+        * :func:`isinstance`.
+        * :func:`issubclass`.
+    exception_cls : TypeException
+        Type of exception to be raised.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this object is *not* runtime-checkable according to the passed
+        object tester and raiser.
+    '''
+    assert callable(obj_raiser), f'{repr(obj_raiser)} uncallable.'
+    assert callable(obj_tester), f'{repr(obj_tester)} uncallable.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.cls.utilclstest import die_unless_type_or_types
+    from beartype._util.hint.pep.proposal.utilpep604 import is_hint_pep604
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+
+    # If this object is *NOT* a PEP 604-compliant new union...
+    if not is_hint_pep604(obj):
+        # If this object is neither a class nor tuple of classes, raise an
+        # exception.
+        die_unless_type_or_types(
+            type_or_types=obj,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+        # Else, this object is either a class or tuple of classes.
+    # Else, this object is a PEP 604-compliant new union. In either case, this
+    # object now *COULD* be runtime-checkable. To decide whether this object is
+    # actually instanceable, further introspection is needed.
+
+    # If this object is a class...
+    if isinstance(obj, type):
+        # If this class is *NOT* runtime-checkable, raise an exception.
+        obj_raiser(
+            cls=obj,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+        # Else, this class is runtime-checkable.
+    # Else, this object *MUST* (by process of elimination and validation
+    # above) be either a tuple of classes *OR* new union. In either case...
+    else:
+        # Attempt to pass this object as the second parameter to isinstance().
+        try:
+            obj_tester(obj_pith, obj)  # type: ignore[arg-type]
+        # If doing so raises a "TypeError" exception, this object is *NOT*
+        # runtime-checkable. In this case, raise a human-readable exception.
+        #
+        # See the die_unless_type_runtime-checkable() docstring for details.
+        except TypeError as exception:
+            assert isinstance(exception_cls, type), (
+                f'{repr(exception_cls)} not exception class.')
+            assert isinstance(exception_prefix, str), (
+                f'{repr(exception_prefix)} not string.')
+
+            # Tuple of all items of this iterable object.
+            obj_items: tuple = None  # type: ignore[assignment]
+
+            # Human-readable label describing this object in this exception
+            # message.
+            obj_label: str = None  # type: ignore[assignment]
+
+            # Human-readable label describing the first non-runtime-checkable
+            # item of this object in this exception message.
+            obj_item_label: str = None  # type: ignore[assignment]
+
+            # If this object is a tuple, define these locals accordingly.
+            if isinstance(obj, tuple):
+                obj_items = obj
+                obj_label = 'tuple union'
+                obj_item_label = 'tuple union item'
+            # Else, this object is a new union. Define these locals accordingly.
+            else:
+                obj_items = get_hint_pep_args(obj)
+                obj_label = 'PEP 604 new union'
+                obj_item_label = 'new union child type'
+
+            # Exception message to be raised.
+            exception_message = (
+                f'{exception_prefix} {obj_label} {repr(obj)} '
+                f'uncheckable at runtime'
+            )
+
+            # For the 0-based index of each tuple class and that class...
+            for cls_index, cls in enumerate(obj_items):
+                # If this class is *NOT* runtime-checkable, raise an exception.
+                obj_raiser(
+                    cls=cls,
+                    exception_cls=exception_cls,
+                    exception_prefix=(
+                        f'{exception_message}, as '
+                        f'{obj_item_label} {cls_index} '
+                    ),
+                )
+                # Else, this class is runtime-checkable. Continue to the next.
+
+            # Raise this exception chained onto this lower-level exception.
+            # Although this should *NEVER* happen (as we should have already
+            # raised an exception above), we nonetheless do so for safety.
+            raise exception_cls(f'{exception_message}.') from exception
+        # If doing so raised any exception *OTHER* than a "TypeError" exception,
+        # this class may or may not be runtime-checkable. Since we have no means
+        # of differentiating the two, we err on the side of caution. Avoid
+        # returning a false negative by quietly ignoring this exception.
+        except Exception:
+            pass
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cls/pep/utilpep557.py
@@ -0,0 +1,57 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`557`-compliant **testers** (i.e., low-level callables testing
+various properties of dataclasses standardized by :pep:`557`).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from dataclasses import is_dataclass
+
+# ....................{ TESTERS                           }....................
+def is_type_pep557(cls: type) -> bool:
+    '''
+    :data:`True` only if the passed class is a **dataclass** (i.e.,
+    :pep:`557`-compliant class decorated by the standard
+    :func:`dataclasses.dataclass` decorator).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    cls : type
+        Class to be inspected.
+
+    Returns
+    ----------
+    bool
+        :data:`True` only if this class is a dataclass.
+
+    Raises
+    ----------
+    _BeartypeUtilTypeException
+        If this object is *not* a class.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.cls.utilclstest import die_unless_type
+
+    # If this object is *NOT* a type, raise an exception.
+    die_unless_type(cls)
+    # Else, this object is a type.
+
+    # Return true only if this type is a dataclass.
+    #
+    # Note that the is_dataclass() tester was intentionally implemented
+    # ambiguously to return true for both actual dataclasses *AND*
+    # instances of dataclasses. Since the prior validation omits the
+    # latter, this call unambiguously returns true *ONLY* if this object is
+    # an actual dataclass. (Dodged a misfired bullet there, folks.)
+    return is_dataclass(cls)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cls/utilclsget.py
@@ -0,0 +1,169 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **class getters** (i.e., low-level callables obtaining various
+properties of arbitrary classes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilTypeException
+from beartype.typing import (
+    Optional,
+)
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    TypeException,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up.
+def get_type_filename_or_none(cls: type) -> Optional[str]:
+    '''
+    Absolute filename of the file on the local filesystem containing the
+    pure-Python source code for the script or module defining the passed class
+    if that class is defined on-disk *or* :data:`None` otherwise (i.e., if that
+    class is dynamically defined in-memory by a prior call to the :func:`exec`
+    or :func:`eval` builtins).
+
+    Parameters
+    ----------
+    cls : type
+        Class to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If this class was physically declared by a file, the absolute filename
+          of that file.
+        * If this class was dynamically declared in-memory, :data:`None`.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodget import (
+        get_module_filename_or_none,
+        get_object_module_name_or_none,
+    )
+    from beartype._util.module.utilmodget import get_module_imported_or_none
+
+    # Fully-qualified name of the module declaring this type if any *OR* "None".
+    #
+    # Note that *ALL* types should be declared by *SOME* modules. Nonetheless,
+    # this is Python. It's best to assume the worst.
+    type_module_name = get_object_module_name_or_none(cls)
+
+    # If a module declares this type...
+    if type_module_name:
+        # This module if previously imported *OR* "None".
+        #
+        # Note that this module *SHOULD* necessarily already have been imported,
+        # as this type obviously exists. Nonetheless, this module will be
+        # unimportable for types dynamically declared in-memory rather than
+        # on-disk, in which case the name of this module will have been a lie.
+        type_module = get_module_imported_or_none(type_module_name)
+
+        # If this module was previously imported...
+        if type_module:
+            # Return the filename defining this module if any *OR* "None".
+            return get_module_filename_or_none(type_module)
+    # Else, *NO* modules defines this type.
+
+    # If all else fails, this type was probably declared in-memory rather than
+    # on-disk. In this case, fallback to merely returning "None". 
+    return None
+
+
+#FIXME: Unit test us up, please.
+def get_type_locals(
+    # Mandatory parameters.
+    cls: type,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilTypeException,
+) -> LexicalScope:
+    '''
+    **Local scope** (i.e., dictionary mapping from the name to value of each
+    attribute directly declared by that class) for the passed class.
+
+    Caveats
+    -------
+    **This getter returns an immutable rather than mutable mapping.** Callers
+    requiring the latter are encouraged to manually coerce the immutable mapping
+    returned by this getter into a mutable mapping (e.g., by passing the former
+    to the :class:`dict` constructor as is).
+
+    Design
+    ------
+    This getter currently reduces to a trivial one-liner returning
+    ``cls.__dict__`` and has thus been defined mostly just for orthogonality
+    with the comparable
+    :func:`beartype._util.func.utilfuncscope.get_func_locals` getter. That said,
+    :pep:`563` suggests this non-trivial heuristic for computing the local scope
+    of a given class:
+
+        For classes, localns can be composed by chaining vars of the given class
+        and its base classes (in the method resolution order). Since slots can
+        only be filled after the class was defined, we don’t need to consult
+        them for this purpose.
+
+    We fail to grok that suggestion, because we lack a galactic brain. A
+    minimal-length example (MLE) refutes all of the above by demonstrating that
+    superclass attributes are *not* local to subclasses:
+
+    .. code-block:: python
+
+       >>> class Superclass(object):
+       ...     my_int = int
+       >>> class Subclass(Superclass):
+       ...     def get_str(self) -> my_int:
+       ...         return 'Oh, Gods.'
+       NameError: name 'my_int' is not defined
+
+    We are almost certainly confused about what :pep:`563` is talking about, but
+    we are almost certain that :pep:`536` is also confused about what :pep:`563`
+    is talking about. That said, the standard :func:`typing.get_type_hints`
+    getter implements that suggestion with iteration over the method-resolution
+    order (MRO) of the passed class resembling:
+
+    .. code-block:: python
+
+       for base in reversed(obj.__mro__):
+           ...
+           base_locals = dict(vars(base)) if localns is None else localns
+
+    The standard :func:`typing.get_type_hints` getter appears to recursively
+    retrieve all type hints annotating both the passed class and all
+    superclasses of that class. Why? We have no idea, frankly. We're unconvinced
+    that is useful in practice. We prefer a trivial one-liner, which behaves
+    exactly as advertised and efficiently at decoration-time.
+
+    Parameters
+    ----------
+    cls : type
+        Class to be inspected.
+    exception_cls : Type[Exception]
+        Type of exception to be raised. Defaults to
+        :exc:`_BeartypeUtilTypeException`.
+
+    Returns
+    -------
+    LexicalScope
+        Local scope for this class.
+
+    Raises
+    ------
+    exception_cls
+        If the next non-ignored frame following the last ignored frame is *not*
+        the parent callable or module directly declaring the passed callable.
+    '''
+    assert isinstance(cls, type), f'{repr(cls)} not type.'
+
+    # Return the dictionary of class attributes bundled with this class.
+    return cls.__dict__  # type: ignore[return-value]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cls/utilclsmake.py
@@ -0,0 +1,135 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable factories** (i.e., low-level functions dynamically
+creating and returning new in-memory callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilTypeException
+from beartype.typing import Optional
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    TupleTypes,
+    TypeException,
+)
+from beartype._data.kind.datakinddict import DICT_EMPTY
+from beartype._util.text.utiltextidentifier import die_unless_identifier
+
+# ....................{ MAKERS                             }....................
+def make_type(
+    # Mandatory arguments.
+    type_name: str,
+
+    # Optional arguments.
+    type_module_name: Optional[str] = None,
+    type_bases: Optional[TupleTypes] = None,
+    type_scope: Optional[LexicalScope] = None,
+    type_doc: Optional[str] = None,
+    exception_cls: TypeException = _BeartypeUtilTypeException,
+    exception_prefix: str = '',
+) -> type:
+    '''
+    Dynamically create and return a new class with the passed name subclassing
+    all passed base classes and defined by the passed class scope.
+
+    Parameters
+    ----------
+    type_name : str
+        Name of the class to be created.
+    type_module_name : Optional[str]
+        Fully-qualified name of the module declaring this class. Defaults to
+        :data:`None`, in which case this class remains undeclared by any module.
+    type_bases : Optional[Tuple[type, ...]]
+        Tuple of all base classes to be inherited by this class. Defaults to
+        the empty tuple, equivalent to the 1-tuple ``(object,)`` inheriting this
+        class from only the root base class :class:`object` of all classes.
+    type_scope : Optional[Dict[str, Any]]
+        Dictionary mapping from the name to value of each **class-scoped
+        attribute** (i.e., method, variable) to be defined by this class.
+        Defaults to the empty dictionary, equivalent to declaring a class with
+        the trivial body ``pass``.
+    type_doc : Optional[str]
+        Human-readable docstring documenting this class. Defaults to
+        :data:`None`, in which case this class remains undocumented.
+    exception_cls : Type[Exception], optional
+        Type of exception to raise in the event of a fatal error. Defaults to
+        :exc:`._BeartypeUtilTypeException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    type
+        Class with this name subclassing these base classes and defined by this
+        class scope.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * The passed classname is empty.
+        * The passed classname is non-empty but *not* a valid unqualified Python
+          identifier.
+    '''
+    assert isinstance(type_name, str), f'{repr(type_name)} not string.'
+    assert isinstance(type_module_name, NoneTypeOr[str]), (
+        f'{repr(type_module_name)} neither string nor "None".')
+    assert isinstance(type_doc, NoneTypeOr[str]), (
+        f'{repr(type_doc)} neither string nor "None".')
+
+    # If this classname is *NOT* a valid unqualified Python identifier, raise an
+    # exception. Insanely, the builtin type.__init__() constructor silently
+    # allows this classname to be invalid -- despite the resulting class
+    # violating sanity and normative standards. Note that invalid names include:
+    # * The empty string.
+    # * An invalid Python identifier.
+    # * A valid fully-qualified Python identifier.
+    if not type_name.isidentifier():
+        raise exception_cls(
+            f'{exception_prefix}class name {repr(type_name)} invalid.')
+    # Else, this classname is a valid unqualified Python identifier.
+
+    # Default all unpassed parameters.
+    if type_bases is None:
+        type_bases = ()  # type: ignore[assignment]
+    if type_scope is None:
+        type_scope = DICT_EMPTY  # type: ignore[assignment]
+    assert isinstance(type_bases, tuple), (
+        f'{repr(type_bases)} neither tuple nor "None".')
+    assert isinstance(type_scope, dict), (
+        f'{repr(type_scope)} neither dictionary nor "None".')
+
+    # Thank you, bizarre 3-parameter variant of the type.__init__() constructor.
+    cls = type(type_name, type_bases, type_scope)
+
+    # If this class has a module name...
+    if type_module_name is not None:
+        # If this module name is *NOT* a valid Python identifier, raise an
+        # exception.
+        die_unless_identifier(
+            text=type_module_name,
+            exception_cls=exception_cls,
+            exception_prefix='Class module name ',
+        )
+        # Else, this module name is a valid Python identifier.
+
+        # Set the module name of this class.
+        cls.__module__ = type_module_name
+    # Else, this class has *NO* module name.
+
+    # If documenting this class, do so.
+    if type_doc is not None:
+        cls.__doc__ = type_doc
+    # Else, this class is undocumented.
+
+    # Return this class.
+    return cls
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cls/utilclsset.py
@@ -0,0 +1,88 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **class setters** (i.e., low-level callables modifying various
+properties of arbitrary classes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_10
+
+# ....................{ SETTERS                            }....................
+#FIXME: Unit test us up.
+def set_type_attr(cls: type, attr_name: str, attr_value: object) -> None:
+    '''
+    Dynamically set the **class variable** (i.e., attribute of the passed class)
+    with the passed name to the passed value.
+
+    Parameters
+    ----------
+    cls : type
+        Class to set this attribute on.
+    attr_name : str
+        Name of the class attribute to be set.
+    attr_value : object
+        Value to set this class attribute to.
+
+    Caveats
+    -------
+    **This function is unavoidably slow.** Class attributes are *only* settable
+    by calling the tragically slow :func:`setattr` builtin. Attempting to
+    directly set an attribute on the class dictionary raises an exception. Why?
+    Because class dictionaries are actually low-level :class:`mappingproxy`
+    objects that intentionally override the ``__setattr__()`` dunder method to
+    unconditionally raise an exception. Why? Because that constraint enables the
+    :meth:`type.__setattr__` dunder method to enforce critical efficiency
+    constraints on class attributes -- including that class attribute keys are
+    *not* only strings but also valid Python identifiers:
+
+    .. code-block:: pycon
+
+       >>> class OhGodHelpUs(object): pass
+       >>> OhGodHelpUs.__dict__['even_god_cannot_help'] = 2
+       TypeError: 'mappingproxy' object does not support item
+       assignment
+
+    See also this `relevant StackOverflow answer by Python luminary
+    Raymond Hettinger <answer_>`__.
+
+    .. _answer:
+       https://stackoverflow.com/a/32720603/2809027
+    '''
+
+    # Attempt to set the class attribute with this name to this value.
+    try:
+        setattr(cls, attr_name, attr_value)
+    # If doing so raises a builtin "TypeError"...
+    except TypeError as exception:
+        # Message raised with this "TypeError".
+        exception_message = str(exception)
+
+        # If this message satisfies a well-known pattern unique to the current
+        # Python version, then this exception signifies this attribute to be
+        # inherited from an immutable builtin type (e.g., "str") subclassed by
+        # this user-defined subclass. In this case, silently skip past this
+        # uncheckable attribute to the next.
+        if (
+            # The active Python interpreter targets Python >= 3.10, match a
+            # message of the form "cannot set '{attr_name}' attribute of
+            # immutable type '{cls_name}'".
+            IS_PYTHON_AT_LEAST_3_10 and (
+                exception_message.startswith("cannot set '") and
+                "' attribute of immutable type " in exception_message
+            # Else, the active Python interpreter targets Python <= 3.9. In this
+            # case, match a message of the form "can't set attributes of
+            # built-in/extension type '{cls_name}'".
+            ) or exception_message.startswith(
+                "can't set attributes of built-in/extension type '")
+        ):
+            return
+        # Else, this message does *NOT* satisfy that pattern.
+
+        # Preserve this exception by re-raising this exception.
+        raise
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/cls/utilclstest.py
@@ -0,0 +1,378 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **class testers** (i.e., low-level callables testing and validating
+various properties of arbitrary classes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilTypeException
+from beartype._cave._cavefast import TestableTypes as TestableTypesTuple
+from beartype._data.cls.datacls import TYPES_BUILTIN
+from beartype._data.hint.datahinttyping import (
+    TypeException,
+    TypeOrTupleTypes,
+)
+from beartype._data.module.datamodpy import BUILTINS_MODULE_NAME
+
+# ....................{ RAISERS                            }....................
+def die_unless_type(
+    # Mandatory parameters.
+    cls: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilTypeException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is a class.
+
+    Parameters
+    ----------
+    cls : object
+        Object to be validated.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilTypeException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is *not* a class.
+    '''
+
+    # If this object is *NOT* a class, raise an exception.
+    if not isinstance(cls, type):
+        assert isinstance(exception_cls, type), (
+            'f{repr(exception_cls)} not exception class.')
+        assert isinstance(exception_prefix, str), (
+            'f{repr(exception_prefix)} not string.')
+
+        raise exception_cls(f'{exception_prefix}{repr(cls)} not class.')
+    # Else, this object is a class.
+
+
+#FIXME: Unit test us up.
+def die_unless_type_or_types(
+    # Mandatory parameters.
+    type_or_types: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilTypeException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is either a
+    class *or* tuple of one or more classes.
+
+    Parameters
+    ----------
+    type_or_types : object
+        Object to be validated.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilTypeException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is neither a class *nor* tuple of one or more classes.
+    '''
+
+    # If this object is neither a class *NOR* tuple of one or more classes,
+    # raise an exception.
+    if not is_type_or_types(type_or_types):
+        assert isinstance(exception_cls, type), (
+            'f{repr(exception_cls)} not exception class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Exception message to be raised below.
+        exception_message = (
+            f'{exception_prefix}{repr(type_or_types)} neither '
+            f'class nor tuple of one or more classes'
+        )
+
+        # If this object is a tuple...
+        if isinstance(type_or_types, tuple):
+            # If this tuple is empty, note that.
+            if not type_or_types:
+                exception_message += ' (i.e., is empty tuple)'
+            # Else, this tuple is non-empty. In this case...
+            else:
+                # For the 0-based index of each tuple item and that item...
+                for cls_index, cls in enumerate(type_or_types):
+                    # If this object is *NOT* a class...
+                    if not isinstance(cls, type):
+                        # Note this.
+                        exception_message += (
+                            f' (i.e., tuple item {cls_index} '
+                            f'{repr(cls)} not class)'
+                        )
+
+                        # Halt iteration.
+                        break
+                    # Else, this object is a class. Continue to the next item.
+        # Else, this object is a non-tuple. In this case, the general-purpose
+        # exception message suffices.
+
+        # Raise this exception.
+        raise exception_cls(f'{exception_message}.')
+    # Else, this object is either a class *OR* tuple of one or more classes.
+
+# ....................{ TESTERS                            }....................
+def is_type_or_types(type_or_types: object) -> bool:
+    '''
+    :data:`True` only if the passed object is either a class *or* tuple of one
+    or more classes.
+
+    Parameters
+    ----------
+    type_or_types : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is either a class *or* tuple of one or
+        more classes.
+    '''
+
+    # Return true only if either...
+    return (
+        # This object is a class *OR*...
+        isinstance(type_or_types, type) or
+        (
+            # This object is a tuple *AND*...
+            isinstance(type_or_types, tuple) and
+            # This tuple is non-empty *AND*...
+            bool(type_or_types) and
+            # This tuple contains only classes.
+            all(isinstance(cls, type) for cls in type_or_types)
+        )
+    )
+
+# ....................{ TESTERS ~ builtin                  }....................
+def is_type_builtin(cls: type) -> bool:
+    '''
+    :data:`True` only if the passed object is a **builtin type** (i.e., globally
+    accessible C-based type implicitly accessible from all scopes and thus
+    requiring *no* explicit importation).
+
+    Caveats
+    -------
+    This tester intentionally ignores **fake builtin types** (i.e., types that
+    are *not* builtin but nonetheless erroneously masquerade as being builtin,
+    including the type of the :data:`None` singleton) by returning :data:`False`
+    when passed a fake builtin type. If this is undesirable, consider calling
+    the lower-level :func:`.is_type_builtin_or_fake` tester.
+
+    Parameters
+    ----------
+    cls : type
+        Class to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this class is builtin.
+    '''
+
+    # Return true only if this is a builtin type.
+    return cls in TYPES_BUILTIN
+
+
+def is_type_builtin_or_fake(cls: type) -> bool:
+    '''
+    :data:`True` only if the passed object is a **possibly fake builtin type**
+    (i.e., type declared by the standard :mod:`builtins` module).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    This tester intentionally accepts **fake builtin types** (i.e., types that
+    are *not* builtin but nonetheless erroneously masquerade as being builtin,
+    including the type of the :data:`None` singleton) by returning :data:`True`
+    when passed a fake builtin type. If this is undesirable, consider calling
+    the higher-level :func:`.is_type_builtin` tester.
+
+    Like all non-builtin types, fake builtin types are globally inaccessible
+    until explicitly imported into the current lexical variable scope. Unlike
+    all non-builtin types, however, fake builtin types declare themselves to be
+    builtin. The standard example is the type of the :data:`None` singleton:
+
+    .. code-block:: python
+
+       >>> f'{type(None).__module__}.{type(None).__name__}'
+       'builtins.NoneType'
+       >>> NoneType
+       NameError: name 'NoneType' is not defined    # <---- this is balls
+
+    These inconsistencies almost certainly constitute bugs in the CPython
+    interpreter itself, but it seems doubtful CPython developers would see it
+    that way and almost certain everyone else would defend these edge cases.
+
+    We're *not* dying on that lonely hill. We obey the Iron Law of Guido.
+
+    Parameters
+    ----------
+    cls : type
+        Class to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a possibly fake builtin type.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodget import (
+        get_object_type_module_name_or_none)
+
+    # If this object is *NOT* a type, return false.
+    if not isinstance(cls, type):
+        return False
+    # Else, this object is a type.
+
+    # Fully-qualified name of the module defining this type if this type is
+    # defined by a module *OR* "None" otherwise (i.e., if this type is
+    # dynamically defined in-memory).
+    cls_module_name = get_object_type_module_name_or_none(cls)
+
+    # This return true only if this name is that of the "builtins" module
+    # declaring all builtin types.
+    return cls_module_name == BUILTINS_MODULE_NAME
+
+# ....................{ TESTERS ~ subclass                 }....................
+def is_type_subclass(
+    cls: object, base_classes: TypeOrTupleTypes) -> bool:
+    '''
+    :data:`True` only if the passed object is an inclusive subclass of the
+    passed superclass(es).
+
+    Specifically, this tester returns :data:`True` only if either:
+
+    * If ``base_classes`` is a single superclass, the passed class is either:
+
+      * That superclass itself *or*...
+      * A subclass of that superclass.
+
+    * Else, ``base_classes`` is a tuple of one or more superclasses. In this
+      case, the passed class is either:
+
+      * One of those superclasses themselves *or*...
+      * A subclass of one of those superclasses.
+
+    Caveats
+    -------
+    **This higher-level tester should always be called in lieu of the
+    lower-level** :func:`issubclass` **builtin,** which raises an undescriptive
+    exception when the first passed parameter is *not* a class: e.g.,
+
+    .. code-block:: python
+
+       >>> issubclass(object(), type)
+       TypeError: issubclass() arg 1 must be a class
+
+    This tester suffers no such deficits, instead safely returning ``False``
+    when the first passed parameter is *not* a class.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+    base_classes : TestableTypes
+        Superclass(es) to test whether this object is a subclass of defined as
+        either:
+
+        * A single class.
+        * A tuple of one or more classes.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an inclusive subclass of these
+        superclass(es).
+    '''
+    assert isinstance(base_classes, TestableTypesTuple), (
+        f'{repr(base_classes)} neither class nor tuple of classes.')
+
+    # Return true only if...
+    return (
+        # This object is a class *AND*...
+        isinstance(cls, type) and
+        # This class either is this superclass(es) or a subclass of this
+        # superclass(es).
+        issubclass(cls, base_classes)
+    )
+
+
+#FIXME: Unit test us up, please.
+def is_type_subclass_proper(
+    cls: object, base_classes: TypeOrTupleTypes) -> bool:
+    '''
+    ``True`` only if the passed object is a proper subclass of the passed
+    superclass(es).
+
+    Specifically, this tester returns ``True`` only if either:
+
+    * If ``base_classes`` is a single superclass, the passed class is a subclass
+      of that superclass (but *not* that superclass itself).
+    * Else, ``base_classes`` is a tuple of one or more superclasses. In this
+      case, the passed class is a subclass of one of those superclasses (but
+      *not* one of those superclasses themselves).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+    base_classes : TestableTypes
+        Superclass(es) to test whether this object is a subclass of defined as
+        either:
+
+        * A single class.
+        * A tuple of one or more classes.
+
+    Returns
+    -------
+    bool
+        ``True`` only if this object is a proper subclass of these
+        superclass(es).
+    '''
+    assert isinstance(base_classes, TestableTypesTuple), (
+        f'{repr(base_classes)} neither class nor tuple of classes.')
+
+    # Return true only if...
+    return (
+        # This object is a class *AND*...
+        isinstance(cls, type) and
+        # This class either is this superclass(es) or a subclass of this
+        # superclass(es) *AND*...
+        issubclass(cls, base_classes) and
+        # It is *NOT* the case that...
+        not (
+            # If the caller passed a tuple of one or more superclasses, this
+            # class is one of these superclasses themselves;
+            cls in base_classes
+            if isinstance(base_classes, tuple) else
+            # Else, the caller passed a single superclass. In this case, this
+            # class is this superclass itself.
+            cls is base_classes
+        )
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/error/utilerrget.py
@@ -0,0 +1,133 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **exception getters** (i.e., low-level callables retrieving
+metadata associated with various types of exceptions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilExceptionException
+from beartype._util.text.utiltextlabel import label_exception
+
+# ....................{ GETTERS                            }....................
+def get_name_error_attr_name(name_error: NameError) -> str:
+    '''
+    Unqualified basename of the non-existent attribute referenced by the passed
+    :class:`NameError` exception.
+
+    Parameters
+    ----------
+    name_error : NameError
+        :class:`NameError` exception to be inspected.
+
+    Returns
+    -------
+    str
+        Unqualified basename of this non-existent attribute.
+
+    Raises
+    ------
+    _BeartypeUtilExceptionException
+        If this is *not* a well-known :class:`NameError` exception raised by the
+        standard Python interpreter.
+
+    Examples
+    --------
+    .. code-block:: pycon
+
+       >>> from beartype._util.error.utilerrget import (
+       ...     get_name_error_attr_name)
+       >>> try:
+       ...     undefined_attr
+       ... except NameError as name_error:
+       ...     print(get_name_error_attr_name(name_error))
+       ...     print(name_error)
+       undefined_attr
+       name 'undefined_attr' is not defined
+    '''
+    assert isinstance(name_error, NameError), (
+        f'{repr(name_error)} not "NameError" exception.')
+
+    # Message associated with this name error.
+    error_message = str(name_error)
+
+    # Unqualified basename of the non-existent attribute referenced by this
+    # message, initialized to the empty string.
+    attr_name = ''
+
+    # 0-based index of the first single quote in this message if this message
+    # contains a single quote or "-1" otherwise.
+    #
+    # Note that:
+    # * *ALL* well-recognized name errors contain one or more single-quoted
+    #   substrings of the form "'{attr_name}'". The first such single-quoted
+    #   substring in each name error provides the desired unqualified basename
+    #   of the undefined attribute described by this name error.
+    # * There exist at least three such kinds of name errors, including:
+    #   * Most "NameError" exception messages assume the common form:
+    #         NameError: name '{attr_name}' is not defined
+    #   * Some "NameError" exception messages assume the less common form:
+    #         UnboundLocalError: cannot access local variable '{attr_name}'
+    #         where it is not associated with a value
+    #   * A few "NameError" exception messages assume the uncommon form:
+    #         UnboundLocalError: cannot access free variable '{attr_name}' where
+    #         it is not associated with a value in enclosing scope.
+    # * The str.find()-based approach performed below is more efficient than:
+    #   * A brute-force iterative approach attempting to manually match this
+    #     message against an iterable of well-known message prefixes.
+    #   * A Python-compatible regular expression (PCRE)-based approach. In
+    #     general, PCRE-based matching is only faster than str.find()-based
+    #     matching as the number of str.find() calls increases past a certain
+    #     threshold. Certainly, two str.find() calls is below that threshold.
+    ERROR_MESSAGE_QUOTE_FIRST_INDEX = error_message.find("'")
+
+    # If this name error contains at least one single quote...
+    if ERROR_MESSAGE_QUOTE_FIRST_INDEX != -1:
+        # Truncate the prefix of this message preceding this first single quote
+        # (e.g., from "name '{attr_name}' is not defined" to "{attr_name}' is
+        # not defined").
+        error_message = error_message[ERROR_MESSAGE_QUOTE_FIRST_INDEX + 1:]
+        # print(f'error_message truncated: {error_message}')
+
+        # 0-based index of the next single quote in this message if this message
+        # contains a second single quote or "-1" otherwise.
+        ERROR_MESSAGE_QUOTE_NEXT_INDEX = error_message.find("'")
+
+        # If this name error contains at least two single quotes...
+        if ERROR_MESSAGE_QUOTE_NEXT_INDEX != -1:
+            # Define the unqualified basename of the non-existent attribute
+            # referenced by this message as the substring of this message
+            # bounded by the first and second single quotes in this message
+            # (e.g., from "{attr_name}' is not defined" to "{attr_name}").
+            attr_name = error_message[:ERROR_MESSAGE_QUOTE_NEXT_INDEX]
+        # Else, this name error contains only one single quote.
+    # Else, this name error contains *NO* single quotes.
+
+    # If this name error is unrecognized, raise an exception.
+    #
+    # Note that this should *NEVER* occur. Of course, this will occur.
+    if not attr_name:
+        raise _BeartypeUtilExceptionException(  # pragma: no cover
+            f'Non-standard "{label_exception(name_error)}" unrecognized '
+            f"(i.e., single-quoted substring '{{attr_name}}' not found)."
+        ) from name_error
+    # Else, this name error is recognized.
+    #
+    # If this basename is *NOT* a Python identifier, raise an exception.
+    #
+    # Note that this should *NEVER* occur. Of course, this will occur.
+    elif not attr_name.isidentifier():
+        raise _BeartypeUtilExceptionException(  # pragma: no cover
+            f'Non-standard "{label_exception(name_error)}" unrecognized '
+            f"(i.e., single-quoted substring '{attr_name}' found but not a "
+            f'valid Python identifier).'
+        ) from name_error
+    # Else, this name error is a Python identifier.
+
+    # Return this basename.
+    return attr_name
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/error/utilerrraise.py
@@ -0,0 +1,138 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **exception handlers** (i.e., low-level callables manipulating
+fatal exceptions in a human-readable, general-purpose manner).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from beartype._util.error.utilerrtest import is_exception_message_str
+from beartype._util.text.utiltextmunge import uppercase_str_char_first
+
+# ....................{ RAISERS                            }....................
+def reraise_exception_placeholder(
+    # Mandatory parameters.
+    exception: Exception,
+    target_str: str,
+
+    # Optional parameters.
+    source_str: str = EXCEPTION_PLACEHOLDER,
+) -> None:
+    '''
+    Reraise the passed exception in a safe manner preserving both this exception
+    object *and* the original traceback associated with this exception object,
+    but globally replacing all instances of the passed source substring
+    hard-coded into this exception's message with the passed target substring.
+
+    Parameters
+    ----------
+    exception : Exception
+        Exception to be reraised.
+    target_str : str
+        Target human-readable format substring to replace the passed source
+        substring previously hard-coded into this exception's message.
+    source_str : Optional[str]
+        Source non-human-readable substring previously hard-coded into this
+        exception's message to be replaced by the passed target substring.
+        Defaults to :data:`.EXCEPTION_PLACEHOLDER`.
+
+    Raises
+    ------
+    exception
+        The passed exception, globally replacing all instances of this source
+        substring in this exception's message with this target substring.
+
+    See Also
+    --------
+    :data:`.EXCEPTION_PLACEHOLDER`
+        Further commentary on usage and motivation.
+    https://stackoverflow.com/a/62662138/2809027
+        StackOverflow answer mildly inspiring this implementation.
+
+    Examples
+    --------
+    .. code-block:: pycon
+
+       >>> from beartype.roar import BeartypeDecorHintPepException
+       >>> from beartype._util.cache.utilcachecall import callable_cached
+       >>> from beartype._util.error.utilerrraise import (
+       ...     reraise_exception_placeholder, EXCEPTION_PLACEHOLDER)
+       >>> from random import getrandbits
+       >>> @callable_cached
+       ... def portend_low_level_winter(is_winter_coming: bool) -> str:
+       ...     if is_winter_coming:
+       ...         raise BeartypeDecorHintPepException(
+       ...             '{} intimates that winter is coming.'.format(
+       ...                 EXCEPTION_PLACEHOLDER))
+       ...     else:
+       ...         return 'PRAISE THE SUN'
+       >>> def portend_high_level_winter() -> None:
+       ...     try:
+       ...         print(portend_low_level_winter(is_winter_coming=False))
+       ...         print(portend_low_level_winter(is_winter_coming=True))
+       ...     except BeartypeDecorHintPepException as exception:
+       ...         reraise_exception_placeholder(
+       ...             exception=exception,
+       ...             target_str=(
+       ...                 'Random "Song of Fire and Ice" spoiler' if getrandbits(1) else
+       ...                 'Random "Dark Souls" plaintext meme'
+       ...             ))
+       >>> portend_high_level_winter()
+       PRAISE THE SUN
+       Traceback (most recent call last):
+         File "<input>", line 30, in <module>
+           portend_high_level_winter()
+         File "<input>", line 27, in portend_high_level_winter
+           'Random "Dark Souls" plaintext meme'
+         File "/home/leycec/py/beartype/beartype._util.error.utilerrraise.py", line 225, in reraise_exception_placeholder
+           raise exception.with_traceback(exception.__traceback__)
+         File "<input>", line 20, in portend_high_level_winter
+           print(portend_low_level_winter(is_winter_coming=True))
+         File "/home/leycec/py/beartype/beartype/_util/cache/utilcachecall.py", line 296, in _callable_cached
+           raise exception
+         File "/home/leycec/py/beartype/beartype/_util/cache/utilcachecall.py", line 289, in _callable_cached
+           *args, **kwargs)
+         File "<input>", line 13, in portend_low_level_winter
+           EXCEPTION_PLACEHOLDER))
+       beartype.roar.BeartypeDecorHintPepException: Random "Song of Fire and Ice" spoiler intimates that winter is coming.
+    '''
+    assert isinstance(exception, Exception), (
+        f'{repr(exception)} not exception.')
+    assert isinstance(source_str, str), f'{repr(source_str)} not string.'
+    assert isinstance(target_str, str), f'{repr(target_str)} not string.'
+
+
+    # If this is a conventional exception...
+    if is_exception_message_str(exception):
+        # Munged exception message globally replacing all instances of this
+        # source substring with this target substring.
+        #
+        # Note that we intentionally call the lower-level str.replace() method
+        # rather than the higher-level
+        # beartype._util.text.utiltextmunge.replace_str_substrs() function here,
+        # as the latter unnecessarily requires this exception message to contain
+        # one or more instances of this source substring.
+        exception_message = exception.args[0].replace(source_str, target_str)
+
+        # If doing so actually changed this message...
+        if exception_message != exception.args[0]:
+            # Uppercase the first character of this message if needed.
+            exception_message = uppercase_str_char_first(exception_message)
+
+            # Reconstitute this exception argument tuple from this message.
+            #
+            # Note that if this tuple contains only this message, this slice
+            # "exception.args[1:]" safely yields the empty tuple. Go, Python!
+            exception.args = (exception_message,) + exception.args[1:]
+        # Else, this message remains preserved as is.
+    # Else, this is an unconventional exception. In this case, preserve this
+    # exception as is.
+
+    # Re-raise this exception while preserving its original traceback.
+    raise exception.with_traceback(exception.__traceback__)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/error/utilerrtest.py
@@ -0,0 +1,45 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **exception testers** (i.e., low-level callables introspecting
+metadata associated with various types of exceptions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_exception_message_str(exception: Exception) -> bool:
+    '''
+    :data:`True` only if the message encapsulated by the passed exception is a
+    simple string (as is typically but *not* necessarily the case).
+
+    Parameters
+    ----------
+    exception : Exception
+        Exception to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this exception's message is a simple string.
+    '''
+    assert isinstance(exception, Exception), f'{repr(exception)} not exception.'
+
+    # Return true only if...
+    return bool(
+        # Exception arguments are a tuple (as is typically but not necessarily
+        # the case) *AND*...
+        isinstance(exception.args, tuple) and
+        # This tuple is non-empty (as is typically but not necessarily the
+        # case) *AND*...
+        exception.args and
+        # The first item of this tuple is a string providing this exception's
+        # message (as is typically but *NOT* necessarily the case)...
+        isinstance(exception.args[0], str)
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/error/utilerrwarn.py
@@ -0,0 +1,212 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **warning handlers** (i.e., low-level callables manipulating
+non-fatal warnings -- which, technically, are also exceptions -- in a
+human-readable, general-purpose manner).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Any,
+    Iterable,
+)
+from beartype._data.error.dataerrmagic import EXCEPTION_PLACEHOLDER
+from beartype._data.hint.datahinttyping import TypeWarning
+from beartype._util.error.utilerrtest import is_exception_message_str
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_12
+from beartype._util.text.utiltextmunge import uppercase_str_char_first
+from collections.abc import Iterable as IterableABC
+from warnings import (
+    WarningMessage,
+    warn,
+    warn_explicit,
+)
+
+# ....................{ WARNERS                            }....................
+# If the active Python interpreter targets Python >= 3.12, the standard
+# warnings.warn() function supports the optional "skip_file_prefixes" parameter
+# critical for emitting more useful warnings. In this case, define the
+# issue_warning() warner to pass that parameter.
+if IS_PYTHON_AT_LEAST_3_12:
+    # ....................{ IMPORTS                        }....................
+    # Defer version-specific imports.
+    import beartype
+    from os.path import dirname
+
+    # ....................{ WARNERS                        }....................
+    def issue_warning(cls: TypeWarning, message: str) -> None:
+        # The warning you gave us is surely our last!
+        warn(message, cls, skip_file_prefixes=_ISSUE_WARNING_IGNORE_DIRNAMES)  # type: ignore[call-overload]
+        # warn(message, cls)  # type: ignore[call-overload]
+
+    # ....................{ PRIVATE ~ globals              }....................
+    _ISSUE_WARNING_IGNORE_DIRNAMES = (dirname(beartype.__file__),)
+    '''
+    Tuple of one or more **ignorable warning dirnames** (i.e., absolute
+    directory names of all Python modules to be ignored by the
+    :func:`.issue_warning` warner when deciding which source module to associate
+    with the issued warning, enabling this warner to associate this warning with
+    the original externally defined module to which this warning applies).
+
+    This tuple includes the dirname of the top-level directory providing the
+    :mod:`beartype` package, enabling this warner to ignore all stack frames
+    produced by internal calls to submodules of this package. Doing so emits
+    substantially more useful and readable warnings for external callers.
+    '''
+# Else, the active Python interpreter targets Python < 3.12. In this case,
+# define the issue_warning() warner to avoid passing that parameter.
+else:
+    def issue_warning(cls: TypeWarning, message: str) -> None:
+        # Time to cry your tears! Now cry!
+        warn(message, cls)
+
+
+issue_warning.__doc__ = (
+    '''
+    Issue (i.e., emit) a non-fatal warning of the passed type with the passed
+    message.
+
+    Caveats
+    -------
+    **This high-level warner should always be called in lieu of the low-level**
+    :func:`warnings.warn` **warner.** Whereas the latter issues warnings that
+    obfuscate the external user-defined modules to which those warnings apply,
+    this warner associates this warning with the applicable user-defined module
+    when the active Python interpreter targets Python >= 3.12.
+
+    Parameters
+    ----------
+    cls: Type[Warning]
+        Type of warning to be issued.
+    message: str
+        Human-readable warning message to be issued.
+    '''
+)
+
+# ....................{ REWARNERS                          }....................
+def reissue_warnings_placeholder(
+    # Mandatory parameters.
+    warnings: Iterable[WarningMessage],
+    target_str: str,
+
+    # Optional parameters.
+    source_str: str = EXCEPTION_PLACEHOLDER,
+) -> None:
+    '''
+    Reissue (i.e., re-emit) the passed warning in a safe manner preserving both
+    this warning object *and* **associated context** (e.g., filename, line
+    number) associated with this warning object, but globally replacing all
+    instances of the passed source substring hard-coded into this warning's
+    message with the passed target substring.
+
+    Parameters
+    ----------
+    warnings : Iterable[WarningMessage]
+        Iterable of zero or more warnings to be reissued, typically produced by
+        an external call to the standard
+        ``warnings.catch_warnings(record=True)`` context manager.
+    target_str : str
+        Target human-readable format substring to replace the passed source
+        substring previously hard-coded into this warning's message.
+    source_str : Optional[str]
+        Source non-human-readable substring previously hard-coded into this
+        warning's message to be replaced by the passed target substring.
+        Defaults to :data:`.EXCEPTION_PLACEHOLDER`.
+
+    Warns
+    -----
+    warning
+        The passed warning, globally replacing all instances of this source
+        substring in this warning's message with this target substring.
+
+    See Also
+    --------
+    :data:`.EXCEPTION_PLACEHOLDER`
+        Further commentary on usage and motivation.
+    https://stackoverflow.com/a/77516994/2809027
+        StackOverflow answer strongly inspiring this implementation.
+    '''
+    assert isinstance(warnings, IterableABC), (
+        f'{repr(warnings)} not iterable.')
+    assert isinstance(source_str, str), f'{repr(source_str)} not string.'
+    assert isinstance(target_str, str), f'{repr(target_str)} not string.'
+
+    # For each warning descriptor in this iterable of zero or more warning
+    # descriptors...
+    for warning_info in warnings:
+        assert isinstance(warning_info, WarningMessage), (  # <-- terrible name!
+           f'{repr(warning_info)} not "WarningMessage" instance.')
+
+        # Original warning wrapped by this warning descriptor, localized both
+        # for readability *AND* negligible speed. *sigh*
+        warning = warning_info.message
+
+        # Munged warning message to be issued below.
+        warning_message_new: Any = None
+
+        # If either...
+        if (
+            # This warning is... *ALREADY A STRING!?* What is going on here?
+            # Look. Not even we know. But mypy claims that warnings recorded by
+            # calls to the standard "warnings.catch_warnings(record=True)"
+            # function satisfy the union "Warning | str". Technically, that
+            # makes no sense. Pragmatically, that makes no sense. But mypy says
+            # it's true. We are too tired to argue with static type-checkers at
+            # 4:11AM in the morning.
+            isinstance(warning, str) or
+            # This warning is conventional...
+            is_exception_message_str(warning)
+        # Then this warning is or has a standard message. In this case...
+        ):
+            # Original warning message, coerced from the original warning.
+            #
+            # Note that the poorly named "message" attribute is the original
+            # warning rather warning message. Just as with exceptions, coercing
+            # this warning into a string reliably retrieves its message.
+            warning_message_old = str(warning)
+
+            # Munged warning message globally replacing all instances of this
+            # source substring with this target substring.
+            #
+            # Note that we intentionally call the lower-level str.replace()
+            # method rather than the higher-level
+            # beartype._util.text.utiltextmunge.replace_str_substrs() function
+            # here, as the latter unnecessarily requires this warning message to
+            # contain one or more instances of this source substring.
+            warning_message_new = warning_message_old.replace(
+                source_str, target_str)
+
+            # If doing so actually changed this message...
+            if warning_message_new != warning_message_old:
+                # Uppercase the first character of this message if needed.
+                warning_message_new = uppercase_str_char_first(
+                    warning_message_new)
+            # Else, this message remains preserved as is.
+        # Else, this is an unconventional warning. In this case...
+        else:
+            # Tuple of the zero or more arguments with which this warning was
+            # originally issued.
+            warning_args = warning.args
+
+            # Assert that this warning was issued with exactly one argument.
+            # Since the warnings.warn() signature accepts only a single
+            # "message" parameter, this assertion *SHOULD* always hold. *sigh*
+            assert len(warning_args) == 1
+
+            # Preserve this warning as is.
+            warning_message_new = warning_args[0]
+
+        # Reissue this warning with a possibly modified message.
+        warn_explicit(
+            message=warning_message_new,
+            category=warning_info.category,
+            filename=warning_info.filename,
+            lineno=warning_info.lineno,
+            source=warning_info.source,
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/arg/utilfuncargget.py
@@ -0,0 +1,347 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable parameter getter utilities** (i.e., callables
+introspectively querying metadata on parameters accepted by arbitrary
+callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import Optional
+from beartype._cave._cavefast import MethodBoundInstanceOrClassType
+from beartype._data.hint.datahinttyping import (
+    Codeobjable,
+    TypeException,
+)
+from beartype._util.func.arg.utilfuncargiter import (
+    ARG_META_INDEX_NAME,
+    iter_func_args,
+)
+from beartype._util.func.utilfunccodeobj import (
+    get_func_codeobj_or_none,
+    get_func_codeobj,
+)
+from collections.abc import Callable
+
+# ....................{ GETTERS ~ arg                      }....................
+#FIXME: Unit test us up, please.
+def get_func_arg_first_name_or_none(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+) -> Optional[str]:
+    '''
+    Name of the first parameter listed in the signature of the passed
+    pure-Python callable if any *or* :data:`None` otherwise (i.e., if that
+    callable accepts *no* parameters and is thus parameter-less).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Pure-Python callable, frame, or code object to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function.
+        Defaults to :data:`True` for safety. See :func:`.iter_func_args` for
+        further commentary.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If that callable accepts one or more parameters, the name of the first
+          parameter listed in the signature of that callable.
+        * Else, :data:`None`.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* pure-Python.
+    '''
+
+    # For metadata describing each parameter accepted by this callable...
+    for arg_meta in iter_func_args(
+        func=func,
+        is_unwrap=is_unwrap,
+        exception_cls=exception_cls,
+    ):
+        # Return the name of this parameter.
+        return arg_meta[ARG_META_INDEX_NAME]  # type: ignore[return-value]
+    # Else, the above "return" statement was *NOT* performed. In this case, this
+    # callable accepts *NO* parameters.
+
+    # Return "None".
+    return None
+
+# ....................{ GETTERS ~ args                     }....................
+def get_func_args_flexible_len(
+    # Mandatory parameters.
+    func: Codeobjable,
+
+    # Optional parameters.
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> int:
+    '''
+    Number of **flexible parameters** (i.e., parameters passable as either
+    positional or keyword arguments but *not* positional-only, keyword-only,
+    variadic, or other more constrained kinds of parameters) accepted by the
+    passed pure-Python callable.
+
+    This getter transparently handles all of the following:
+
+    * Conventional pure-Python callables.
+    * If ``is_unwrap`` is :data:`True`:
+
+      * Pure-Python **partials** (i.e., pure-Python callable
+        :class:`functools.partial` objects directly wrapping pure-Python
+        callables). If a partial is passed, this getter transparently returns
+        the total number of flexible parameters accepted by the lower-level
+        callable wrapped by this partial minus the number of flexible parameters
+        partialized away by this partial.
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Pure-Python callable, frame, or code object to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function.
+        Defaults to :data:`True` for safety. See :func:`.get_func_codeobj` for
+        further commentary.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the message of any exception raised in
+        the event of a fatal error. Defaults to the empty string.
+
+    Returns
+    -------
+    int
+        Number of flexible parameters accepted by this callable.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* pure-Python.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.api.utilapifunctools import (
+        get_func_functools_partial_args_flexible_len,
+        is_func_functools_partial,
+    )
+
+    # Code object underlying the passed pure-Python callable unwrapped if any
+    # *OR* "None" otherwise (i.e., that callable has *NO* code object).
+    func_codeobj = get_func_codeobj_or_none(func=func, is_unwrap=is_unwrap)
+
+    # If that callable has a code object, return the number of flexible
+    # parameters accepted by this callable exposed by this code object.
+    if func_codeobj:
+        return func_codeobj.co_argcount
+    # Else, that callable has *NO* code object.
+
+    # If that callable is *NOT* actually callable, raise an exception.
+    if not callable(func):
+        raise exception_cls(f'{exception_prefix}{repr(func)} uncallable.')
+    # Else, that callable is callable.
+
+    # If unwrapping that callable *AND* that callable is a partial (i.e.,
+    # "functools.partial" object wrapping a lower-level callable), return the
+    # total number of flexible parameters accepted by the pure-Python wrappee
+    # callable wrapped by this partial minus the number of flexible parameters
+    # passed by this partial to this wrappee.
+    if is_unwrap and is_func_functools_partial(func):
+        return get_func_functools_partial_args_flexible_len(
+            func=func,
+            is_unwrap=is_unwrap,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+    # Else, that callable is *NOT* a partial.
+    #
+    # By process of elimination, that callable *MUST* be an otherwise uncallable
+    # object whose class has intentionally made that object callable by defining
+    # the __call__() dunder method. Fallback to introspecting that method.
+
+    # "__call__" attribute of that callable if any *OR* "None" otherwise (i.e.,
+    # if that callable is actually uncallable).
+    func_call_attr = getattr(func, '__call__', None)
+
+    # If that callable fails to define the "__call__" attribute, that callable
+    # is actually uncallable. But the callable() builtin claimed that callable
+    # to be callable above. In this case, raise an exception.
+    #
+    # Note that this should *NEVER* happen. Nonetheless, this just happened.
+    if func_call_attr is None:  # pragma: no cover
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} uncallable '
+            f'(i.e., defines no __call__() dunder method).'
+        )
+    # Else, that callable defines the __call__() dunder method.
+
+    # Return the total number of flexible parameters accepted by the pure-Python
+    # wrappee callable wrapped by this bound method descriptor minus one to
+    # account for the first "self" parameter implicitly
+    # passed by this descriptor to that callable.
+    return _get_func_boundmethod_args_flexible_len(
+        func=func_call_attr,
+        is_unwrap=is_unwrap,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+
+#FIXME: Unit test us up, please.
+def get_func_args_nonvariadic_len(
+    # Mandatory parameters.
+    func: Codeobjable,
+
+    # Optional parameters.
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+) -> int:
+    '''
+    Number of **non-variadic parameters** (i.e., parameters passable as either
+    positional, positional-only, keyword, or keyword-only arguments) accepted by
+    the passed pure-Python callable.
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Pure-Python callable, frame, or code object to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function.
+        Defaults to :data:`True` for safety. See :func:`.get_func_codeobj` for
+        further commentary.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+
+    Returns
+    -------
+    int
+        Number of flexible parameters accepted by this callable.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* pure-Python.
+    '''
+
+    # Code object underlying the passed pure-Python callable unwrapped.
+    func_codeobj = get_func_codeobj(
+        func=func,
+        is_unwrap=is_unwrap,
+        exception_cls=exception_cls,
+    )
+
+    # Return the number of non-variadic parameters accepted by this callable.
+    return func_codeobj.co_argcount + func_codeobj.co_kwonlyargcount
+
+# ....................{ PRIVATE ~ getters : args           }....................
+def _get_func_boundmethod_args_flexible_len(
+    # Mandatory parameters.
+    func: MethodBoundInstanceOrClassType,
+
+    # Optional parameters.
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> int:
+    '''
+    Number of **flexible parameters** (i.e., parameters passable as either
+    positional or keyword arguments but *not* positional-only, keyword-only,
+    variadic, or other more constrained kinds of parameters) accepted by the
+    passed **C-based bound instance method descriptor** (i.e., callable
+    implicitly instantiated and assigned on the instantiation of an object whose
+    class declares an instance function (whose first parameter is typically
+    named ``self``)).
+
+    Specifically, this getter transparently returns one less than the total
+    number of flexible parameters accepted by the lower-level callable wrapped
+    by this descriptor to account for the first ``self`` parameter implicitly
+    passed by this descriptor to that callable.
+
+    Parameters
+    ----------
+    func : MethodBoundInstanceOrClassType
+        Bound method descriptor to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function.
+        Defaults to :data:`True` for safety. See :func:`.get_func_codeobj` for
+        further commentary.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the message of any exception raised in
+        the event of a fatal error. Defaults to the empty string.
+
+    Returns
+    -------
+    int
+        Number of flexible parameters accepted by this callable.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* pure-Python.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfuncwrap import unwrap_func_boundmethod_once
+
+    # Unbound pure-Python function encapsulated by this C-based bound method
+    # descriptor bound to some callable object.
+    wrappee = unwrap_func_boundmethod_once(
+        func=func,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # Number of flexible parameters accepted by that function.
+    #
+    # Note that this recursive function call is guaranteed to immediately bottom
+    # out and thus be safe for similar reasons as given above.
+    wrappee_args_flexible_len = get_func_args_flexible_len(
+        func=wrappee,
+        is_unwrap=is_unwrap,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # If this number is zero, the caller maliciously defined a non-static
+    # function accepting *NO* parameters. Since this paradoxically includes the
+    # mandatory first "self" parameter for a bound method descriptor, it is
+    # infeasible for this edge case to occur. Nonetheless, raise an exception.
+    if not wrappee_args_flexible_len:  # pragma: no cover
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} accepts no '
+            f'parameters despite being a bound instance method descriptor.'
+        )
+    # Else, this number is positive.
+
+    # Return this number minus one to account for the fact that this bound
+    # method descriptor implicitly passes the instance object to which this
+    # method descriptor is bound as the first parameter to all calls of this
+    # method descriptor.
+    return wrappee_args_flexible_len - 1
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/arg/utilfuncargiter.py
@@ -0,0 +1,549 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable parameter iterator utilities** (i.e., low-level
+callables introspectively iterating over parameters accepted by arbitrary
+callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import (
+    Dict,
+    Iterable,
+    Optional,
+    Tuple,
+)
+from beartype._data.hint.datahinttyping import (
+    # Codeobjable,
+    TypeException,
+)
+from beartype._data.kind.datakinddict import DICT_EMPTY
+from beartype._util.func.utilfunccodeobj import get_func_codeobj
+from beartype._util.func.utilfuncwrap import unwrap_func_all_isomorphic
+from collections.abc import Callable
+from enum import (
+    Enum,
+    auto as next_enum_member_value,
+    unique as die_unless_enum_member_values_unique,
+)
+from inspect import CO_VARARGS, CO_VARKEYWORDS
+from itertools import count
+from types import CodeType
+
+# ....................{ ENUMERATIONS                       }....................
+@die_unless_enum_member_values_unique
+class ArgKind(Enum):
+    '''
+    Enumeration of all kinds of **callable parameters** (i.e., arguments passed
+    to pure-Python callables).
+
+    This enumeration intentionally declares members of the same name as those
+    declared by the standard :class:`inspect.Parameter` class. Whereas the
+    former are unconditionally declared below and thus portable across Python
+    versions, the latter are only conditionally declared depending on Python
+    version and thus non-portable across Python versions. Notably, the
+    :attr:`inspect.Parameter.POSITIONAL_ONLY` attribute is only defined under
+    Python >= 3.8.
+
+    Attributes
+    ----------
+    POSITIONAL_ONLY : EnumMemberType
+        Kind of all **positional-only parameters** (i.e., parameters required
+        to be passed positionally, syntactically followed in the signatures of
+        their callables by the :pep:`570`-compliant ``/,`` pseudo-parameter).
+    POSITIONAL_OR_KEYWORD : EnumMemberType
+        Kind of all **flexible parameters** (i.e., parameters permitted to be
+        passed either positionally or by keyword).
+    VAR_POSITIONAL : EnumMemberType
+        Kind of all **variadic positional parameters** (i.e., tuple of zero or
+        more positional parameters *not* explicitly named by preceding
+        positional-only or flexible parameters, syntactically preceded by the
+        ``*`` prefix and typically named ``*args``).
+    KEYWORD_ONLY  : EnumMemberType
+        Kind of all **keyword-only parameters** (i.e., parameters required to
+        be passed by keyword, syntactically preceded in the signatures of
+        their callables by the :pep:`3102`-compliant ``*,`` pseudo-parameter).
+    VAR_KEYWORD : EnumMemberType
+        Kind of all **variadic keyword parameters** (i.e., tuple of zero or
+        more keyword parameters *not* explicitly named by preceding
+        keyword-only or flexible parameters, syntactically preceded by the
+        ``**`` prefix and typically named ``**kwargs``).
+    '''
+
+    POSITIONAL_ONLY = next_enum_member_value()
+    POSITIONAL_OR_KEYWORD = next_enum_member_value()
+    VAR_POSITIONAL = next_enum_member_value()
+    KEYWORD_ONLY = next_enum_member_value()
+    VAR_KEYWORD = next_enum_member_value()
+
+# ....................{ SINGLETONS                         }....................
+ArgMandatory = object()
+'''
+Arbitrary sentinel singleton assigned by the :func:`.iter_func_args` generator
+to the :data:`.ARG_META_INDEX_DEFAULT` fields of all :class:`.ArgMeta` instances
+describing **mandatory parameters** (i.e., parameters that *must* be explicitly
+passed to their callables).
+'''
+
+# ....................{ HINTS                              }....................
+ArgMeta = Tuple[ArgKind, str, object]
+'''
+PEP-compliant type hint matching each 3-tuple ``(arg_kind, arg_name,
+default_value_or_mandatory)`` iteratively yielded by the :func:`.iter_func_args`
+generator for each parameter accepted by the passed pure-Python callable, where:
+
+* ``arg_kind`` is this parameter's **kind** (i.e., ".ArgKind" enumeration member
+  conveying the syntactic class of this parameter, constraining how the callable
+  declaring this parameter requires this parameter to be passed).
+* ``name`` is this parameter's **name** (i.e., syntactically valid Python
+  identifier uniquely identifying this parameter in its parameter list).
+* ``default_value_or_mandatory`` is either:
+
+    * If this parameter is mandatory, the magic constant :data:`.ArgMandatory`.
+    * Else, this parameter is optional and thus defaults to a default value when
+      unpassed. In this case, this is that default value.
+'''
+
+# ....................{ CONSTANTS ~ index                  }....................
+# Iterator yielding the next integer incrementation starting at 0, to be safely
+# deleted *AFTER* defining the following 0-based indices via this iterator.
+__arg_meta_index_counter = count(start=0, step=1)
+
+
+ARG_META_INDEX_KIND = next(__arg_meta_index_counter)
+'''
+0-based index into each 4-tuple iteratively yielded by the generator returned by
+the :func:`.iter_func_args` generator function of the currently iterated
+parameter's **kind** (i.e., :class:`ArgKind` enumeration member conveying this
+parameter's syntactic class, constraining how the callable declaring this
+parameter requires this parameter to be passed).
+'''
+
+
+ARG_META_INDEX_NAME = next(__arg_meta_index_counter)
+'''
+0-based index into each 4-tuple iteratively yielded by the generator returned by
+the :func:`.iter_func_args` generator function of the currently iterated
+parameter's **name** (i.e., syntactically valid Python identifier uniquely
+identifying this parameter in its parameter list).
+'''
+
+
+ARG_META_INDEX_DEFAULT = next(__arg_meta_index_counter)
+'''
+0-based index into each 4-tuple iteratively yielded by the generator returned by
+the :func:`.iter_func_args` generator function of the currently iterated
+parameter's **default value** specified as either:
+
+* If this parameter is mandatory, the magic constant :data:`.ArgMandatory`.
+* Else, this parameter is optional and thus defaults to a default value when
+  unpassed. In this case, this is that default value.
+'''
+
+
+# Delete the above counter for safety and sanity in equal measure.
+del __arg_meta_index_counter
+
+# ....................{ GENERATORS                         }....................
+def iter_func_args(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    func_codeobj: Optional[CodeType] = None,
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+# Note this generator is intentionally annotated as returning a high-level
+# "Iterable[...]" rather than a low-level "Generator[..., ..., ...]", as the
+# syntax governing the latter is overly verbose and largely unhelpful.
+) -> Iterable[ArgMeta]:
+    '''
+    Generator yielding one **parameter metadata tuple** (i.e., tuple whose
+    items describe a single parameter) for each parameter accepted by the
+    passed pure-Python callable.
+
+    For consistency with the official grammar for callable signatures
+    standardized by :pep:`570`, this generator is guaranteed to yield parameter
+    metadata in the same order as required by Python syntax and semantics. In
+    order, this is:
+
+    * **Mandatory positional-only parameters** (i.e., parameter metadata
+      whose kind is :attr:`ArgKind.POSITIONAL_ONLY` and whose default value is
+      :data:`ArgMandatory`).
+    * **Optional positional-only parameters** (i.e., parameter metadata
+      whose kind is :attr:`ArgKind.POSITIONAL_ONLY` and whose default value is
+      *not* :data:`ArgMandatory`).
+    * **Mandatory flexible parameters** (i.e., parameter metadata whose kind is
+      :attr:`ArgKind.POSITIONAL_OR_KEYWORD` and whose default value is
+      :data:`ArgMandatory`).
+    * **Optional flexible parameters** (i.e., parameter metadata whose kind is
+      :attr:`ArgKind.POSITIONAL_OR_KEYWORD` and whose default value is *not*
+      :data:`ArgMandatory`).
+    * **Variadic positional parameters** (i.e., parameter metadata whose kind
+      is :attr:`ArgKind.VAR_POSITIONAL` and whose default value is
+      :data:`ArgMandatory`).
+    * **Mandatory and optional keyword-only parameters** (i.e., parameter
+      metadata whose kind is :attr:`ArgKind.KEYWORD_ONLY`). Unlike all other
+      parameter kinds, keyword-only parameters are (by definition) unordered;
+      ergo, Python explicitly permits mandatory and optional keyword-only
+      parameters to be heterogeneously intermingled rather than clustered.
+    * **Variadic keyword parameters** (i.e., parameter metadata whose kind
+      is :attr:`ArgKind.VAR_KEYWORD` and whose default value is
+      :data:`ArgMandatory`).
+
+    Caveats
+    -------
+    **This highly optimized generator function should always be called in lieu
+    of the highly unoptimized** :func:`inspect.signature` **function,** which
+    implements a similar introspection as this generator with significantly
+    worse space and time consumption. Seriously. *Never* call that anywhere.
+
+    Parameters
+    ----------
+    func : Callable
+        Pure-Python callable to be inspected.
+    func_codeobj: CodeType, optional
+        Code object underlying that callable unwrapped. Defaults to
+        :data:`None`, in which case this iterator internally defers to the
+        comparatively slower :func:`get_func_codeobj` function.
+    is_unwrap: bool, optional
+        :data:`True` only if this generator implicitly calls the
+        :func:`unwrap_func_all_isomorphic` function to unwrap this possibly higher-level
+        wrapper into its possibly lowest-level wrappee *before* returning the
+        code object of that wrappee. Note that doing so incurs worst-case time
+        complexity ``O(n)`` for ``n`` the number of lower-level wrappees
+        wrapped by this wrapper. Defaults to :data:`True` for robustness. Why?
+        Because this generator *must* always introspect lowest-level wrappees
+        rather than higher-level wrappers. The latter typically do *not* wrap
+        the default values of the former, since this is the default behaviour
+        of the :func:`functools.update_wrapper` function underlying the
+        :func:`functools.wrap` decorator underlying all sane decorators. If
+        this boolean is set to :data:`False` while that callable is actually a
+        wrapper, this generator will erroneously misidentify optional as
+        mandatory parameters and fail to yield their default values. Only set
+        this boolean to :data:`False` if you pretend to know what you're doing.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+
+    Yields
+    ------
+    ArgMeta
+        Parameter metadata tuple describing the currently yielded parameter.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* pure-Python.
+    '''
+
+    # ..................{ LOCALS ~ noop                      }..................
+    # If unwrapping that callable, do so *BEFORE* obtaining the code object of
+    # that callable for safety (to avoid desynchronization between the two).
+    if is_unwrap:
+        func = unwrap_func_all_isomorphic(func)
+    # Else, that callable is assumed to have already been unwrapped by the
+    # caller. We should probably assert that, but doing so requires an
+    # expensive call to hasattr(). What you gonna do?
+
+    # If passed *NO* code object, query that callable for its code object.
+    if func_codeobj is None:
+        func_codeobj = get_func_codeobj(func=func, exception_cls=exception_cls)
+    # In any case, that code object is now defined.
+
+    # Bit field of OR-ed binary flags describing this callable.
+    func_codeobj_flags = func_codeobj.co_flags
+
+    # Number of both optional and mandatory non-keyword-only parameters (i.e.,
+    # positional-only *AND* flexible (i.e., positional or keyword) parameters)
+    # accepted by that callable.
+    args_len_posonly_or_flex = func_codeobj.co_argcount
+
+    # Number of both optional and mandatory keyword-only parameters accepted by
+    # that callable.
+    args_len_kwonly = func_codeobj.co_kwonlyargcount
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the is_func_arg_variadic_positional() and
+    # is_func_arg_variadic_keyword() testers.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # True only if that callable accepts variadic positional or keyword
+    # parameters. For efficiency, these tests are inlined from the
+    # is_func_arg_variadic_positional() and is_func_arg_variadic_keyword()
+    # testers. Yes, this optimization has been profiled to yield joy.
+    is_arg_var_pos = bool(func_codeobj_flags & CO_VARARGS)
+    is_arg_var_kw  = bool(func_codeobj_flags & CO_VARKEYWORDS)
+    # print(f'func.__name__ = {func.__name__}\nis_arg_var_pos = {is_arg_var_pos}\nis_arg_var_kw = {is_arg_var_kw}')
+
+    # If that callable accepts *NO* parameters, silently reduce to the empty
+    # generator (i.e., noop) for both space and time efficiency. Just. Do. It.
+    #
+    # Note that this is a critical optimization when @beartype is
+    # unconditionally applied with import hook automation to *ALL* physical
+    # callables declared by a package, many of which will be argumentless.
+    if (
+        args_len_posonly_or_flex +
+        args_len_kwonly +
+        is_arg_var_pos +
+        is_arg_var_kw
+    ) == 0:
+        yield from ()
+        return
+    # Else, that callable accepts one or more parameters.
+
+    # ..................{ LOCALS ~ names                     }..................
+    # Tuple of the names of all variables localized to that callable.
+    #
+    # Note that this tuple contains the names of both:
+    # * All parameters accepted by that callable.
+    # * All local variables internally declared in that callable's body.
+    #
+    # Ergo, this tuple *CANNOT* be searched in full. Only the subset of this
+    # tuple containing argument names is relevant and may be safely searched.
+    #
+    # Lastly, note the "func_codeobj.co_names" attribute is incorrectly
+    # documented in the "inspect" module as the "tuple of names of local
+    # variables." That's a lie. That attribute is instead a mostly useless
+    # tuple of the names of both globals and object attributes accessed in the
+    # body of that callable. *shrug*
+    args_name = func_codeobj.co_varnames
+
+    # ..................{ LOCALS ~ defaults                  }..................
+    # Tuple of the default values assigned to all optional non-keyword-only
+    # parameters (i.e., all optional positional-only *AND* optional flexible
+    # (i.e., positional or keyword) parameters) accepted by that callable if any
+    # *OR* the empty tuple otherwise.
+    args_defaults_posonly_or_flex = func.__defaults__ or ()  # type: ignore[attr-defined]
+    # print(f'args_defaults_posonly_or_flex: {args_defaults_posonly_or_flex}')
+
+    # Dictionary mapping from the name of each optional keyword-only parameter
+    # accepted by that callable to the default value assigned to that parameter
+    # if any *OR* the empty dictionary otherwise.
+    #
+    # For both space and time efficiency, the empty dictionary is intentionally
+    # *NOT* accessed here as "{}". Whereas each instantiation of the empty tuple
+    # efficiently reduces to the same empty tuple, each instantiation of the
+    # empty dictionary inefficiently creates a new empty dictionary: e.g.,
+    #     >>> () is ()
+    #     True
+    #     >>> {} is {}
+    #     False
+    args_defaults_kwonly = func.__kwdefaults__ or DICT_EMPTY  # type: ignore[attr-defined]
+
+    # ..................{ LOCALS ~ len                       }..................
+    # Number of both optional and mandatory positional-only parameters accepted
+    # by that callable,  standardized under Python >= 3.8 by PEP 570.
+    args_len_posonly = func_codeobj.co_posonlyargcount  # type: ignore[attr-defined]
+    assert args_len_posonly_or_flex >= args_len_posonly, (
+        f'Positional-only and flexible argument count {args_len_posonly_or_flex} < '
+        f'positional-only argument count {args_len_posonly}.')
+
+    # Number of both optional and mandatory flexible parameters accepted by
+    # that callable.
+    args_len_flex = args_len_posonly_or_flex - args_len_posonly
+
+    # Number of optional non-keyword-only parameters accepted by that callable.
+    args_len_posonly_or_flex_optional = len(args_defaults_posonly_or_flex)
+
+    # Number of optional flexible parameters accepted by that callable, defined
+    # as the number of optional non-keyword-only parameters capped to the total
+    # number of flexible parameters. Why? Because optional flexible parameters
+    # preferentially consume non-keyword-only default values first; optional
+    # positional-only parameters consume all remaining non-keyword-only default
+    # values. Why? Because:
+    # * Default values are *ALWAYS* assigned to positional parameters from
+    #   right-to-left.
+    # * Flexible parameters reside to the right of positional-only parameters.
+    #
+    # Specifically, this number is defined as...
+    args_len_flex_optional = min(
+        # If the number of optional non-keyword-only parameters exceeds the
+        # total number of flexible parameters, the total number of flexible
+        # parameters. For obvious reasons, the number of optional flexible
+        # parameters *CANNOT* exceed the total number of flexible parameters;
+        args_len_flex,
+        # Else, the total number of flexible parameters is strictly greater
+        # than the number of optional non-keyword-only parameters, implying
+        # optional flexible parameters consume all non-keyword-only default
+        # values. In this case, the number of optional flexible parameters is
+        # the number of optional non-keyword-only parameters.
+        args_len_posonly_or_flex_optional,
+    )
+
+    # Number of optional positional-only parameters accepted by that callable,
+    # defined as all remaining optional non-keyword-only parameters *NOT*
+    # already consumed by positional parameters. Note that this number is
+    # guaranteed to be non-negative. Why? Because, it is the case that either:
+    # * "args_len_posonly_or_flex_optional >= args_len_flex", in which case
+    #   "args_len_flex_optional == args_len_flex", in which case
+    #   "args_len_posonly_or_flex_optional >= args_len_flex_optional".
+    # * "args_len_posonly_or_flex_optional < args_len_flex", in which case
+    #   "args_len_flex_optional == args_len_posonly_or_flex_optional", in which
+    #   case "args_len_posonly_or_flex_optional == args_len_flex_optional".
+    #
+    # Just roll with it, folks. It's best not to question the unfathomable.
+    args_len_posonly_optional = (
+        args_len_posonly_or_flex_optional - args_len_flex_optional)
+
+    # Number of mandatory positional-only parameters accepted by that callable.
+    args_len_posonly_mandatory = args_len_posonly - args_len_posonly_optional
+
+    # Number of mandatory flexible parameters accepted by that callable.
+    args_len_flex_mandatory = args_len_flex - args_len_flex_optional
+
+    # ..................{ INTROSPECTION                      }..................
+    # 0-based index of the first parameter of the currently iterated kind
+    # accepted by that callable in the "args_name" tuple.
+    args_index_kind_first = 0
+
+    # If that callable accepts at least one mandatory positional-only
+    # parameter...
+    if args_len_posonly_mandatory:
+        # For each mandatory positional-only parameter accepted by that
+        # callable, yield a tuple describing this parameter.
+        for arg_name in args_name[
+            args_index_kind_first:args_len_posonly_mandatory]:
+            yield (ArgKind.POSITIONAL_ONLY, arg_name, ArgMandatory,)
+
+        # 0-based index of the first parameter of the next iterated kind.
+        args_index_kind_first = args_len_posonly_mandatory
+
+    # If that callable accepts at least one optional positional-only
+    # parameter...
+    if args_len_posonly_optional:
+        # 0-based index of the parameter following the last optional
+        # positional-only parameter in the "args_name" tuple.
+        args_index_kind_last_after = (
+            args_index_kind_first + args_len_posonly_optional)
+
+        # For the 0-based index of each optional positional-only parameter
+        # accepted by that callable and that parameter, yield a tuple
+        # describing this parameter.
+        for arg_index, arg_name in enumerate(args_name[
+            args_index_kind_first:args_index_kind_last_after]):
+            # assert arg_posonly_optional_index < args_len_posonly_optional, (
+            #     f'Optional positional-only parameter index {arg_posonly_optional_index} >= '
+            #     f'optional positional-only parameter count {args_len_posonly_optional}.')
+            yield (
+                ArgKind.POSITIONAL_ONLY,
+                arg_name,
+                args_defaults_posonly_or_flex[arg_index],
+            )
+
+        # 0-based index of the first parameter of the next iterated kind.
+        args_index_kind_first = args_index_kind_last_after
+
+    # If that callable accepts at least one mandatory flexible parameter...
+    if args_len_flex_mandatory:
+        # 0-based index of the parameter following the last mandatory
+        # flexible parameter in the "args_name" tuple.
+        args_index_kind_last_after = (
+            args_index_kind_first + args_len_flex_mandatory)
+
+        # For each mandatory flexible parameter accepted by that callable,
+        # yield a tuple describing this parameter.
+        for arg_name in args_name[
+            args_index_kind_first:args_index_kind_last_after]:
+            yield (ArgKind.POSITIONAL_OR_KEYWORD, arg_name, ArgMandatory,)
+
+        # 0-based index of the first parameter of the next iterated kind.
+        args_index_kind_first = args_index_kind_last_after
+
+    # If that callable accepts at least one optional flexible parameter...
+    if args_len_flex_optional:
+        # 0-based index of the parameter following the last optional
+        # flexible parameter in the "args_name" tuple.
+        args_index_kind_last_after = (
+            args_index_kind_first + args_len_flex_optional)
+
+        # For the 0-based index of each optional flexible parameter accepted by
+        # this callable and that parameter, yield a 3-tuple describing this
+        # parameter.
+        for arg_index, arg_name in enumerate(args_name[
+            args_index_kind_first:args_index_kind_last_after]):
+            # assert arg_flex_optional_index < args_len_flex_optional, (
+            #     f'Optional flexible parameter index {arg_flex_optional_index} >= '
+            #     f'optional flexible parameter count {args_len_flex_optional}.')
+            yield (
+                ArgKind.POSITIONAL_OR_KEYWORD,
+                arg_name,
+                args_defaults_posonly_or_flex[
+                    args_len_posonly_optional + arg_index],
+            )
+
+        # 0-based index of the first parameter of the next iterated kind.
+        args_index_kind_first = args_index_kind_last_after
+
+    # 0-based index of the parameter following the last keyword-only
+    # parameter in the "args_name" tuple. This index is required by multiple
+    # branches below (rather than merely one branch) and thus unconditionally
+    # computed for all these branches.
+    args_index_kind_last_after = args_index_kind_first + args_len_kwonly
+
+    # If that callable accepts a variadic positional parameter, yield a tuple
+    # describing this parameter.
+    #
+    # Note that:
+    # * This parameter is intentionally yielded *BEFORE* keyword-only
+    #   parameters to conform with syntactic standards. A variadic positional
+    #   parameter necessarily appears before any keyword-only parameters in the
+    #   signature of that callable.
+    # * The 0-based index of this parameter in the "args_name" tuple is exactly
+    #   one *AFTER* the last keyword-only parameter in that tuple if any and
+    #   one *BEFORE* the variadic keyword parameter in that tuple if any. This
+    #   idiosyncrasy is entirely the fault of CPython, which grouped the
+    #   two variadic positional and keyword parameters at the end of this list
+    #   despite syntactic constraints on their lexical position.
+    if is_arg_var_pos:
+        yield (
+            ArgKind.VAR_POSITIONAL,
+            args_name[args_index_kind_last_after],
+            ArgMandatory,
+        )
+
+    # If that callable accepts at least one keyword-only parameter...
+    if args_len_kwonly:
+        # dict.get() method repeatedly called below and thus localized for
+        # negligible efficiency. Look. Just do this. We needs godspeed.
+        args_defaults_kwonly_get = args_defaults_kwonly.get
+
+        # For each keyword-only parameter accepted by that callable, yield a
+        # tuple describing this parameter.
+        for arg_name in args_name[
+            args_index_kind_first:args_index_kind_last_after]:
+            yield (
+                ArgKind.KEYWORD_ONLY,
+                arg_name,
+                # Either:
+                # * If this is an optional keyword-only parameter, the default
+                #   value of this parameter.
+                # * If this is a mandatory keyword-only parameter, the
+                #   placeholder "ArgMandatory" singleton.
+                args_defaults_kwonly_get(arg_name, ArgMandatory),
+            )
+
+    # If that callable accepts a variadic keyword parameter...
+    if is_arg_var_kw:
+        # 0-based index of the variadic keyword parameter accepted by that
+        # callable in the "args_name" tuple, optimized by noting that Python
+        # booleans are literally integers that can be computed with. Notably:
+        # * If that callable accepts *NO* variadic positional parameter, then:
+        #       is_arg_var_pos == 0
+        #       args_index_var_kw == args_index_var_pos
+        # * If that callable accepts a variadic positional parameter, then:
+        #       is_arg_var_kw == 1
+        #       args_index_var_pos == args_index_var_pos + 1
+        args_index_kind_last_after += is_arg_var_pos
+
+        # Yield a tuple describing this parameter.
+        yield (
+            ArgKind.VAR_KEYWORD,
+            args_name[args_index_kind_last_after],
+            ArgMandatory,
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/arg/utilfuncargtest.py
@@ -0,0 +1,391 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable parameter tester utilities** (i.e., callables
+introspectively validating and testing parameters accepted by arbitrary
+callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype._util.func.arg.utilfuncargiter import (
+    ARG_META_INDEX_NAME,
+    iter_func_args,
+)
+from beartype._util.func.utilfunccodeobj import get_func_codeobj
+from beartype._data.hint.datahinttyping import (
+    Codeobjable,
+    TypeException,
+)
+from collections.abc import Callable
+from inspect import (
+    CO_VARARGS,
+    CO_VARKEYWORDS,
+)
+
+# ....................{ VALIDATORS                         }....................
+def die_unless_func_args_len_flexible_equal(
+    # Mandatory parameters.
+    func: Codeobjable,
+    func_args_len_flexible: int,
+
+    # Optional parameters.
+    is_unwrap: bool = True,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed pure-Python callable accepts the passed
+    number of **flexible parameters** (i.e., parameters passable as either
+    positional or keyword arguments).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Pure-Python callable, frame, or code object to be inspected.
+    func_args_len_flexible : int
+        Number of flexible parameters to validate this callable as accepting.
+    is_unwrap: bool, optional
+        :data:`True` only if this validator implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function to
+        unwrap this possibly higher-level wrapper into its possibly lowest-level
+        wrappee *before* returning the code object of that wrappee. Note that
+        doing so incurs worst-case time complexity :math:`O(n)` for :math:`n`
+        the number of lower-level wrappees wrapped by this wrapper. Defaults to
+        :data:`True` for robustness. Why? Because this validator *must* always
+        introspect lowest-level wrappees rather than higher-level wrappers. The
+        latter typically do *not* accurately replicate the signatures of the
+        former. In particular, decorator wrappers typically wrap decorated
+        callables with variadic positional and keyword parameters (e.g., ``def
+        _decorator_wrapper(*args, **kwargs)``). Since neither constitutes a
+        flexible parameter, this validator raises an exception when passed such
+        a wrapper with this boolean set to :data:`False`. Only set this boolean
+        to :data:`False` if you pretend to know what you're doing.
+    exception_cls : type, optional
+        Type of exception to be raised. Defaults to
+        :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing this exception message. Defaults to the
+        empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this callable either:
+
+        * Is *not* callable.
+        * Is callable but is *not* pure-Python.
+        * Is a pure-Python callable accepting either more or less than this
+          Number of flexible parameters.
+    '''
+    assert isinstance(func_args_len_flexible, int)
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.arg.utilfuncargget import (
+        get_func_args_flexible_len)
+
+    # Number of flexible parameters accepted by this callable.
+    func_args_len_flexible_actual = get_func_args_flexible_len(
+        func=func,
+        is_unwrap=is_unwrap,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # If this callable accepts more or less than this number of flexible
+    # parameters, raise an exception.
+    if func_args_len_flexible_actual != func_args_len_flexible:
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        raise exception_cls(
+            f'{exception_prefix}callable {repr(func)} flexible argument count '
+            f'{func_args_len_flexible_actual} != {func_args_len_flexible} '
+            f'(i.e., {repr(func)} accepts {func_args_len_flexible_actual} '
+            f'rather than {func_args_len_flexible} positional and/or keyword '
+            f'parameters).'
+        )
+    # Else, this callable accepts exactly this number of flexible parameters.
+
+
+#FIXME: Uncomment as needed.
+# def die_unless_func_argless(
+#     # Mandatory parameters.
+#     func: Codeobjable,
+#
+#     # Optional parameters.
+#     func_label: str = 'Callable',
+#     exception_cls: Type[Exception] = _BeartypeUtilCallableException,
+# ) -> None:
+#     '''
+#     Raise an exception unless the passed pure-Python callable is
+#     **argumentless** (i.e., accepts *no* arguments).
+#
+#     Parameters
+#     ----------
+#     func : Codeobjable
+#         Pure-Python callable, frame, or code object to be inspected.
+#     func_label : str, optional
+#         Human-readable label describing this callable in exception messages
+#         raised by this validator. Defaults to ``'Callable'``.
+#     exception_cls : type, optional
+#         Type of exception to be raised if this callable is neither a
+#         pure-Python function nor method. Defaults to
+#         :class:`_BeartypeUtilCallableException`.
+#
+#     Raises
+#     ----------
+#     exception_cls
+#         If this callable either:
+#
+#         * Is *not* callable.
+#         * Is callable but is *not* pure-Python.
+#         * Is a pure-Python callable accepting one or more parameters.
+#     '''
+#
+#     # If this callable accepts one or more arguments, raise an exception.
+#     if is_func_argless(
+#         func=func, func_label=func_label, exception_cls=exception_cls):
+#         assert isinstance(func_label, str), f'{repr(func_label)} not string.'
+#         assert isinstance(exception_cls, type), (
+#             f'{repr(exception_cls)} not class.')
+#
+#         raise exception_cls(
+#             f'{func_label} {repr(func)} not argumentless '
+#             f'(i.e., accepts one or more arguments).'
+#         )
+
+# ....................{ TESTERS ~ kind                     }....................
+def is_func_argless(
+    # Mandatory parameters.
+    func: Codeobjable,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+) -> bool:
+    '''
+    :data:`True` only if the passed pure-Python callable is **argumentless**
+    (i.e., accepts *no* arguments).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Pure-Python callable, frame, or code object to be inspected.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of fatal error. Defaults to
+        :class:`._BeartypeUtilCallableException`.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if the passed callable accepts *no* arguments.
+
+    Raises
+    ------
+    exception_cls
+         If the passed callable is *not* pure-Python.
+    '''
+
+    # Code object underlying the passed pure-Python callable unwrapped.
+    func_codeobj = get_func_codeobj(
+        func=func, is_unwrap=False, exception_cls=exception_cls)
+
+    # Return true only if this callable accepts neither...
+    return not (
+        # One or more non-variadic arguments *NOR*...
+        is_func_arg_nonvariadic(func_codeobj) or
+        # One or more variadic arguments.
+        is_func_arg_variadic(func_codeobj)
+    )
+
+# ....................{ TESTERS ~ kind : non-variadic      }....................
+#FIXME: Unit test us up, please.
+def is_func_arg_nonvariadic(func: Codeobjable) -> bool:
+    '''
+    :data:`True` only if the passed pure-Python callable accepts any
+    **non-variadic parameters** (i.e., one or more positional, positional-only,
+    keyword, or keyword-only arguments).
+
+    Parameters
+    ----------
+    func : Union[Callable, CodeType, FrameType]
+        Pure-Python callable, frame, or code object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if that callable accepts any non-variadic parameters.
+
+    Raises
+    ------
+    _BeartypeUtilCallableException
+         If that callable is *not* pure-Python.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.arg.utilfuncargget import (
+        get_func_args_nonvariadic_len)
+
+    # Return true only if this callable accepts any non-variadic parameters.
+    return bool(get_func_args_nonvariadic_len(func))
+
+# ....................{ TESTERS ~ kind : variadic          }....................
+def is_func_arg_variadic(func: Codeobjable) -> bool:
+    '''
+    :data:`True` only if the passed pure-Python callable accepts any **variadic
+    parameters** (i.e., either a variadic positional argument (e.g.,
+    ``*args``) *or* a variadic keyword argument (e.g., ``**kwargs``)).
+
+    Parameters
+    ----------
+    func : Union[Callable, CodeType, FrameType]
+        Pure-Python callable, frame, or code object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if that callable accepts either:
+
+        * Variadic positional arguments (e.g., ``*args``).
+        * Variadic keyword arguments (e.g., ``**kwargs``).
+
+    Raises
+    ------
+    _BeartypeUtilCallableException
+         If that callable is *not* pure-Python.
+    '''
+
+    # Return true only if this callable declares either...
+    #
+    # We can't believe it's this simple, either. But it is.
+    return (
+        # Variadic positional arguments *OR*...
+        is_func_arg_variadic_positional(func) or
+        # Variadic keyword arguments.
+        is_func_arg_variadic_keyword(func)
+    )
+
+
+def is_func_arg_variadic_positional(func: Codeobjable) -> bool:
+    '''
+    :data:`True` only if the passed pure-Python callable accepts a variadic
+    positional argument (e.g., ``*args``).
+
+    Parameters
+    ----------
+    func : Union[Callable, CodeType, FrameType]
+        Pure-Python callable, frame, or code object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if the passed callable accepts a variadic positional
+        argument.
+
+    Raises
+    ------
+    _BeartypeUtilCallableException
+         If the passed callable is *not* pure-Python.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the iter_func_args() iterator.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Code object underlying the passed pure-Python callable unwrapped.
+    func_codeobj = get_func_codeobj(func=func, is_unwrap=False)
+
+    # Return true only if this callable declares variadic positional arguments.
+    return func_codeobj.co_flags & CO_VARARGS != 0
+
+
+def is_func_arg_variadic_keyword(func: Codeobjable) -> bool:
+    '''
+    :data:`True` only if the passed pure-Python callable accepts a variadic
+    keyword argument (e.g., ``**kwargs``).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Pure-Python callable, frame, or code object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if the passed callable accepts a variadic keyword
+        argument.
+
+    Raises
+    ------
+    _BeartypeUtilCallableException
+         If the passed callable is *not* pure-Python.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Synchronize with the iter_func_args() iterator.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Code object underlying the passed pure-Python callable unwrapped.
+    func_codeobj = get_func_codeobj(func=func, is_unwrap=False)
+
+    # Return true only if this callable declares variadic keyword arguments.
+    return func_codeobj.co_flags & CO_VARKEYWORDS != 0
+
+# ....................{ TESTERS ~ name                     }....................
+#FIXME: *THIS TESTER IS HORRIFYINGLY SLOW*, thanks to a naive implementation
+#deferring to the slow iter_func_args() iterator. A substantially faster
+#get_func_arg_names() getter should be implemented instead and this tester
+#refactored to call that getter. How? Simple:
+#    def get_func_arg_names(func: Callable) -> Tuple[str]:
+#        # A trivial algorithm for deciding the number of arguments can be
+#        # found at the head of the iter_func_args() iterator.
+#        args_len = ...
+#
+#        # One-liners for great glory.
+#        return func.__code__.co_varnames[:args_len] # <-- BOOM
+def is_func_arg_name(func: Callable, arg_name: str) -> bool:
+    '''
+    :data:`True` only if the passed pure-Python callable accepts an argument
+    with the passed name.
+
+    Caveats
+    -------
+    **This tester exhibits worst-case time complexity** ``O(n)`` **for** ``n``
+    **the total number of arguments accepted by this callable,** due to
+    unavoidably performing a linear search for an argument with this name is
+    this callable's argument list. This tester should thus be called sparingly
+    and certainly *not* repeatedly for the same callable.
+
+    Parameters
+    ----------
+    func : Callable
+        Pure-Python callable to be inspected.
+    arg_name : str
+        Name of the argument to be searched for.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if that callable accepts an argument with this name.
+
+    Raises
+    ------
+    _BeartypeUtilCallableException
+         If the passed callable is *not* pure-Python.
+    '''
+    assert isinstance(arg_name, str), f'{arg_name} not string.'
+
+    # Return true only if...
+    return any(
+        # This is the passed name...
+        arg_meta[ARG_META_INDEX_NAME] == arg_name
+        # For the name of any parameter accepted by this callable.
+        for arg_meta in iter_func_args(func)
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/pep/utilpep484func.py
@@ -0,0 +1,39 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant **callable utilities** (i.e., callables
+specifically applicable to :pep:`484`-compliant decorators used to decorate
+user-defined callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from collections.abc import Callable
+
+# ....................{ TESTERS                            }....................
+def is_func_pep484_notypechecked(func: Callable) -> bool:
+    '''
+    ``True`` only if the passed callable was decorated by the
+    :pep:`484`-compliant :func:`typing.no_type_check` decorator instructing
+    both static and runtime type checkers to ignore that callable with respect
+    to type-checking (and thus preserve that callable as is).
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+
+    Returns
+    ----------
+    bool
+        ``True`` only if that callable was decorated by the
+        :pep:`484`-compliant :func:`typing.no_type_check` decorator.
+    '''
+
+    # Return true only if that callable declares a dunder attribute hopefully
+    # *ONLY* declared on that callable by the @typing.no_type_check decorator.
+    return getattr(func, '__no_type_check__', False) is True
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfunccode.py
@@ -0,0 +1,700 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable source code** (i.e., file providing the uncompiled
+pure-Python source code from which a compiled callable originated) utilities.
+
+This private submodule implements supplementary callable-specific utility
+functions required by various :mod:`beartype` facilities, including callables
+generated by the :func:`beartype.beartype` decorator.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: *FILE UPSTREAM CPYTHON ISSUES.* Unfortunately, this submodule exposed a
+#number of significant issues in the CPython stdlib -- all concerning parsing
+#of lambda functions. These include:
+#
+#1. The inspect.getsourcelines() function raises unexpected
+#   "tokenize.TokenError" exceptions when passed lambda functions preceded by
+#   one or more triple-quoted strings: e.g.,
+#       >>> import inspect
+#       >>> built_to_fail = (
+#       ...     ('''Uh-oh.
+#       ... ''', lambda obj: 'Oh, Gods above and/or below!'
+#       ...     )
+#       ... )
+#       >>> inspect.getsourcelines(built_to_fail[1])}
+#       tokenize.TokenError: ('EOF in multi-line string', (323, 8))
+#2. The "func.__code__.co_firstlineno" attribute is incorrect for syntactic
+#   constructs resembling:
+#       assert is_hint_pep593_beartype(Annotated[        # <--- line 1
+#           str, Is[lambda text: bool(text)]]) is True   # <--- line 2
+#   Given such a construct, the nested lambda function should have a
+#   "func.__code__.co_firstlineno" attribute whose value is "2". Instead, that
+#   attribute's value is "1". This then complicates detection of lambda
+#   functions, which are already non-trivial enough to detect. Specifically,
+#   this causes the inspect.findsource() function to either raise an unexpected
+#   "OSError" *OR* return incorrect source when passed a file containing the
+#   above snippet. In either case, that is bad. *sigh*
+#3. Introspecting the source code for two or more lambdas defined on the same
+#   line is infeasible, because code objects only record line numbers rather
+#   than both line and column numbers. Well, that's unfortunate.
+#   ^--- Actually, we're *PRETTY* sure that Python 3.11 has finally resolved
+#        this by now recording column numbers with code objects. So, let's
+#        improve the logic below to handle this edge case under Python >= 3.11.
+#FIXME: Contribute get_func_code_or_none() back to this StackOverflow question
+#as a new answer, as this is highly non-trivial, frankly:
+#    https://stackoverflow.com/questions/59498679/how-can-i-get-exactly-the-code-of-a-lambda-function-in-python/64421174#64421174
+
+# ....................{ IMPORTS                           }....................
+from ast import (
+    NodeVisitor,
+    parse as ast_parse,
+)
+from beartype.roar._roarwarn import _BeartypeUtilCallableWarning
+from beartype.typing import (
+    List,
+    Optional,
+)
+from beartype._data.hint.datahinttyping import TypeWarning
+from beartype._util.error.utilerrwarn import issue_warning
+from beartype._util.func.utilfunccodeobj import get_func_codeobj
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+from collections.abc import Callable
+from inspect import (
+    findsource,
+    getsource,
+)
+from traceback import format_exc
+
+# ....................{ GETTERS ~ code : lines             }....................
+#FIXME: Unit test us up.
+def get_func_code_lines_or_none(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    warning_cls: TypeWarning = _BeartypeUtilCallableWarning,
+) -> Optional[str]:
+    '''
+    **Line-oriented callable source code** (i.e., string concatenating the
+    subset of all lines of the on-disk Python script or module declaring the
+    passed pure-Python callable) if that callable was declared on-disk *or*
+    ``None`` otherwise (i.e., if that callable was dynamically declared
+    in-memory).
+
+    Caveats
+    ----------
+    **The higher-level** :func:`get_func_code_or_none` **getter should
+    typically be called instead.** Why? Because this lower-level getter
+    inexactly returns all lines embedding the declaration of the passed
+    callable rather than the exact substring of those lines declaring that
+    callable. Although typically identical for non-lambda functions, those two
+    strings typically differ for lambda functions. Lambda functions are
+    expressions embedded in larger statements rather than full statements.
+
+    **This getter is excruciatingly slow.** See the
+    :func:`get_func_code_or_none` getter for further commentary.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+    warning_cls : TypeWarning, optional
+        Type of warning to be emitted in the event of a non-fatal error.
+        Defaults to :class:`_BeartypeUtilCallableWarning`.
+
+    Returns
+    ----------
+    Optional[str]
+        Either:
+
+        * If the passed callable was physically declared by a file, a string
+          concatenating the subset of lines of that file declaring that
+          callable.
+        * If the passed callable was dynamically declared in-memory, ``None``.
+
+    Warns
+    ----------
+    :class:`warning_cls`
+         If the passed callable is defined by a pure-Python source code file
+         but is *not* parsable from that file. While we could allow any parser
+         exception to percolate up the call stack and halt the active Python
+         process when left unhandled, doing so would render :mod:`beartype`
+         fragile -- gaining us little and costing us much.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfuncfile import is_func_file
+    from beartype._util.text.utiltextlabel import label_callable
+
+    # If the passed callable exists on-disk and is thus pure-Python...
+    if is_func_file(func):
+        # Attempt to defer to the standard inspect.getsource() function.
+        try:
+            return getsource(func)
+        # If that function raised *ANY* exception, reduce that exception to a
+        # non-fatal warning.
+        except Exception:
+            # Reduce this fatal error to a non-fatal warning embedding a full
+            # exception traceback as a formatted string.
+            issue_warning(
+                cls=warning_cls,
+                message=f'{label_callable(func)} not parsable:\n{format_exc()}',
+            )
+    # Else, the passed callable only exists in-memory.
+
+    # Return "None" as a fallback.
+    return None
+
+
+#FIXME: Unit test us up.
+def get_func_file_code_lines_or_none(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    warning_cls: TypeWarning = _BeartypeUtilCallableWarning,
+) -> Optional[str]:
+    '''
+    **Line-oriented callable source file code** (i.e., string concatenating
+    *all* lines of the on-disk Python script or module declaring the passed
+    pure-Python callable) if that callable was declared on-disk *or* ``None``
+    otherwise (i.e., if that callable was dynamically declared in-memory).
+
+    Caveats
+    ----------
+    **This getter is excruciatingly slow.** See the
+    :func:`get_func_code_or_none` getter for further commentary.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+    warning_cls : TypeWarning, optional
+        Type of warning to be emitted in the event of a non-fatal error.
+        Defaults to :class:`_BeartypeUtilCallableWarning`.
+
+    Returns
+    ----------
+    Optional[str]
+        Either:
+
+        * If the passed callable was physically declared by an file, a string
+          concatenating *all* lines of that file.
+        * If the passed callable was dynamically declared in-memory, ``None``.
+
+    Warns
+    ----------
+    :class:`warning_cls`
+         If the passed callable is defined by a pure-Python source code file
+         but is *not* parsable from that file. While we could allow any parser
+         exception to percolate up the call stack and halt the active Python
+         process when left unhandled, doing so would render :mod:`beartype`
+         fragile -- gaining us little and costing us much.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfuncfile import is_func_file
+    from beartype._util.text.utiltextlabel import label_callable
+
+    # If the passed callable exists on-disk and is thus pure-Python...
+    if is_func_file(func):
+        # Attempt to defer to the standard inspect.findsource() function, which
+        # returns a 2-tuple "(file_code_lines, file_code_lineno_start)", where:
+        # * "file_code_lines" is a list of all lines of the script or module
+        #    declaring the passed callable.
+        # * "file_code_lineno_start" is the line number of the first such line
+        #   declaring the passed callable. Since this line number is already
+        #   provided by the "co_firstlineno" instance variable of this
+        #   callable's code object, however, there is *NO* reason whatsoever to
+        #   return this line number. Indeed, it's unclear why that function
+        #   returns this uselessly redundant metadata in the first place.
+        try:
+            # List of all lines of the file declaring the passed callable.
+            func_file_code_lines, _ = findsource(func)
+
+            # Return this list concatenated into a string.
+            return ''.join(func_file_code_lines)
+        # If that function raised *ANY* exception, reduce that exception to a
+        # non-fatal warning. While we could permit this exception to percolate
+        # up the call stack and inevitably halt the active Python process when
+        # left unhandled, doing so would render @beartype fragile -- gaining us
+        # little and costing us much.
+        #
+        # Notably, the lower-level inspect.getblock() function internally
+        # called by the higher-level findsource() function prematurely halted
+        # due to an unexpected bug in the pure-Python tokenizer leveraged by
+        # inspect.getblock(). Notably, this occurs when passing lambda
+        # functions preceded by triple-quoted strings: e.g.,
+        #     >>> import inspect
+        #     >>> built_to_fail = (
+        #     ...     ('''Uh-oh.
+        #     ... ''', lambda obj: 'Oh, Gods above and/or below!'
+        #     ...     )
+        #     ... )
+        #     >>> inspect.findsource(built_to_fail[1])}
+        #     tokenize.TokenError: ('EOF in multi-line string', (323, 8))
+        except Exception:
+            # Reduce this fatal error to a non-fatal warning embedding a full
+            # exception traceback as a formatted string.
+            issue_warning(
+                cls=warning_cls,
+                message=f'{label_callable(func)} not parsable:\n{format_exc()}',
+            )
+    # Else, the passed callable only exists in-memory.
+
+    # Return "None" as a fallback.
+    return None
+
+# ....................{ GETTERS ~ code : lambda            }....................
+# If the active Python interpreter targets Python >= 3.9 and thus defines the
+# ast.unparse() function required to decompile AST nodes into source code,
+# define the get_func_code_or_none() getter to get only the exact source code
+# substring defining a passed lambda function rather than the inexact
+# concatenation of all source code lines embedding that definition.
+if IS_PYTHON_AT_LEAST_3_9:
+    # Defer version-specific imports.
+    from ast import unparse as ast_unparse  # type: ignore[attr-defined]
+
+
+    _LAMBDA_CODE_FILESIZE_MAX = 1000000
+    '''
+    Maximum size (in bytes) of files to be safely parsed for lambda function
+    declarations by the :func:`get_func_code_or_none` getter.
+    '''
+
+
+    def get_func_code_or_none(
+        # Mandatory parameters.
+        func: Callable,
+
+        # Optional parameters.
+        warning_cls: TypeWarning = _BeartypeUtilCallableWarning,
+    ) -> Optional[str]:
+
+        # Avoid circular import dependencies.
+        from beartype._util.func.utilfunctest import is_func_lambda
+        from beartype._util.text.utiltextlabel import label_callable
+
+        # If the passed callable is a pure-Python lambda function...
+        if is_func_lambda(func):
+            # Attempt to parse the substring of the source code defining this
+            # lambda from the file providing that code.
+            #
+            # For safety, this function reduces *ALL* exceptions raised by this
+            # introspection to non-fatal warnings and returns "None". Why?
+            # Because the standard "ast" module in general and our
+            # "_LambdaNodeUnparser" class in specific are sufficiently fragile
+            # as to warrant extreme caution. AST parsing and unparsing is
+            # notoriously unreliable across different versions of different
+            # Python interpreters and compilers.
+            #
+            # Moreover, we *NEVER* call this function in a critical code path;
+            # we *ONLY* call this function to construct human-readable
+            # exception messages. Clearly, raising low-level non-human-readable
+            # exceptions when attempting to raise high-level human-readable
+            # exceptions rather defeats the entire purpose of the latter.
+            #
+            # Lastly, note that "pytest" will still fail any tests emitting
+            # unexpected warnings. In short, raising exceptions here would gain
+            # @beartype little and cost @beartype much.
+            try:
+                # String concatenating all lines of the file defining that
+                # lambda if that lambda is defined by a file *OR* "None".
+                lambda_file_code = get_func_file_code_lines_or_none(
+                    func=func, warning_cls=warning_cls)
+
+                # If that lambda is defined by a file...
+                if lambda_file_code:
+                    # Code object underlying this lambda.
+                    func_codeobj = get_func_codeobj(func)
+
+                    # If this file exceeds a sane maximum file size, emit a
+                    # non-fatal warning and safely ignore this file.
+                    if len(lambda_file_code) >= _LAMBDA_CODE_FILESIZE_MAX:
+                        issue_warning(
+                            cls=warning_cls,
+                            message=(
+                                f'{label_callable(func)} not parsable, '
+                                f'as file size exceeds safe maximum '
+                                f'{_LAMBDA_CODE_FILESIZE_MAX}MB.'
+                            ),
+                        )
+                    # Else, this file *SHOULD* be safely parsable by the
+                    # standard "ast" module without inducing a fatal
+                    # segmentation fault.
+                    else:
+                        # Abstract syntax tree (AST) parsed from this file.
+                        ast_tree = ast_parse(lambda_file_code)
+
+                        # Lambda node unparser decompiling all AST lambda nodes
+                        # encapsulating lambda functions starting at the same
+                        # line number as the passed lambda in this file.
+                        lambda_node_unparser = _LambdaNodeUnparser(
+                            lambda_lineno=func_codeobj.co_firstlineno)
+
+                        # Perform this decompilation.
+                        lambda_node_unparser.visit(ast_tree)
+
+                        # List of each code substring exactly covering each
+                        # lambda function starting at that line number.
+                        lambdas_code = lambda_node_unparser.lambdas_code
+
+                        # If one or more lambda functions start at that line
+                        # number...
+                        if lambdas_code:
+                            # If two or more lambda functions start at that
+                            # line number, emit a non-fatal warning. Since
+                            # lambda functions only provide a starting line
+                            # number rather than both starting line number
+                            # *AND* column, we have *NO* means of
+                            # disambiguating between these lambda functions and
+                            # thus *CANNOT* raise an exception.
+                            if len(lambdas_code) >= 2:
+                                # Human-readable concatenation of the
+                                # definitions of all lambda functions defined
+                                # on that line.
+                                lambdas_code_str = '\n    '.join(lambdas_code)
+
+                                # Emit this warning.
+                                issue_warning(
+                                    cls=warning_cls,
+                                    message=(
+                                        f'{label_callable(func)} ambiguous, '
+                                        f'as that line defines '
+                                        f'{len(lambdas_code)} lambdas; '
+                                        f'arbitrarily selecting first '
+                                        f'lambda:\n{lambdas_code_str}'
+                                    ),
+                                )
+                            # Else, that line number defines one lambda.
+
+                            # Return the substring covering that lambda.
+                            return lambdas_code[0]
+                        # Else, *NO* lambda functions start at that line
+                        # number. In this case, emit a non-fatal warning.
+                        #
+                        # Ideally, we would instead raise a fatal exception.
+                        # Why? Because this edge case violates expectations.
+                        # Since the passed lambda function claims it originates
+                        # from some line number of some file *AND* since that
+                        # file both exists and is parsable as valid Python, we
+                        # expect that line number to define one or more lambda
+                        # functions. If it does not, raising an exception seems
+                        # superficially reasonable. Yet, we don't. See above.
+                        else:
+                            issue_warning(
+                                cls=warning_cls,
+                                message=f'{label_callable(func)} not found.',
+                            )
+                # Else, that lambda is dynamically defined in-memory.
+            # If *ANY* of the dodgy stdlib callables (e.g., ast.parse(),
+            # inspect.findsource()) called above raise *ANY* other unexpected
+            # exception, reduce this fatal error to a non-fatal warning with an
+            # exception traceback as a formatted string.
+            #
+            # Note that the likeliest (but certainly *NOT* only) type of
+            # exception to be raised is a "RecursionError", as described by the
+            # official documentation for the ast.unparse() function:
+            #     Warning: Trying to unparse a highly complex expression would
+            #     result with RecursionError.
+            except Exception:
+                issue_warning(
+                    cls=warning_cls,
+                    message=(
+                        f'{label_callable(func)} not parsable:\n'
+                        f'{format_exc()}'
+                    ),
+                )
+        # Else, the passed callable is *NOT* a pure-Python lambda function.
+
+        # In any case, the above logic failed to introspect code for the passed
+        # callable. Defer to the get_func_code_lines_or_none() function.
+        return get_func_code_lines_or_none(func=func, warning_cls=warning_cls)
+
+
+    # Helper class instantiated above to decompile AST lambda nodes.
+    class _LambdaNodeUnparser(NodeVisitor):
+        '''
+        **Lambda node unparser** (i.e., object decompiling the abstract syntax
+        tree (AST) nodes of *all* pure-Python lambda functions defined in a
+        caller-specified block of source code into the exact substrings of that
+        block defining those lambda functions by applying the visitor design
+        pattern to an AST parsed from that block).
+
+        Attributes
+        ----------
+        lambdas_code : List[str]
+            List of one or more **source code substrings** (i.e., of one or
+            more lines of code) defining each of the one or more lambda
+            functions starting at line :attr:`_lambda_lineno` of the code from
+            which the AST visited by this visitor was parsed.
+        _lambda_lineno : int
+            Caller-requested line number (of the code from which the AST
+            visited by this object was parsed) starting the definition of the
+            lambda functions to be unparsed by this visitor.
+        '''
+
+        # ................{ INITIALIZERS                      }................
+        def __init__(self, lambda_lineno: int) -> None:
+            '''
+            Initialize this visitor.
+
+            Parameters
+            ----------
+            lambda_lineno : int
+                Caller-specific line number (of the code from which the AST
+                visited by this object was parsed) starting the definition of
+                the lambda functions to be unparsed by this visitor.
+            '''
+            assert isinstance(lambda_lineno, int), (
+                f'{repr(lambda_lineno)} not integer.')
+            assert lambda_lineno >= 0, f'{lambda_lineno} < 0.'
+
+            # Initialize our superclass.
+            super().__init__()
+
+            # Classify all passed parameters.
+            self._lambda_lineno = lambda_lineno
+
+            # Initialize all remaining instance variables.
+            self.lambdas_code: List[str] = []
+
+
+        def visit_Lambda(self, node):
+            '''
+            Visit (i.e., handle, process) the passed AST node encapsulating the
+            definition of a lambda function (parsed from the code from which
+            the AST visited by this visitor was parsed) *and*, if that lambda
+            starts on the caller-requested line number, decompile this node
+            back into the substring of this line defining that lambda.
+
+            Parameters
+            ----------
+            node : LambdaNode
+                AST node encapsulating the definition of a lambda function.
+            '''
+
+            # If the desired lambda starts on the current line number...
+            if node.lineno == self._lambda_lineno:
+                # Decompile this node into the substring of this line defining
+                # this lambda.
+                self.lambdas_code.append(ast_unparse(node))
+
+                # Recursively visit all child nodes of this lambda node. While
+                # doing so is largely useless, a sufficient number of dragons
+                # are skulking to warrant an abundance of caution and magic.
+                self.generic_visit(node)
+            # Else if the desired lambda starts on a later line number than
+            # the current line number, recursively visit all child nodes of
+            # the current lambda node.
+            elif node.lineno < self._lambda_lineno:
+                self.generic_visit(node)
+            #FIXME: Consider raising an exception here instead like
+            #"StopException" to force a premature halt to this recursion. Of
+            #course, handling exceptions also incurs a performance cost, so...
+            # Else, the desired lambda starts on an earlier line number than
+            # the current line number, the current lambda *CANNOT* be the
+            # desired lambda and is thus ignorable. In this case, avoid
+            # recursively visiting *ANY* child nodes of the current lambda node
+            # to induce a premature halt to this recursive visitation.
+# Else, the active Python interpreter targets only Python < 3.9 and thus does
+# *NOT* define the ast.unparse() function required to decompile AST nodes into
+# source code. In this case...
+else:
+    def get_func_code_or_none(
+        # Mandatory parameters.
+        func: Callable,
+
+        # Optional parameters.
+        warning_cls: TypeWarning = _BeartypeUtilCallableWarning,
+    ) -> Optional[str]:
+
+        # Defer to the get_func_code_lines_or_none() function as is.
+        return get_func_code_lines_or_none(func=func, warning_cls=warning_cls)
+
+
+get_func_code_or_none.__doc__ = '''
+**Callable source code** (i.e., substring of all lines of the on-disk Python
+script or module declaring the passed pure-Python callable) if that callable
+was declared on-disk *or* ``None`` otherwise (i.e., if that callable was
+dynamically declared in-memory).
+
+Specifically, this getter returns:
+
+* If the passed callable is a lambda function *and* active Python interpreter
+  targets Python >= 3.9 (and thus defines the ast.unparse() function required
+  to decompile AST lambda nodes into original source code), the exact substring
+  of that code declaring that lambda function.
+* Else, the concatenation of all lines of that code declaring that callable.
+
+Caveats
+----------
+**This getter is excruciatingly slow.** This getter should *only* be called
+when unavoidable and ideally *only* in performance-agnostic code paths.
+Notably, this getter finds relevant lines by parsing the script or module
+declaring the passed callable starting at the first line of that declaration
+and continuing until a rudimentary tokenizer implemented in pure-Python (with
+*no* concern for optimization and thus slow beyond all understanding of slow)
+detects the last line of that declaration. In theory, we could significantly
+optimize that routine; in practice, anyone who cares will preferably compile or
+JIT :mod:`beartype` instead.
+
+Parameters
+----------
+func : Callable
+    Callable to be inspected.
+warning_cls : TypeWarning, optional
+    Type of warning to be emitted in the event of a non-fatal error. Defaults
+    to :class:`_BeartypeUtilCallableWarning`.
+
+Returns
+----------
+Optional[str]
+    Either:
+
+    * If the passed callable was physically declared by a file, the exact
+      substring of all lines of that file declaring that callable.
+    * If the passed callable was dynamically declared in-memory, ``None``.
+
+Warns
+----------
+:class:`warning_cls`
+    If the passed callable is a pure-Python lambda function that was physically
+    declared by either:
+
+    * A large file exceeding a sane maximum file size (e.g., 1MB). Note that:
+
+      * If this is *not* explicitly guarded against, passing absurdly long
+        strings to the :func:`ast.parse` function can actually induce a
+        segmentation fault in the active Python process. This is a longstanding
+        and unresolved issue in the :mod:`ast` module. See also:
+        https://bugs.python.org/issue32758
+      * Generously assuming each line of that file contains between
+        40 to 80 characters, this maximum supports files of between 12,500 to
+        25,000 lines, which at even the lower end of that range covers most
+        real-world files of interest.
+
+    * A complex (but *not* necessarily large) file causing the recursive
+      :func:`ast.parse` or :func:`ast.unparse` function or any other :mod:`ast`
+      callable to exceed Python's recursion limit by exhausting the stack.
+    * A line of source code declaring two or more lambda functions (e.g.,
+      ``lambdas = lambda: 'and black,', lambda: 'and pale,'``). In this case,
+      the substring of code declaring the first such function is ambiguously
+      returned; all subsequent such functions are unavoidably ignored.
+
+See Also
+----------
+https://stackoverflow.com/questions/59498679/how-can-i-get-exactly-the-code-of-a-lambda-function-in-python/64421174#64421174
+    StackOverflow answer strongly inspiring this implementation.
+'''
+
+# ....................{ GETTERS ~ label                    }....................
+#FIXME: This getter no longer has a sane reason to exist. Consider excising.
+# from beartype.roar._roarexc import _BeartypeUtilCallableException
+# from beartype._cave._cavefast import CallableTypes
+# from sys import modules
+#
+# def get_func_code_label(func: Callable) -> str:
+#     '''
+#     Human-readable label describing the **origin** (i.e., uncompiled source) of
+#     the passed callable.
+#
+#     Specifically, this getter returns either:
+#
+#     * If that callable is pure-Python *and* physically declared on-disk, the
+#       absolute filename of the uncompiled on-disk Python script or module
+#       physically declaring that callable.
+#     * If that callable is pure-Python *and* dynamically declared in-memory,
+#       the placeholder string ``"<string>"``.
+#     * If that callable is C-based, the placeholder string ``"<C-based>"``.
+#
+#     Caveats
+#     ----------
+#     **This getter is intentionally implemented for speed rather than robustness
+#     against unlikely edge cases.** The string returned by this getter is *only*
+#     intended to be embedded in human-readable labels, warnings, and exceptions.
+#     Avoid using this string for *any* mission-critical purpose.
+#
+#     Parameters
+#     ----------
+#     func : Callable
+#         Callable to be inspected.
+#
+#     Returns
+#     ----------
+#     str
+#         Either:
+#
+#         * If that callable is physically declared by an uncompiled Python
+#           script or module, the absolute filename of this script or module.
+#         * Else, the placeholder string ``"<string>"`` implying that callable to
+#           have been dynamically declared in-memory.
+#
+#     Raises
+#     ------
+#     _BeartypeUtilCallableException
+#         If that callable is *not* callable.
+#
+#     See Also
+#     ----------
+#     :func:`inspect.getsourcefile`
+#         Inefficient stdlib function strongly inspiring this implementation,
+#         which has been highly optimized for use by the performance-sensitive
+#         :func:`beartype.beartype` decorator.
+#     '''
+#
+#     # If this callable is uncallable, raise an exception.
+#     if not callable(func):
+#         raise _BeartypeUtilCallableException(f'{repr(func)} not callable.')
+#     # Else, this callable is callable.
+#
+#     # Human-readable label describing the origin of the passed callable.
+#     func_origin_label = '<string>'
+#
+#     # If this callable is a standard callable rather than arbitrary class or
+#     # object overriding the __call__() dunder method...
+#     if isinstance(func, CallableTypes):
+#         # Avoid circular import dependencies.
+#         from beartype._util.func.utilfuncfile import get_func_filename_or_none
+#         from beartype._util.func.utilfuncwrap import unwrap_func_all_isomorphic
+#
+#         # Code object underlying the passed pure-Python callable unwrapped if
+#         # this callable is pure-Python *OR* "None" otherwise.
+#         func_filename = get_func_filename_or_none(unwrap_func_all_isomorphic(func))
+#
+#         # If this callable has a code object, set this label to either the
+#         # absolute filename of the physical Python module or script declaring
+#         # this callable if this code object provides that metadata *OR* a
+#         # placeholder string specific to C-based callables otherwise.
+#         func_origin_label = func_filename if func_filename else '<C-based>'
+#     # Else, this callable is *NOT* a standard callable. In this case...
+#     else:
+#         # If this callable is *NOT* a class (i.e., is an object defining the
+#         # __call__() method), reduce this callable to the class of this object.
+#         if not isinstance(func, type):
+#             func = type(func)
+#         # In either case, this callable is now a class.
+#
+#         # Fully-qualified name of the module declaring this class if this class
+#         # was physically declared by an on-disk module *OR* "None" otherwise.
+#         func_module_name = func.__module__
+#
+#         # If this class was physically declared by an on-disk module, defer to
+#         # the absolute filename of that module.
+#         #
+#         # Note that arbitrary modules need *NOT* declare the "__file__" dunder
+#         # attribute. Unlike most other core Python objects, modules are simply
+#         # arbitrary objects that reside in the "sys.modules" dictionary.
+#         if func_module_name:
+#             func_origin_label = getattr(
+#                 modules[func_module_name], '__file__', func_origin_label)
+#
+#     # Return this label.
+#     return func_origin_label
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfunccodeobj.py
@@ -0,0 +1,327 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable code object utilities** (i.e., callables introspecting
+**code objects** (i.e., instances of the :class:`CodeType` type) underlying all
+pure-Python callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import (
+    Any,
+    Optional,
+)
+from beartype._data.hint.datahinttyping import (
+    Codeobjable,
+    TypeException,
+)
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_11
+from types import (
+    CodeType,
+    FrameType,
+    FunctionType,
+    GeneratorType,
+    MethodType,
+)
+
+# ....................{ GETTERS                            }....................
+def get_func_codeobj(
+    # Mandatory parameters.
+    func: Codeobjable,
+
+    # Optional parameters.
+    is_unwrap: bool = False,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> CodeType:
+    '''
+    **Code object** (i.e., instance of the :class:`CodeType` type) underlying
+    the passed **codeobjable** (i.e., pure-Python object directly associated
+    with a code object) if this object is codeobjable *or* raise an exception
+    otherwise (e.g., if this object is *not* codeobjable).
+
+    For convenience, this getter also accepts a code object, in which case that
+    code object is simply returned as is.
+
+    Code objects have a docstring under CPython resembling:
+
+    .. code-block:: python
+
+       Code objects provide these attributes:
+           co_argcount         number of arguments (not including *, ** args
+                               or keyword only arguments)
+           co_code             string of raw compiled bytecode
+           co_cellvars         tuple of names of cell variables
+           co_consts           tuple of constants used in the bytecode
+           co_filename         name of file in which this code object was
+                               created
+           co_firstlineno      number of first line in Python source code
+           co_flags            bitmap: 1=optimized | 2=newlocals | 4=*arg |
+                               8=**arg | 16=nested | 32=generator | 64=nofree |
+                               128=coroutine | 256=iterable_coroutine |
+                               512=async_generator
+           co_freevars         tuple of names of free variables
+           co_posonlyargcount  number of positional only arguments
+           co_kwonlyargcount   number of keyword only arguments (not including
+                               ** arg)
+           co_lnotab           encoded mapping of line numbers to bytecode
+                               indices
+           co_name             name with which this code object was defined
+           co_names            tuple of names of local variables
+           co_nlocals          number of local variables
+           co_qualname         fully-qualified name with which this code object
+                               was defined (Python >= 3.11 only)
+           co_stacksize        virtual machine stack space required
+           co_varnames         tuple of names of arguments and local variables
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Codeobjable to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function to
+        unwrap this possibly higher-level wrapper into a possibly lower-level
+        wrappee *before* returning the code object of that wrappee. Note that
+        doing so incurs worst-case time complexity :math:`O(n)` for :math:`n`
+        the number of lower-level wrappees wrapped by this wrapper. Defaults to
+        :data:`False` for efficiency.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the message of any exception raised in
+        the event of a fatal error. Defaults to the empty string.
+
+    Returns
+    -------
+    CodeType
+        Code object underlying this codeobjable.
+
+    Raises
+    ------
+    exception_cls
+         If this codeobjable has *no* code object and is thus *not* pure-Python.
+    '''
+
+    # Code object underlying this callable if this callable is pure-Python *OR*
+    # "None" otherwise.
+    func_codeobj = get_func_codeobj_or_none(func=func, is_unwrap=is_unwrap)
+
+    # If this callable is *NOT* pure-Python...
+    if func_codeobj is None:
+        # Avoid circular import dependencies.
+        from beartype._util.func.utilfunctest import die_unless_func_python
+
+        # Raise an exception.
+        die_unless_func_python(
+            func=func,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+    # Else, this callable is pure-Python and this code object exists.
+
+    # Return this code object.
+    return func_codeobj  # type: ignore[return-value]
+
+
+def get_func_codeobj_or_none(
+    # Mandatory parameters.
+    #
+    # Note that the "func" parameter is intentionally annotated as "Any" rather
+    # than "Codeobjable", as this tester transparently supports *ALL* objects.
+    func: Any,
+
+    # Optional parameters.
+    is_unwrap: bool = False,
+) -> Optional[CodeType]:
+    '''
+    **Code object** (i.e., instance of the :class:`CodeType` type) underlying
+    the passed **codeobjable** (i.e., pure-Python object directly associated
+    with a code object) if this object is codeobjable *or* :data:`None`
+    otherwise (e.g., if this object is *not* codeobjable).
+
+    Specifically, if the passed object is a:
+
+    * Pure-Python function, this getter returns the code object of that
+      function (i.e., ``func.__code__``).
+    * Pure-Python bound method wrapping a pure-Python unbound function, this
+      getter returns the code object of the latter (i.e.,
+      ``func.__func__.__code__``).
+    * Pure-Python call stack frame, this getter returns the code object of the
+      pure-Python callable encapsulated by that frame (i.e., ``func.f_code``).
+    * Pure-Python generator, this getter returns the code object of that
+      generator (i.e., ``func.gi_code``).
+    * Code object, this getter returns that code object as is.
+    * Any other object, this getter raises an exception.
+
+    Caveats
+    -------
+    If ``is_unwrap``, **this callable has worst-case time complexity**
+    :math:`O(n)` **for** :math:`n` **the number of lower-level wrappees wrapped
+    by this higher-level wrapper.** That parameter should thus be disabled in
+    time-critical code paths; instead, the lowest-level wrappee returned by the
+    :func:``beartype._util.func.utilfuncwrap.unwrap_func_all` function should be
+    temporarily stored and then repeatedly passed.
+
+    Parameters
+    ----------
+    func : Any
+        Codeobjable to be inspected.
+    is_unwrap: bool, optional
+        :data:`True` only if this getter implicitly calls the
+        :func:`beartype._util.func.utilfuncwrap.unwrap_func_all` function to
+        unwrap this possibly higher-level wrapper into a possibly lower-level
+        wrappee *before* returning the code object of that wrappee. Note that
+        doing so incurs worst-case time complexity :math:`O(n)` for :math:`n`
+        the number of lower-level wrappees wrapped by this wrapper. Defaults to
+        :data:`False` for both efficiency and disambiguity.
+
+    Returns
+    -------
+    Optional[CodeType]
+        Either:
+
+        * If this codeobjable is pure-Python, the code object underlying this
+          codeobjable.
+        * Else, :data:`None`.
+
+    See Also
+    --------
+    :func:`.get_func_codeobj`
+        Further details.
+    '''
+    assert is_unwrap.__class__ is bool, f'{is_unwrap} not boolean.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfuncwrap import unwrap_func_all
+
+    # Note that:
+    # * For efficiency, tests are intentionally ordered in decreasing likelihood
+    #   of a successful match.
+    # * An equivalent algorithm could also technically be written as a chain of
+    #   "getattr(func, '__code__', None)" calls, but that doing so would both be
+    #   less efficient *AND* render this getter less robust. Why? Because the
+    #   getattr() builtin internally calls the __getattr__() and
+    #   __getattribute__() dunder methods (either of which could raise
+    #   arbitrary exceptions) and is thus considerably less safe.
+    #
+    # If this object is already a code object, return this object as is.
+    if isinstance(func, CodeType):
+        return func
+    # Else, this object is *NOT* already a code object.
+    #
+    # If this object is a pure-Python function...
+    #
+    # Note that this test intentionally leverages the standard
+    # "types.FunctionType" class rather than our equivalent
+    # "beartype.cave.FunctionType" class to avoid circular import issues.
+    elif isinstance(func, FunctionType):
+        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+        # CAUTION: Synchronize this with the same test below (for methods).
+        #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+        # Return the code object of either:
+        # * If unwrapping this function, the lowest-level wrappee wrapped by
+        #   this function.
+        # * Else, this function as is.
+        return (unwrap_func_all(func) if is_unwrap else func).__code__  # type: ignore[attr-defined]
+    # Else, this object is *NOT* a pure-Python function.
+    #
+    # If this callable is a bound method, return this method's code object.
+    #
+    # Note this test intentionally tests the standard "types.MethodType" class
+    # rather than our equivalent "beartype.cave.MethodBoundInstanceOrClassType"
+    # class to avoid circular import issues.
+    elif isinstance(func, MethodType):
+        # Unbound function underlying this bound method.
+        func = func.__func__
+
+        #FIXME: Can "MethodType" objects actually bind lower-level C-based
+        #rather than pure-Python functions? We kinda doubt it -- but maybe they
+        #can. If they can't, then this test is superfluous and should be
+        #removed with all haste.
+
+        # If this unbound function is pure-Python...
+        if isinstance(func, FunctionType):
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # CAUTION: Synchronize this with the same test above.
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # Return the code object of either:
+            # * If unwrapping this function, the lowest-level wrappee wrapped
+            #   by this function.
+            # * Else, this function as is.
+            return (unwrap_func_all(func) if is_unwrap else func).__code__  # type: ignore[attr-defined]
+    # Else, this callable is *NOT* a pure-Python bound method.
+    #
+    # If this object is a pure-Python generator, return this generator's code
+    # object.
+    elif isinstance(func, GeneratorType):
+        return func.gi_code
+    # Else, this object is *NOT* a pure-Python generator.
+    #
+    # If this object is a call stack frame, return this frame's code object.
+    elif isinstance(func, FrameType):
+        #FIXME: *SUS AF.* This is likely to behave as expected *ONLY* for frames
+        #encapsulating pure-Python callables. For frames encapsulating C-based
+        #callables, this is likely to fail with an "AttributeError" exception.
+        #That said, we have *NO* idea how to test this short of defining our own
+        #C-based callable accepting a pure-Python callable as a callback
+        #parameter and calling that callback. Are there even C-based callables
+        #like that in the wild?
+        return func.f_code
+    # Else, this object is *NOT* a call stack frame. Since none of the above
+    # tests matched, this object *MUST* be a C-based callable.
+
+    # Fallback to returning "None".
+    return None
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_func_codeobj_basename(func: Codeobjable, **kwargs) -> str:
+    '''
+    Unqualified basename (contextually depending on the version of the active
+    Python interpreter) of the passed **codeobjable** (i.e., pure-Python object
+    directly associated with a code object) if this object is codeobjable *or*
+    raise an exception otherwise (e.g., if this object is *not* codeobjable).
+
+    Specifically, this getter returns:
+
+    * If the active Python interpreter targets Python >= 3.11, the value of the
+      the ``co_qualname`` attribute on this code object.
+    * Else, the value of the ``co_name`` attribute on this code object.
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Codeobjable to be inspected.
+
+    All remaining keyword parameters are passed as is to the
+    :func:`.get_func_codeobj` getter.
+
+    Raises
+    ------
+    exception_cls
+         If this codeobjable has *no* code object and is thus *not* pure-Python.
+    '''
+
+    # Code object underlying this codeobjable if pure-Python *OR* raise an
+    # exception otherwise (i.e., if this codeobjable is C-based).
+    func_codeobj = get_func_codeobj(func, **kwargs)
+
+    # Return either...
+    return (
+        # If the active Python interpreter targets Python >= 3.11 and thus
+        # defines the "co_qualname" attribute on code objects, that attribute;
+        func_codeobj.co_qualname  # type: ignore[attr-defined]
+        if IS_PYTHON_AT_LEAST_3_11 else
+        # Else, the active Python interpreter targets Python < 3.11 and thus
+        # does *NOT* defines the "co_qualname" attribute on code objects. In
+        # this case, the "co_name" attribute instead.
+        func_codeobj.co_name
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfuncfile.py
@@ -0,0 +1,168 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable origin** (i.e., uncompiled source from which a compiled
+callable originated) utilities.
+
+This private submodule implements supplementary callable-specific utility
+functions required by various :mod:`beartype` facilities, including callables
+generated by the :func:`beartype.beartype` decorator.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: *FILE UPSTREAM CPYTHON ISSUES.* Unfortunately, this submodule exposed a
+#number of significant issues in the CPython stdlib -- all concerning parsing
+#of lambda functions. These include:
+#
+#1. The inspect.getsourcelines() function raises unexpected
+#   "tokenize.TokenError" exceptions when passed lambda functions preceded by
+#   one or more triple-quoted strings: e.g.,
+#       >>> import inspect
+#       >>> built_to_fail = (
+#       ...     ('''Uh-oh.
+#       ... ''', lambda obj: 'Oh, Gods above and/or below!'
+#       ...     )
+#       ... )
+#       >>> inspect.getsourcelines(built_to_fail[1])}
+#       tokenize.TokenError: ('EOF in multi-line string', (323, 8))
+#FIXME: Contribute get_func_code_or_none() back to this StackOverflow question
+#as a new answer, as this is highly non-trivial, frankly:
+#    https://stackoverflow.com/questions/59498679/how-can-i-get-exactly-the-code-of-a-lambda-function-in-python/64421174#64421174
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Optional
+from beartype._data.hint.datahinttyping import Codeobjable
+from beartype._util.func.utilfunccodeobj import get_func_codeobj_or_none
+from linecache import cache as linecache_cache
+
+# ....................{ TESTERS                            }....................
+def is_func_file(func: Codeobjable) -> bool:
+    '''
+    :data:`True` only if the passed callable is defined **on-disk** (e.g., by a
+    script or module whose pure-Python source code is accessible to the active
+    Python interpreter as a file on the local filesystem).
+
+    Equivalently, this tester returns :data:`False` if that callable is
+    dynamically defined in-memory (e.g., by a prior call to the :func:`exec` or
+    :func:`eval` builtins).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Codeobjable to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if the passed callable is defined on-disk.
+    '''
+
+    # One-liners for abstruse abstraction.
+    return get_func_filename_or_none(func) is not None
+
+# ....................{ GETTERS                            }....................
+def get_func_filename_or_none(func: Codeobjable, **kwargs) -> Optional[str]:
+    '''
+    Absolute filename of the file on the local filesystem containing the
+    pure-Python source code for the script or module defining the passed
+    callable if that callable is defined on-disk *or* :data:`None` otherwise
+    (i.e., if that callable is dynamically defined in-memory by a prior call to
+    the :func:`exec` or :func:`eval` builtins).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Codeobjable to be inspected.
+
+    All remaining keyword parameters are passed as is to the
+    :func:`beartype._util.func.utilfunccodeobj.get_func_codeobj` getter.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If that callable was physically declared by a file, the absolute
+          filename of that file.
+        * If that callable was dynamically declared in-memory, :data:`None`.
+    '''
+
+    # Code object underlying the passed callable if that callable is pure-Python
+    # *OR* "None" otherwise (i.e., if that callable is C-based).
+    #
+    # Note that we intentionally do *NOT* test whether this callable is
+    # explicitly pure-Python or C-based: e.g.,
+    #     # If this callable is implemented in C, this callable has no code
+    #     # object with which to inspect the filename declaring this callable.
+    #     # In this case, defer to a C-specific placeholder string.
+    #     if isinstance(func, CallableCTypes):
+    #         func_origin_label = '<C-based>'
+    #     # Else, this callable is implemented in Python. In this case...
+    #     else:
+    #         # If this callable is a bound method wrapping an unbound function,
+    #         # unwrap this method into the function it wraps. Why? Because only
+    #         # the latter provides the code object for this callable.
+    #         if isinstance(func, MethodBoundInstanceOrClassType):
+    #             func = func.__func__
+    #
+    #         # Defer to the absolute filename of the Python file declaring this
+    #         # callable, dynamically retrieved from this callable's code object.
+    #         func_origin_label = func.__code__.co_filename
+    #
+    # Why? Because PyPy. The logic above succeeds for CPython but fails for
+    # PyPy, because *ALL CALLABLES ARE C-BASED IN PYPY.* Adopting the above
+    # approach would unconditionally return the C-specific placeholder string
+    # for all callables -- including those originally declared as pure-Python in
+    # a Python module. So it goes.
+    func_codeobj = get_func_codeobj_or_none(func, **kwargs)
+
+    # If the passed callable has *NO* code object and is thus *NOT* pure-Python,
+    # that callable was *NOT* defined by a pure-Python source code file. In this
+    # case, return "None".
+    if not func_codeobj:
+        return None
+    # Else, that callable is pure-Python.
+
+    # Absolute filename of the pure-Python source code file defining that
+    # callable if this code object offers that metadata *OR* "None" otherwise.
+    #
+    # Note that we intentionally do *NOT* assume all code objects to offer this
+    # metadata (e.g., by unconditionally returning "func_codeobj.co_filename").
+    # Why? Because PyPy yet again. For inexplicable reasons, PyPy provides
+    # *ALL* C-based builtins (e.g., len()) with code objects failing to provide
+    # this metadata. Yes, this is awful. Yes, this is the Python ecosystem.
+    func_filename = getattr(func_codeobj, 'co_filename', None)
+
+    # If either this code object does not provide this filename *OR*...
+    if not func_filename or (
+        # This filename is a "<"- and ">"-bracketed placeholder string, this
+        # filename is a placeholder signifying this callable to be dynamically
+        # declared in-memory rather than by an on-disk module. Examples include:
+        # * "<string>", signifying a callable dynamically declared in-memory.
+        # * "<@beartype(...) at 0x...}>', signifying a callable dynamically
+        #   declared in-memory by the
+        #   beartype._util.func.utilfuncmake.make_func() function, possibly
+        #   cached with the standard "linecache" module.
+        func_filename[ 0] == '<' and
+        func_filename[-1] == '>' and
+        # This in-memory callable's source code was *NOT* cached with the
+        # "linecache" module and has thus effectively been destroyed.
+        func_filename not in linecache_cache
+    # Then return "None", as this filename is useless for almost all purposes.
+    ):
+        return None
+    # Else, this filename is either:
+    # * That of an on-disk module, which is good.
+    # * That of an in-memory callable whose source code was cached with the
+    #   "linecache" module. Although less good, this filename *CAN* technically
+    #   be used to recover this code by querying the "linecache" module.
+
+    # Return this filename as is, regardless of whether this file exists.
+    # Callers are responsible for performing further validation if desired.
+    # print(f'func_filename: {func_filename}')
+    return func_filename
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfuncframe.py
@@ -0,0 +1,381 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **call stack frame utilities** (i.e., callables introspecting the
+current stack of frame objects, encapsulating the linear chain of calls to
+external callables underlying the call to the current callable).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+import sys
+from beartype.roar._roarexc import _BeartypeUtilCallFrameException
+from beartype.typing import (
+    Callable,
+    Iterable,
+    Optional,
+)
+from beartype._cave._cavefast import CallableFrameType
+from beartype._data.hint.datahinttyping import TypeException
+
+# ....................{ GETTERS                            }....................
+#FIXME: Mypy insists this getter can return "None" in certain edge cases. But...
+#what are those? Official documentation is seemingly silent on the issue. *sigh*
+get_frame: Optional[Callable[[int], Optional[CallableFrameType]]] = getattr(
+    sys, '_getframe', None)
+'''
+Private low-level :func:`sys._getframe` getter if the active Python interpreter
+declares this getter *or* :data:`None` otherwise (i.e., if this interpreter does
+*not* declare this getter).
+
+All standard Python interpreters supported by this package including both
+CPython *and* PyPy declare this getter. Ergo, this attribute should *always* be
+a valid callable rather than :data:`None`.
+
+If this getter is *not* :data:`None`, this getter's signature and docstring
+under CPython resembles:
+
+::
+
+    _getframe([depth]) -> frameobject
+
+    Return a frame object from the call stack.  If optional integer depth is
+    given, return the frame object that many calls below the top of the
+    stack. If that is deeper than the call stack, ValueError is raised. The
+    default for depth is zero, returning the frame at the top of the call
+    stack.
+
+    Frame objects provide these attributes:
+        f_back          next outer frame object (this frame's caller)
+        f_builtins      built-in namespace seen by this frame
+        f_code          code object being executed in this frame
+        f_globals       global namespace seen by this frame
+        f_lasti         index of last attempted instruction in bytecode
+        f_lineno        current line number in Python source code
+        f_locals        local namespace seen by this frame
+        f_trace         tracing function for this frame, or None
+
+Parameters
+----------
+depth : int
+    0-based index of the stack frame on the current call stack to be returned.
+    Defaults to 0, signifying the stack frame encapsulating the lexical scope
+    directly calling this getter.
+
+Returns
+-------
+CallableFrameType
+    Stack frame with the passed index on the current call stack.
+
+Raises
+------
+ValueError
+     If this index exceeds the **height** (i.e., total number of stack frames)
+     of the current call stack.
+'''
+
+#FIXME: Preserve until we inevitably require this getter, please.
+#def get_frame_or_none(ignore_frames: int) -> Optional[FrameType]:
+#    try:
+#        return get_frame(ignore_frames + 1)
+#    except ValueError:
+#        return None
+#def get_frame_caller_or_none() -> Optional[FrameType]:
+#    return get_frame_or_none(ignore_frames=2)
+
+# ....................{ GETTERS ~ name                     }....................
+#FIXME: Unit test us up, please.
+def get_frame_package_name(
+    # Mandatory parameters.
+    frame: CallableFrameType,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallFrameException,
+) -> Optional[str]:
+    '''
+    Fully-qualified name of the parent package of the child module declaring the
+    callable whose code object is that of the passed **stack frame** (i.e.,
+    :class:`types.CallableFrameType` instance encapsulating all metadata
+    describing a single call on the current call stack) if module has a parent
+    package *or* the empty string otherwise (e.g., if that module is either a
+    top-level module or script residing outside any parent package structure).
+
+    Parameters
+    ----------
+    frame : CallableFrameType
+        Stack frame to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallFrameException`.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If the callable described by this frame resides in a package, the
+          fully-qualified name of that package.
+        * Else, :data:`None`.
+
+    Raises
+    ------
+    exception_cls
+         If that callable has *no* code object and is thus *not* pure-Python.
+
+    See Also
+    --------
+    :func:`beartype._util.func.utilfunccodeobj.get_func_codeobj_basename`
+        Related getter getting the unqualified basename of that callable.
+    '''
+    assert isinstance(frame, CallableFrameType), (
+        f'{repr(frame)} not stack frame.')
+
+    # Fully-qualified name of the parent package of the child module declaring
+    # the callable whose code object is that of this stack frame's if that
+    # module declares its name *OR* the empty string otherwise (e.g., if that
+    # module is either a top-level module or script residing outside any parent
+    # package structure).
+    frame_package_name = frame.f_globals.get('__package__')
+
+    # Return the name of this parent package.
+    return frame_package_name
+
+
+#FIXME: Unit test us up, please.
+def get_frame_module_name(
+    # Mandatory parameters.
+    frame: CallableFrameType,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallFrameException,
+) -> Optional[str]:
+    '''
+    Fully-qualified name of the module declaring the callable whose code object
+    is that of the passed **stack frame** (i.e.,
+    :class:`types.CallableFrameType` instance encapsulating all metadata
+    describing a single call on the current call stack).
+
+    Parameters
+    ----------
+    frame : CallableFrameType
+        Stack frame to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If the callable described by this frame resides in a module, the
+          fully-qualified name of that module.
+        * Else, :data:`None`.
+
+    See Also
+    --------
+    :func:`beartype._util.func.utilfunccodeobj.get_func_codeobj_basename`
+        Related getter getting the unqualified basename of that callable.
+    '''
+    assert isinstance(frame, CallableFrameType), (
+        f'{repr(frame)} not stack frame.')
+
+    # Fully-qualified name of the module declaring the callable described by
+    # this frame.
+    frame_module_name = frame.f_globals.get('__name__')
+
+    # Return this name.
+    return frame_module_name
+
+
+#FIXME: Preserved for posterity. Currently unused, but potentially useful.
+# from beartype._data.func.datafunccodeobj import FUNC_CODEOBJ_NAME_MODULE
+# #FIXME: Unit test us up, please.
+# def get_frame_name(
+#     # Mandatory parameters.
+#     frame: CallableFrameType,
+#
+#     # Optional parameters.
+#     exception_cls: TypeException = _BeartypeUtilCallFrameException,
+# ) -> str:
+#     '''
+#     Fully-qualified name of the callable whose code object is that of the passed
+#     **stack frame** (i.e., :class:`types.CallableFrameType` instance
+#     encapsulating all metadata describing a single call on the current call
+#     stack).
+#
+#     Parameters
+#     ----------
+#     frame : CallableFrameType
+#         Stack frame to be inspected.
+#
+#     Returns
+#     -------
+#     str
+#         Fully-qualified name of the callable described by this frame.
+#     '''
+#
+#     # Avoid circular import dependencies.
+#     from beartype._util.func.utilfunccodeobj import get_func_codeobj_basename
+#
+#     # Fully-qualified name of the module declaring the callable described by
+#     # this frame.
+#     frame_module_name = get_frame_module_name(
+#         frame=frame, exception_cls=exception_cls)
+#
+#     # Unqualified basename of that callable.
+#     frame_basename = get_func_codeobj_basename(
+#         func=frame, exception_cls=exception_cls)
+#
+#     # Possibly fully-qualified name of that callable, defined as either...
+#     frame_name = (
+#         # If that callable is *NOT* actually a callable but instead the
+#         # top-level lexical scope of a module, omit the prefixing module name
+#         # (which is, in any case, the meaningless magic string "<module>");
+#         frame_basename
+#         if frame_module_name == FUNC_CODEOBJ_NAME_MODULE else
+#         # Else, that callable is actually a callable. In this case, prefix the
+#         # unqualified basename of that callable by the fully-qualified name of
+#         # the module declaring that callable.
+#         f'{frame_module_name}.{frame_basename}'
+#     )
+#
+#     # Return this name.
+#     return frame_name
+
+# ....................{ ITERATORS                          }....................
+def iter_frames(
+    # Optional parameters.
+    func_stack_frames_ignore: int = 0,
+) -> Iterable[CallableFrameType]:
+    '''
+    Generator yielding one **frame** (i.e., :class:`types.CallableFrameType` instance)
+    for each call on the current **call stack** (i.e., stack of frame objects,
+    encapsulating the linear chain of calls to external callables underlying
+    the current call to this callable).
+
+    Notably, for each:
+
+    * **C-based callable call** (i.e., call of a C-based rather than
+      pure-Python callable), this generator yields one frame encapsulating *no*
+      code object. Only pure-Python frame objects have code objects.
+    * **Class-scoped callable call** (i.e., call of an arbitrary callable
+      occurring at class scope rather than from within the body of a callable
+      or class, typically due to a method being decorated), this generator
+      yields one frame ``func_frame`` for that class ``cls`` such that
+      ``func_frame.f_code.co_name == cls.__name__`` (i.e., the name of the code
+      object encapsulated by that frame is the unqualified name of the class
+      encapsulating the lexical scope of this call). Actually, we just made all
+      of that up. That is *probably* (but *not* necessarily) the case. Research
+      is warranted.
+    * **Module-scoped callable call** (i.e., call of an arbitrary callable
+      occurring at module scope rather than from within the body of a callable
+      or class, typically due to a function or class being decorated), this
+      generator yields one frame ``func_frame`` such that
+      ``func_frame.f_code.co_name == '<module>'`` (i.e., the name of the code
+      object encapsulated by that frame is the placeholder string assigned by
+      the active Python interpreter to all scopes encapsulating the top-most
+      lexical scope of a module in the current call stack).
+
+    The above constraints imply that frames yielded by this generator *cannot*
+    be assumed to encapsulate code objects. See the "Examples" subsection for
+    standard logic handling this edge case.
+
+    Caveats
+    -------
+    **This high-level iterator requires the private low-level**
+    :func:`sys._getframe` **getter.** If that getter is undefined, this iterator
+    reduces to the empty generator yielding nothing rather than raising an
+    exception. Since all standard Python implementations (e.g., CPython, PyPy)
+    define that getter, this should typically *not* be a real-world concern.
+
+    Parameters
+    ----------
+    func_stack_frames_ignore : int, optional
+        Number of frames on the call stack to be ignored (i.e., silently
+        incremented past). Defaults to 0.
+
+    Returns
+    -------
+    Iterable[CallableFrameType]
+        Generator yielding one frame for each call on the current call stack.
+
+    See Also
+    --------
+    :func:`.get_frame`
+        Further details on stack frame objects.
+
+    Examples
+    --------
+        >>> from beartype._util.func.utilfunccodeobj import (
+        ...     get_func_codeobj_or_none)
+        >>> from beartype._util.func.utilfuncframe import iter_frames
+
+        # For each stack frame on the call stack...
+        >>> for func_frame in iter_frames():
+        ...     # Code object underlying this frame's scope if this scope is
+        ...     # pure-Python *OR* "None" otherwise.
+        ...     func_frame_codeobj = get_func_codeobj_or_none(func_frame)
+        ...
+        ...     # If this code object does *NOT* exist, this scope is C-based.
+        ...     # In this case, silently ignore this scope and proceed to the
+        ...     # next frame in the call stack.
+        ...     if func_frame_codeobj is None:
+        ...         continue
+        ...     # Else, this code object exists, implying this scope to be
+        ...     # pure-Python.
+        ...
+        ...     # Fully-qualified name of this scope's module.
+        ...     func_frame_module_name = func_frame.f_globals['__name__']
+        ...
+        ...     # Unqualified name of this scope.
+        ...     func_frame_name = func_frame_codeobj.co_name
+        ...
+        ...     # Print the fully-qualified name of this scope.
+        ...     print(f'On {func_frame_module_name}.{func_frame_name}()!')
+    '''
+    assert isinstance(func_stack_frames_ignore, int), (
+        f'{func_stack_frames_ignore} not integer.')
+    assert func_stack_frames_ignore >= 0, (
+        f'{func_stack_frames_ignore} negative.')
+
+    # If the active Python interpreter fails to declare the private
+    # sys._getframe() getter, reduce to the empty generator (i.e., noop).
+    if get_frame is None:  # pragma: no cover
+        yield from ()
+        return
+    # Else, the active Python interpreter declares the sys._getframe() getter.
+
+    # Attempt to obtain the...
+    try:
+        # Next non-ignored frame following the last ignored frame, ignoring an
+        # additional frame embodying the current call to this iterator.
+        func_frame = get_frame(func_stack_frames_ignore + 1)  # type: ignore[misc]
+    # If doing so raises a "ValueError" exception...
+    except ValueError as value_error:
+        # Whose message matches this standard boilerplate, the caller requested
+        # that this generator ignore more stack frames than currently exist on
+        # the call stack. Permitting this exception to unwind the call stack
+        # would only needlessly increase the fragility of this already fragile
+        # mission-critical generator. Instead, swallow this exception and
+        # silently reduce to the empty generator (i.e., noop).
+        if str(value_error) == 'call stack is not deep enough':
+            yield from ()
+            return
+        # Whose message does *NOT* match this standard boilerplate, an
+        # unexpected exception occurred. In this case, re-raise this exception.
+
+        raise
+    # Else, doing so raised *NO* "ValueError" exception.
+    # print(f'start frame: {repr(func_frame)}')
+
+    # While at least one frame remains on the call stack...
+    while func_frame:
+        # print(f'current frame: {repr(func_frame)}')
+
+        # Yield this frame to the caller.
+        yield func_frame
+
+        # Iterate to the next frame on the call stack.
+        func_frame = func_frame.f_back
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfuncget.py
@@ -0,0 +1,192 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable getters** (i.e., utility functions dynamically
+querying and retrieving various properties of passed callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import (
+    Callable,
+    Optional,
+)
+from beartype._cave._cavefast import MethodBoundInstanceOrClassType
+from beartype._data.hint.datahinttyping import (
+    HintAnnotations,
+    TypeException,
+)
+
+# ....................{ GETTERS ~ descriptors              }....................
+#FIXME: Unit test us up, please.
+#FIXME: Docstring us up, please.
+def get_func_boundmethod_self(
+    # Mandatory parameters.
+    func: MethodBoundInstanceOrClassType,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> object:
+    '''
+    Instance object to which the passed **C-based bound instance method
+    descriptor** (i.e., callable implicitly instantiated and assigned on the
+    instantiation of an object whose class declares an instance function (whose
+    first parameter is typically named ``self``) as an instance variable of that
+    object such that that callable unconditionally passes that object as the
+    value of that first parameter on all calls to that callable) was bound as an
+    instance attribute at instantiation time.
+
+    Parameters
+    ----------
+    func : object
+        Bound method descriptor to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilCallableWrapperException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    object
+        Instance object to which this bound method descriptor is bound to.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a bound method descriptor.
+
+    See Also
+    --------
+    :func:`beartype._util.func.utilfunctest.is_func_boundmethod`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import die_unless_func_boundmethod
+
+    # If this object is *NOT* a class method descriptor, raise an exception.
+    die_unless_func_boundmethod(
+        func=func,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this object is a class method descriptor.
+
+    # Return the pure-Python function wrapped by this descriptor. Just do it!
+    return func.__self__
+
+# ....................{ GETTERS ~ hints                    }....................
+#FIXME: Refactor all unsafe access of the low-level "__annotations__" dunder
+#attribute to instead call this high-level getter, please.
+#FIXME: Unit test us up, please.
+def get_func_annotations(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> HintAnnotations:
+    '''
+    **Annotations** (i.e., dictionary mapping from the name of each annotated
+    parameter or return of the passed pure-Python callable to the type hint
+    annotating that parameter or return) of that callable.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    HintAnnotations
+        Annotations of that callable.
+
+    Raises
+    ------
+    exception_cls
+         If that callable is *not* actually a pure-Python callable.
+
+    See Also
+    --------
+    :func:`.get_func_annotations_or_none`
+        Further details.
+    '''
+
+    # Annotations of that callable if that callable is actually a pure-Python
+    # callable *OR* "None" otherwise.
+    hint_annotations = get_func_annotations_or_none(func)
+
+    # If that callable is *NOT* pure-Python, raise an exception.
+    if hint_annotations is None:
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # If that callable is uncallable, raise an appropriate exception.
+        if not callable(func):
+            raise exception_cls(f'{exception_prefix}{repr(func)} not callable.')
+        # Else, that callable is callable.
+
+        # Raise a human-readable exception.
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} not pure-Python function.')
+    # Else, that callable is pure-Python.
+
+    # Return these annotations.
+    return hint_annotations
+
+
+#FIXME: Refactor all unsafe access of the low-level "__annotations__" dunder
+#attribute to instead call this high-level getter, please.
+#FIXME: Unit test us up, please.
+def get_func_annotations_or_none(func: Callable) -> Optional[HintAnnotations]:
+    '''
+    **Annotations** (i.e., dictionary mapping from the name of each annotated
+    parameter or return of the passed pure-Python callable to the type hint
+    annotating that parameter or return) of that callable if that callable is
+    actually a pure-Python callable *or* :data:`None` otherwise (i.e., if that
+    callable is *not* a pure-Python callable).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[HintAnnotations]
+        Either:
+
+        * If that callable is actually a pure-Python callable, the annotations
+          of that callable.
+        * Else, :data:`None`.
+    '''
+
+    # Demonstrable monstrosity demons!
+    #
+    # Note that the "__annotations__" dunder attribute is guaranteed to exist
+    # *ONLY* for standard pure-Python callables. Various other callables of
+    # interest (e.g., functions exported by the standard "operator" module) do
+    # *NOT* necessarily declare that attribute. Since this tester is commonly
+    # called in general-purpose contexts where this guarantee does *NOT*
+    # necessarily hold, we intentionally access that attribute safely albeit
+    # somewhat more slowly via getattr().
+    return getattr(func, '__annotations__', None)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfuncmake.py
@@ -0,0 +1,425 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable factories** (i.e., low-level functions dynamically
+creating and returning new in-memory callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import Optional
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    TypeException,
+)
+from beartype._util.text.utiltextlabel import label_exception
+from beartype._util.text.utiltextmunge import number_str_lines
+from beartype._util.utilobject import get_object_name
+from collections.abc import Callable
+from functools import update_wrapper
+from linecache import cache as linecache_cache  # type: ignore[attr-defined]
+from weakref import finalize
+
+# ....................{ MAKERS                             }....................
+def make_func(
+    # Mandatory arguments.
+    func_name: str,
+    func_code: str,
+
+    # Optional arguments.
+    func_globals: Optional[LexicalScope] = None,
+    func_locals: Optional[LexicalScope] = None,
+    func_doc: Optional[str] = None,
+    func_label: Optional[str] = None,
+    func_wrapped: Optional[Callable] = None,
+    is_debug: bool = False,
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+) -> Callable:
+    '''
+    Dynamically create and return a new function with the passed name declared
+    by the passed code snippet and internally accessing the passed dictionaries
+    of globally and locally scoped variables.
+
+    Parameters
+    ----------
+    func_name : str
+        Name of the function to be created.
+    func_code : str
+        Code snippet defining this function, including both this function's
+        signature prefixed by zero or more decorations *and* body. **This
+        snippet must be unindented.** If this snippet is indented, this factory
+        raises a syntax error.
+    func_globals : dict[str, Any] | None
+        Dictionary mapping from the name to value of each **globally scoped
+        attribute** (i.e., internally referenced in the body of the function
+        declared by this code snippet). Defaults to the empty dictionary.
+    func_locals : dict[str, Any] | None
+        Dictionary mapping from the name to value of each **locally scoped
+        attribute** (i.e., internally referenced either in the signature of
+        the function declared by this code snippet *or* as decorators
+        decorating that function). **Note that this factory necessarily
+        modifies the contents of this dictionary.** Defaults to the empty
+        dictionary.
+    func_doc : str | None
+        Human-readable docstring documenting this function. Defaults to
+        :data:`None`, in which case this function remains undocumented.
+    func_label : str | None
+        Human-readable label describing this function for error-handling
+        purposes. Defaults to :data:`None`, in which case this label effectively
+        defaults to ``"{func_name}()"``.
+    func_wrapped : Callable | None
+        Callable wrapped by the function to be created. If non-:data:`None`,
+        special dunder attributes will be propagated (i.e., copied) from this
+        wrapped callable into this created function; these include:
+
+        * ``__name__``, this function's unqualified name.
+        * ``__doc__``, this function's docstring.
+        * ``__module__``, the fully-qualified name of this function's module.
+
+        Defaults to :data:`None`.
+    is_debug : bool, optional
+        :data:`True` only if this function is being debugged. If :data:`True`,
+        then the definition (including signature and body) of this function is:
+
+        * Printed to standard output.
+        * Cached with the standard :mod:`linecache` module under a fake
+          filename uniquely synthesized by this factory for this function.
+          External callers may then subsequently access the definition of this
+          function from that module as:
+
+          .. code-block:: python
+
+             from linecache import cache as linecache_cache
+             func_source = linecache_cache[func.__code__.co_filename]
+
+        Defaults to :data:`False`.
+    exception_cls : Type[Exception], optional
+        Type of exception to raise in the event of a fatal error. Defaults to
+        :exc:`._BeartypeUtilCallableException`.
+
+    Returns
+    -------
+    Callable
+        Function with this name declared by this snippet.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * ``func_locals`` contains a key whose value is that of ``func_name``,
+          implying the caller already declared a local attribute whose name
+          collides with that of this function.
+        * This code snippet is syntactically invalid.
+        * This code snippet is syntactically valid but fails to declare a
+          function with this name.
+    '''
+
+    # ..................{ VALIDATION ~ pre                   }..................
+    assert isinstance(func_name, str), f'{repr(func_name)} not string.'
+    assert isinstance(func_code, str), f'{repr(func_code)} not string.'
+    assert isinstance(is_debug, bool), f'{repr(is_debug)} not bool.'
+    assert func_name, 'Parameter "func_name" empty.'
+    assert func_code, 'Parameter "func_code" empty.'
+
+    # Default all unpassed parameters.
+    if func_globals is None:
+        func_globals = {}
+    if func_locals is None:
+        func_locals = {}
+    if func_label is None:
+        func_label = f'{func_name}()'
+    assert isinstance(func_globals, dict), (
+        f'{repr(func_globals)} not dictionary.')
+    assert isinstance(func_locals, dict), (
+        f'{repr(func_locals)} not dictionary.')
+    assert isinstance(func_label, str), f'{repr(func_label)} not string.'
+
+    # If that function's name is already in this local scope, the caller
+    # already declared a local attribute whose name collides with that
+    # function's. In this case, raise an exception for safety.
+    if func_name in func_locals:
+        raise exception_cls(
+            f'{func_label} already defined by caller locals:\n'
+            f'{repr(func_locals)}'
+        )
+    # Else, that function's name is *NOT* already in this local scope.
+
+    # ..................{ STARTUP ~ filename                 }..................
+    # Note that this logic is intentionally performed *BEFORE* munging the
+    # "func_code" string in-place below, as this logic depends upon the unique
+    # ID of that string. Reassignment obliterates that uniqueness.
+
+    # Arbitrary object uniquely associated with this function.
+    func_filename_object: object = None
+
+    # Possibly fully-qualified name of an arbitrary object uniquely associated
+    # with this function.
+    func_filename_name: str = None  # type: ignore[assignment]
+
+    # If this function is a high-level wrapper wrapping a lower-level
+    # wrappee, uniquify the subsequent filename against this wrappee. This
+    # wrappee's fully-qualified name guarantees the uniqueness of this
+    # filename. Ergo, this is the ideal case.
+    if func_wrapped:
+        func_filename_name = get_object_name(func_wrapped)
+        func_filename_object = func_wrapped
+    # Else, this function is *NOT* such a wrapper. In this less ideal case,
+    # fallback to a poor man's uniquification against the unqualified name and
+    # code string underlying this function.
+    else:
+        func_filename_name = func_name
+        func_filename_object = func_code
+
+    # Fake in-memory filename hopefully unique to this function.
+    # Optimistically, a fully-qualified object name and ID *SHOULD* be unique
+    # for the lifetime of the active Python process.
+    #
+    # Specifically, this filename guarantees the uniqueness of the 3-tuple
+    # ``({func_filename}, {func_file_line_number}, {func_name})`` commonly
+    # leveraged by profilers (e.g., "cProfile") to identify arbitrary callables,
+    # where:
+    # * `{func_filename}` is this filename (e.g.,
+    #   `"</home/leycec/py/betse/betse/lib/libs.py:beartype({func_name})>"`).
+    # * `{func_file_line_number}`, is *ALWAYS* 0 and thus *NEVER* unique.
+    # * `{func_name}`, is identical to that of the decorated callable and also
+    #   thus *NEVER* unique.
+    #
+    # Ergo, uniquifying this filename is the *ONLY* means of uniquifying
+    # metadata identifying this wrapper function via runtime inspection. Failure
+    # to do so reduces tracebacks induced by exceptions raised by this wrapper
+    # to non-human-readability, which is less than ideal: e.g.,
+    #
+    #    Traceback (most recent call last):
+    #      File "/home/leycec/py/betsee/betsee/gui/simconf/stack/widget/mixin/guisimconfwdgeditscalar.py", line 313, in _set_alias_to_widget_value_if_sim_conf_open
+    #        widget=self, value_old=self._widget_value_last)
+    #      File "<string>", line 25, in func_beartyped
+    #      File "/home/leycec/py/betsee/betsee/gui/simconf/stack/widget/mixin/guisimconfwdgeditscalar.py", line 409, in __init__
+    #        *args, widget=widget, synopsis=widget.undo_synopsis, **kwargs)
+    #      File "<string>", line 13, in func_beartyped
+    #
+    # See the final traceback line, which is effectively useless.
+    func_filename = (
+        f'<@beartype({func_filename_name}) at {id(func_filename_object):#x}>')
+
+    # ..................{ STARTUP ~ code                     }..................
+    # Code snippet defining this function, stripped of all leading and trailing
+    # whitespace to improve both readability and disambiguity. Since this
+    # whitespace is safely ignorable, the original snippet is safely
+    # replaceable by this stripped snippet.
+    func_code = func_code.strip()
+
+    # If debugging this function, print the definition of this function.
+    if is_debug:
+        print(f'{number_str_lines(func_code)}')
+    # else:
+    #     print('!!!!!!!!!PRINTING NOTHING!!!!!!!!!!!')
+    # Else, leave that definition obscured by the voracious bitbuckets of time.
+
+    # ..................{ CREATION                           }..................
+    # Attempt to...
+    try:
+        # Call the more verbose and obfuscatory compile() builtin instead of
+        # simply calling "exec(func_code, func_globals, func_locals)". Why?
+        # Because the exec() builtin does *NOT* provide a means to set this
+        # function's "__code__.co_filename" read-only attribute.
+        #
+        # Note that we could pass "single" instead of "exec" here if we were
+        # willing to constrain the passed "func_code" to a single statement. In
+        # casual testing, there is very little performance difference between
+        # the two (with an imperceptibly slight edge going to "single").
+        func_code_compiled = compile(func_code, func_filename, 'exec')
+        assert func_name not in func_locals
+
+        # Define that function. For obscure and likely uninteresting reasons,
+        # Python fails to capture that function (i.e., expose that function to
+        # this factory) when the locals() dictionary is passed; instead, a
+        # unique local dictionary *MUST* be passed.
+        exec(func_code_compiled, func_globals, func_locals)
+    # If doing so fails for *ANY* reason whatsoever, wrap that low-level
+    # exception with a higher-level exception exhibiting the exact issue. Doing
+    # so enables users to submit meaningful issues to our tracker.
+    except Exception as exception:
+        # Raise an exception suffixed by that function's declaration such that
+        # each line of that declaration is prefixed by that line's number. This
+        # renders "SyntaxError" exceptions referencing arbitrary line numbers
+        # human-readable: e.g.,
+        #       File "<string>", line 56
+        #         if not (
+        #          ^
+        #     SyntaxError: invalid syntax
+        raise exception_cls(
+            f'{func_label} unparseable, as @beartype generated '
+            f'invalid code raising "{label_exception(exception)}":\n\n'
+            f'{number_str_lines(func_code)}'
+        ) from exception
+
+    # ..................{ VALIDATION ~ post                  }..................
+    # If that function's name is *NOT* in this local scope, this code snippet
+    # failed to declare that function. In this case, raise an exception.
+    if func_name not in func_locals:
+        raise exception_cls(
+            f'{func_label} undefined by code snippet:\n\n'
+            f'{number_str_lines(func_code)}'
+        )
+    # Else, that function's name is in this local scope.
+
+    # Function declared by this code snippet.
+    func: Callable = func_locals[func_name]  # type: ignore[assignment]
+
+    # If that function is uncallable, raise an exception.
+    if not callable(func):
+        raise exception_cls(
+            f'{func_label} defined by code snippet uncallable:\n\n'
+            f'{number_str_lines(func_code)}'
+        )
+    # Else, that function is callable.
+    #
+    # If that function is a wrapper wrapping a wrappee callable, propagate
+    # dunder attributes from that wrappee onto this wrapper.
+    elif func_wrapped is not None:
+        assert callable(func_wrapped), f'{repr(func_wrapped)} uncallable.'
+        update_wrapper(wrapper=func, wrapped=func_wrapped)
+    # Else, that function is *NOT* such a wrapper.
+
+    # ..................{ CLEANUP                            }..................
+    # If that function is documented...
+    #
+    # Note that function is intentionally documented *AFTER* propagating dunder
+    # attributes to enable callers to explicitly overwrite documentation
+    # propagated from that wrappee onto this wrapper.
+    if func_doc is not None:
+        assert isinstance(func_doc, str), f'{repr(func_doc)} not string.'
+        assert func_doc, '"func_doc" empty.'
+
+        # Document that function.
+        func.__doc__ = func_doc
+    # Else, that function is undocumented.
+
+    # If debugging this function...
+    if is_debug:
+        # Render this function debuggable (e.g., via the standard "pdb" module)
+        # by exposing this function's definition to the standard "linecache"
+        # module under the fake filename synthesized above.
+        #
+        # Technically, we *COULD* slightly improve the uniquification of this
+        # filename for the uncommon edge case when this function does *NOT*
+        # wrap a lower-level wrappee (e.g., by embedding the ID of this
+        # function that now exists rather than an arbitrary string object).
+        # Pragmatically, doing so would prevent external callers from trivially
+        # retrieving this function's definition from "linecache". Why? Because
+        # reusing the "func_filename" string embedded in this function as
+        # "func.__code__.co_filename" trivializes this lookup for callers.
+        # Ultimately, sane lookup >>> slightly uniquer filename.
+        linecache_cache[func_filename] = (  # type: ignore[assignment]
+            len(func_code),  # type: ignore[assignment]  # Y u gotta b diff'rnt Python 3.7? WHY?!
+            None,  # usually mtime for determining when to discard files, but
+                   # providing None instructs linecache to no-op (never discard)
+            func_code.splitlines(keepends=True),
+            func_filename,
+        )
+
+        # Define and register a cleanup callback removing that function's
+        # linecache entry called if and when that function is
+        # garbage-collected.
+        def _remove_func_linecache_entry():
+            linecache_cache.pop(func_filename, None)
+        finalize(func, _remove_func_linecache_entry)
+    # Else, this function is *NOT* being debugged.
+
+    # Return that function.
+    return func
+
+# ....................{ COPIERS                            }....................
+#FIXME: Consider excising. Although awesome, this is no longer needed.
+# from beartype._util.func.utilfunctest import die_unless_func_python
+# from types import FunctionType
+# def copy_func_shallow(
+#     # Mandatory arguments.
+#     func: Callable,
+#
+#     # Optional arguments.
+#     exception_cls: Type[Exception] = _BeartypeUtilCallableException,
+# ) -> Callable:
+#     '''
+#     Create and return a new shallow copy of the passed callable.
+#
+#     Specifically, this function creates and returns a new function sharing with
+#     the passed callable the same:
+#
+#     * Underlying code object (i.e., ``func.__code__``).
+#     * Unqualified and fully-qualified names (i.e., ``func.__name__`` and
+#       ``func.__qualname__``).
+#     * Docstring (i.e., ``func.__doc__``).
+#     * Type hints (i.e., ``func.__annotations__``).
+#     * Global scope (i.e., ``func.__globals__``).
+#     * Fully-qualified module name (i.e., ``func.__module__``).
+#     * Default values of optional parameters (i.e., ``f.__defaults__`` and
+#       ``f.__kwdefaults__``).
+#     * Closure-specific cell variables (i.e., ``f.__closure__``).
+#     * Custom public and private attributes.
+#
+#     Parameters
+#     ----------
+#     func : Callable
+#         Callable to be copied.
+#     exception_cls : type, optional
+#         Type of exception to raise in the event of a fatal error. Defaults to
+#         :exc:`_BeartypeUtilCallableException`.
+#
+#     Returns
+#     ----------
+#     Callable
+#         Function shallowly copied from the passed callable.
+#
+#     Raises
+#     ----------
+#     exception_cls
+#         If the passed callable is *not* pure-Python.
+#
+#     See Also
+#     ----------
+#     https://stackoverflow.com/a/30714299/2809027
+#         StackOverflow answer strongly inspiring this implementation.
+#     '''
+#
+#     # If the passed callable is *NOT* pure-Python, raise an exception.
+#     die_unless_func_python(func=func, exception_cls=exception_cls)
+#
+#     # Function shallowly copied from the passed callable.
+#     #
+#     # Note that *ALL* pure-Python callables are guaranteed to define the
+#     # following dunder attributes.
+#     func_copy = FunctionType(
+#         func.__code__,
+#         func.__globals__,  # type: ignore[attr-defined]
+#         func.__name__,
+#         func.__defaults__,  # type: ignore[attr-defined]
+#         func.__closure__,  # type: ignore[attr-defined]
+#     )
+#
+#     # Shallowly copy all remaining dunder attributes from the original callable
+#     # onto this copy *NOT* already copied by the FunctionType.__init__() method
+#     # called above.
+#     #
+#     # Note that *ALL* pure-Python callables are guaranteed to define the
+#     # following dunder attributes.
+#     func_copy.__annotations__ = func.__annotations__
+#     func_copy.__doc__ = func.__doc__
+#     func_copy.__kwdefaults__ = func.__kwdefaults__  # type: ignore[attr-defined]
+#     func_copy.__module__ = func.__module__
+#     func_copy.__qualname__ = func.__qualname__
+#
+#     # Shallowly copy all custom attributes (i.e., non-dunder attributes
+#     # explicitly set by the caller) from the original callable onto this copy.
+#     func_copy.__dict__.update(func.__dict__)
+#     # print(f'func.__dict__: {func.__dict__}')
+#     # print(f'func_copy.__dict__: {func_copy.__dict__}')
+#
+#     # Return this copy.
+#     return func_copy
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfuncscope.py
@@ -0,0 +1,630 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable scope** utilities (i.e., functions handling the
+possibly nested lexical scopes enclosing arbitrary callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import (
+    _BeartypeUtilCallableScopeException,
+    _BeartypeUtilCallableScopeNotFoundException,
+)
+from beartype.typing import (
+    Any,
+    Optional,
+)
+from beartype._util.utilobject import get_object_basename_scoped
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    TypeException,
+)
+from beartype._data.kind.datakinddict import DICT_EMPTY
+from collections.abc import Callable
+from types import CodeType
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_func_globals(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableScopeException,
+) -> LexicalScope:
+    '''
+    **Global scope** (i.e., a dictionary mapping from the name to value of each
+    globally scoped attribute declared by the module transitively declaring
+    the passed pure-Python callable) for this callable.
+
+    This getter transparently supports **wrapper callables** (i.e.,
+    higher-level callables whose identifying metadata was propagated from other
+    lowel-level callables at either decoration time via the
+    :func:`functools.wraps` decorator *or* after declaration via the
+    :func:`functools.update_wrapper` function).
+
+    Note that the primary (and indeed only, at the moment) use case for this
+    getter is :pep:`563`-compliant resolution of postponed annotations.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+    func_stack_frames_ignore : int, optional
+        Number of frames on the call stack to be ignored (i.e., silently
+        incremented past), such that the next non-ignored frame following the
+        last ignored frame is the parent callable or module directly declaring
+        the passed callable. Defaults to 0.
+    exception_cls : Type[Exception], optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableScopeException`.
+
+    Returns
+    -------
+    Dict[str, Any]
+        Global scope for this callable.
+
+    Raises
+    ------
+    exception_cls
+        If this callable is a wrapper wrapping a C-based rather than
+        pure-Python wrappee callable.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import die_unless_func_python
+    from beartype._util.func.utilfuncwrap import unwrap_func_all_isomorphic
+
+    # If this callable is *NOT* pure-Python, raise an exception. C-based
+    # callables do *NOT* define the "__globals__" dunder attribute.
+    die_unless_func_python(func=func, exception_cls=exception_cls)
+    # Else, this callable is pure-Python.
+
+    # Lowest-level wrappee callable wrapped by this wrapper callable.
+    func_wrappee = unwrap_func_all_isomorphic(func)
+
+    # Dictionary mapping from the name to value of each locally scoped
+    # attribute accessible to this wrappee callable to be returned.
+    #
+    # Note that we intentionally do *NOT* return the global scope for this
+    # wrapper callable, as wrappers are typically defined in different modules
+    # (and thus different global scopes) by different module authors.
+    return func_wrappee.__globals__  # type: ignore[attr-defined]
+
+
+def get_func_locals(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    func_scope_names_ignore: int = 0,
+    func_stack_frames_ignore: int = 0,
+    exception_cls: TypeException = _BeartypeUtilCallableScopeException,
+) -> LexicalScope:
+    '''
+    **Local scope** for the passed callable.
+
+    This getter returns either:
+
+    * If that callable is **nested** (i.e., is a method *or* is a non-method
+      callable declared in the body of another callable), a dictionary mapping
+      from the name to value of each **locally scoped attribute** (i.e., local
+      attribute declared by a parent callable transitively declaring that
+      callable) accessible to that callable.
+    * Else, the empty dictionary otherwise (i.e., if that callable is a
+      function directly declared by a module).
+
+    This getter transparently supports methods, which in Python are lexically
+    nested in the scope encapsulating all previously declared **class
+    variables** (i.e., variables declared from class scope and thus accessible
+    as type hints when annotating the methods of that class). When declaring a
+    class, Python creates a stack frame for the declaration of that class whose
+    local scope is the set of all class-scoped attributes declared in the body
+    of that class (including class variables, class methods, static methods,
+    and instance methods). When passed any method, this getter finds and
+    returns that local scope. When passed the ``MuhClass.muh_method` method
+    declared by the following example, for example, this getter returns the
+    local scope containing the key ``'muh_class_var'`` with value ``int``:
+
+    .. code-block:: python
+
+       >>> from typing import ClassVar
+       >>> class MuhClass(object):
+       ...    # Class variable declared in class scope.
+       ...    muh_class_var: ClassVar[type] = int
+       ...    # Instance method annotated by this class variable.
+       ...    def muh_method(self) -> muh_class_var: return 42
+
+    However, note that this getter's transparent support for methods does *not*
+    extend to methods of the currently decorated class. Why? Because that class
+    has yet to be declared and thus added to the call stack.
+
+    Caveats
+    -------
+    **This high-level getter requires the private low-level**
+    :func:`sys._getframe` **getter.** If that getter is undefined, this getter
+    unconditionally treats the passed callable as module-scoped by returning the
+    empty dictionary rather than raising an exception. Since all standard
+    Python implementations (e.g., CPython, PyPy) define that getter, this
+    should typically *not* be a real-world concern.
+
+    **This high-level getter is inefficient and should thus only be called if
+    absolutely necessary.** Specifically, deciding the local scope for any
+    callable is an ``O(k)`` operation for ``k`` the distance in call stack
+    frames from the call of the current function to the call of the top-most
+    parent scope transitively declaring the passed callable in its submodule.
+    Ergo, this decision problem should be deferred as long as feasible to
+    minimize space and time consumption.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+    func_scope_names_ignore : int, optional
+        Number of parent lexical scopes in the fully-qualified name of that
+        callable to be ignored (i.e., silently incremented past), such that the
+        next non-ignored lexical scope preceding the first ignored lexical scope
+        is that of the parent callable or module directly declaring the passed
+        callable. This parameter is typically used to ignore the parent lexical
+        scopes of parent classes lexically nesting that callable that have yet
+        to be fully declared and thus encapsulated by stack frames on the call
+        stack (e.g., due to being currently decorated by
+        :func:`beartype.beartype`). See the :mod:`beartype._decor._pep.pep563`
+        submodule for the standard use case. Defaults to 0.
+    func_stack_frames_ignore : int, optional
+        Number of frames on the call stack to be ignored (i.e., silently
+        incremented past), such that the next non-ignored frame following the
+        last ignored frame is the parent callable or module directly declaring
+        the passed callable. Defaults to 0.
+    exception_cls : Type[Exception], optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilCallableScopeException`.
+
+    Returns
+    -------
+    LexicalScope
+        Local scope for this callable.
+
+    Raises
+    ------
+    exception_cls
+        If the next non-ignored frame following the last ignored frame is *not*
+        the parent callable or module directly declaring the passed callable.
+    _BeartypeUtilCallableScopeNotFoundException
+        If this lexical scope cannot be found (i.e., if this getter found the
+        lexical scope of the module declaring the passed callable *before* that
+        of the parent callable or class declaring that callable), enabling
+        callers to identify this common edge case.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+    assert isinstance(func_scope_names_ignore, int), (
+        f'{func_scope_names_ignore} not integer.')
+    assert func_scope_names_ignore >= 0, (
+        f'{func_scope_names_ignore} negative.')
+    assert isinstance(func_stack_frames_ignore, int), (
+        f'{func_stack_frames_ignore} not integer.')
+    assert func_stack_frames_ignore >= 0, (
+        f'{func_stack_frames_ignore} negative.')
+    # print(f'\n--------- Capturing nested {func.__qualname__}() local scope...')
+
+    # ..................{ IMPORTS                            }..................
+    # Avoid circular import dependencies.
+    from beartype._data.func.datafunccodeobj import FUNC_CODEOBJ_NAME_MODULE
+    from beartype._util.func.utilfunccodeobj import get_func_codeobj_or_none
+    from beartype._util.func.utilfuncframe import iter_frames
+    from beartype._util.func.utilfunctest import is_func_nested
+
+    # ..................{ NOOP                               }..................
+    # Fully-qualified name of the module declaring the passed callable if that
+    # callable was physically declared by an on-disk module *OR* "None"
+    # otherwise (i.e., if that callable was dynamically declared in-memory).
+    func_module_name = func.__module__
+
+    # Note that we intentionally return the local scope for this wrapper rather
+    # than wrappee callable, as local scope can *ONLY* be obtained by
+    # dynamically inspecting local attributes bound to call frames on the
+    # current call stack. However, this wrapper was called at a higher call
+    # frame than this wrappee. All local attributes declared within the body of
+    # this wrapper callable are irrelevant to this wrappee callable, as Python
+    # syntactically parsed the latter at a later time than the former. If we
+    # returned the local scope for this wrappee rather than wrapper callable,
+    # we would erroneously return local attributes that this wrappee callable
+    # originally had no lexical access to. That's bad. So, we don't do that.
+    #
+    # If either...
+    if (
+        # The passed callable is dynamically declared in-memory...
+        func_module_name is None or
+        # The passed callable is module-scoped rather than nested *OR*...
+        not is_func_nested(func)
+    # Then silently reduce to a noop by treating this nested callable as
+    # module-scoped by preserving "func_locals" as the empty dictionary.
+    ):
+        return DICT_EMPTY
+    # Else, all of the following constraints hold:
+    # * The passed callable is physically declared on-disk.
+    # * The passed callable is nested.
+
+    # ..................{ LOCALS ~ scope                     }..................
+    # Local scope of the passed callable to be returned.
+    func_scope: LexicalScope = {}
+
+    # ..................{ LOCALS ~ scope : name              }..................
+    # Unqualified name of this nested callable.
+    func_name_unqualified = func.__name__
+
+    # Fully-qualified name of this nested callable. If this nested callable is
+    # a non-method, this name contains one or more meaningless placeholders
+    # "<locals>" -- each identifying one parent callable lexically containing
+    # this nested callable: e.g.,
+    #     >>> def muh_func():
+    #     ...     def muh_closure(): pass
+    #     ...     return muh_closure()
+    #     >>> muh_func().__qualname__
+    #     'muh_func.<locals>.muh_closure'
+    func_name_qualified = get_object_basename_scoped(func)
+
+    # Non-empty list of the unqualified names of all parent callables lexically
+    # containing that nested callable (including that nested callable itself).
+    #
+    # Note that:
+    # * The set of all callables embodied by the current runtime call stack is
+    #   a (usually proper) superset of the set of all callables embodied by the
+    #   lexical scopes encapsulating this nested callable. Ergo:
+    #   * Some stack frames have no corresponding lexical scopes (e.g., stack
+    #     frames embodying callables defined by different modules).
+    #   * *ALL* lexical scopes have a corresponding stack frame.
+    # * Stack frames are only efficiently accessible relative to the initial
+    #   stack frame embodying this nested callable, which resides at the end of
+    #   the call stack. This implies we *MUST* iteratively search up the call
+    #   stack for frames with relevant lexical scopes and ignore intervening
+    #   frames with irrelevant lexical scopes, starting at the stack top (end).
+    func_scope_names = func_name_qualified.rsplit(sep='.')
+
+    # Number of lexical scopes encapsulating that callable.
+    func_scope_names_len = len(func_scope_names)
+
+    # If that nested callable is *NOT* encapsulated by at least two lexical
+    # scopes identifying at least that nested callable and the parent callable
+    # or class declaring that nested callable, raise an exception.
+    #
+    # You are probably now contemplating to yourself in the special darkness of
+    # your own personal computer cave: "But @leycec, isn't this condition
+    # *ALWAYS* the case? The above `not is_func_nested()` check already ignored
+    # non-nested callables."
+    #
+    # Allow me to now explicate. By the check above, that callable is nested...
+    # By the check below, however, only one lexical scope encapsulates that
+    # callable. This is not a contradiction. This is just a malicious caller.
+    # The get_object_basename_scoped() getter called above silently removed all
+    # "<locals>." placeholders from this list of lexical scopes, because those
+    # "<locals>." placeholders convey no meaningful semantics. But the
+    # is_func_nested() tester detects nested callables by searching for those
+    # "<locals>." placeholders. It follows that the caller triggered this
+    # condition by maliciously renaming the "__qualname__" dunder attribute of
+    # the passed callable to be erroneously prefixed by "<locals>". Curiously,
+    # Python permits such manhandling: e.g.,
+    #     # Python thinks this is fine.
+    #     >>> def muh_func(): pass
+    #     >>> muh_func.__qualname__ = '<locals>.muh_func'  # <-- curse you!
+    if func_scope_names_len < 2:
+        raise exception_cls(
+            f'{func_name_unqualified}() fully-qualified name '
+            f'{func.__qualname__}() invalid (e.g., placeholder substring '
+            f'"<locals>" not preceded by parent callable name).'
+        )
+    # Else, that nested callable is encapsulated by at least two lexical
+    # scopes identifying at least that nested callable and the parent callable
+    # or class declaring that nested callable.
+    #
+    # If the unqualified basename of the last parent callable lexically
+    # containing the passed callable is *NOT* that callable itself, the caller
+    # maliciously renamed one but *NOT* both of "__qualname__" and "__name__".
+    # In this case, raise an exception. Again, Python permits this. *sigh*
+    elif func_scope_names[-1] != func_name_unqualified:
+        raise exception_cls(
+            f'{func_name_unqualified}() fully-qualified name '
+            f'{func.__qualname__}() invalid (i.e., last lexical scope '
+            f'"{func_scope_names[-1]}" != unqualified name '
+            f'"{func_name_unqualified}").'
+        )
+    # Else, the unqualified basename of the last parent callable lexically
+    # containing the passed callable is that callable itself.
+
+    # 1-based negative index of the unqualified basename of the parent callable
+    # or module directly lexically containing the passed callable in the list of
+    # all unqualified basenames encapsulating that callable. By the above
+    # validation, this index is guaranteed to begin at the second-to-last
+    # basename in this list.
+    func_scope_names_index = -2 - func_scope_names_ignore
+
+    # Number of unignorable lexical scopes encapsulating that callable,
+    # magically adding 1 to account for the fact that "func_scope_names_index"
+    # is a 1-based negative index rather than 0-based positive index.
+    func_scope_names_search_len = (
+        func_scope_names_len + func_scope_names_index + 1)
+
+    # If exactly *ZERO* unignorable lexical scopes encapsulate that callable,
+    # all lexical scopes encapsulating that callable are exactly ignorable,
+    # implying that there is *NO* parent lexical scope to search for. In this
+    # case, silently reduce to a noop by returning the empty dictionary.
+    if func_scope_names_search_len == 0:
+        return DICT_EMPTY
+    # If a *NEGATIVE* number of unignorable lexical scopes encapsulate that
+    # callable, the caller erroneously insists that there exist more ignorable
+    # lexical scopes encapsulating that callable than there actually exist
+    # lexical scopes encapsulating that callable. The caller is profoundly
+    # mistaken. Whereas the prior branch is a non-erroneous condition that
+    # commonly occurs, this current branch is an erroneous condition that should
+    # *NEVER* occur. In this case...
+    elif func_scope_names_search_len < 0:
+        # Number of parent lexical scopes containing that callable.
+        func_scope_parents_len = func_scope_names_len - 1
+
+        # Raise an exception.
+        raise exception_cls(
+            f'Callable name "{func_name_qualified}" contains only '
+            f'{func_scope_parents_len} parent lexical scope(s) but '
+            f'"func_scope_names_ignore" parameter ignores '
+            f'{func_scope_names_ignore} parent lexical scope(s), leaving '
+            f'{func_scope_names_search_len} parent lexical scope(s) to be '
+            f'searched for {func_name_qualified}() locals.'
+        )
+    # Else, there are one or more unignorable lexical scopes to be searched.
+
+    # Unqualified basename of the parent callable or module directly lexically
+    # containing the passed callable.
+    #
+    # Note that that the parent callable's local runtime scope transitively
+    # contains *ALL* local variables accessible to this nested callable
+    # (including the local variables directly contained in the body of that
+    # parent callable as well as the local variables directly contained in the
+    # bodies of all parent callables of that callable in the same lexical
+    # scope). Since that parent callable's local runtime scope is exactly the
+    # dictionary to be returned, iteration below searches up the runtime call
+    # stack for a stack frame embodying that parent callable and no further.
+    func_scope_name = func_scope_names[func_scope_names_index]
+    # print(f'Searching for parent {func_scope_name}() local scope...')
+
+    # ..................{ LOCALS ~ frame                     }..................
+    # Code object underlying the parent callable associated with the current
+    # stack frame if that callable is pure-Python *OR* "None".
+    func_frame_codeobj: Optional[CodeType] = None
+
+    # Fully-qualified name of that callable's module.
+    func_frame_module_name = ''
+
+    # Unqualified name of that callable.
+    func_frame_name = ''
+
+    # ..................{ SEARCH                             }..................
+    # While at least one frame remains on the call stack, iteratively search up
+    # the call stack for a stack frame embodying the parent callable directly
+    # declaring this nested callable, whereupon that parent callable's local
+    # runtime scope is returned as is.
+    #
+    # Note this also implicitly skips past all other decorators applied *AFTER*
+    # @beartype (and thus residing lexically above @beartype) in caller code to
+    # this nested callable: e.g.,
+    #     @the_way_of_kings   <--- skipped past
+    #     @words_of_radiance  <--- skipped past
+    #     @oathbringer        <--- skipped past
+    #     @rhythm_of_war      <--- skipped past
+    #     @beartype
+    #     def the_stormlight_archive(bruh: str) -> str:
+    #         return bruh
+    for func_frame in iter_frames(
+        # 0-based index of the first non-ignored frame following the last
+        # ignored frame, ignoring an additional frame embodying the current
+        # call to this getter.
+        func_stack_frames_ignore=func_stack_frames_ignore + 1,
+    ):
+        # Code object underlying this frame's scope if that scope is
+        # pure-Python *OR* "None" otherwise.
+        func_frame_codeobj = get_func_codeobj_or_none(func_frame)
+
+        # If this code object does *NOT* exist, this scope is C-based. In this
+        # case, silently ignore this scope and proceed to the next frame.
+        if func_frame_codeobj is None:
+            continue
+        # Else, this code object exists, implying this scope to be pure-Python.
+
+        # Fully-qualified name of that scope's module.
+        func_frame_module_name = func_frame.f_globals['__name__']
+
+        # Unqualified name of that scope.
+        func_frame_name = func_frame_codeobj.co_name
+        # print(f'{func_frame_name}() locals: {repr(func_frame.f_locals)}')
+
+        # If that scope is the placeholder string assigned by the active Python
+        # interpreter to all scopes encapsulating the top-most lexical scope of
+        # a module in the current call stack, this search has just crossed a
+        # module boundary and is thus no longer searching within the module
+        # declaring this nested callable and has thus failed to find the
+        # lexical scope of the parent declaring this nested callable. Why?
+        # Because that scope *MUST* necessarily be in the same module as that
+        # of this nested callable. In this case, raise an exception.
+        if func_frame_name == FUNC_CODEOBJ_NAME_MODULE:
+            raise _BeartypeUtilCallableScopeNotFoundException(
+                f'{func_name_qualified}() parent lexical scope '
+                f'"{func_scope_name}" not found on call stack.'
+            )
+        # Else, that scope is *NOT* a module.
+        #
+        # If...
+        elif (
+            # That callable's name is that of the current lexical scope to be
+            # found *AND*...
+            func_frame_name == func_scope_name and
+            # That callable's module is that of this nested callable's and thus
+            # resides in the same lexical scope...
+            func_frame_module_name == func_module_name
+        ):
+        # Then that callable embodies the lexical scope to be found. In this
+        # case, that callable is the parent callable directly declaring this
+        # nested callable.
+        #
+        # Note that this scope *CANNOT* be validated to declare this nested
+        # callable. Why? Because this getter function is called by the
+        # @beartype decorator when decorating this nested callable, which has
+        # yet to be declared until @beartype creates and returns a new wrapper
+        # function and is thus unavailable from this scope: e.g.,
+        #     # This conditional *ALWAYS* raises an exception, because this
+        #     # nested callable has yet to be declared.
+        #     if func_name not in func_locals:
+        #         raise exception_cls(
+        #             f'{func_label} not declared by lexically scoped parent '
+        #             f'callable(s) that declared local variables:\n{repr(func_locals)}'
+        #         )
+        #
+        # Ergo, we have *NO* alternative but to blindly assume the above
+        # algorithm correctly collected this scope, which we only do because we
+        # have exhaustively tested this with *ALL* edge cases.
+            # print(f'{func_frame_name}() locals: {repr(func_frame.f_locals)}')
+
+            # Local scope of the passed callable. Since this nested callable is
+            # directly declared in the body of this parent callable, the local
+            # scope of this nested callable is *EXACTLY* the local scope of the
+            # body of this parent callable. Well, isn't that special?
+            func_scope = func_frame.f_locals
+
+            # Halt iteration.
+            break
+        # Else, that callable does *NOT* embody the current lexical scope to be
+        # found. In this case, silently ignore that callable and proceed to the
+        # next frame in the call stack.
+
+    # Return the local scope of the passed callable.
+    return func_scope
+
+# ....................{ ADDERS                             }....................
+def add_func_scope_attr(
+    # Mandatory parameters.
+    attr: Any,
+    func_scope: LexicalScope,
+
+    # Optional parameters.
+    exception_prefix: str = 'Globally or locally scoped attribute ',
+) -> str:
+    '''
+    Add a new **scoped attribute** (i.e., new key-value pair of the passed
+    dictionary mapping from the name to value of each globally or locally scoped
+    attribute externally accessed elsewhere, whose key is a machine-readable
+    name internally generated by this function to uniquely refer to the passed
+    object and whose value is that object) to the passed scope *and* return that
+    name.
+
+    Parameters
+    ----------
+    attr : Any
+        Arbitrary object to be added to this scope.
+    func_scope : LexicalScope
+        Local or global scope to add this object to.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    str
+        Name of the passed object in this scope generated by this function.
+
+    Raises
+    ------
+    _BeartypeUtilCallableScopeException
+        If an attribute with the same name as that internally generated by
+        this adder but having a different value already exists in this scope.
+        This adder uniquifies names by object identifier and should thus
+        *never* generate name collisions. This exception is thus intentionally
+        raised as a private rather than public exception.
+    '''
+    assert isinstance(func_scope, dict), f'{repr(func_scope)} not dictionary.'
+    assert isinstance(exception_prefix, str), (
+        f'{repr(exception_prefix)} not string.')
+
+    # Possibly negative integer uniquely identifying the new attribute referring
+    # to this object in this scope.
+    attr_id = id(attr)
+
+    # Name of the new attribute referring to this object in this scope, defined
+    # as either...
+    attr_name = (
+        # If this integer is positive, embed this positive integer into this
+        # name as is.
+        f'{_ATTR_NAME_PREFIX_ID_POSITIVE}{attr_id}'
+        if attr_id >= 0 else
+        # Else, this integer is negative. In this case, instead embed the
+        # absolute value of this negative integer rather than this negative
+        # integer itself. The unary prefix "-" is prohibited in Python
+        # identifiers. Since this integer is subsequently embedded in a Python
+        # identifier, this integer *MUST* be coerced from a negative to
+        # non-negative integer first.
+        #
+        # Note that this edge case *ONLY* applies to PyPy. Specifically, under:
+        # * CPython, this integer is guaranteed to be a memory address and thus
+        #   non-negative (i.e., "id(attr) >= 0" for all possible attributes).
+        # * PyPy, this integer is typically (but *NOT* necessarily) a 0-based
+        #   index into an internal object array and thus also non-negative.
+        #   Unfortunately, this heuristic is *NOT* a universal guarantee. In a
+        #   small handful of edge cases (for presumably exotic objects of
+        #   unknown origin), this integer is negative under PyPy. This makes
+        #   testing non-deterministic and thus infeasible.
+        #
+        # This must be what it feels like when code cries.
+        f'{_ATTR_NAME_PREFIX_ID_NEGATIVE}{-attr_id}'  # pragma: no cover
+    )
+
+    # If an attribute with the same name but differing value already exists in
+    # this scope, raise an exception.
+    if func_scope.get(attr_name, attr) is not attr:
+        raise _BeartypeUtilCallableScopeException(
+            f'{exception_prefix}"{attr_name}" already exists with '
+            f'differing value:\n'
+            f'~~~~[ NEW VALUE ]~~~~\n{repr(attr)}\n'
+            f'~~~~[ OLD VALUE ]~~~~\n{repr(func_scope[attr_name])}'
+        )
+    # Else, either no attribute with this name exists in this scope *OR* an
+    # attribute with this name and value already exists in this scope.
+
+    # Refer to the passed object in this scope with this name.
+    func_scope[attr_name] = attr
+
+    # Return this name.
+    return attr_name
+
+# ....................{ PRIVATE                            }....................
+_ATTR_NAME_PREFIX_ID_POSITIVE = '__beartype_object_'
+'''
+Arbitrary substring prefixing names dynamically synthesized by the
+:func:`.add_func_scope_attr` function for attributes whose **object ids** (i.e.,
+the integers returned by the :func:`id` builtin) are positive.
+
+See Also
+--------
+:data:`._ATTR_NAME_PREFIX_ID_NEGATIVE`
+    Further details.
+'''
+
+
+# NegaBeartype: I challenge you!
+_ATTR_NAME_PREFIX_ID_NEGATIVE = (
+    f'{_ATTR_NAME_PREFIX_ID_POSITIVE}oh_pypy_you_sweet_summer_child_')
+'''
+Arbitrary substring prefixing names dynamically synthesized by the
+:func:`.add_func_scope_attr` function for attributes whose **object ids** (i.e.,
+the integers returned by the :func:`id` builtin) are negative.
+
+That function coerces negative into positive attribute IDs. Doing so renders the
+former suitable for embedding in attribute names that are valid Python
+identifiers. That's good. Doing so naively, however, would invite name
+collisions between negative and positive attribute IDs whose absolute values are
+equal (e.g., ``|-42| == |42|``). To avoid this, the names of attributes whose
+IDs are negative are prefixed by a different substring than those of attributes
+whose IDs are positive. It's complicated. Did our hand-waving not convince you!?
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfunctest.py
@@ -0,0 +1,925 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable testers** (i.e., utility functions dynamically
+validating and inspecting various properties of passed callables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableException
+from beartype.typing import Any
+from beartype._cave._cavefast import MethodBoundInstanceOrClassType
+from beartype._data.hint.datahintfactory import TypeGuard
+from beartype._data.hint.datahinttyping import (
+    Codeobjable,
+    TypeException,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.func.arg.utilfuncargget import (
+    get_func_args_nonvariadic_len)
+from beartype._util.func.arg.utilfuncargtest import (
+    is_func_arg_variadic_positional,
+    is_func_arg_variadic_keyword,
+)
+from beartype._util.func.utilfunccodeobj import get_func_codeobj_or_none
+from collections.abc import Callable
+from inspect import (
+    CO_ASYNC_GENERATOR,
+    CO_COROUTINE,
+    CO_GENERATOR,
+)
+
+# ....................{ CONSTANTS                          }....................
+FUNC_NAME_LAMBDA = '<lambda>'
+'''
+Default name of all **pure-Python lambda functions** (i.e., function declared
+as a ``lambda`` expression embedded in a larger statement rather than as a
+full-blown ``def`` statement).
+
+Python initializes the names of *all* lambda functions to this lambda-specific
+placeholder string on lambda definition.
+
+Caveats
+-------
+**Usage of this placeholder to differentiate lambda from non-lambda callables
+invites false positives in unlikely edge cases.** Technically, malicious third
+parties may externally change the name of any lambda function *after* defining
+that function. Pragmatically, no one sane should ever do such a horrible thing.
+While predictably absurd, this is also the only efficient (and thus sane) means
+of differentiating lambda from non-lambda callables. Alternatives require
+AST-based parsing, which comes with its own substantial caveats, concerns,
+edge cases, and false positives. If you must pick your poison, pick this one.
+'''
+
+# ....................{ RAISERS                            }....................
+def die_unless_func_python(
+    # Mandatory parameters.
+    func: Codeobjable,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception if the passed callable is **C-based** (i.e., implemented
+    in C as either a builtin bundled with the active Python interpreter *or*
+    third-party C extension function).
+
+    Equivalently, this validator raises an exception unless the passed function
+    is **pure-Python** (i.e., implemented in Python as either a function or
+    method).
+
+    Parameters
+    ----------
+    func : Codeobjable
+        Callable to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+         If the passed callable is C-based.
+
+    See Also
+    --------
+    :func:`.is_func_python`
+        Further details.
+    '''
+
+    # If that callable is *NOT* pure-Python, raise an exception.
+    if not is_func_python(func):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # If that callable is uncallable, raise an appropriate exception.
+        if not callable(func):
+            raise exception_cls(f'{exception_prefix}{repr(func)} not callable.')
+        # Else, that callable is callable.
+
+        # Raise a human-readable exception.
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} not pure-Python function.')
+    # Else, that callable is pure-Python.
+
+# ....................{ RAISERS ~ descriptors              }....................
+#FIXME: Unit test us up, please.
+def die_unless_func_boundmethod(
+    # Mandatory parameters.
+    func: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **C-based bound instance
+    method descriptor** callable implicitly instantiated and assigned on the
+    instantiation of an object whose class declares an instance function (whose
+    first parameter is typically named ``self``) as an instance variable of that
+    object such that that callable unconditionally passes that object as the
+    value of that first parameter on all calls to that callable).
+
+    Parameters
+    ----------
+    func : Any
+        Object to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a bound method descriptor.
+
+    See Also
+    --------
+    :func:`.is_func_boundmethod`
+        Further details.
+    '''
+
+    # If this object is *NOT* a bound method descriptor, raise an exception.
+    if not is_func_boundmethod(func):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Raise a human-readable exception.
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} not '
+            f'C-based bound instance method descriptor.'
+        )
+    # Else, this object is a bound method descriptor.
+
+
+def die_unless_func_classmethod(
+    # Mandatory parameters.
+    func: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **C-based unbound class
+    method descriptor** (i.e., method decorated by the builtin
+    :class:`classmethod` decorator, yielding a non-callable instance of that
+    :class:`classmethod` decorator class implemented in low-level C and
+    accessible via the low-level :attr:`object.__dict__` dictionary rather than
+    as class or instance attributes).
+
+    Parameters
+    ----------
+    func : Any
+        Object to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :class:`._BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a class method descriptor.
+
+    See Also
+    --------
+    :func:`.is_func_classmethod`
+        Further details.
+    '''
+
+    # If this object is *NOT* a class method descriptor, raise an exception.
+    if not is_func_classmethod(func):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Raise a human-readable exception.
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} not '
+            f'C-based unbound class method descriptor.'
+        )
+    # Else, this object is a class method descriptor.
+
+
+def die_unless_func_property(
+    # Mandatory parameters.
+    func: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **C-based unbound property
+    method descriptor** (i.e., method decorated by the builtin :class:`property`
+    decorator, yielding a non-callable instance of that :class:`property`
+    decorator class implemented in low-level C and accessible as a class rather
+    than instance attribute).
+
+    Parameters
+    ----------
+    func : Any
+        Object to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :property:`_BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a property method descriptor.
+
+    See Also
+    --------
+    :func:`.is_func_property`
+        Further details.
+    '''
+
+    # If this object is *NOT* a property method descriptor, raise an exception.
+    if not is_func_property(func):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Raise a human-readable exception.
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} not '
+            f'C-based unbound property method descriptor.'
+        )
+    # Else, this object is a property method descriptor.
+
+
+def die_unless_func_staticmethod(
+    # Mandatory parameters.
+    func: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **C-based unbound static
+    method descriptor** (i.e., method decorated by the builtin
+    :class:`staticmethod` decorator, yielding a non-callable instance of that
+    :class:`staticmethod` decorator class implemented in low-level C and
+    accessible via the low-level :attr:`object.__dict__` dictionary rather than
+    as class or instance attributes).
+
+    Parameters
+    ----------
+    func : Any
+        Object to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :static:`_BeartypeUtilCallableException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a static method descriptor.
+
+    See Also
+    --------
+    :func:`.is_func_staticmethod`
+        Further details.
+    '''
+
+    # If this object is *NOT* a static method descriptor, raise an exception.
+    if not is_func_staticmethod(func):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not class.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Raise a human-readable exception.
+        raise exception_cls(
+            f'{exception_prefix}{repr(func)} not '
+            f'C-based unbound static method descriptor.'
+        )
+    # Else, this object is a static method descriptor.
+
+# ....................{ TESTERS                            }....................
+def is_func_lambda(func: Any) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is a **pure-Python lambda function**
+    (i.e., function declared as a ``lambda`` expression embedded in a larger
+    statement rather than as a full-blown ``def`` statement).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a pure-Python lambda function.
+    '''
+
+    # Return true only if this both...
+    return (
+        # This callable is pure-Python *AND*...
+        is_func_python(func) and
+        # This callable's name is the lambda-specific placeholder name
+        # initially given by Python to *ALL* lambda functions. Technically,
+        # this name may be externally changed by malicious third parties after
+        # the declaration of this lambda. Pragmatically, no one sane would ever
+        # do such a horrible thing. Would they!?!?
+        #
+        # While predictably absurd, this is also the only efficient (and thus
+        # sane) means of differentiating lambda from non-lambda callables.
+        # Alternatives require AST-based parsing, which comes with its own
+        # substantial caveats, concerns, and edge cases.
+        func.__name__ == FUNC_NAME_LAMBDA
+    )
+
+
+def is_func_python(func: object) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is a **pure-Python callable** (i.e.,
+    implemented in Python as either a function or method rather than in C as
+    either a builtin bundled with the active Python interpreter *or*
+    third-party C extension function).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a pure-Python callable.
+    '''
+
+    # Return true only if a pure-Python code object underlies this object.
+    # C-based callables are associated with *NO* code objects.
+    return get_func_codeobj_or_none(func) is not None
+
+# ....................{ TESTERS ~ descriptor               }....................
+#FIXME: Unit test us up, please.
+def is_func_boundmethod(func: Any) -> TypeGuard[MethodBoundInstanceOrClassType]:
+    '''
+    :data:`True` only if the passed object is a **C-based bound instance method
+    descriptor** (i.e., callable implicitly instantiated and assigned on the
+    instantiation of an object whose class declares an instance function (whose
+    first parameter is typically named ``self``) as an instance variable of that
+    object such that that callable unconditionally passes that object as the
+    value of that first parameter on all calls to that callable).
+
+    Caveats
+    -------
+    Instance method objects are *only* directly accessible as instance
+    attributes. When accessed as either class attributes *or* via the low-level
+    :attr:`object.__dict__` dictionary, instance methods are only functions
+    (i.e., instances of the standard :class:`beartype.cave.FunctionType` type).
+
+    Instance method objects are callable. Indeed, the callability of instance
+    method objects is the entire point of instance method objects.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a C-based bound instance method
+        descriptor.
+    '''
+
+    # Only the penitent one-liner shall pass.
+    return isinstance(func, MethodBoundInstanceOrClassType)
+
+
+def is_func_classmethod(func: Any) -> TypeGuard[classmethod]:
+    '''
+    :data:`True` only if the passed object is a **C-based unbound class method
+    descriptor** (i.e., method decorated by the builtin :class:`classmethod`
+    decorator, yielding a non-callable instance of that :class:`classmethod`
+    decorator class implemented in low-level C and accessible via the
+    low-level :attr:`object.__dict__` dictionary rather than as class or
+    instance attributes).
+
+    Caveats
+    -------
+    Class method objects are *only* directly accessible via the low-level
+    :attr:`object.__dict__` dictionary. When accessed as class or instance
+    attributes, class methods reduce to instances of the standard
+    :class:`MethodBoundInstanceOrClassType` type.
+
+    Class method objects are *not* callable, as their implementations fail to
+    define the ``__call__`` dunder method.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a C-based unbound class method
+        descriptor.
+    '''
+
+    # Now you too have seen the pure light of the one-liner.
+    return isinstance(func, classmethod)
+
+
+def is_func_property(func: Any) -> TypeGuard[property]:
+    '''
+    :data:`True` only if the passed object is a **C-based unbound property
+    method descriptor** (i.e., method decorated by the builtin :class:`property`
+    decorator, yielding a non-callable instance of that :class:`property`
+    decorator class implemented in low-level C and accessible as a class rather
+    than instance attribute).
+
+    Caveats
+    -------
+    Property objects are directly accessible both as class attributes *and* via
+    the low-level :attr:`object.__dict__` dictionary. Property objects are *not*
+    accessible as instance attributes, for hopefully obvious reasons.
+
+    Property objects are *not* callable, as their implementations fail to define
+    the ``__call__`` dunder method.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a pure-Python property.
+    '''
+
+    # We rejoice in the shared delight of one-liners.
+    return isinstance(func, property)
+
+
+def is_func_staticmethod(func: Any) -> TypeGuard[staticmethod]:
+    '''
+    :data:`True` only if the passed object is a **C-based unbound static method
+    descriptor** (i.e., method decorated by the builtin :class:`staticmethod`
+    decorator, yielding a non-callable instance of that :class:`staticmethod`
+    decorator class implemented in low-level C and accessible via the low-level
+    :attr:`object.__dict__` dictionary rather than as class or instance
+    attributes).
+
+    Caveats
+    -------
+    Static method objects are *only* directly accessible via the low-level
+    :attr:`object.__dict__` dictionary. When accessed as class or instance
+    attributes, static methods reduce to instances of the standard
+    :class:`FunctionType` type.
+
+    Static method objects are *not* callable, as their implementations fail to
+    define the ``__call__`` dunder method.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a pure-Python static method.
+    '''
+
+    # Does the one-liner have Buddhahood? Mu.
+    return isinstance(func, staticmethod)
+
+# ....................{ TESTERS ~ async                    }....................
+def is_func_async(func: object) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is an **asynchronous callable
+    factory** (i.e., awaitable factory callable implicitly creating and
+    returning an awaitable object (i.e., satisfying the
+    :class:`collections.abc.Awaitable` protocol) by being declared via the
+    ``async def`` syntax and thus callable *only* when preceded by comparable
+    ``await`` syntax).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an asynchronous callable.
+
+    See Also
+    --------
+    :func:`inspect.iscoroutinefunction`
+    :func:`inspect.isasyncgenfunction`
+        Stdlib functions strongly inspiring this implementation.
+    '''
+
+    # Code object underlying this pure-Python callable if any *OR* "None".
+    #
+    # Note this tester intentionally:
+    # * Inlines the tests performed by the is_func_coro() and
+    #   is_func_async_generator() testers for efficiency.
+    # * Calls the get_func_codeobj_or_none() with "is_unwrap" disabled
+    #   rather than enabled. Why? Because the asynchronicity of this possibly
+    #   higher-level wrapper has *NO* relation to that of the possibly
+    #   lower-level wrappee wrapped by this wrapper. Notably, it is both
+    #   feasible and commonplace for third-party decorators to enable:
+    #   * Synchronous callables to be called asynchronously by wrapping
+    #     synchronous callables with asynchronous closures.
+    #   * Asynchronous callables to be called synchronously by wrapping
+    #     asynchronous callables with synchronous closures. Indeed, our
+    #     top-level "conftest.py" pytest plugin does exactly this -- enabling
+    #     asynchronous tests to be safely called by pytest's currently
+    #     synchronous framework.
+    func_codeobj = get_func_codeobj_or_none(func)
+
+    # If this object is *NOT* a pure-Python callable, immediately return false.
+    if func_codeobj is None:
+        return False
+    # Else, this object is a pure-Python callable.
+
+    # Bit field of OR-ed binary flags describing this callable.
+    func_codeobj_flags = func_codeobj.co_flags
+
+    # Return true only if these flags imply this callable to be either...
+    return (
+        # An asynchronous coroutine *OR*...
+        func_codeobj_flags & CO_COROUTINE != 0 or
+        # An asynchronous generator.
+        func_codeobj_flags & CO_ASYNC_GENERATOR != 0
+    )
+
+
+def is_func_coro(func: object) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is an **asynchronous coroutine
+    factory** (i.e., awaitable callable containing *no* ``yield`` expression
+    implicitly creating and returning an awaitable object (i.e., satisfying the
+    :class:`collections.abc.Awaitable` protocol) by being declared via the
+    ``async def`` syntax and thus callable *only* when preceded by comparable
+    ``await`` syntax).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an asynchronous coroutine factory.
+
+    See Also
+    --------
+    :func:`inspect.iscoroutinefunction`
+        Stdlib function strongly inspiring this implementation.
+    '''
+
+    # Code object underlying this pure-Python callable if any *OR* "None".
+    func_codeobj = get_func_codeobj_or_none(func)
+
+    # Return true only if...
+    return (
+        # This object is a pure-Python callable *AND*...
+        func_codeobj is not None and
+        # This callable's code object implies this callable to be an
+        # asynchronous coroutine.
+        func_codeobj.co_flags & CO_COROUTINE != 0
+    )
+
+
+def is_func_async_generator(func: object) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is an **asynchronous generator
+    factory** (i.e., awaitable callable containing one or more ``yield``
+    expressions implicitly creating and returning an awaitable object (i.e.,
+    satisfying the :class:`collections.abc.Awaitable` protocol) by being
+    declared via the ``async def`` syntax and thus callable *only* when preceded
+    by comparable ``await`` syntax).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an asynchronous generator.
+
+    See Also
+    --------
+    :func:`inspect.isasyncgenfunction`
+        Stdlib function strongly inspiring this implementation.
+    '''
+
+    # Code object underlying this pure-Python callable if any *OR* "None".
+    func_codeobj = get_func_codeobj_or_none(func)
+
+    # Return true only if...
+    return (
+        # This object is a pure-Python callable *AND*...
+        func_codeobj is not None and
+        # This callable's code object implies this callable to be an
+        # asynchronous generator.
+        func_codeobj.co_flags & CO_ASYNC_GENERATOR != 0
+    )
+
+# ....................{ TESTERS ~ sync                     }....................
+def is_func_sync_generator(func: object) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is an **synchronous generator
+    factory** (i.e., awaitable callable containing one or more ``yield``
+    expressions implicitly creating and returning a generator object (i.e.,
+    satisfying the :class:`collections.abc.Generator` protocol) by being
+    declared via the ``def`` rather than ``async def`` syntax).
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a synchronous generator.
+
+    See Also
+    --------
+    :func:`inspect.isgeneratorfunction`
+        Stdlib function strongly inspiring this implementation.
+    '''
+
+    # If this object is uncallable, immediately return False.
+    #
+    # Note this test is explicitly required to differentiate synchronous
+    # generator callables from synchronous generator objects (i.e., the objects
+    # they implicitly create and return). Whereas both asynchronous coroutine
+    # objects *AND* asynchronous generator objects do *NOT* contain code
+    # objects whose "CO_COROUTINE" and "CO_ASYNC_GENERATOR" flags are non-zero,
+    # synchronous generator objects do contain code objects whose
+    # "CO_GENERATOR" flag is non-zero. This implies synchronous generator
+    # callables to create and return synchronous generator objects that are
+    # themselves technically valid synchronous generator callables, which is
+    # absurd. We prohibit this ambiguity by differentiating the two here.
+    if not callable(func):
+        return False
+    # Else, this object is callable.
+
+    # Code object underlying this pure-Python callable if any *OR* "None".
+    func_codeobj = get_func_codeobj_or_none(func)
+
+    # Return true only if...
+    return (
+        # This object is a pure-Python callable *AND*...
+        func_codeobj is not None and
+        # This callable's code object implies this callable to be a
+        # synchronous generator.
+        func_codeobj.co_flags & CO_GENERATOR != 0
+    )
+
+# ....................{ TESTERS : nested                   }....................
+def is_func_nested(func: Callable) -> bool:
+    '''
+    :data:`True` only if the passed callable is **nested** (i.e., a pure-Python
+    callable declared in the body of another pure-Python callable or class).
+
+    Equivalently, this tester returns :data:`True` only if that callable is
+    either:
+
+    * A closure, which by definition is nested inside another callable.
+    * A method, which by definition is nested inside its class.
+    * A **nested non-closure function** (i.e., a closure-like function that does
+      *not* reference local attributes of the parent callable enclosing that
+      function and is thus technically *not* a closure): e.g.,
+
+      .. code-block:: python
+
+         def muh_parent_callable():           # <-- parent callable
+             def muh_nested_callable(): pass  # <-- nested non-closure function
+             return muh_nested_callable
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this callable is nested.
+    '''
+
+    # Return true only if either...
+    return (
+        # That callable is a closure (in which case that closure is necessarily
+        # nested inside another callable) *OR*...
+        #
+        # Note that this tester intentionally tests for whether that callable is
+        # a closure first, as doing so efficiently reduces to a constant-time
+        # attribute test -- whereas the following test for non-closure nested
+        # callables inefficiently requires a linear-time string search.
+        is_func_closure(func) or
+        # The fully-qualified name of that callable contains one or more "."
+        # delimiters, each signifying a nested lexical scope. Since *ALL*
+        # callables (i.e., both pure-Python and C-based) define a non-empty
+        # "__qualname__" dunder variable containing at least their unqualified
+        # names, this simplistic test is guaranteed to be safe.
+        #
+        # Note this tester intentionally tests for the general-purpose existence
+        # of a "." delimiter rather than the special-cased existence of a
+        # ".<locals>." placeholder substring. Why? Because there are two types
+        # of nested callables:
+        # * Non-methods, which are lexically nested in a parent callable whose
+        #   scope encapsulates all previously declared local variables. For
+        #   unknown reasons, the unqualified names of nested non-method
+        #   callables are *ALWAYS* prefixed by ".<locals>." in their
+        #   "__qualname__" variables:
+        #       >>> from collections.abc import Callable
+        #       >>> def muh_parent_callable() -> Callable:
+        #       ...     def muh_nested_callable() -> None: pass
+        #       ...     return muh_nested_callable
+        #       >>> muh_nested_callable = muh_parent_callable()
+        #       >>> muh_parent_callable.__qualname__
+        #       'muh_parent_callable'
+        #       >>> muh_nested_callable.__qualname__
+        #       'muh_parent_callable.<locals>.muh_nested_callable'
+        # * Methods, which are lexically nested in the scope encapsulating all
+        #   previously declared class variables (i.e., variables declared in
+        #   class scope and thus accessible as method annotations). For unknown
+        #   reasons, the unqualified names of methods are *NEVER* prefixed by
+        #   ".<locals>." in their "__qualname__" variables: e.g.,
+        #       >>> from typing import ClassVar
+        #       >>> class MuhClass(object):
+        #       ...    # Class variable declared in class scope.
+        #       ...    muh_class_var: ClassVar[type] = int
+        #       ...    # Instance method annotated by this class variable.
+        #       ...    def muh_method(self) -> muh_class_var: return 42
+        #       >>> MuhClass.muh_method.__qualname__
+        #       'MuhClass.muh_method'
+        '.' in func.__qualname__
+    )
+
+# ....................{ TESTERS ~ nested : closure         }....................
+def is_func_closure(func: Any) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed callable is a **closure** (i.e., nested
+    callable accessing one or more variables declared by the parent callable
+    also declaring that callable).
+
+    Note that all closures are necessarily nested callables but that the
+    converse is *not* necessarily the case. In particular, a nested callable
+    accessing *no* variables declared by the parent callable also declaring that
+    callable is *not* a closure; it's simply a nested callable.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this callable is a closure.
+    '''
+
+    # Return true only if that callable defines the closure-specific
+    # "__closure__" dunder variable whose value is either:
+    # * If that callable is a closure, a tuple of zero or more cell variables.
+    # * If that callable is a pure-Python non-closure, "None".
+    # * If that callable is C-based, undefined.
+    return getattr(func, '__closure__', None) is not None
+
+# ....................{ TESTERS ~ wrapper                  }....................
+def is_func_wrapper(func: Any) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is a **callable wrapper** (i.e.,
+    callable decorated by the standard :func:`functools.wraps` decorator for
+    wrapping a pure-Python callable with additional functionality defined by a
+    higher-level decorator).
+
+    Note that this tester returns :data:`True` for both pure-Python and C-based
+    callable wrappers. As an example of the latter, the standard
+    :func:`functools.lru_cache` decorator creates and returns low-level C-based
+    callable wrappers of the private type :class:`functools._lru_cache_wrapper`
+    wrapping pure-Python callables.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a callable wrapper.
+    '''
+
+    # Return true only if this object defines a dunder attribute uniquely
+    # specific to the @functools.wraps decorator.
+    #
+    # Technically, *ANY* callable (including non-wrappers *NOT* created by the
+    # @functools.wraps decorator) could trivially define this attribute; ergo,
+    # this invites the possibility of false positives. Pragmatically, doing so
+    # would violate ad-hoc standards and real-world practice across the
+    # open-source ecosystem; ergo, this effectively excludes false positives.
+    return hasattr(func, '__wrapped__')
+
+
+@callable_cached
+def is_func_wrapper_isomorphic(func: Any) -> TypeGuard[Callable]:
+    '''
+    :data:`True` only if the passed object is an **isomorphic wrapper** (i.e.,
+    callable decorated by the standard :func:`functools.wraps` decorator for
+    wrapping a pure-Python callable with additional functionality defined by a
+    higher-level decorator such that that wrapper isomorphically preserves both
+    the number and types of all passed parameters and returns by accepting only
+    a variadic positional argument and a variadic keyword argument).
+
+    This tester enables callers to detect when a user-defined callable has been
+    decorated by an isomorphic decorator, which constitutes *most* real-world
+    decorators of interest.
+
+    This tester is memoized for efficiency.
+
+    Caveats
+    -------
+    **This tester is merely a heuristic** -- albeit a reasonably robust
+    heuristic likely to succeed in almost all real-world use cases. Nonetheless,
+    this tester *could* return false positives and negatives in edge cases.
+
+    Parameters
+    ----------
+    func : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an isomorphic decorator wrapper.
+    '''
+
+    # If the passed callable is *NOT* a wrapper, immediately return false.
+    if not is_func_wrapper(func):
+        return False
+    # Else, that callable is a wrapper.
+
+    # Code object underlying that callable as is (rather than possibly unwrapped
+    # to another code object entirely) if that callable is pure-Python *OR*
+    # "None" otherwise (i.e., if that callable is C-based).
+    func_codeobj = get_func_codeobj_or_none(func)
+
+    # Return true only if...
+    return (
+        # That callable is pure-Python *AND*...
+        func_codeobj is not None and
+        # That callable accepts a variadic positional argument *AND*...
+        is_func_arg_variadic_positional(func_codeobj) and
+        # That callable accepts a variadic keyword argument *AND*...
+        is_func_arg_variadic_keyword(func_codeobj) and
+        # That callable accepts *NO* non-variadic arguments.
+        get_func_args_nonvariadic_len(func_codeobj) == 0
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/func/utilfuncwrap.py
@@ -0,0 +1,373 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **callable wrapper** (i.e., higher-level callable, typically
+implemented as a decorator, wrapping a lower-level callable) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilCallableWrapperException
+from beartype.typing import Any
+from beartype._cave._cavefast import MethodBoundInstanceOrClassType
+from beartype._data.hint.datahinttyping import TypeException
+from collections.abc import Callable
+
+# ....................{ UNWRAPPERS ~ once                  }....................
+#FIXME: Unit test us up, please.
+def unwrap_func_once(func: Any) -> Callable:
+    '''
+    Immediate **wrappee** (i.e., callable wrapped by the passed wrapper
+    callable) of the passed higher-level **wrapper** (i.e., callable wrapping
+    the wrappee callable to be returned) if the passed callable is a wrapper
+    *or* that callable as is otherwise (i.e., if that callable is *not* a
+    wrapper).
+
+    Specifically, this getter undoes the work performed by any of the following:
+
+    * A single use of the :func:`functools.wrap` decorator on the wrappee
+      callable to be returned.
+    * A single call to the :func:`functools.update_wrapper` function on the
+      wrappee callable to be returned.
+
+    Parameters
+    ----------
+    func : Callable
+        Wrapper callable to be unwrapped.
+
+    Returns
+    -------
+    Callable
+        The immediate wrappee callable wrapped by the passed wrapper callable.
+
+    Raises
+    ------
+    _BeartypeUtilCallableWrapperException
+        If the passed callable is *not* a wrapper.
+    '''
+
+    # Immediate wrappee callable wrapped by the passed wrapper callable if any
+    # *OR* "None" otherwise (i.e., if that callable is *NOT* a wrapper).
+    func_wrappee = getattr(func, '__wrapped__', None)
+
+    # If that callable is *NOT* a wrapper, raise an exception.
+    if func_wrappee is None:
+        raise _BeartypeUtilCallableWrapperException(
+            f'Callable {repr(func)} not wrapper '
+            f'(i.e., has no "__wrapped__" dunder attribute '
+            f'defined by @functools.wrap or functools.update_wrapper()).'
+        )
+    # Else, that callable is a wrapper.
+
+    # Return this immediate wrappee callable.
+    return func_wrappee
+
+# ....................{ UNWRAPPERS ~ once : descriptor     }....................
+#FIXME: Unit test us up, please.
+def unwrap_func_boundmethod_once(
+    # Mandatory parameters.
+    func: MethodBoundInstanceOrClassType,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableWrapperException,
+    exception_prefix: str = '',
+) -> Callable:
+    '''
+    Pure-Python unbound function wrapped by the passed **C-based bound instance
+    method descriptor** (i.e., callable implicitly instantiated and assigned on
+    the instantiation of an object whose class declares an instance function
+    (whose first parameter is typically named ``self``) as an instance variable
+    of that object such that that callable unconditionally passes that object as
+    the value of that first parameter on all calls to that callable).
+
+    Parameters
+    ----------
+    func : MethodBoundInstanceOrClassType
+        Bound method descriptor to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilCallableWrapperException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Callable
+        Pure-Python unbound function wrapped by this bound method descriptor.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a bound method descriptor.
+
+    See Also
+    --------
+    :func:`beartype._util.func.utilfunctest.is_func_boundmethod`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import die_unless_func_boundmethod
+
+    # If this object is *NOT* a class method descriptor, raise an exception.
+    die_unless_func_boundmethod(
+        func=func,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this object is a class method descriptor.
+
+    # Return the pure-Python function wrapped by this descriptor. Just do it!
+    return func.__func__
+
+
+def unwrap_func_classmethod_once(
+    # Mandatory parameters.
+    func: classmethod,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableWrapperException,
+    exception_prefix: str = '',
+) -> Callable:
+    '''
+    Pure-Python unbound function wrapped by the passed **C-based unbound class
+    method descriptor** (i.e., method decorated by the builtin
+    :class:`classmethod` decorator, yielding a non-callable instance of that
+    :class:`classmethod` decorator class implemented in low-level C and
+    accessible via the low-level :attr:`object.__dict__` dictionary rather than
+    as class or instance attributes).
+
+    Parameters
+    ----------
+    func : classmethod
+        Class method descriptor to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilCallableWrapperException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Callable
+        Pure-Python unbound function wrapped by this class method descriptor.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a class method descriptor.
+
+    See Also
+    --------
+    :func:`beartype._util.func.utilfunctest.is_func_classmethod`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import die_unless_func_classmethod
+
+    # If this object is *NOT* a class method descriptor, raise an exception.
+    die_unless_func_classmethod(
+        func=func,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this object is a class method descriptor.
+
+    # Return the pure-Python function wrapped by this descriptor. Just do it!
+    return func.__func__
+
+
+def unwrap_func_staticmethod_once(
+    # Mandatory parameters.
+    func: staticmethod,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilCallableWrapperException,
+    exception_prefix: str = '',
+) -> Callable:
+    '''
+    Pure-Python unbound function wrapped by the passed **C-based unbound static
+    method descriptor** (i.e., method decorated by the builtin
+    :class:`staticmethod` decorator, yielding a non-callable instance of that
+    :class:`staticmethod` decorator class implemented in low-level C and
+    accessible via the low-level :attr:`object.__dict__` dictionary rather than
+    as class or instance attributes).
+
+    Parameters
+    ----------
+    func : staticmethod
+        Static method descriptor to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilCallableWrapperException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Callable
+        Pure-Python unbound function wrapped by this static method descriptor.
+
+    Raises
+    ------
+    exception_cls
+         If the passed object is *not* a static method descriptor.
+
+    See Also
+    --------
+    :func:`beartype._util.func.utilfunctest.is_func_staticmethod`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import die_unless_func_staticmethod
+
+    # If this object is *NOT* a static method descriptor, raise an exception.
+    die_unless_func_staticmethod(
+        func=func,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this object is a static method descriptor.
+
+    # Return the pure-Python function wrapped by this descriptor. Just do it!
+    return func.__func__
+
+# ....................{ UNWRAPPERS ~ all                   }....................
+def unwrap_func_all(func: Any) -> Callable:
+    '''
+    Lowest-level **wrappee** (i.e., callable wrapped by the passed wrapper
+    callable) of the passed higher-level **wrapper** (i.e., callable wrapping
+    the wrappee callable to be returned) if the passed callable is a wrapper
+    *or* that callable as is otherwise (i.e., if that callable is *not* a
+    wrapper).
+
+    Specifically, this getter iteratively undoes the work performed by:
+
+    * One or more consecutive uses of the :func:`functools.wrap` decorator on
+      the wrappee callable to be returned.
+    * One or more consecutive calls to the :func:`functools.update_wrapper`
+      function on the wrappee callable to be returned.
+
+    Parameters
+    ----------
+    func : Callable
+        Wrapper callable to be unwrapped.
+
+    Returns
+    -------
+    Callable
+        Either:
+
+        * If the passed callable is a wrapper, the lowest-level wrappee
+          callable wrapped by that wrapper.
+        * Else, the passed callable as is.
+    '''
+
+    #FIXME: Not even this suffices to avoid a circular import, sadly. *sigh*
+    # Avoid circular import dependencies.
+    # from beartype._util.func.utilfunctest import is_func_wrapper
+
+    # While this callable still wraps another callable, unwrap one layer of
+    # wrapping by reducing this wrapper to its next wrappee.
+    while hasattr(func, '__wrapped__'):
+    # while is_func_wrapper(func):
+        func = func.__wrapped__  # type: ignore[attr-defined]
+
+    # Return this wrappee, which is now guaranteed to *NOT* be a wrapper.
+    return func
+
+
+#FIXME: Unit test us up, please.
+def unwrap_func_all_isomorphic(func: Any) -> Callable:
+    '''
+    Lowest-level **non-isomorphic wrappee** (i.e., callable wrapped by the
+    passed wrapper callable) of the passed higher-level **isomorphic wrapper**
+    (i.e., closure wrapping the wrappee callable to be returned by accepting
+    both a variadic positional and keyword argument and thus preserving both the
+    positions and types of all parameters originally passed to that wrappee) if
+    the passed callable is an isomorphic wrapper *or* that callable as is
+    otherwise (i.e., if that callable is *not* an isomorphic wrapper).
+
+    Specifically, this getter iteratively undoes the work performed by:
+
+    * One or more consecutive decorations of the :func:`functools.wrap`
+      decorator on the wrappee callable to be returned.
+    * One or more consecutive calls to the :func:`functools.update_wrapper`
+      function on the wrappee callable to be returned.
+
+    Parameters
+    ----------
+    func : Callable
+        Wrapper callable to be unwrapped.
+
+    Returns
+    -------
+    Callable
+        Either:
+
+        * If the passed callable is an isomorphic wrapper, the lowest-level
+          non-isomorphic wrappee callable wrapped by that wrapper.
+        * Else, the passed callable as is.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import (
+        is_func_python,
+        is_func_wrapper_isomorphic,
+    )
+
+    # While that callable is a higher-level isomorphic wrapper wrapping a
+    # lower-level callable...
+    while is_func_wrapper_isomorphic(func):
+        # Undo one layer of wrapping by reducing the former to the latter.
+        # print(f'Unwrapping isomorphic closure wrapper {func} to wrappee {func.__wrapped__}...')
+        func_wrapped = func.__wrapped__  # type: ignore[attr-defined]
+
+        # If the lower-level object wrapped by this higher-level isomorphic
+        # wrapper is *NOT* a pure-Python callable, this object is something
+        # uselessly pathological like a class or C-based callable. Silently
+        # ignore this useless object by halting iteration. Doing so preserves
+        # this useful higher-level isomorphic wrapper as is.
+        #
+        # Note that this insane edge case arises due to the standard
+        # @functools.wraps() decorator, which passively accepts possibly C-based
+        # classes by wrapping those classes with pure-Python functions: e.g.,
+        #     from beartype import beartype
+        #     from functools import wraps
+        #     from typing import Any
+        #
+        #     @beartype
+        #     @wraps(list)
+        #     def wrapper(*args: Any, **kwargs: Any):
+        #         return list(*args, **kwargs)
+        #
+        # In the above example, the higher-level isomorphic wrapper wrapper()
+        # wraps the lower-level C-based class "list".
+        #
+        # Unwrapping this wrapper to this class would induce insanity throughout
+        # the codebase, which sanely expects wrappers to be callables rather
+        # than classes. Clearly, classes have *NO* signatures. Technically, a
+        # pure-Python class may define __new__() and/or __init__() dunder
+        # methods that could be considered to be the signatures of those
+        # classes. Nonetheless, C-based classes like "list" have *NO* such
+        # analogues. The *ONLY* sane approach here is to pretend that we never
+        # saw this pathological edge case.
+        if not is_func_python(func_wrapped):
+            break
+        # Else, this lower-level callable is pure-Python.
+
+        # Reduce this higher-level wrapper to this lower-level wrappee.
+        func = func_wrapped
+
+    # Return this wrappee, which is now guaranteed to *NOT* be an isomorphic
+    # wrapper but might very well still be a wrapper, which is fine.
+    return func
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/nonpep/mod/utilmodnumpy.py
@@ -0,0 +1,348 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-noncompliant NumPy type hint** (i.e., type hint defined by
+the third-party :mod:`numpy` package) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: The top-level of this module should avoid importing from third-party
+# optional libraries, both because those libraries cannot be guaranteed to be
+# either installed or importable here *AND* because those imports are likely to
+# be computationally expensive, particularly for imports transitively importing
+# C extensions (e.g., anything from NumPy or SciPy).
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.roar import (
+    BeartypeDecorHintNonpepNumpyException,
+    BeartypeDecorHintNonpepNumpyWarning,
+)
+from beartype.typing import (
+    Any,
+    FrozenSet,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.error.utilerrwarn import issue_warning
+from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+from beartype._util.api.utilapityping import import_typing_attr_or_none
+from beartype._util.utilobject import is_object_hashable
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Refactor this function to make this function *EFFECTIVELY* cached. How?
+#By splitting this function up into smaller functions -- each of which is
+#actually cached by @callable_cached and thus called with positional arguments.
+def reduce_hint_numpy_ndarray(
+    hint: Any,
+    exception_prefix: str,
+    *args, **kwargs
+) -> Any:
+    '''
+    Reduce the passed **PEP-noncompliant typed NumPy array** (i.e.,
+    subscription of the third-party :attr:`numpy.typing.NDArray` type hint
+    factory) to the equivalent PEP-compliant beartype validator validating
+    arbitrary objects be instances of that array type -- which has the
+    substantial merit of already being well-supported, well-tested, and
+    well-known to generate optimally efficient type-checking by the
+    :func:`beartype.beartype` decorator.
+
+    Technically, beartype could instead explicitly handle typed NumPy arrays
+    throughout the codebase. Of course, doing so would yield *no* tangible
+    benefits while imposing a considerable maintenance burden.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        PEP-noncompliant typed NumPy array to be reduced.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    ----------
+    object
+        This PEP-noncompliant typed NumPy array reduced to a PEP-compliant type
+        hint supported by :mod:`beartype`.
+
+    Raises
+    ----------
+    BeartypeDecorHintNonpepNumpyException
+        If either:
+
+        * The active Python interpreter targets Python < 3.9 and either:
+
+          * The third-party :mod:`typing_extensions` module is unimportable.
+          * The third-party :mod:`typing_extensions` module is importable but
+            sufficiently old that it fails to declare the
+            :attr:`typing_extensions.Annotated` attribute.
+
+        * This hint is a typed NumPy array but either:
+
+          * *Not* subscripted by exactly two arguments.
+          * Subscripted by exactly two arguments but whose second argument is
+            neither:
+
+            * A **NumPy data type** (i.e., :class:`numpy.dtype` instance).
+            * An object coercible into a NumPy data type by passing to the
+              :meth:`numpy.dtype.__init__` method.
+    '''
+
+    # ..................{ IMPORTS                            }..................
+    # Defer heavyweight imports until *AFTER* validating this hint to be a
+    # typed NumPy array. Why? Because these imports are *ONLY* safely
+    # importable if this hint is a typed NumPy array. Why? Because
+    # instantiating this hint required these imports. QED.
+    #
+    # Note that third-party packages should typically *ONLY* be imported via
+    # utility functions raising human-readable exceptions when those packages
+    # are either uninstalled or unimportable. In this case, however, NumPy will
+    # almost *ALWAYS* be importable. Why? Because this hint was externally
+    # instantiated by the user by first importing the "numpy.typing.NDArray"
+    # attribute passed to this getter.
+    from beartype.vale import IsAttr, IsEqual, IsSubclass
+    from numpy import dtype, ndarray  # pyright: ignore[reportMissingImports]
+    from numpy.typing import NDArray  # type: ignore[attr-defined]
+
+    #FIXME: Consider submitting an upstream issue about this. We don't
+    #particularly feel like arguing tonight, because that's a lonely hill.
+
+    # If this hint is the unsubscripted "NDArray" type hint, this hint
+    # permissively matches *ALL* NumPy arrays rather than strictly matching
+    # *ONLY* appropriately typed NumPy arrays. In this case, reduce this hint
+    # to the untyped "numpy.ndarray" class.
+    #
+    # Note the similar test matching the subscripted "NDArray[Any]" hint below.
+    # Moreover, note this test *CANNOT* be performed elsewhere (e.g., by
+    # adding "HintSignNumpyArray" to the "HINT_SIGNS_ORIGIN_ISINSTANCEABLE"
+    # frozen set of all signs whose unsubscripted type hint factories are
+    # shallowly type-checkable). Why? Because the "NDArray" type hint factory
+    # violates type hinting standards. Specifically, this factory implicitly
+    # subscripts *AND* parametrizes itself with the "numpy.ScalarType" type
+    # variable bounded above by the "numpy.generic" abstract base class for
+    # NumPy scalars.
+    #
+    # We have *NO* idea why NumPy does this. This implicit behaviour is
+    # semantically lossy rather than lossless and thus arguably constitutes an
+    # upstream bug. Why? Because this behaviour violates:
+    # * The NumPy API. The "NDArray" type hint factory is subscriptable by more
+    #   than merely NumPy scalar types. Ergo, "NDArray" is semantically
+    #   inaccurate!
+    # * PEP 484, which explicitly standardizes an equivalence between
+    #   unsubscripted type hint factories and the same factories subscripted by
+    #   the "typing.Any" singleton. However, "NDArray" is *MUCH* semantically
+    #   narrower than and thus *NOT* equivalent to "NDArray[Any]"!
+    #
+    # Of course, upstream is unlikely to see it that way. We're *NOT* dying on
+    # an argumentative hill about semantics. Upstream makes the rules. Do it.
+    if hint is NDArray:
+        return ndarray
+
+    # ..................{ CONSTANTS                          }..................
+    # Frozen set of all NumPy scalar data type abstract base classes (ABCs).
+    NUMPY_DTYPE_TYPE_ABCS = _get_numpy_dtype_type_abcs()
+
+    # ..................{ ARGS                               }..................
+    # Objects subscripting this hint if any *OR* the empty tuple otherwise.
+    hint_args = get_hint_pep_args(hint)
+
+    # If this hint was *NOT* subscripted by exactly two arguments, this hint is
+    # malformed as a typed NumPy array. In this case, raise an exception.
+    if len(hint_args) != 2:
+        raise BeartypeDecorHintNonpepNumpyException(
+            f'{exception_prefix}typed NumPy array {repr(hint)} '
+            f'not subscripted by exactly two arguments.'
+        )
+    # Else, this hint was subscripted by exactly two arguments.
+
+    # Data type subhint subscripting this hint. Yes, the "numpy.typing.NDArray"
+    # type hint bizarrely encapsulates its data type argument into a private
+    # "numpy._DTypeMeta" type subhint. Why? We have absolutely no idea, but we
+    # have no say in the matter. NumPy, you're on notice for stupidity.
+    hint_dtype_subhint = hint_args[1]
+
+    # Objects subscripting this subhint if any *OR* the empty tuple otherwise.
+    hint_dtype_subhint_args = get_hint_pep_args(hint_dtype_subhint)
+
+    # If this hint was *NOT* subscripted by exactly one argument, this subhint
+    # is malformed as a data type subhint. In this case, raise an exception.
+    if len(hint_dtype_subhint_args) != 1:
+        raise BeartypeDecorHintNonpepNumpyException(
+            f'{exception_prefix}typed NumPy array {repr(hint)} '
+            f'data type subhint {repr(hint_dtype_subhint)} '
+            f'not subscripted by exactly one argument.'
+        )
+    # Else, this subhint was subscripted by exactly one argument.
+
+    # Data type-like object subscripting this subhint. Look, just do it.
+    hint_dtype_like = hint_dtype_subhint_args[0]
+
+    # If this dtype-like is "typing.Any", this hint permissively matches *ALL*
+    # NumPy arrays rather than strictly matching *ONLY* appropriately typed
+    # NumPy arrays. In this case, reduce this hint to the untyped
+    # "numpy.ndarray" class.
+    #
+    # Note the similar test matching the unsubscripted "NDArray" hint above.
+    if hint_dtype_like is Any:
+        return ndarray
+
+    # ..................{ REDUCTION                          }..................
+    #FIXME: Safely replace this with "from typing import Annotated" after
+    #dropping Python 3.8 support.
+    # "typing.Annotated" type hint factory safely imported from whichever of
+    # the "typing" or "typing_extensions" modules declares this attribute if
+    # one or more do *OR* "None" otherwise (i.e., if none do).
+    typing_annotated = import_typing_attr_or_none('Annotated')
+
+    # If this factory is unimportable, this typed NumPy array *CANNOT* be
+    # reduced to a subscription of this factory by one or more semantically
+    # equivalent beartype validators. In this case...
+    if typing_annotated is None:
+        # Emit a non-fatal warning informing the user of this issue.
+        issue_warning(
+            cls=BeartypeDecorHintNonpepNumpyWarning,
+            message=(
+                f'{exception_prefix}typed NumPy array {repr(hint)} '
+                f'reduced to untyped NumPy array {repr(ndarray)} '
+                f'(i.e., as neither "typing.Annotated" nor '
+                f'"typing_extensions.Annotated" importable).'
+            ),
+        )
+
+        # Reduce this hint to the untyped "ndarray" class with apologies.
+        return ndarray
+    # Else, this factory is importable.
+
+    # Equivalent nested beartype validator reduced from this hint.
+    hint_validator = None  # type: ignore[assignment]
+
+    # If...
+    if (
+        # This dtype-like is hashable *AND*...
+        is_object_hashable(hint_dtype_like) and
+        # This dtype-like is a scalar data type abstract base class (ABC)...
+        hint_dtype_like in NUMPY_DTYPE_TYPE_ABCS
+    ):
+        # Then avoid attempting to coerce this possibly non-dtype into a proper
+        # dtype. Although NumPy previously silently coerced these ABCs into
+        # dtypes (e.g., from "numpy.floating" to "numpy.float64"), recent
+        # versions of NumPy now emit non-fatal deprecation warnings on doing so
+        # and will presumably raise fatal exceptions in the near future:
+        #     >>> import numpy as np
+        #     >>> np.dtype(np.floating)
+        #     DeprecationWarning: Converting `np.inexact` or `np.floating` to a
+        #     dtype is deprecated. The current result is `float64` which is not
+        #     strictly correct.
+        #
+        # We instead follow mypy's lead presumably defined somewhere in the
+        # incredibly complex innards of NumPy's mypy plugin -- which we
+        # admittedly failed to grep despite ~~wasting~~ "investing" several
+        # hours in doing so. Specifically, mypy treats subscriptions of the
+        # "numpy.typing.NDArray" type hint factory by one of these ABCs (rather
+        # than either a scalar or proper dtype) as a type inheritance (rather
+        # than object equality) relation. Since this is sensible, we do too.
+
+        # Equivalent nested beartype validator reduced from this hint.
+        hint_validator = (
+            IsAttr['dtype', IsAttr['type', IsSubclass[hint_dtype_like]]])
+    # Else, this dtype-like is either unhashable *OR* not such an ABC.
+    else:
+        # Attempt to coerce this possibly non-dtype into a proper dtype. Note
+        # that the dtype.__init__() constructor efficiently maps non-dtype
+        # scalar types (e.g., "numpy.float64") to corresponding cached dtypes:
+        #     >>> import numpy
+        #     >>> i4_dtype = numpy.dtype('>i4')
+        #     >>> numpy.dtype(i4_dtype) is numpy.dtype(i4_dtype)
+        #     True
+        #     >>> numpy.dtype(numpy.float64) is numpy.dtype(numpy.float64)
+        #     True
+        #
+        # Ergo, the call to this constructor here is guaranteed to already
+        # effectively be memoized.
+        try:
+            hint_dtype = dtype(hint_dtype_like)
+        # If this object is *NOT* coercible into a dtype, raise an exception.
+        # This is essential. As of NumPy 1.21.0, "numpy.typing.NDArray" fails
+        # to validate its subscripted argument to actually be a dtype: e.g.,
+        #     >>> from numpy.typing import NDArray
+        #     >>> NDArray['wut']
+        #     numpy.ndarray[typing.Any, numpy.dtype['wut']]  # <-- you kidding me?
+        except Exception as exception:
+            raise BeartypeDecorHintNonpepNumpyException(
+                f'{exception_prefix}typed NumPy array {repr(hint)} '
+                f'data type {repr(hint_dtype_like)} invalid '
+                f'(i.e., neither data type nor coercible into data type).'
+            ) from exception
+        # Else, this object is now a proper dtype.
+
+        # Equivalent nested beartype validator reduced from this hint.
+        hint_validator = IsAttr['dtype', IsEqual[hint_dtype]]
+
+    # Replace the usually less readable representation of this validator with
+    # the usually more readable representation of this hint (e.g.,
+    # "numpy.ndarray[typing.Any, numpy.float64]").
+    hint_validator.get_repr = repr(hint)
+
+    # Return this validator annotating the NumPy array type.
+    return typing_annotated[ndarray, hint_validator]
+
+# ....................{ PRIVATE ~ getter                   }....................
+#FIXME: File an upstream NumPy issue politely requesting they publicize either:
+#* An equivalent container listing these types.
+#* Documentation officially listing these types.
+@callable_cached
+def _get_numpy_dtype_type_abcs() -> FrozenSet[type]:
+    '''
+    Frozen set of all **NumPy scalar data type abstract base classes** (i.e.,
+    superclasses of all concrete NumPy scalar data types (e.g.,
+    :class:`numpy.int64`, :class:`numpy.float32`)).
+
+    This getter is memoized for efficiency. To defer the substantial cost of
+    importing from NumPy, the frozen set memoized by this getter is
+    intentionally deferred to call time rather than globalized as a constant.
+
+    Caveats
+    ----------
+    **NumPy currently provides no official container listing these classes.**
+    Likewise, NumPy documentation provides no official list of these classes.
+    Ergo, this getter. This has the dim advantage of working but the profound
+    disadvantage of inviting inevitable discrepancies between the
+    :mod:`beartype` and :mod:`numpy` codebases. So it goes.
+    '''
+
+    # Defer heavyweight imports.
+    from numpy import (  # pyright: ignore[reportMissingImports]
+        character,
+        complexfloating,
+        flexible,
+        floating,
+        generic,
+        inexact,
+        integer,
+        number,
+        signedinteger,
+        unsignedinteger,
+    )
+
+    # Create, return, and cache a frozen set listing these ABCs.
+    return frozenset((
+        character,
+        complexfloating,
+        flexible,
+        floating,
+        generic,
+        inexact,
+        integer,
+        number,
+        signedinteger,
+        unsignedinteger,
+    ))
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/nonpep/mod/utilmodpandera.py
@@ -0,0 +1,188 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-noncompliant NumPy type hint** (i.e., type hint defined by
+the third-party :mod:`numpy` package) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: The top-level of this module should avoid importing from third-party
+# optional libraries, both because those libraries cannot be guaranteed to be
+# either installed or importable here *AND* because those imports are likely to
+# be computationally expensive, particularly for imports transitively importing
+# C extensions (e.g., anything from NumPy or SciPy).
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.roar import BeartypeDecorHintNonpepPanderaException
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pandera(
+    hint: object,
+    exception_prefix: str,
+    *args, **kwargs
+) -> type:
+    '''
+    Reduce the passed **PEP-noncompliant Pandera type hint** (i.e.,
+    subscription of *any* PEP-noncompliant type hint factory published by the
+    third-party :mod:`pandera.typing` type hint factory) to the isinstanceable
+    Pandas type subclassed by this hint, which :mod:`beartype` then subsequently
+    subjects to shallow type-checking.
+
+    This reducer enables :mod:`beartype` to at least shallowly type-check
+    Pandera type hints while allowing Pandera itself to deeply type-check the
+    same hints. Pandera publishes its own Pandera-specific PEP-noncompliant
+    runtime type-checking decorator :func:`pandera.check_types` that supports
+    *only* Pandera-specific PEP-noncompliant :mod:`pandera.typing` type hints.
+    Since Pandera users are already accustomed to decorating *all* Pandera-based
+    callables (i.e., callables accepting one or more parameters and/or returning
+    one or more values annotated by Pandera type hints) with
+    :func:`pandera.check_types`, attempting to deeply type-check the same
+    objects already type-checked by that decorator would only inefficiently and
+    needlessly slow type-checking wrappers generated by the
+    :func:`beartype.beartype` decorator. Moreover, doing so is infeasible.
+    Pandera type hints are extremely non-standard and thus *not* reasonably
+    type-checkable by any standards-compliant static or runtime type-checkers.
+    Shallowly type-checking Pandera type hints is still beneficial, however, as:
+
+    * Pandera itself currently fails to shallowly type-check its own type hints.
+      That is to say, if a caller passes a string rather than a Pandas data
+      frame to a :func:`pandera.check_types`-decorated function, that function
+      will silently accept that string rather than raise an exception. *sigh*
+    * Functions annotated by one or more Pandera type hints that are (either
+      intentionally or accidentally) *not* decorated by
+      :func:`pandera.check_types` will still receive at least a modicum of
+      shallow type-checking support from :mod:`beartype` itself.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Motivation
+    ----------
+    The core issue with Pandera type hints is somewhat more subtle than the glib
+    hand-waving performed above. Yes, Pandera type hints *are* PEP-noncompliant,
+    but they're more than just that. Pandera type hints fundamentally contravene
+    established semantics for PEP-compliant generics. Generally speaking,
+    generics are *not* simply descriptive type hints; they're full-blown classes
+    intended to be instantiated as objects throughout the codebase using those
+    generics as type hints. The unsubscripted portion of a generic hint is an
+    instanceable class (e.g., the "list" in "list[str]" is itself an
+    instanceable class). @beartype expects any object annotated by a generic
+    type hint to be an instance of that generic: e.g.,
+
+    .. code-block:: pycon
+
+       # A PEP 585-compliant generic.
+       >>> class ListOfStrings(list[str]): pass
+
+       # An instance of this generic satisfies this generic used as a type hint.
+       >>> from beartype import beartype
+       >>> @beartype
+       ... def accept_list_of_strings(lst: ListOfStrings): return 'Okie-dokie!'
+       >>> accept_list_of_strings(ListOfStrings())
+       'Okie-dokie!'
+
+    Pandera type hints violate this expectation. Syntactically, Pandera type
+    hints are PEP-compliant generics (of course); semantically, Pandera type
+    hints are PEP-noncompliant generics, because the objects they describe
+    (i.e., Pandas data frames) are *not* instances of these generics. Pandas
+    data frames are instances of the Pandera-agnostic
+    "pandas.core.frame.DataFrame" non-generic class rather than Pandera-specific
+    "pandera.typing.pandas.DataFrame" generic.
+
+    Pandera type hints *should* have been instead defined as PEP 544-compliant
+    protocols that exploit ephemeral duck typing. Since they weren't, downstream
+    consumers like @beartype must now pretend that Pandera type hints are the
+    Pandas types they semantically alias by reducing the former to the latter.
+
+    Caveats
+    ----------
+    **This reducer does not validate the callable annotated by this Pandera type
+    hint to be decorated by the** :func:`pandera.check_types` **decorator.**
+    Ideally, this reducer would do so to prevent :mod:`beartype` from emitting
+    false positives and negatives from calls to callables for which the user
+    accidentally omitted the :func:`pandera.check_types` decorator.
+    Unfortunately, order of decoration is arbitrary. :mod:`beartype` has no
+    means of distinguishing between these two cases:
+
+    * The valid case in which the user decorated this callable first by
+      :func:`beartype.beartype` and then by :func:`pandera.check_types`. In this
+      case, :func:`beartype.beartype` runs first and has no efficient means of
+      deciding that the :func:`pandera.check_types` will be run immediately
+      after -- short of abstract syntax tree (AST) inspection, which would be
+      extraordinarily inefficient, non-portable, and fragile.
+    * The invalid case in which the user accidentally omitted the
+      :func:`pandera.check_types` decorator.
+
+    **This reducer does not validate that this Pandera type hint annotates a
+    callable.** Technically, Pandera type hints are invalid in *all* type
+    hinting contexts except as callable annotations -- including:
+
+    * As a class type hint.
+    * As an attribute assignment type hint.
+    * As the type hint passed to a statement-level runtime type-checker (e.g.,
+      :func:`beartype.door.is_bearable`).
+
+    Pragmatically, refactoring :mod:`beartype` to inform reducers of whether or
+    not the current hint (that may be a nested child type hint of a parent type
+    hint) annotates a callable or not would be extraordinarily non-trivial.
+    Doing so would require refactoring our low-level:
+
+    * Code generators to accept an additional parameter describing this case.
+    * Type hint reducers to transitively pass that same parameter here.
+
+    Since Pandera type hints are already PEP-noncompliant, the only sane
+    approach is to continue unconditionally ignoring them. Let us not break
+    :mod:`beartype` for the PEP-noncompliant.
+
+    Parameters
+    ----------
+    hint : object
+        PEP-noncompliant typed NumPy array to return the data type of.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    ----------
+    type
+        Isinstanceable Pandas type subclassed by this Pandera type hint.
+
+    Raises
+    ----------
+    BeartypeDecorHintNonpepPanderaException
+        If either:
+
+        * This hint is *not* a PEP 484- or 585-compliant generic.
+        * This hint is a PEP 484- or 585-compliant generic *not* subclassing one
+          or more Pandas-specific superclasses.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+        find_hint_pep484585_generic_module_base_first)
+
+    # Find and return the first Pandas type subclassed by this Pandera generic
+    # type hint.
+    #
+    # Note that we intentionally pass positional rather than keyword arguments
+    # as a microoptimization for improved cache-time efficiency. Gah!
+    return find_hint_pep484585_generic_module_base_first(
+        hint=hint,
+        module_name=_PANDAS_MODULE_NAME,
+        exception_cls=BeartypeDecorHintNonpepPanderaException,
+        exception_prefix=exception_prefix,
+    )
+
+# ....................{ PRIVATE ~ constants                }....................
+_PANDAS_MODULE_NAME='pandas'
+'''
+Fully-qualified name of the package providing the third-party Pandas project.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/nonpep/utilnonpeptest.py
@@ -0,0 +1,565 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-noncompliant type hint tester** (i.e., callable validating an
+arbitrary object to be a PEP-noncompliant type hint) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Validate strings to be syntactically valid classnames via a globally
+#scoped compiled regular expression. Raising early exceptions at decoration
+#time is preferable to raising late exceptions at call time.
+#FIXME: Indeed, we now provide such a callable:
+#    from beartype._util.module.utilmodget import die_unless_module_attr_name
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintNonpepException
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.cls.pep.utilpep3119 import (
+    die_unless_type_isinstanceable,
+    is_type_isinstanceable,
+)
+from beartype._data.hint.datahinttyping import TypeException
+
+# ....................{ VALIDATORS                         }....................
+#FIXME: Unit test us up, please.
+def die_if_hint_nonpep(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    is_str_valid: bool = True,
+    exception_cls: TypeException = BeartypeDecorHintNonpepException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception if the passed object is a **PEP-noncompliant type hint**
+    (i.e., :mod:`beartype`-specific annotation *not* compliant with
+    annotation-centric PEPs).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    is_str_valid : bool, optional
+        :data:`True` only if this function permits this tuple to contain
+        strings. Defaults to :data:`False`. If this boolean is:
+
+        * :data:`True`, this tuple is valid only when containing classes and/or
+          classnames.
+        * :data:`False`, this object is valid only when containing classes.
+    exception_cls : type[Exception]
+        Type of the exception to be raised by this function. Defaults to
+        :class:`BeartypeDecorHintNonpepException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is either:
+
+        * An **isinstanceable type** (i.e., standard class passable as the
+          second parameter to the :func:`isinstance` builtin and thus typically
+          *not* compliant with annotation-centric PEPs).
+        * A **non-empty tuple** (i.e., semantic union of types) containing one
+          or more:
+
+          * Non-:mod:`typing` types.
+          * If ``is_str_valid``, **strings** (i.e., forward references
+            specified as either fully-qualified or unqualified classnames).
+    '''
+
+    # If this object is a PEP-noncompliant type hint, raise an exception.
+    #
+    # Note that this memoized call is intentionally passed positional rather
+    # than keyword parameters to maximize efficiency.
+    if is_hint_nonpep(hint, is_str_valid):
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not type.')
+        assert issubclass(exception_cls, Exception), (
+            f'{repr(exception_cls)} not exception type.')
+
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} '
+            f'is PEP-noncompliant (e.g., neither ' +
+            (
+                (
+                    'isinstanceable class, forward reference, nor tuple of '
+                    'isinstanceable classes and/or forward references).'
+                )
+                if is_str_valid else
+                'isinstanceable class nor tuple of isinstanceable classes).'
+            )
+        )
+    # Else, this object is *NOT* a PEP-noncompliant type hint.
+
+
+#FIXME: Unit test this function with respect to non-isinstanceable classes.
+def die_unless_hint_nonpep(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    is_str_valid: bool = True,
+    exception_cls: TypeException = BeartypeDecorHintNonpepException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **PEP-noncompliant type
+    hint** (i.e., :mod:`beartype`-specific annotation *not* compliant with
+    annotation-centric PEPs).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    is_str_valid : bool, optional
+        :data:`True` only if this function permits this tuple to contain
+        strings. Defaults to :data:`False`. If this boolean is:
+
+        * :data:`True`, this tuple is valid only when containing classes and/or
+          classnames.
+        * :data:`False`, this object is valid only when containing classes.
+    exception_cls : type[Exception], optional
+        Type of the exception to be raised by this function. Defaults to
+        :class:`BeartypeDecorHintNonpepException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is neither:
+
+        * An **isinstanceable type** (i.e., standard class passable as the
+          second parameter to the :func:`isinstance` builtin and thus typically
+          *not* compliant with annotation-centric PEPs).
+        * A **non-empty tuple** (i.e., semantic union of types) containing one
+          or more:
+
+          * Non-:mod:`typing` types.
+          * If ``is_str_valid``, **strings** (i.e., forward references
+            specified as either fully-qualified or unqualified classnames).
+    '''
+
+    # If this object is a PEP-noncompliant type hint, reduce to a noop.
+    #
+    # Note that this memoized call is intentionally passed positional rather
+    # than keyword parameters to maximize efficiency.
+    if is_hint_nonpep(hint, is_str_valid):
+        return
+    # Else, this object is *NOT* a PEP-noncompliant type hint. In this case,
+    # subsequent logic raises an exception specific to the passed parameters.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with the is_hint_nonpep() tester below.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    assert isinstance(exception_cls, type), (
+        f'{repr(exception_cls)} not type.')
+    assert isinstance(exception_prefix, str), (
+        f'{repr(exception_prefix)} not string.')
+
+    # If this object is a class...
+    if isinstance(hint, type):
+        # If this class is *NOT* PEP-noncompliant, raise an exception.
+        die_unless_hint_nonpep_type(
+            hint=hint,
+            exception_prefix=exception_prefix,
+            exception_cls=exception_cls,
+        )
+
+        # Else, this class is isinstanceable. In this case, silently accept
+        # this class as is.
+        return
+    # Else, this object is *NOT* a class.
+    #
+    # If this object is a tuple, raise a tuple-specific exception.
+    elif isinstance(hint, tuple):
+        die_unless_hint_nonpep_tuple(
+            hint=hint,
+            is_str_valid=is_str_valid,
+            exception_prefix=exception_prefix,
+            exception_cls=exception_cls,
+        )
+    # Else, this object is neither a type nor type tuple.
+
+    # Raise a generic exception.
+    raise exception_cls(
+        f'{exception_prefix}type hint {repr(hint)} either '
+        f'PEP-noncompliant or currently unsupported by @beartype.'
+    )
+
+# ....................{ VALIDATORS ~ kind                  }....................
+#FIXME: Unit test us up.
+def die_unless_hint_nonpep_type(
+    # Mandatory parameters.
+    hint: type,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintNonpepException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is an **isinstanceable type**
+    (i.e., standard class passable as the second parameter to the
+    :func:`isinstance` builtin and thus typically *not* compliant with
+    annotation-centric PEPs).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Parameters
+    ----------
+    hint : type
+        Object to be validated.
+    exception_cls : Optional[type]
+        Type of the exception to be raised by this function. Defaults to
+        :class:`BeartypeDecorHintNonpepException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this object is *not* an isinstanceable class (i.e., class passable
+        as the second argument to the :func:`isinstance` builtin).
+    exception_cls
+        If this object is a PEP-compliant type hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpeptest import die_if_hint_pep
+
+    # If this object is a PEP-compliant type hint, raise an exception.
+    die_if_hint_pep(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this object is *NOT* a PEP-noncompliant type hint.
+    #
+    # If this object is *NOT* an isinstanceable class, raise an exception. Note
+    # that this validation is typically slower than the prior validation and
+    # thus intentionally performed last.
+    die_unless_type_isinstanceable(
+        cls=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # If this object is an isinstanceable class.
+
+
+#FIXME: Unit test this function with respect to tuples containing
+#non-isinstanceable classes.
+#FIXME: Optimize both this and the related _is_hint_nonpep_tuple() tester
+#defined below. The key realization here is that EAFP is *MUCH* faster in this
+#specific case than iteration. Why? Because iteration is guaranteed to
+#internally raise a stop iteration exception, whereas EAFP only raises an
+#exception if this tuple is invalid, in which case efficiency is no longer a
+#concern. So, what do we do instead? Simple. We internally refactor:
+#* If "is_str_valid" is True, we continue to perform the existing
+#  implementation of both functions. *shrug*
+#* Else, we:
+#  * Perform a new optimized EAFP-style isinstance() check resembling that
+#    performed by die_unless_type_isinstanceable().
+#  * Likewise for _is_hint_nonpep_tuple() vis-a-vis is_type_isinstanceable().
+#Fortunately, tuple unions are now sufficiently rare in the wild (i.e., in
+#real-world use cases) that this mild inefficiency probably no longer matters.
+#FIXME: Indeed! Now that we have the die_unless_object_isinstanceable()
+#validator, this validator should reduce to efficiently calling
+#die_unless_object_isinstanceable() directly if "is_str_valid" is False.
+#die_unless_object_isinstanceable() performs the desired EAFP-style
+#isinstance() check in an optimally efficient manner.
+def die_unless_hint_nonpep_tuple(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    is_str_valid: bool = False,
+    exception_cls: TypeException = BeartypeDecorHintNonpepException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **PEP-noncompliant tuple**
+    (i.e., :mod:`beartype`-specific tuple of one or more PEP-noncompliant types
+    *not* compliant with annotation-centric PEPs).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    is_str_valid : bool, optional
+        :data:`True` only if this function permits this tuple to contain
+        strings. Defaults to :data:`False`. If this boolean is:
+
+        * :data:`True`, this tuple is valid only when containing classes and/or
+          classnames.
+        * :data:`False`, this object is valid only when containing classes.
+    exception_cls : type, optional
+        Type of the exception to be raised by this function. Defaults to
+        :class:`BeartypeDecorHintNonpepException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is neither:
+
+        * A non-:mod:`typing` type (i.e., class *not* defined by the
+          :mod:`typing` module, whose public classes are used to instantiate
+          PEP-compliant type hints or objects satisfying such hints that
+          typically violate standard class semantics and thus require
+          PEP-specific handling).
+        * A **non-empty tuple** (i.e., semantic union of types) containing one
+          or more:
+
+          * Non-:mod:`typing` types.
+          * If ``is_str_valid``, **strings** (i.e., forward references
+            specified as either fully-qualified or unqualified classnames).
+    '''
+
+    # If this object is a tuple union, reduce to a noop.
+    #
+    # Note that this memoized call is intentionally passed positional rather
+    # than keyword parameters to maximize efficiency.
+    if _is_hint_nonpep_tuple(hint, is_str_valid):
+        return
+    # Else, this object is *NOT* a tuple union. In this case, subsequent logic
+    # raises an exception specific to the passed parameters.
+    #
+    # Note that the prior call has already validated "is_str_valid".
+    assert isinstance(exception_cls, type), f'{repr(exception_cls)} not type.'
+    assert isinstance(exception_prefix, str), (
+        f'{repr(exception_prefix)} not string.')
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with the _is_hint_nonpep_tuple() tester.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # If this object is *NOT* a tuple, raise an exception.
+    if not isinstance(hint, tuple):
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not tuple.')
+    # Else, this object is a tuple.
+    #
+    # If this tuple is empty, raise an exception.
+    elif not hint:
+        raise exception_cls(f'{exception_prefix}tuple type hint empty.')
+    # Else, this tuple is non-empty.
+
+    # For each item of this tuple...
+    for hint_item in hint:
+        # Duplicate the above logic. For negligible efficiency gains (and more
+        # importantly to avoid exhausting the stack), avoid calling this
+        # function recursively to do so. *shrug*
+
+        # If this item is a class...
+        if isinstance(hint_item, type):
+            # If this class is *NOT* isinstanceable, raise an exception.
+            die_unless_type_isinstanceable(
+                cls=hint_item,
+                exception_prefix=exception_prefix,
+                exception_cls=exception_cls,
+            )
+        # Else, this item is *NOT* a class.
+        #
+        # If this item is a forward reference...
+        elif isinstance(hint_item, str):
+            # If forward references are unsupported, raise an exception.
+            if not is_str_valid:
+                raise exception_cls(
+                    f'{exception_prefix}tuple type hint {repr(hint)} '
+                    f'forward reference "{hint_item}" unsupported.'
+                )
+            # Else, silently accept this item.
+        # Else, this item is neither a class nor forward reference. Ergo,
+        # this item is *NOT* a PEP-noncompliant type hint. In this case,
+        # raise an exception whose message contextually depends on whether
+        # forward references are permitted or not.
+        else:
+            raise exception_cls(
+                f'{exception_prefix}tuple type hint {repr(hint)} '
+                f'item {repr(hint_item)} invalid '
+                f'{"neither type nor string" if is_str_valid else "not type"}.'
+            )
+
+# ....................{ TESTERS                            }....................
+def is_hint_nonpep(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    is_str_valid: bool = False,
+) -> bool:
+    '''
+    :data:`True` only if the passed object is a **PEP-noncompliant type hint**
+    (i.e., :mod:`beartype`-specific annotation *not* compliant with
+    annotation-centric PEPs).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    is_str_valid : bool, optional
+        :data:`True` only if this function permits this tuple to contain
+        strings. Defaults to :data:`False`. If this boolean is:
+
+        * :data:`True`, this tuple is valid only when containing classes and/or
+          classnames.
+        * :data:`False`, this object is valid only when containing classes.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is either:
+
+        * A non-:mod:`typing` type (i.e., class *not* defined by the
+          :mod:`typing` module, whose public classes are used to instantiate
+          PEP-compliant type hints or objects satisfying such hints that
+          typically violate standard class semantics and thus require
+          PEP-specific handling).
+        * A **non-empty tuple** (i.e., semantic union of types) containing one
+          or more:
+
+          * Non-:mod:`typing` types.
+          * If ``is_str_valid``, **strings** (i.e., forward references
+            specified as either fully-qualified or unqualified classnames).
+    '''
+    assert isinstance(is_str_valid, bool), f'{repr(is_str_valid)} not boolean.'
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with die_unless_hint_nonpep() above.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Return true only if either...
+    return (
+        # If this object is a class, return true only if this is *NOT* a
+        # PEP-compliant class, in which case this *MUST* be a PEP-noncompliant
+        # class by definition.
+        _is_hint_nonpep_type(hint) if isinstance(hint, type) else
+        # Else, this object is *NOT* a class.
+        #
+        # If this object is a tuple, return true only if this tuple contains
+        # only one or more caller-permitted forward references and
+        # PEP-noncompliant classes.
+        _is_hint_nonpep_tuple(hint, is_str_valid) if isinstance(hint, tuple)
+        # Else, this object is neither a class nor tuple. Return false, as this
+        # object *CANNOT* be PEP-noncompliant.
+        else False
+    )
+
+# ....................{ TESTERS ~ private                  }....................
+@callable_cached
+def _is_hint_nonpep_tuple(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    is_str_valid: bool = False,
+) -> bool:
+    '''
+    :data:`True` only if the passed object is a PEP-noncompliant non-empty tuple
+    of one or more types.
+
+    This tester is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    is_str_valid : bool, optional
+        :data:`True` only if this function permits this tuple to contain
+        strings. Defaults to :data:`False`. If this boolean is:
+
+        * :data:`True`, this tuple is valid only when containing classes and/or
+          classnames.
+        * :data:`False`, this object is valid only when containing classes.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a **non-empty tuple** (i.e.,
+        semantic union of types) containing one or more:
+
+          * Non-:mod:`typing` types.
+          * If ``is_str_valid``, **strings** (i.e., forward references
+            specified as either fully-qualified or unqualified classnames).
+    '''
+    assert isinstance(is_str_valid, bool), f'{repr(is_str_valid)} not boolean.'
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with die_unless_hint_nonpep() above.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Return true only if this object is...
+    return (
+        # A tuple *AND*...
+        isinstance(hint, tuple) and
+        # This tuple is non-empty *AND*...
+        len(hint) > 0 and
+        # Each item of this tuple is either a caller-permitted forward
+        # reference *OR* an isinstanceable class.
+        all(
+            is_type_isinstanceable(hint_item) if isinstance(hint_item, type) else
+            is_str_valid                               if isinstance(hint_item, str) else
+            False
+            for hint_item in hint
+        )
+    )
+
+
+def _is_hint_nonpep_type(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a PEP-noncompliant type.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a PEP-noncompliant type.
+    '''
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with die_unless_hint_nonpep() above.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpeptest import is_hint_pep
+
+    # Return true only if this object is isinstanceable and *NOT* a
+    # PEP-compliant class, in which case this *MUST* be a PEP-noncompliant
+    # class by definition.
+    return is_type_isinstanceable(hint) and not is_hint_pep(hint)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484/utilpep484.py
@@ -0,0 +1,292 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.meta import URL_PEP585_DEPRECATIONS
+from beartype.roar import BeartypeDecorHintPep585DeprecationWarning
+from beartype._cave._cavefast import NoneType
+from beartype._data.hint.pep.datapeprepr import (
+    HINTS_PEP484_REPR_PREFIX_DEPRECATED)
+from beartype._util.error.utilerrwarn import issue_warning
+
+# Intentionally import PEP 484-compliant "typing" type hint factories rather
+# than possibly PEP 585-compliant "beartype.typing" type hint factories.
+from typing import (
+    Generic,
+    Tuple,
+)
+
+# ....................{ HINTS                              }....................
+HINT_PEP484_TUPLE_EMPTY = Tuple[()]
+'''
+:pep:`484`-compliant empty fixed-length tuple type hint.
+'''
+
+# ....................{ TESTERS ~ ignorable                }....................
+#FIXME: Shift into a more appropriate submodule, please.
+def is_hint_pep484585_generic_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed :pep:`484`- or :pep:`585`-compliant generic
+    is ignorable.
+
+    Specifically, this tester ignores *all* parametrizations of the
+    :class:`typing.Generic` abstract base class (ABC) by one or more type
+    variables. As the name implies, this ABC is generic and thus fails to impose
+    any meaningful constraints. Since a type variable in and of itself also
+    fails to impose any meaningful constraints, these parametrizations are
+    safely ignorable in all possible contexts: e.g.,
+
+    .. code-block:: python
+
+       from typing import Generic, TypeVar
+       T = TypeVar('T')
+       def noop(param_hint_ignorable: Generic[T]) -> T: pass
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`484`-compliant type hint is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_origin_or_none
+    # print(f'Testing generic hint {repr(hint)} deep ignorability...')
+
+    # If this generic is the "typing.Generic" superclass directly parametrized
+    # by one or more type variables (e.g., "typing.Generic[T]"), return true.
+    #
+    # Note that we intentionally avoid calling the
+    # get_hint_pep_origin_type_isinstanceable_or_none() function here, which has
+    # been intentionally designed to exclude PEP-compliant type hints
+    # originating from "typing" type origins for stability reasons.
+    if get_hint_pep_origin_or_none(hint) is Generic:
+        # print(f'Testing generic hint {repr(hint)} deep ignorability... True')
+        return True
+    # Else, this generic is *NOT* the "typing.Generic" superclass directly
+    # parametrized by one or more type variables and thus *NOT* an ignorable
+    # non-protocol.
+    #
+    # Note that this condition being false is *NOT* sufficient to declare this
+    # hint to be unignorable. Notably, the origin type originating both
+    # ignorable and unignorable protocols is "Protocol" rather than "Generic".
+    # Ergo, this generic could still be an ignorable protocol.
+    # print(f'Testing generic hint {repr(hint)} deep ignorability... False')
+
+    #FIXME: Probably insufficient. *shrug*
+    return False
+
+
+#FIXME: Remove this *AFTER* properly supporting type variables. For now,
+#ignoring type variables is required ta at least shallowly support generics
+#parametrized by one or more type variables.
+def is_hint_pep484_typevar_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` unconditionally.
+
+    This tester currently unconditionally ignores *all* :pep:`484`-compliant
+    type variables, which require non-trivial and currently unimplemented
+    code generation support.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`484`-compliant type hint is ignorable.
+    '''
+
+    # Ignore *ALL* PEP 484-compliant type variables.
+    return True
+
+
+#FIXME: Shift into a more appropriate submodule, please.
+def is_hint_pep484604_union_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed :pep:`484`- or :pep:`604`-compliant union is
+    ignorable.
+
+    Specifically, this tester ignores the :obj:`typing.Optional` or
+    :obj:`typing.Union` singleton subscripted by one or more ignorable type
+    hints (e.g., ``typing.Union[typing.Any, bool]``). Why? Because unions are by
+    definition only as narrow as their widest child hint. However, shallowly
+    ignorable type hints are ignorable precisely because they are the widest
+    possible hints (e.g., :class:`object`, :attr:`typing.Any`), which are so
+    wide as to constrain nothing and convey no meaningful semantics. A union of
+    one or more shallowly ignorable child hints is thus the widest possible
+    union, which is so wide as to constrain nothing and convey no meaningful
+    semantics. Since there exist a countably infinite number of possible
+    :data:`Union` subscriptions by one or more ignorable type hints, these
+    subscriptions *cannot* be explicitly listed in the
+    :data:`beartype._data.hint.pep.datapeprepr.HINTS_REPR_IGNORABLE_SHALLOW`
+    frozenset. Instead, these subscriptions are dynamically detected by this
+    tester at runtime and thus referred to as **deeply ignorable type hints.**
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`484`-compliant type hint is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+    from beartype._util.hint.utilhinttest import is_hint_ignorable
+
+    # Return true only if one or more child hints of this union are recursively
+    # ignorable. See the function docstring.
+    return any(
+        is_hint_ignorable(hint_child) for hint_child in get_hint_pep_args(hint))
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep484_deprecated(
+    hint: object, exception_prefix : str, *args, **kwargs) -> object:
+    '''
+    Preserve the passed :pep:`484`-compliant type hint as is while emitting one
+    non-fatal deprecation warning for this type hint if **deprecated** (i.e.,
+    obsoleted by an equivalent :pep:`585`-compliant type hint *and* the active
+    Python interpreter targets Python >= 3.9).
+
+    While *not* explicitly defined by the :mod:`typing` module, :pep:`484`
+    explicitly supports this singleton:
+
+        When used in a type hint, the expression :data:`None` is considered
+        equivalent to ``type(None)``.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be reduced.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        warning message. Defaults to the empty string.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        This hint unmodified.
+
+    Warns
+    -----
+    BeartypeDecorHintPep585DeprecationWarning
+        If this :pep:`484`-compliant type hint is deprecated by :pep:`585` *and*
+        the active Python interpreter targets Python >= 3.9.
+    '''
+    assert isinstance(exception_prefix, str), (
+        f'{repr(exception_prefix)} not string.')
+    # print(f'Testing PEP 484 type hint {repr(hint)} for PEP 585 deprecation...')
+    # print(f'{HINTS_PEP484_REPR_PREFIX_DEPRECATED}')
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhintget import get_hint_repr
+
+    # Machine-readable representation of this hint.
+    hint_repr = get_hint_repr(hint)
+
+    # Substring of the machine-readable representation of this hint preceding
+    # the first "[" delimiter if this representation contains that delimiter
+    # *OR* this representation as is otherwise.
+    #
+    # Note that the str.partition() method has been profiled to be the optimally
+    # efficient means of parsing trivial prefixes.
+    hint_repr_bare, _, _ = hint_repr.partition('[')
+
+    # If this hint is a PEP 484-compliant type hint originating from an origin
+    # type (e.g., "typing.List[int]"), this hint has been deprecated by the
+    # equivalent PEP 585-compliant type hint (e.g., "list[int]"). In this case,
+    # emit a non-fatal PEP 585-specific deprecation warning.
+    if hint_repr_bare in HINTS_PEP484_REPR_PREFIX_DEPRECATED:
+        issue_warning(
+            cls=BeartypeDecorHintPep585DeprecationWarning,
+            message=(
+                f'{exception_prefix}PEP 484 type hint {repr(hint)} '
+                f'deprecated by PEP 585. '
+                f'This hint is scheduled for removal in the first Python '
+                f'version released after October 5th, 2025. To resolve this, '
+                f'import this hint from "beartype.typing" rather than "typing". '
+                f'For further commentary and alternatives, see also:\n'
+                f'    {URL_PEP585_DEPRECATIONS}'
+            ),
+        )
+    # Else, this hint is *NOT* deprecated. In this case, reduce to a noop.
+
+    # Preserve this hint as is, regardless of deprecation.
+    return hint
+
+
+# Note that this reducer is intentionally typed as returning "type" rather than
+# "NoneType". While the former would certainly be preferable, mypy erroneously
+# emits false positives when this reducer is typed as returning "NoneType":
+#     beartype/_util/hint/pep/proposal/pep484/utilpep484.py:190: error: Variable
+#     "beartype._cave._cavefast.NoneType" is not valid as a type [valid-type]
+def reduce_hint_pep484_none(hint: object, *args, **kwargs) -> type:
+    '''
+    Reduce the passed :pep:`484`-compliant :data:`None` type hint to the type of
+    that type hint (i.e., the builtin :class:`types.NoneType` class).
+
+    While *not* explicitly defined by the :mod:`typing` module, :pep:`484`
+    explicitly supports this singleton:
+
+        When used in a type hint, the expression :data:`None` is considered
+        equivalent to ``type(None)``.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type variable to be reduced.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    NoneType
+        Type of the :data:`None` singleton.
+    '''
+    assert hint is None, f'Type hint {hint} not "None" singleton.'
+
+    # Unconditionally return the type of the "None" singleton.
+    return NoneType
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484/utilpep484generic.py
@@ -0,0 +1,485 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant **generic type hint utilities** (i.e.,
+callables generically applicable to :pep:`484`-compliant generic classes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep484Exception
+from beartype.typing import (
+    Any,
+    Generic,
+)
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.cls.utilclstest import is_type_subclass
+
+# ....................{ TESTERS                            }....................
+def is_hint_pep484_generic(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a :pep:`484`-compliant **generic**
+    (i.e., object that may *not* actually be a class originally subclassing at
+    least one PEP-compliant type hint defined by the :mod:`typing` module).
+
+    Specifically, this tester returns :data:`True` only if this object was
+    originally defined as a class subclassing a combination of:
+
+    * At least one of:
+
+      * The :pep:`484`-compliant :mod:`typing.Generic` superclass.
+      * The :pep:`544`-compliant :mod:`typing.Protocol` superclass.
+
+    * Zero or more non-class :mod:`typing` pseudo-superclasses (e.g.,
+      ``typing.List[int]``).
+    * Zero or more other standard superclasses.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation trivially reduces to
+    an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :mod:`typing` generic.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+        get_hint_pep484585_generic_type_or_none)
+
+    # If this hint is *NOT* a class, this hint is *NOT* an unsubscripted
+    # generic but could still be a subscripted generic (i.e., generic
+    # subscripted by one or more PEP-compliant child type hints). To
+    # decide, reduce this hint to the object originating this hint if any,
+    # enabling the subsequent test to test whether this origin object is an
+    # unsubscripted generic, which would then imply this hint to be a
+    # subscripted generic. If this strikes you as insane, you're not alone.
+    hint = get_hint_pep484585_generic_type_or_none(hint)
+
+    # Return true only if this hint is a subclass of the "typing.Generic"
+    # abstract base class (ABC), in which case this hint is a user-defined
+    # generic.
+    #
+    # Note that this test is robust against edge cases, as the "typing"
+    # module guarantees all user-defined classes subclassing one or more
+    # "typing" pseudo-superclasses to subclass the "typing.Generic"
+    # abstract base class (ABC) regardless of whether those classes did so
+    # explicitly. How? By type erasure, of course, the malignant gift that
+    # keeps on giving:
+    #     >>> import typing as t
+    #     >>> class MuhList(t.List): pass
+    #     >>> MuhList.__orig_bases__
+    #     (typing.List)
+    #     >>> MuhList.__mro__
+    #     (__main__.MuhList, list, typing.Generic, object)
+    #
+    # Note that:
+    # * This issubclass() call implicitly performs a surprisingly
+    #   inefficient search over the method resolution order (MRO) of all
+    #   superclasses of this hint. In theory, the cost of this search might
+    #   be circumventable by observing that this ABC is expected to reside
+    #   at the second-to-last index of the tuple exposing this MRO far all
+    #   generics by virtue of fragile implementation details violating
+    #   privacy encapsulation. In practice, this codebase is already
+    #   fragile enough.
+    # * The following logic superficially appears to implement the same
+    #   test *WITHOUT* the onerous cost of a search:
+    #       return len(get_hint_pep484_generic_bases_unerased_or_none(hint)) > 0
+    #   Why didn't we opt for that, then? Because this tester is routinely
+    #   passed objects that *CANNOT* be guaranteed to be PEP-compliant.
+    #   Indeed, the high-level is_hint_pep() tester establishing the
+    #   PEP-compliance of arbitrary objects internally calls this
+    #   lower-level tester to do so. Since the
+    #   get_hint_pep484_generic_bases_unerased_or_none() getter internally
+    #   reduces to returning the tuple of the general-purpose
+    #   "__orig_bases__" dunder attribute formalized by PEP 560, testing
+    #   whether that tuple is non-empty or not in no way guarantees this
+    #   object to be a PEP-compliant generic.
+    return is_type_subclass(hint, Generic)  # type: ignore[arg-type]
+
+# ....................{ GETTERS                            }....................
+@callable_cached
+def get_hint_pep484_generic_base_erased_from_unerased(hint: Any) -> type:
+    '''
+    Erased superclass originating the passed :pep:`484`-compliant **unerased
+    pseudo-superclass** (i.e., :mod:`typing` object originally listed as a
+    superclass prior to its implicit type erasure by the :mod:`typing` module).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation trivially reduces to
+    an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        :pep:`484`-compliant unerased pseudo-superclass to be reduced to its
+        erased superclass.
+
+    Returns
+    -------
+    type
+        Erased superclass originating this :pep:`484`-compliant unerased
+        pseudo-superclass.
+
+    Raises
+    ------
+    BeartypeDecorHintPep484Exception
+        if this object is *not* a :pep:`484`-compliant unerased
+        pseudo-superclass.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_origin_or_none
+
+    # Erased superclass originating this unerased pseudo-superclass if any *OR*
+    # "None" otherwise.
+    hint_origin_type = get_hint_pep_origin_or_none(hint)
+
+    # If this hint originates from *NO* such superclass, raise an exception.
+    if hint_origin_type is None:
+        raise BeartypeDecorHintPep484Exception(
+            f'Unerased PEP 484 generic or PEP 544 protocol {repr(hint)} '
+            f'originates from no erased superclass.'
+        )
+    # Else, this hint originates from such a superclass.
+
+    # Return this superclass.
+    return hint_origin_type
+
+
+@callable_cached
+def get_hint_pep484_generic_bases_unerased(
+    # Mandatory parameters.
+    hint: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484Exception,
+    exception_prefix: str = '',
+) -> tuple:
+    '''
+    Tuple of all unerased :mod:`typing` **pseudo-superclasses** (i.e.,
+    :mod:`typing` objects originally listed as superclasses prior to their
+    implicit type erasure under :pep:`560`) of the passed :pep:`484`-compliant
+    **generic** (i.e., class subclassing at least one non-class :mod:`typing`
+    object).
+
+    This getter is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    tuple
+        Tuple of the one or more unerased pseudo-superclasses of this
+        :mod:`typing` generic. Specifically:
+
+        * If this generic defines an ``__orig_bases__`` dunder instance
+          variable, the value of that variable as is.
+        * Else, the value of the ``__mro__`` dunder instance variable stripped
+          of all ignorable classes conveying *no* semantic meaning, including:
+
+          * This generic itself.
+          * The :class:`object` root superclass.
+
+    Raises
+    ------
+    exception_cls
+        If this hint is either:
+
+        * *Not* a :mod:`typing` generic.
+        * A :mod:`typing` generic that erased *none* of its superclasses but
+          whose method resolution order (MRO) lists strictly less than four
+          classes. Valid :pep:`484`-compliant generics should list at least
+          four classes, including (in order):
+
+          #. This class itself.
+          #. The one or more :mod:`typing` objects directly subclassed by this
+             generic.
+          #. The :class:`typing.Generic` superclass.
+          #. The zero or more non-:mod:`typing` superclasses subsequently
+             subclassed by this generic (e.g., :class:`abc.ABC`).
+          #. The :class:`object` root superclass.
+
+    See Also
+    --------
+    :func:`beartype._util.hint.pep.proposal.pep484585.utilpep484585generic.get_hint_pep484585_generic_bases_unerased`
+        Further details.
+    '''
+
+    #FIXME: This tuple appears to be implemented erroneously -- at least under
+    #Python 3.7, anyway. Although this tuple is implemented correctly for the
+    #common case of user-defined types directly subclassing "typing" types,
+    #this tuple probably is *NOT* implemented correctly for the edge case of
+    #user-defined types indirectly subclassing "typing" types: e.g.,
+    #
+    #    >>> import collections.abc, typing
+    #    >>> T = typing.TypeVar('T')
+    #    >>> class Direct(collections.abc.Sized, typing.Generic[T]): pass
+    #    >>> Direct.__orig_bases__
+    #    (collections.abc.Sized, typing.Generic[~T])
+    #    >>> class Indirect(collections.abc.Container, Direct): pass
+    #    >>> Indirect.__orig_bases__
+    #    (collections.abc.Sized, typing.Generic[~T])
+    #
+    #*THAT'S COMPLETELY INSANE.* Clearly, their naive implementation failed to
+    #account for actual real-world use cases.
+    #
+    #On the bright side, the current implementation prevents us from actually
+    #having to perform a breadth-first traversal of all original superclasses
+    #of this class in method resolution order (MRO). On the dark side, it's
+    #pants-on-fire balls -- but there's not much we can do about that. *sigh*
+    #
+    #If we ever need to perform that breadth-first traversal, resurrect this:
+    #
+    #    # If this class was *NOT* subject to type erasure, reduce to a noop.
+    #    if not hint_bases:
+    #        return hint_bases
+    #
+    #    # Fixed list of all typing super attributes to be returned.
+    #    superattrs = acquire_fixed_list(FIXED_LIST_SIZE_MEDIUM)
+    #
+    #    # 0-based index of the last item of this list.
+    #    superattrs_index = 0
+    #
+    #    # Fixed list of all transitive superclasses originally listed by this
+    #    # class iterated in method resolution order (MRO).
+    #    hint_orig_mro = acquire_fixed_list(FIXED_LIST_SIZE_MEDIUM)
+    #
+    #    # 0-based indices of the current and last items of this list.
+    #    hint_orig_mro_index_curr = 0
+    #    hint_orig_mro_index_last = 0
+    #
+    #    # Initialize this list with the tuple of all direct superclasses of this
+    #    # class, which iteration then expands to all transitive superclasses.
+    #    hint_orig_mro[:len(hint_bases)] = hint_bases
+    #
+    #    # While the heat death of the universe has been temporarily forestalled...
+    #    while (True):
+    #        # Currently visited superclass of this class.
+    #        hint_base = hint_orig_mro[hint_orig_mro_index_curr]
+    #
+    #        # If this superclass is a typing attribute...
+    #        if is_hint_pep_type_typing(hint_base):
+    #            # Avoid inserting this attribute into the "hint_orig_mro" list.
+    #            # Most typing attributes are *NOT* actual classes and those that
+    #            # are have no meaningful public superclass. Ergo, iteration
+    #            # terminates with typing attributes.
+    #            #
+    #            # Insert this attribute at the current item of this list.
+    #            superattrs[superattrs_index] = hint_base
+    #
+    #            # Increment this index to the next item of this list.
+    #            superattrs_index += 1
+    #
+    #            # If this class subclasses more than the maximum number of "typing"
+    #            # attributes supported by this function, raise an exception.
+    #            if superattrs_index >= FIXED_LIST_SIZE_MEDIUM:
+    #                raise BeartypeDecorHintPep560Exception(
+    #                    '{} PEP type {!r} subclasses more than '
+    #                    '{} "typing" types.'.format(
+    #                        exception_prefix,
+    #                        hint,
+    #                        FIXED_LIST_SIZE_MEDIUM))
+    #        # Else, this superclass is *NOT* a typing attribute. In this case...
+    #        else:
+    #            # Tuple of all direct superclasses originally listed by this class
+    #            # prior to PEP 484 type erasure if any *OR* the empty tuple
+    #            # otherwise.
+    #            hint_base_bases = getattr(hint_base, '__orig_bases__')
+    #
+    #            #FIXME: Implement breadth-first traversal here.
+    #
+    #    # Tuple sliced from the prefix of this list assigned to above.
+    #    superattrs_tuple = tuple(superattrs[:superattrs_index])
+    #
+    #    # Release and nullify this list *AFTER* defining this tuple.
+    #    release_fixed_list(superattrs)
+    #    del superattrs
+    #
+    #    # Return this tuple as is.
+    #    return superattrs_tuple
+    #
+    #Also resurrect this docstring snippet:
+    #
+    #    Raises
+    #    ----------
+    #    BeartypeDecorHintPep560Exception
+    #        If this object defines the ``__orig_bases__`` dunder attribute but that
+    #        attribute transitively lists :data:`FIXED_LIST_SIZE_MEDIUM` or more :mod:`typing`
+    #        attributes.
+    #
+    #Specifically:
+    #  * Acquire a fixed list of sufficient size (e.g., 64). We probably want
+    #    to make this a constant in "utilcachelistfixedpool" for reuse
+    #    everywhere, as this is clearly becoming a common idiom.
+    #  * Slice-assign "__orig_bases__" into this list.
+    #  * Maintain two simple 0-based indices into this list:
+    #    * "bases_index_curr", the current base being visited.
+    #    * "bases_index_last", the end of this list also serving as the list
+    #      position to insert newly discovered bases at.
+    #  * Iterate over this list and keep slice-assigning from either
+    #    "__orig_bases__" (if defined) or "__mro__" (otherwise) into
+    #    "list[bases_index_last:len(__orig_bases__)]". Note that this has the
+    #    unfortunate disadvantage of temporarily iterating over duplicates,
+    #    but... *WHO CARES.* It still works and we subsequently
+    #    eliminate duplicates at the end.
+    #  * Return a frozenset of this list, thus implicitly eliminating
+    #    duplicate superclasses.
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+        get_hint_pep484585_generic_type_or_none)
+
+    # If this hint is *NOT* a class, reduce this hint to the object originating
+    # this hint if any. See is_hint_pep484_generic() for details.
+    hint = get_hint_pep484585_generic_type_or_none(hint)
+
+    # If this hint is *NOT* a PEP 484-compliant generic, raise an exception.
+    if not is_hint_pep484_generic(hint):
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} neither '
+            f'PEP 484 generic nor PEP 544 protocol.'
+        )
+    # Else, this hint is a PEP 484-compliant generic.
+
+    # Unerased pseudo-superclasses of this generic if any *OR* "None" otherwise
+    # (e.g., if this generic is a single-inherited protocol).
+    hint_bases = getattr(hint, '__orig_bases__', None)
+
+    # If this generic erased its superclasses, return these superclasses as is.
+    if hint_bases is not None:
+        return hint_bases
+    # Else, this generic erased *NONE* of its superclasses. These superclasses
+    # *MUST* by definition be unerased and thus safely returnable as is.
+
+    # Unerased superclasses of this generic defined by the method resolution
+    # order (MRO) for this generic.
+    hint_bases = hint.__mro__
+
+    # If this MRO lists strictly less than four classes, raise an exception.
+    # The MRO for any unerased generic should list at least four classes:
+    # * This class itself.
+    # * The one or more "typing" objects directly subclassed by this generic.
+    # * The "typing.Generic" superclass. Note that this superclass is typically
+    #   but *NOT* necessarily the second-to-last superclass. Since this ad-hoc
+    #   heuristic is *NOT* an actual constraint, we intentionally avoid
+    #   asserting this to be the case. An example in which "typing.Generic" is
+    #   *NOT* the second-to-last superclass is:
+    #       class ProtocolCustomSuperclass(Protocol): pass
+    #       class ProtocolCustomABC(ProtocolCustomSuperclass, ABC): pass
+    # * The "object" root superclass.
+    if len(hint_bases) < 4:
+        raise exception_cls(
+            f'{exception_prefix}PEP 484 generic {repr(hint)} '
+            f'subclasses less than four superclasses {repr(hint_bases)}.'
+        )
+    # Else, this MRO lists at least four classes.
+    #
+    # If any class listed by this MRO fails to comply with the above
+    # expectations, raise an exception.
+    elif hint_bases[0] is not hint:
+        raise exception_cls(
+            f'{exception_prefix}PEP 484 generic {repr(hint)} '
+            f'first superclass {repr(hint_bases[0])} != {repr(hint)}.'
+        )
+    elif hint_bases[-1] is not object:
+        raise exception_cls(
+            f'{exception_prefix}PEP 484 generic {repr(hint)} '
+            f'last superclass {repr(hint_bases[-1])} != {repr(object)}.'
+        )
+    # Else, all classes listed by this MRO comply with the above expectations.
+
+    # Return a slice of this tuple preserving *ONLY* the non-ignorable
+    # superclasses listed by this tuple for conformance with the tuple returned
+    # by this getter from the "__orig_bases__", which similarly lists *ONLY*
+    # non-ignorable superclasses. Specifically, strip from this tuple:
+    # * This class itself.
+    # * The "object" root superclass.
+    #
+    # Ideally, the ignorable "(beartype.|)typing.(Generic|Protocol)"
+    # superclasses would also be stripped. Sadly, as exemplified by the above
+    # counter-example, those superclasses are *NOT* guaranteed to occupy the
+    # third- and second-to-last positions (respectively) of this tuple. Ergo,
+    # stripping these superclasses safely would require an inefficient
+    # iterative O(n) search across this tuple for those superclasses. Instead,
+    # we defer ignoring these superclasses to the caller -- which necessarily
+    # already (and hopefully efficiently) ignores ignorable superclasses.
+    return hint_bases[1:-1]
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep484_generic(
+    hint: object, exception_prefix: str, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`484`-compliant **generic** (i.e., object that may
+    *not* actually be a class originally subclassing at least one PEP-compliant
+    type hint defined by the :mod:`typing` module) to a more suitable type hint
+    better supported by :mod:`beartype` if necessary.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Generic to be reduced.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        More suitable type hint better supported by :mod:`beartype`.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.utilpep544 import (
+        is_hint_pep484_generic_io,
+        reduce_hint_pep484_generic_io_to_pep544_protocol,
+    )
+
+    # If this hint is a PEP 484-compliant IO generic base class *AND* the active
+    # Python interpreter targets Python >= 3.8 and thus supports PEP
+    # 544-compliant protocols, reduce this functionally useless hint to the
+    # corresponding functionally useful beartype-specific PEP 544-compliant
+    # protocol implementing this hint.
+    #
+    # IO generic base classes are extremely rare and thus detected even later.
+    #
+    # Note that PEP 484-compliant IO generic base classes are technically
+    # usable under Python < 3.8 (e.g., by explicitly subclassing those classes
+    # from third-party classes). Ergo, we can neither safely emit warnings nor
+    # raise exceptions on visiting these classes under *ANY* Python version.
+    if is_hint_pep484_generic_io(hint):
+        hint = reduce_hint_pep484_generic_io_to_pep544_protocol(
+            hint=hint, exception_prefix=exception_prefix)
+    # Else, this hint is either *NOT* a PEP 484-compliant IO generic base class
+    # *OR* is but the active Python interpreter targets Python < 3.8 and thus
+    # fails to support PEP 544-compliant protocols. In either case, preserve
+    # this hint as is.
+
+    # Return this possibly reduced hint.
+    return hint
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484/utilpep484namedtuple.py
@@ -0,0 +1,130 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant **named tuple utilities** (i.e.,
+callables generically applicable to :pep:`484`-compliant named tuples -- which
+is to say, instances of concrete subclasses of the standard
+:attr:`typing.NamedTuple` superclass).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._util.cls.utilclstest import is_type_subclass_proper
+# from beartype.roar import BeartypeDecorHintPep484Exception
+# from beartype.typing import Any
+# from beartype._data.hint.pep.sign.datapepsigns import HintSignNewType
+# from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_10
+# from types import FunctionType
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+#FIXME: Actually call this tester in the get_hint_pep_sign_or_none() getter to
+#map "typing.NamedTuple" subclasses to the "HintSignNamedTuple" sign, please.
+#FIXME: Actually type-check type hints identified by the "HintSignNamedTuple"
+#sign. Specifically, for each "typing.NamedTuple" subclass identified by that
+#sign, type-check that subclass as follows:
+#* If that subclass is decorated by @beartype, reduce to the standard trivial
+#  isinstance() check. Since @beartype already type-checks instances of that
+#  subclass on instantiation, *NO* further type-checking is required or desired.
+#* Else, that subclass is *NOT* decorated by @beartype. In this case, matters
+#  become considerably non-trivial. Why? Because:
+#  * This situation commonly arises when type-checking "typing.NamedTuple"
+#    subclasses *NOT* under user control (e.g., defined by upstream third-party
+#    packages in an app stack). Since these subclasses are *NOT* under user
+#    control, there exists *NO* safe means for @beartype to monkey-patch these
+#    subclasses with itself. Ergo, instances of these subclasses are guaranteed
+#    to *NOT* be type-checked at instantiation time.
+#  * The prior point implies that @beartype must instead type-check instances of
+#    these subclasses at @beartype call time. However, the naive approach to
+#    doing so is likely to prove inefficient. The naive approach is simply to
+#    type-check *ALL* fields of these instances *EVERY* time these instances are
+#    type-checked at @beartype call time. Since these fields could themselves
+#    refer to other "typing.NamedTuple" subclasses, combinatorial explosion
+#    violating O(1) constraints becomes a real possibility here.
+#  * *RECURSION.* Both direct and indirect recursion are feasible here. Both
+#    require PEP 563 and are thus unlikely. Nonetheless:
+#    * Direct recursion occurs under PEP 563 as follows:
+#          from __future__ import annotations
+#          from typing import NamedTuple
+#
+#          class DirectlyRecursiveNamedTuple(NamedTuple):
+#              uhoh: DirectlyRecursiveNamedTuple
+#    * Indirect recursion occurs  as PEP 563 follows:
+#          from typing import NamedTuple
+#
+#          class IndirectlyRecursiveNamedTuple(NamedTuple):
+#              uhoh: YetAnotherNamedTuple
+#
+#          class YetAnotherNamedTuple(NamedTuple):
+#              ohboy: IndirectlyRecursiveNamedTuple
+#
+#Guarding against both combinatorial explosion *AND* recursion is imperative. To
+#do so, we'll need to fundamentally refactor our existing breadth-first search
+#(BFS) over type hints into a new depth-first search (DFS) over type hints.
+#We've extensively documented this in the "beartype._check.code.__init__"
+#submodule. Simply know that this will be non-trivial, albeit fun and needed!
+def is_hint_pep484_namedtuple_subclass(hint: object) -> bool:
+    '''
+    ``True`` only if the passed object is a :pep:`484`-compliant **named tuple
+    subclass** (i.e., concrete subclass of the standard
+    :attr:`typing.NamedTuple` superclass).
+
+    Note that the :attr:`typing.NamedTuple` attribute is *not* actually a
+    superclass; that attribute only superficially masquerades (through
+    inscrutable metaclass trickery) as a superclass. As one might imagine,
+    detecting "subclasses" of a non-existent superclass is non-trivial.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    ----------
+    bool
+        ``True`` only if this object is a :pep:`484`-compliant named tuple
+        subclass.
+    '''
+
+    # Return true only if...
+    return (
+        # This hint is a proper tuple subclass (i.e., subclass of the builtin
+        # "tuple" type but *NOT* that type itself) *AND*...
+        is_type_subclass_proper(hint, tuple) and
+        #FIXME: Implement us up, please. To do so efficiently, we'll probably
+        #want to:
+        #* Declare a private global frozenset of the names of all uniquely
+        #  identifying "typing.NamedTuple" attributes: e.g.,
+        #  _NAMEDTUPLE_UNIQUE_ATTR_NAMES = frozenset((
+        #      # "typing.NamedTuple"-specific quasi-public attributes.
+        #      '__annotations__',
+        #
+        #      # "collections.namedtuple"-specific quasi-public attributes.
+        #      '_asdict',
+        #      '_field_defaults',
+        #      '_fields',
+        #      '_make',
+        #      '_replace',
+        #  ))
+        #* Efficiently take the set intersection of that frozenset and
+        #  "dir(tuple)". If that intersection is non-empty, then this type is
+        #  *PROBABLY* a "typing.NamedTuple" subclass.
+        #
+        #Note that there does exist an alternative. Sadly, that alternative
+        #requires an O(n) test and is thus non-ideal. Nonetheless:
+        #    typing.NamedTuple in getattr(hint, '__orig_bases__', ())
+        #
+        #That *DOES* have the advantage of being deterministic. But the above
+        #set intersection test is mostly deterministic and considerably
+        #faster... we think. Actually, is it? We have *NO* idea. Perhaps we
+        #should simply opt for the simplistic and deterministic O(n) approach.
+        True
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484/utilpep484newtype.py
@@ -0,0 +1,258 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant **new type hint utilities** (i.e.,
+callables generically applicable to :pep:`484`-compliant types).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep484Exception
+from beartype.typing import Any
+from beartype._data.hint.pep.sign.datapepsigns import HintSignNewType
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_10
+from types import FunctionType
+
+# ....................{ TESTERS                            }....................
+def is_hint_pep484_newtype_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed :pep:`484`-compliant
+    :obj:`typing.NewType`-style type alias is ignorable.
+
+    Specifically, this tester ignores the :obj:`typing.NewType` factory passed
+    an ignorable child type hint. Unlike most :mod:`typing` constructs, that
+    factory does *not* cache the objects it returns: e.g.,
+
+    .. code-block:: python
+
+       >>> from typing import NewType
+       >>> NewType('TotallyNotAStr', str) is NewType('TotallyNotAStr', str)
+       False
+
+    Since this implies every call to ``NewType({same_name}, object)`` returns a
+    new closure, the *only* means of ignoring ignorable new type aliases is
+    dynamically within this function.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`484`-compliant type hint is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhinttest import is_hint_ignorable
+
+    # Return true only if this hint aliases an ignorable child type hint.
+    return is_hint_ignorable(get_hint_pep484_newtype_alias(hint))
+
+
+# If the active Python interpreter targets Python >= 3.10 and thus defines
+# "typing.NewType" type hints as instances of that class, implement this tester
+# unique to prior Python versions to raise an exception.
+if IS_PYTHON_AT_LEAST_3_10:
+    def is_hint_pep484_newtype_pre_python310(hint: object) -> bool:
+        raise BeartypeDecorHintPep484Exception(
+            'is_hint_pep484_newtype_pre_python310() assumes Python < 3.10, '
+            'but current Python interpreter targets Python >= 3.10.'
+        )
+# Else, the active Python interpreter targets Python < 3.10 and thus defines
+# "typing.NewType" type hints as closures returned by that function. Since
+# these closures are sufficiently dissimilar from all other type hints to
+# require unique detection, implement this tester unique to this obsolete
+# Python version to detect these closures.
+else:
+    def is_hint_pep484_newtype_pre_python310(hint: object) -> bool:
+
+        # Return true only if...
+        return (
+            # This hint is a pure-Python function *AND*...
+            #
+            # Note that we intentionally do *NOT* call the callable() builtin
+            # here, as that builtin erroneously returns false positives for
+            # non-standard classes defining the __call__() dunder method to
+            # unconditionally raise exceptions. Critically, this includes most
+            # PEP 484-compliant type hints, which naturally fail to define both
+            # the "__module__" *AND* "__qualname__" dunder instance variables
+            # accessed below. Shoot me now, fam.
+            isinstance(hint, FunctionType) and
+            # This callable is a closure created and returned by the
+            # typing.NewType() function. Note that:
+            #
+            # * The "__module__" and "__qualname__" dunder instance variables
+            #   are *NOT* generally defined for arbitrary objects but are
+            #   specifically defined for callables.
+            # * "__qualname__" is safely available under Python >= 3.3.
+            # * This test derives from the observation that the concatenation
+            #   of this callable's "__qualname__" and "__module" dunder
+            #   instance variables suffices to produce a string unambiguously
+            #   identifying whether this hint is a "NewType"-generated closure:
+            #       >>> from typing import NewType
+            #       >>> UserId = t.NewType('UserId', int)
+            #       >>> UserId.__qualname__
+            #       >>> 'NewType.<locals>.new_type'
+            #       >>> UserId.__module__
+            #       >>> 'typing'
+            f'{hint.__module__}.{hint.__qualname__}'.startswith(
+                'typing.NewType.')
+        )
+
+
+is_hint_pep484_newtype_pre_python310.__doc__ = '''
+    :data:`True` only if the passed object is a Python < 3.10-specific
+    :pep:`484`-compliant **new type** (i.e., closure created and returned by the
+    :func:`typing.NewType` closure factory function).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation trivially reduces to
+    an efficient one-liner.
+
+    Caveats
+    -------
+    **New type aliases are a complete farce and thus best avoided.**
+    Specifically, these PEP-compliant type hints are *not* actually types but
+    rather **identity closures** that return their passed parameters as is.
+    Instead, where distinct types are:
+
+    * *Not* required, simply annotate parameters and return values with the
+      desired superclasses.
+    * Required, simply:
+
+      * Subclass the desired superclasses as usual.
+      * Annotate parameters and return values with those subclasses.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a Python < 3.10-specific
+        :pep:`484`-compliant new type.
+    '''
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+@callable_cached
+def get_hint_pep484_newtype_alias(
+    hint: Any, exception_prefix: str = '') -> object:
+    '''
+    Unaliased type hint (i.e., type hint that is *not* a :obj:`typing.NewType`)
+    encapsulated by the passed **newtype** (i.e., object created and returned by
+    the :pep:`484`-compliant :obj:`typing.NewType` type hint factory).
+
+    This getter is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    object
+        Unaliased type hint encapsulated by this newtype.
+
+    Raises
+    ------
+    BeartypeDecorHintPep484Exception
+        If this object is *not* a new type.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_sign,
+        get_hint_pep_sign_or_none,
+    )
+
+    # If this object is *NOT* a new type, raise an exception.
+    if get_hint_pep_sign(hint) is not HintSignNewType:
+        raise BeartypeDecorHintPep484Exception(
+            f'{exception_prefix}type hint {repr(hint)} not '
+            f'PEP 484 "typing.NewType(...)" object.'
+        )
+    # Else, this object is a new type.
+
+    # While the Universe continues infinitely expanding...
+    while True:
+        # Reduce this new type to the type hint encapsulated by this new type,
+        # which itself is possibly a nested new type. Oh, it happens.
+        hint = hint.__supertype__
+
+        # If this type hint is *NOT* a nested new type, break this iteration.
+        if get_hint_pep_sign_or_none(hint) is not HintSignNewType:
+            break
+        # Else, this type hint is a nested new type. In this case, continue
+        # iteratively unwrapping this nested new type.
+
+    # Return this unaliased type hint.
+    return hint
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep484_newtype(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed **new type** (i.e., object created and returned by the
+    :pep:`484`-compliant :func:`typing.NewType` type hint factory) to the
+    **non-new type type hint** (i.e., PEP-compliant type hint that is *not* a
+    new type) encapsulated by this new type.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This reducer has worst-case linear time complexity** :math:`O(k)` for
+    :math:`k` the number of **nested new types** (e.g., :math:`k = 2` for the
+    doubly nested new type ``NewType('a', NewType('b', int))``) embedded within
+    this new type. Pragmatically, this reducer has average-case constant time
+    complexity :math:`O(1)`. Why? Because nested new types are extremely rare.
+    Almost all real-world new types are non-nested. Indeed, it took three years
+    for a user to submit an issue presenting the existence of a nested new type.
+
+    Parameters
+    ----------
+    hint : object
+        Final type hint to be reduced.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    type
+        Non-new type type hint encapsulated by this new type.
+    '''
+
+    # Reduce this new type to the non-new type type hint encapsulated by this
+    # new type.
+    #
+    # Note that:
+    # * This reducer *CANNOT* be reduced to an efficient alias of the
+    #   get_hint_pep484_newtype_alias() getter, as this reducer accepts
+    #   ignorable arguments *NOT* accepted by that getter.
+    # * get_hint_pep484_newtype_alias() is memoized and thus intentionally
+    #   called with positional arguments.
+    return get_hint_pep484_newtype_alias(hint, exception_prefix)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484/utilpep484typevar.py
@@ -0,0 +1,171 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant **type variable utilities** (i.e.,
+callables generically applicable to :pep:`484`-compliant type variables).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep484Exception
+from beartype.typing import TypeVar
+from beartype._util.cache.utilcachecall import callable_cached
+
+# ....................{ GETTERS                            }....................
+@callable_cached
+def get_hint_pep484_typevar_bound_or_none(
+    hint: TypeVar, exception_prefix: str = '') -> object:
+    '''
+    PEP-compliant type hint synthesized from all bounded constraints
+    parametrizing the passed :pep:`484`-compliant **type variable** (i.e.,
+    :class:`typing.TypeVar` instance) if any *or* :data:`None` otherwise (i.e.,
+    if this type variable was parametrized by *no* bounded constraints).
+
+    Specifically, if this type variable was parametrized by:
+
+    #. One or more **constraints** (i.e., positional arguments passed by the
+       caller to the :meth:`typing.TypeVar.__init__` call initializing this
+       type variable), this getter returns a new **PEP-compliant union type
+       hint** (i.e., :attr:`typing.Union` subscription) of those constraints.
+    #. One **upper bound** (i.e., ``bound`` keyword argument passed by the
+       caller to the :meth:`typing.TypeVar.__init__` call initializing this
+       type variable), this getter returns that bound as is.
+    #. Else, this getter returns the ``None`` singleton.
+
+    Caveats
+    ----------
+    **This getter treats constraints and upper bounds as semantically
+    equivalent,** preventing callers from distinguishing between these two
+    technically distinct variants of type variable metadata.
+
+    For runtime type-checking purposes, type variable constraints and bounds
+    are sufficiently similar as to be semantically equivalent for all intents
+    and purposes. To simplify handling of type variables, this getter
+    ambiguously aggregates both into the same tuple.
+
+    For static type-checking purposes, type variable constraints and bounds
+    are *still* sufficiently similar as to be semantically equivalent for all
+    intents and purposes. Any theoretical distinction between the two is likely
+    to be lost on *most* engineers, who tend to treat the two interchangeably.
+    To quote :pep:`484`:
+
+        ...type constraints cause the inferred type to be _exactly_ one of the
+        constraint types, while an upper bound just requires that the actual
+        type is a subtype of the boundary type.
+
+    Inferred types are largely only applicable to static type-checkers, which
+    internally assign type variables contextual types inferred from set and
+    graph theoretic operations on the network of all objects (nodes) and
+    callables (edges) relating those objects. Runtime type-checkers have *no*
+    analogous operations, due to runtime space and time constraints.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). If this type variable was parametrized
+    by one or more constraints, the :attr:`typing.Union` type hint factory
+    already caches these constraints; else, this getter performs no work. In
+    any case, this getter effectively performs to work.
+
+    Parameters
+    ----------
+    hint : object
+        :pep:`484`-compliant type variable to be inspected.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    ----------
+    object
+        Either:
+
+        * If this type variable was parametrized by one or more constraints, a
+          new PEP-compliant union type hint aggregating those constraints.
+        * If this type variable was parametrized by an upper bound, that bound.
+        * Else, :data:`None`.
+
+    Raises
+    ----------
+    BeartypeDecorHintPep484Exception
+        if this object is *not* a :pep:`484`-compliant type variable.
+    '''
+
+    # If this hint is *NOT* a type variable, raise an exception.
+    if not isinstance(hint, TypeVar):
+        raise BeartypeDecorHintPep484Exception(
+            f'{exception_prefix}type hint {repr(hint)} '
+            f'not PEP 484 type variable.'
+        )
+    # Else, this hint is a type variable.
+
+    # If this type variable was parametrized by one or more constraints...
+    if hint.__constraints__:
+        # Avoid circular import dependencies.
+        from beartype._util.hint.pep.proposal.pep484.utilpep484union import (
+            make_hint_pep484_union)
+
+        # Create and return the PEP 484-compliant union of these constraints.
+        return make_hint_pep484_union(hint.__constraints__)
+    # Else, this type variable was parametrized by *NO* constraints.
+    #
+    # If this type variable was parametrized by an upper bound, return that
+    # bound as is.
+    elif hint.__bound__ is not None:
+        return hint.__bound__
+    # Else, this type variable was parametrized by neither constraints *NOR* an
+    # upper bound.
+
+    # Return "None".
+    return None
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Remove this function *AFTER* deeply type-checking type variables.
+def reduce_hint_pep484_typevar(
+    hint: TypeVar, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`484`-compliant **type variable** (i.e.,
+    :class:`typing.TypedDict` instance) to a lower-level type hint currently
+    supported by :mod:`beartype`.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type variable to be reduced.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    ----------
+    object
+        Lower-level type hint currently supported by :mod:`beartype`.
+    '''
+
+    # PEP-compliant type hint synthesized from all bounded constraints
+    # parametrizing this type variable if any *OR* "None" otherwise.
+    #
+    # Note that this function call is intentionally passed positional rather
+    # positional keywords for efficiency with respect to @callable_cached.
+    hint_bound = get_hint_pep484_typevar_bound_or_none(hint, exception_prefix)
+    # print(f'Reducing PEP 484 type variable {repr(hint)} to {repr(hint_bound)}...')
+    # print(f'Reducing non-beartype PEP 593 type hint {repr(hint)}...')
+
+    # Return either...
+    return (
+        # If this type variable was parametrized by *NO* bounded constraints,
+        # this type variable preserved as is;
+        hint
+        if hint_bound is None else
+        # Else, this type variable was parametrized by one or more bounded
+        # constraints. In this case, these constraints.
+        hint_bound
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484/utilpep484union.py
@@ -0,0 +1,59 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`-compliant **union type hint utilities** (i.e.,
+callables generically applicable to :pep:`484`-compliant :attr:`typing.Union`
+subscriptions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Union
+from beartype._util.cache.utilcachecall import callable_cached
+
+# ....................{ FACTORIES                          }....................
+@callable_cached
+def make_hint_pep484_union(hints: tuple) -> object:
+    '''
+    :pep:`484`-compliant **union type hint** (:attr:`typing.Union`
+    subscription) synthesized from the passed tuple of two or more
+    PEP-compliant type hints if this tuple contains two or more items, the one
+    PEP-compliant type hint in this tuple if this tuple contains only one item,
+    *or* raise an exception otherwise (i.e., if this tuple is empty).
+
+    This factory is memoized for efficiency. Technically, the
+    :attr:`typing.Union` type hint factory already caches its subscripted
+    arguments. Pragmatically, that caching is slow and thus worth optimizing
+    with trivial optimization on our end. Moreover, this factory is called by
+    the performance-sensitive
+    :func:`beartype._check.convert.convcoerce.coerce_hint_any` coercer in an
+    early-time code path of the :func:`beartype.beartype` decorator. Optimizing
+    this factory thus optimizes :func:`beartype.beartype` itself.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If this tuple contains two or more items, the union type hint
+          synthesized from these items.
+        * If this tuple contains only one item, this item as is.
+
+    Raises
+    ------
+    TypeError
+        If this tuple is empty.
+    '''
+    assert isinstance(hints, tuple), f'{repr(hints)} not tuple.'
+
+    # These are the one-liners of our lives.
+    return Union.__getitem__(hints)  # pyright: ignore
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484585/utilpep484585.py
@@ -0,0 +1,172 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`- and :pep:`585`-compliant **dual type hint utilities**
+(i.e., callables generically applicable to both :pep:`484`- and
+:pep:`585`-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep585Exception
+from beartype.typing import Union
+from beartype._util.hint.pep.proposal.pep484.utilpep484 import (
+    HINT_PEP484_TUPLE_EMPTY)
+from beartype._util.hint.pep.proposal.utilpep585 import (
+    HINT_PEP585_TUPLE_EMPTY)
+
+# ....................{ TESTERS ~ kind : tuple             }....................
+def is_hint_pep484585_tuple_empty(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is either a :pep:`484`- or
+    :pep:`585`-compliant **empty fixed-length tuple type hint** (i.e., hint
+    constraining objects to be the empty tuple).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only called under fairly
+    uncommon edge cases.
+
+    Motivation
+    ----------
+    Since type variables are not themselves types but rather placeholders
+    dynamically replaced with types by type checkers according to various
+    arcane heuristics, both type variables and types parametrized by type
+    variables warrant special-purpose handling.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an empty fixed-length tuple hint.
+    '''
+
+    # Return true only if this hint resembles either the PEP 484- or
+    # 585-compliant fixed-length empty tuple type hint. Since there only exist
+    # two such hints *AND* comparison against these hints is mostly fast, this
+    # test is efficient in the general case.
+    #
+    # Note that this test may also be inefficiently performed by explicitly
+    # obtaining this hint's sign and then subjecting this hint to specific
+    # tests conditionally depending on which sign and thus PEP this hint
+    # complies with: e.g.,
+    #     # Return true only if this hint is either...
+    #     return true (
+    #         # A PEP 585-compliant "tuple"-based hint subscripted by no
+    #         # child hints *OR*...
+    #         (
+    #             hint.__origin__ is tuple and
+    #             hint_childs_len == 0
+    #         ) or
+    #         # A PEP 484-compliant "typing.Tuple"-based hint subscripted
+    #         # by exactly one child hint *AND* this child hint is the
+    #         # empty tuple,..
+    #         (
+    #             hint.__origin__ is Tuple and
+    #             hint_childs_len == 1 and
+    #             hint_childs[0] == ()
+    #         )
+    #     )
+    return (
+        hint == HINT_PEP585_TUPLE_EMPTY or
+        hint == HINT_PEP484_TUPLE_EMPTY
+    )
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep484585_args(
+    hint: object, args_len: int, exception_prefix: str) -> object:
+    '''
+    Either the single argument or tuple of all arguments subscripting the passed
+    :pep:`484`- or :pep:`585`-compliant type hint if this hint is subscripted by
+    exactly the passed number of child type hints *or* raise an exception
+    otherwise.
+
+    This getter returns either:
+
+    * If ``args_len == 1``, the single argument subscripting this hint as a
+      convenience to the caller.
+    * Else, the tuple of all arguments subscripting this hint.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation trivially reduces to
+    an efficient one-liner.
+
+    Caveats
+    -------
+    **This higher-level getter should always be called in lieu of directly
+    accessing the low-level** ``__args__`` **dunder attribute,** which is
+    typically *not* validated at runtime and thus should *not* be assumed to be
+    sane. Although the :mod:`typing` module usually validates the arguments
+    subscripting :pep:`484`-compliant type hints and thus the ``__args__``
+    **dunder attribute at hint instantiation time, C-based CPython internals
+    fail to similarly validate the arguments subscripting :pep:`585`-compliant
+    type hints at any time:
+
+    .. code-block:: python
+
+        >>> import typing
+        >>> typing.Type[str, bool]
+        TypeError: Too many parameters for typing.Type; actual 2, expected 1
+        >>> type[str, bool]
+        type[str, bool]   # <-- when everything is okay, nothing is okay
+
+    Parameters
+    ----------
+    hint : Any
+        Type hint to be inspected.
+    args_len : int
+        Number of child type hints expected to subscript this hint.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    Union[object, tuple]
+        Either the single argument or tuple of all arguments subscripting this
+        type hint.
+
+    Raises
+    ------
+    BeartypeDecorHintPep585Exception
+        If this hint is subscripted by an unexpected number of child type hints.
+    '''
+    assert isinstance(args_len, int), f'{repr(args_len)} not integer.'
+    assert args_len >= 1, f'{args_len} < 0.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+
+    # Tuple of all arguments subscripting this hint.
+    hint_args = get_hint_pep_args(hint)
+
+    # If this hint is *NOT* subscripted by the expected number of child type
+    # hints...
+    if len(hint_args) != args_len:
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Raise an exception.
+        raise BeartypeDecorHintPep585Exception(
+            f'{exception_prefix}PEP 585 type hint {repr(hint)} '
+            f'not subscripted (indexed) by {args_len} arguments (i.e., '
+            f'subscripted by {len(hint_args)} != {args_len} arguments).'
+        )
+    # Else, this hint is subscripted by the expected number of child type hints.
+
+    # Return either...
+    return (
+        # If this hint is subscripted by only child hint, this child hint;
+        hint_args[0]
+        if args_len == 1 else
+        # Else, this tuple of arguments as is.
+        hint_args
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484585/utilpep484585callable.py
@@ -0,0 +1,390 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`- and :pep:`585`-compliant **callable type hint
+utilities** (i.e., callables generically applicable to both :pep:`484`- and
+:pep:`585`-compliant ``Callable[...]`` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+import beartype.typing as typing
+from beartype.roar import BeartypeDecorHintPep484585Exception
+from beartype.typing import (
+    TYPE_CHECKING,
+    Union,
+)
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.hint.pep.sign.datapepsigns import HintSignCallable
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_CALLABLE_PARAMS)
+from beartype._data.kind.datakindsequence import TUPLE_EMPTY
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_10
+
+# ....................{ HINTS                              }....................
+# If an external static type checker (e.g., "mypy") is currently subjecting
+# "beartype" to static analysis, reduce this hint to a simplistic facsimile of
+# its full form tolerated by static type checkers.
+if TYPE_CHECKING:
+    _HINT_PEP484585_CALLABLE_PARAMS = Union[
+        # For hints of the form "Callable[[{arg_hints}], {return_hint}]".
+        tuple,
+        # For hints of the form "Callable[typing.ParamSpec[...], {return_hint}]".
+        typing.ParamSpec
+    ]
+# Else, expand this hint to its full form supported by runtime type checkers.
+else:
+    _HINT_PEP484585_CALLABLE_PARAMS = Union[
+        # For hints of the form "Callable[[{arg_hints}], {return_hint}]".
+        tuple,
+        # For hints of the form "Callable[..., {return_hint}]".
+        type(Ellipsis),
+        # If the active Python interpreter targets Python >= 3.10, a union
+        # additionally matching the PEP 612-compliant "ParamSpec" type.
+        (
+            # For hints of the form "Callable[typing.ParamSpec[...], {return_hint}]".
+            typing.ParamSpec
+            if IS_PYTHON_AT_LEAST_3_10 else
+            # Else, the active Python interpreter targets Python < 3.10. In this
+            # case, a meaninglessly redundant type listed above reducing to a noop.
+            tuple
+        )
+    ]
+    '''
+    PEP-compliant type hint matching the first argument originally subscripting
+    a :pep:`484`- or :pep:`585`-compliant **callable type hint** (i.e.,
+    ``typing.Callable[...]`` or ``collections.abc.Callable[...]`` type hint).
+    '''
+
+# ....................{ VALIDATORS                         }....................
+def _die_unless_hint_pep484585_callable(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is either a :pep:`484`- or
+    :pep:`585`-compliant **callable type hint** (i.e., ``typing.Callable[...]``
+    or ``collections.abc.Callable[...]`` type hint).
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ----------
+    :exc:`exception_cls`
+        If this hint is either:
+
+        * PEP-compliant but *not* uniquely identifiable by a sign.
+        * PEP-noncompliant.
+        * *Not* a hint (i.e., neither PEP-compliant nor -noncompliant).
+        * *Not* a callable type hint (i.e., ``typing.Callable[...]`` or
+          ``collections.abc.Callable[...]``).
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign
+
+    # Sign uniquely identifying this hint if any *OR* raise an exception.
+    hint_sign = get_hint_pep_sign(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # If this object is *NOT* a callable type hint, raise an exception.
+    if hint_sign is not HintSignCallable:
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not exception class.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not '
+            f'PEP 484 or 585 callable type hint '
+            f'(i.e., "typing.Callable[...]" or '
+            f'"collections.abc.Callable[...]").'
+        )
+    # Else, this object is a callable type hint, raise an exception.
+
+# ....................{ GETTERS                            }....................
+def get_hint_pep484585_callable_params(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> _HINT_PEP484585_CALLABLE_PARAMS:
+    '''
+    Object describing all **parameter type hints** (i.e., PEP-compliant child
+    type hints typing the parameters accepted by a passed or returned callable)
+    of the passed **callable type hint** (i.e., :pep:`484`-compliant
+    ``typing.Callable[...]`` or :pep:`585`-compliant
+    ``collections.abc.Callable[...]`` type hint).
+
+    This getter returns one of several different types of objects, conditionally
+    depending on the type of the first argument originally subscripting this
+    hint. Specifically, if this hint was of the form:
+
+    * ``Callable[[{arg_hints}], {return_hint}]``, this getter returns a tuple of
+      the zero or more parameter type hints subscripting (indexing) this hint.
+    * ``Callable[..., {return_hint}]``, the :data:`Ellipsis` singleton.
+    * ``Callable[typing.ParamSpec[...], {return_hint}]``, the
+      ``typing.ParamSpec[...]`` subscripting (indexing) this hint.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation requires no
+    iteration and thus exhibits guaranteed constant-time behaviour.
+
+    Parameters
+    ----------
+    hint : object
+        Callable type hint to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`.BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    ----------
+    _HINT_PEP484585_CALLABLE_PARAMS
+        First argument originally subscripting this hint.
+
+    Raises
+    ----------
+    exception_cls
+        If this hint is *not* a callable type hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_args,
+        get_hint_pep_sign_or_none,
+    )
+
+    # If this hint is *NOT* a callable type hint, raise an exception.
+    _die_unless_hint_pep484585_callable(hint)
+    # Else, this hint is a callable type hint.
+
+    # Flattened tuple of the one or more child type hints subscripting this
+    # callable type hint. Presumably for space efficiency reasons, both PEP 484-
+    # *AND* 585-compliant callable type hints implicitly flatten the "__args__"
+    # dunder tuple from the original data structure subscripting those hints.
+    # CPython produces this flattened tuple as the concatenation of:
+    #
+    # * Either:
+    #   * If the first child type originally subscripting this hint was a list,
+    #     all items subscripting the nested list of zero or more parameter type
+    #     hints originally subscripting this hint as is: e.g.,
+    #         >>> Callable[[], bool].__args__
+    #         (bool,)
+    #         >>> Callable[[int, str], bool].__args__
+    #         (int, str, bool)
+    #
+    #     This includes a list containing only the empty tuple signifying a
+    #     callable accepting *NO* parameters, in which case that empty tuple is
+    #     preserved as is: e.g.,
+    #         >>> Callable[[()], bool].__args__
+    #         ((), bool)
+    #   * Else, the first child type originally subscripting this hint as is. In
+    #     this case, that child type is required to be either:
+    #     * An ellipsis object (i.e., the "Ellipsis" builtin singleton): e.g.,
+    #         >>> Callable[..., bool].__args__
+    #         (Ellipsis, bool)
+    #     * A PEP 612-compliant parameter specification (i.e.,
+    #       "typing.ParamSpec[...]" type hint): e.g.,
+    #         >>> Callable[ParamSpec('P'), bool].__args__
+    #         (~P, bool)
+    #     * A PEP 612-compliant parameter concatenation (i.e.,
+    #       "typing.Concatenate[...]" type hint): e.g.,
+    #         >>> Callable[Concatenate[str, ParamSpec('P')], bool].__args__
+    #         (typing.Concatenate[str, ~P], bool)
+    # * The return type hint originally subscripting this hint.
+    #
+    # Note that both PEP 484- *AND* 585-compliant callable type hints guarantee
+    # this tuple to contain at least one child type hint. Ergo, we avoid
+    # validating that constraint here: e.g.,
+    #     >>> from typing import Callable
+    #     >>> Callable[()]
+    #     TypeError: Callable must be used as Callable[[arg, ...], result].
+    #     >>> from collections.abc import Callable
+    #     >>> Callable[()]
+    #     TypeError: Callable must be used as Callable[[arg, ...], result].
+    hint_args = get_hint_pep_args(hint)
+
+    # Number of parameter type hints flattened into this tuple, calculated by
+    # excluding the trailing return type hint also flattened into this tuple.
+    #
+    # Note that by the above constraint, this number is guaranteed to be
+    # non-negative: e.g.,
+    #     >>> hint_args_len >= 0
+    #     True
+    hint_params_len = len(hint_args) - 1
+
+    # If this callable type hint was subscripted by *NO* parameter type hints,
+    # return the empty tuple for efficiency.
+    if hint_params_len == 0:
+        return ()
+    # Else, this callable type hint was subscripted by one or more parameter
+    # type hints.
+    #
+    # If this callable type hint was subscripted by two or more parameter type
+    # hints, this callable type hint *CANNOT* have been subscripted by a single
+    # "special" parameter type hint (e.g., ellipsis, parameter specification).
+    # By elimination, the only remaining category of parameter type hint is a
+    # nested list of two or more parameter type hints. In this case, return the
+    # tuple slice containing the parameter type hints omitting the trailing
+    # return type hint.
+    elif hint_params_len >= 2:
+        return hint_args[:-1]
+    # Else, this callable type hint was subscripted by exactly one parameter
+    # type hint... which could be either a nested list of one or more parameter
+    # type hints *OR* a "special" parameter type hint. To differentiate the
+    # former from the latter, we explicitly detect all possible instances of the
+    # latter and only fallback to the former after exhausting the latter.
+
+    # Single parameter type hint subscripting this callable type hint.
+    hint_param = hint_args[0]
+
+    # If this parameter type hint is either...
+    #
+    # Note that we intentionally avoid attempting to efficiently test this
+    # parameter type hint against a set (e.g., "hint_param in {..., ()}"). This
+    # parameter type hint is *NOT* guaranteed to be hashable and thus testable
+    # against a hash-based collection.
+    if (
+        # An ellipsis, return an ellipsis.
+        hint_param is ... or
+        # The empty tuple, reduce this unlikely (albeit possible) edge case
+        # to the empty tuple returned for the more common case of a callable
+        # type hint subscripted by an empty list. That is, reduce these two
+        # cases to the same empty tuple for simplicity: e.g.,
+        #     >>> Callable[[], bool].__args__
+        #     (bool,)  # <------ this is good
+        #     >>> Callable[[()], bool].__args__
+        #     ((), bool,)  # <-- this is bad, so pretend this never happens
+        hint_param is TUPLE_EMPTY
+    ):
+        return hint_param
+    # Else, this parameter type hint is neither the empty tuple *NOR* an
+    # ellipsis.
+
+    # Sign uniquely identifying this parameter type hint if any *OR* "None".
+    hint_param_sign = get_hint_pep_sign_or_none(hint_param)
+
+    # If this parameter type hint is a PEP-compliant parameter type (i.e.,
+    # uniquely identifiable by a sign), return this hint as is.
+    #
+    # Note that:
+    # * This requires callers to handle all possible categories of
+    #   PEP-compliant parameter type hints -- including both
+    #   "typing.ParamSpec[...]" and "typing.Concatenate[...]" parameter type
+    #   hints, presumably by (...somewhat redundantly, but what can you do)
+    #   calling the get_hint_pep_sign_or_none() getter themselves.
+    # * Both PEP 484- *AND* 585-compliant callable type hints guarantee
+    #   this parameter type hint to be constrained to the subset of
+    #   PEP-compliant parameter type hints. Arbitrary parameter type hints
+    #   are prohibited. Ergo, we avoid validating that constraint here:
+    #   e.g.,
+    #     >>> from typing import Callable, List
+    #     >>> Callable[List[int], bool]
+    #     TypeError: Callable[args, result]: args must be a list. Got
+    #     typing.List[int]
+    if hint_param_sign in HINT_SIGNS_CALLABLE_PARAMS:
+        return hint_param
+    # Else, this parameter type hint is *NOT* a PEP-compliant parameter type
+    # hint. This hint *CANNOT* be "special" and *MUST* thus be the single
+    # parameter type hint of a nested list: e.g.,
+    #     >>> Callable[[list[int]], bool].__args__
+    #     (list[int], bool)
+
+    # In this case, return the 1-tuple containing exactly this hint.
+    # print(f'get_hint_pep484585_callable_params({repr(hint)}) == ({repr(hint_param)},)')
+    # print(f'{repr(hint_param)} sign: {repr(hint_param_sign)}')
+    return (hint_param,)
+
+
+def get_hint_pep484585_callable_return(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> object:
+    '''
+    **Return type hint** (i.e., PEP-compliant child type hint typing the return
+    returned by a passed or returned callable) of the passed
+    **callable type hint** (i.e., :pep:`484`-compliant ``typing.Callable[...]``
+    or :pep:`585`-compliant ``collections.abc.Callable[...]`` type hint).
+
+    This getter is considerably more trivial than the companion
+    :func:`get_hint_pep484585_callable_params` getter. Although this getter
+    exists largely for orthogonality and completeness, callers are advised to
+    defer to this getter rather than access this return type hint directly.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Callable type hint to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    ----------
+    object
+        Last argument originally subscripting this hint.
+
+    Raises
+    ----------
+    :exc:`exception_cls`
+        If this hint is *not* a callable type hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+
+    # If this hint is *NOT* a callable type hint, raise an exception.
+    _die_unless_hint_pep484585_callable(hint)
+    # Else, this hint is a callable type hint.
+
+    # Flattened tuple of the one or more child type hints subscripting this
+    # callable type hint. See get_hint_pep484585_callable_params() for details.
+    hint_args = get_hint_pep_args(hint)
+
+    # Return the last object subscripting this hint.
+    #
+    # Note that both the PEP 484-compliant "typing.Callable" factory *AND* the
+    # PEP 585-compliant "collections.abc.Callable" factory guarantee this object
+    # to exist. Ergo, we intentionally avoid repeating any validation here:
+    #     $ python3.10
+    #     >>> from collections.abc import Callable
+    #     >>> Callable[()]
+    #     TypeError: Callable must be used as Callable[[arg, ...], result].
+    return hint_args[-1]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484585/utilpep484585func.py
@@ -0,0 +1,219 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`- and :pep:`585`-compliant **decorated callable type
+hint utilities** (i.e., callables generically applicable to both :pep:`484`-
+and :pep:`585`-compliant type hints directly annotating the user-defined
+callable currently being decorated by :func:`beartype.beartype`).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep484585Exception
+from beartype.typing import Tuple
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.hint.pep.sign.datapepsigns import HintSignCoroutine
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_RETURN_GENERATOR_ASYNC,
+    HINT_SIGNS_RETURN_GENERATOR_SYNC,
+)
+from beartype._util.cls.utilclstest import is_type_subclass
+from beartype._util.func.utilfunctest import (
+    is_func_coro,
+    is_func_async_generator,
+    is_func_sync_generator,
+)
+from beartype._util.text.utiltextprefix import prefix_callable_return
+from collections.abc import (
+    AsyncGenerator,
+    Callable,
+    Generator,
+)
+
+# ....................{ REDUCERS ~ return                  }....................
+def reduce_hint_pep484585_func_return(
+    func: Callable,
+    exception_prefix: str,
+) -> object:
+    '''
+    Reduce the possibly PEP-noncompliant type hint annotating the return of the
+    passed callable if any to a simpler form to generate optimally efficient
+    type-checking by the :func:`beartype.beartype` decorator.
+
+    Parameters
+    ----------
+    func : Callable
+        Currently decorated callable to be inspected.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    ----------
+    object
+        Single argument subscripting this hint.
+
+    Raises
+    ----------
+    BeartypeDecorHintPep484585Exception
+        If this callable is either:
+
+        * A synchronous generator *not* annotated by a type hint identified by
+          a sign in the :data:`HINT_SIGNS_RETURN_GENERATOR_SYNC` set.
+        * An asynchronous generator *not* annotated by a type hint identified
+          by a sign in the :data:`HINT_SIGNS_RETURN_GENERATOR_ASYNC` set.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.pep484585.utilpep484585 import (
+        get_hint_pep484585_args)
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign_or_none
+
+    # Type hint annotating this callable's return, which the caller has already
+    # explicitly guaranteed to exist.
+    hint = func.__annotations__[ARG_NAME_RETURN]
+
+    # Sign uniquely identifying this hint if any *OR* "None" otherwise (e.g.,
+    # if this hint is an isinstanceable class).
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # If the decorated callable is a coroutine...
+    if is_func_coro(func):
+        # If this hint is "Coroutine[...]"...
+        if hint_sign is HintSignCoroutine:
+            # 3-tuple of all child type hints subscripting this hint if
+            # subscripted by three such hints *OR* raise an exception.
+            hint_args: Tuple[object, object, object] = get_hint_pep484585_args(  # type: ignore[assignment]
+                hint=hint, args_len=3, exception_prefix=exception_prefix)
+
+            # Reduce this hint to the last child type hint subscripting this
+            # hint, whose value is the return type hint for this coroutine.
+            #
+            # All other child type hints are currently ignorable, as the *ONLY*
+            # means of validating objects sent to and yielded from a coroutine
+            # is to wrap that coroutine with a @beartype-specific wrapper
+            # object, which we are currently unwilling to do. Why? Because
+            # safety and efficiency. Coroutines receiving and yielding multiple
+            # objects are effectively iterators; type-checking all iterator
+            # values is an O(n) rather than O(1) operation, violating the core
+            # @beartype guarantee.
+            #
+            # Likewise, the parent "Coroutine" type is *ALWAYS* ignorable.
+            # Since Python itself implicitly guarantees *ALL* coroutines to
+            # return coroutine objects, validating that constraint is silly.
+            hint = hint_args[-1]
+        # Else, this hint is *NOT* "Coroutine[...]". In this case, silently
+        # accept this hint as if this hint had instead been expanded to the
+        # semantically equivalent PEP 484- or 585-compliant coroutine hint
+        # "Coroutine[None, None, {hint}]".
+    # Else, the decorated callable is *NOT* a coroutine.
+    #
+    # If the decorated callable is an asynchronous generator...
+    elif is_func_async_generator(func):
+        # If this hint is neither...
+        if not (
+            # A PEP-compliant type hint acceptable as the return annotation of
+            # an synchronous generator *NOR*...
+            hint_sign in HINT_SIGNS_RETURN_GENERATOR_ASYNC or
+            # The "collections.abc.AsyncGenerator" abstract base class (ABC) or
+            # a subclass of that ABC...
+            is_type_subclass(hint, AsyncGenerator)
+        # Then this hint is semantically invalid as the return annotation of
+        # this callable. In this case, raise an exception.
+        ):
+            _die_of_hint_return_invalid(
+                func=func,
+                exception_suffix=(
+                    ' (i.e., expected either '
+                    'collections.abc.AsyncGenerator[YieldType, SendType], '
+                    'collections.abc.AsyncIterable[YieldType], '
+                    'collections.abc.AsyncIterator[YieldType], '
+                    'typing.AsyncGenerator[YieldType, SendType], '
+                    'typing.AsyncIterable[YieldType], or '
+                    'typing.AsyncIterator[YieldType] '
+                    'type hint).'
+                ),
+            )
+        # Else, this hint is valid as the return annotation of this callable.
+    # Else, the decorated callable is *NOT* an asynchronous generator.
+    #
+    # If the decorated callable is a synchronous generator...
+    elif is_func_sync_generator(func):
+        # If this hint is neither...
+        if not (
+            # A PEP-compliant type hint acceptable as the return annotation of a
+            # synchronous generator *NOR*...
+            hint_sign in HINT_SIGNS_RETURN_GENERATOR_SYNC or
+            # The "collections.abc.Generator" abstract base class (ABC) or a
+            # subclass of that ABC...
+            is_type_subclass(hint, Generator)
+        # Then this hint is semantically invalid as the return annotation of
+        # this callable. In this case, raise an exception.
+        ):
+            _die_of_hint_return_invalid(
+                func=func,
+                exception_suffix=(
+                    ' (i.e., expected either '
+                    'collections.abc.Generator[YieldType, SendType, ReturnType], '
+                    'collections.abc.Iterable[YieldType], '
+                    'collections.abc.Iterator[YieldType], '
+                    'typing.Generator[YieldType, SendType, ReturnType], '
+                    'typing.Iterable[YieldType], or '
+                    'typing.Iterator[YieldType] '
+                    'type hint).'
+                ),
+            )
+        # Else, this hint is valid as the return annotation of this callable.
+    # Else, the decorated callable is none of the kinds detected above.
+
+    # Return this possibly reduced hint.
+    return hint
+
+# ....................{ PRIVATE ~ validators               }....................
+def _die_of_hint_return_invalid(
+    # Mandatory parameters.
+    func: Callable,
+    exception_suffix: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+) -> str:
+    '''
+    Raise an exception of the passed type with a message suffixed by the passed
+    substring explaining why the possibly PEP-noncompliant type hint annotating
+    the return of the passed decorated callable is contextually invalid.
+
+    Parameters
+    ----------
+    func : Callable
+        Decorated callable whose return is annotated by an invalid type hint.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`.BeartypeDecorHintPep484585Exception`.
+    exception_suffix : str
+        Substring suffixing the exception message to be raised.
+
+    Raises
+    ----------
+    exception_cls
+        Exception explaining the invalidity of this return type hint.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+    assert isinstance(exception_cls, type), f'{repr(exception_cls)} not class.'
+    assert isinstance(exception_suffix, str), (
+        f'{repr(exception_suffix)} not string.')
+
+    # Type hint annotating this callable's return, which the caller has already
+    # explicitly guaranteed to exist.
+    hint = func.__annotations__[ARG_NAME_RETURN]
+
+    # Raise an exception of this type with a message suffixed by this suffix.
+    raise exception_cls(
+        f'{prefix_callable_return(func)}type hint '
+        f'{repr(hint)} contextually invalid{exception_suffix}'
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484585/utilpep484585generic.py
@@ -0,0 +1,892 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`- and :pep:`585`-compliant **generic type hint
+utilities** (i.e., callables generically applicable to both :pep:`484`-
+and :pep:`585`-compliant generic classes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep484585Exception
+from beartype.typing import (
+    Optional,
+    Tuple,
+)
+from beartype._conf.confcls import BeartypeConf
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.hint.pep.sign.datapepsigns import HintSignGeneric
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.cache.pool.utilcachepoollistfixed import (
+    FIXED_LIST_SIZE_MEDIUM,
+    acquire_fixed_list,
+    release_fixed_list,
+)
+from beartype._util.hint.pep.proposal.pep484.utilpep484generic import (
+    get_hint_pep484_generic_bases_unerased,
+    is_hint_pep484_generic,
+)
+from beartype._util.hint.pep.proposal.utilpep585 import (
+    get_hint_pep585_generic_bases_unerased,
+    is_hint_pep585_generic,
+)
+from collections.abc import Iterable
+
+# ....................{ TESTERS                            }....................
+@callable_cached
+def is_hint_pep484585_generic(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is either a :pep:`484`- or
+    :pep:`585`-compliant **generic** (i.e., object that may *not* actually be a
+    class despite subclassing at least one PEP-compliant type hint that also
+    may *not* actually be a class).
+
+    Specifically, this tester returns :data:`True` only if this object is
+    either:
+
+    * A :pep:`484`-compliant generic as tested by the lower-level
+      :func:`is_hint_pep484_generic` function.
+    * A :pep:`585`-compliant generic as tested by the lower-level
+      :func:`is_hint_pep585_generic` function.
+
+    This tester is memoized for efficiency. Although the implementation
+    trivially reduces to a one-liner, constant factors associated with that
+    one-liner are non-negligible. Moreover, this tester is called frequently
+    enough to warrant its reduction to an efficient lookup.
+
+    Caveats
+    -------
+    **Generics are not necessarily classes,** despite originally being declared
+    as classes. Although *most* generics are classes, subscripting a generic
+    class usually produces a generic non-class that *must* nonetheless be
+    transparently treated as a generic class: e.g.,
+
+    .. code-block:: python
+
+       >>> from typing import Generic, TypeVar
+       >>> S = TypeVar('S')
+       >>> T = TypeVar('T')
+       >>> class MuhGeneric(Generic[S, T]): pass
+       >>> non_class_generic = MuhGeneric[S, T]
+       >>> isinstance(non_class_generic, type)
+       False
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a generic.
+
+    See Also
+    --------
+    :func:`beartype._util.hint.pep.utilpeptest.is_hint_pep_typevars`
+        Commentary on the relation between generics and parametrized hints.
+    '''
+
+    # Return true only if this hint is...
+    return (
+        # A PEP 484-compliant generic. Note this test trivially reduces to
+        # an O(1) operation and is thus tested first.
+        is_hint_pep484_generic(hint) or
+        # A PEP 585-compliant generic. Note this test is O(n) in n the
+        # number of pseudo-superclasses originally subclassed by this
+        # generic and is thus tested last.
+        is_hint_pep585_generic(hint)
+    )
+
+# ....................{ GETTERS ~ bases                    }....................
+def get_hint_pep484585_generic_bases_unerased(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> Tuple[object, ...]:
+    '''
+    Tuple of the one or more **unerased pseudo-superclasses** (i.e.,
+    PEP-compliant objects originally listed as superclasses prior to their
+    implicit type erasure under :pep:`560`) of the passed :pep:`484`- or
+    :pep:`585`-compliant **generic** (i.e., class superficially subclassing at
+    least one PEP-compliant type hint that is possibly *not* an actual class) if
+    this object is a generic *or* raise an exception otherwise (i.e., if this
+    object is either not a class *or* is a class subclassing no non-class
+    PEP-compliant objects).
+
+    This getter is guaranteed to return a non-empty tuple. By definition, a
+    generic is a type subclassing one or more generic superclasses.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This function should always be called in lieu of attempting to directly
+    access the low-level** ``__orig_bases__`` **dunder instance variable.**
+    Most PEP-compliant type hints fail to declare that variable, guaranteeing
+    :class:`AttributeError` exceptions from all general-purpose logic
+    attempting to directly access that variable. Thus this function, which
+    "fills in the gaps" by implementing this oversight.
+
+    **This function returns tuples possibly containing a mixture of actual
+    superclasses and pseudo-superclasses superficially masquerading as actual
+    superclasses subscripted by one or more PEP-compliant child hints or type
+    variables** (e.g., ``(typing.Iterable[T], typing.Sized[T])``). Indeed, most
+    type hints used as superclasses produced by subscripting PEP-compliant type
+    hint factories are *not* actually types but singleton objects devilishly
+    masquerading as types. Most actual :mod:`typing` superclasses are private,
+    fragile, and prone to alteration or even removal between Python versions.
+
+    Motivation
+    ----------
+    :pep:`560` (i.e., "Core support for typing module and generic types)
+    formalizes the ``__orig_bases__`` dunder attribute first informally
+    introduced by the :mod:`typing` module's implementation of :pep:`484`.
+    Naturally, :pep:`560` remains as unusable as :pep:`484` itself. Ideally,
+    :pep:`560` would have generalized the core intention of preserving each
+    original user-specified subclass tuple of superclasses as a full-blown
+    ``__orig_mro__`` dunder attribute listing the original method resolution
+    order (MRO) of that subclass had that tuple *not* been modified.
+
+    Naturally, :pep:`560` did no such thing. The original MRO remains obfuscated
+    and effectively inaccessible. While computing that MRO would technically be
+    feasible, doing so would also be highly non-trivial, expensive, and fragile.
+    Instead, this function retrieves *only* the tuple of :mod:`typing`-specific
+    pseudo-superclasses that this object's class originally attempted (but
+    failed) to subclass.
+
+    You are probably now agitatedly cogitating to yourself in the darkness: "But
+    @leycec: what do you mean :pep:`560`? Wasn't :pep:`560` released *after*
+    :pep:`484`? Surely no public API defined by the Python stdlib would be so
+    malicious as to silently alter the tuple of base classes listed by a
+    user-defined subclass?"
+
+    As we've established both above and elsewhere throughout the codebase,
+    everything developed for :pep:`484` -- including :pep:`560`, which derives
+    its entire raison d'etre from :pep:`484` -- are fundamentally insane. In
+    this case, :pep:`484` is insane by subjecting parametrized :mod:`typing`
+    types employed as base classes to "type erasure," because:
+
+         ...it is common practice in languages with generics (e.g. Java,
+         TypeScript).
+
+    Since Java and TypeScript are both terrible languages, blindly
+    recapitulating bad mistakes baked into such languages is an equally bad
+    mistake. In this case, "type erasure" means that the :mod:`typing` module
+    *intentionally* destroys runtime type information for nebulous and largely
+    unjustifiable reasons (i.e., Big Daddy Java and TypeScript do it, so it
+    must be unquestionably good).
+
+    Specifically, the :mod:`typing` module intentionally munges :mod:`typing`
+    types listed as base classes in user-defined subclasses as follows:
+
+    * All base classes whose origin is a builtin container (e.g.,
+      ``typing.List[T]``) are reduced to that container (e.g., :class:`list`).
+    * All base classes derived from an abstract base class declared by the
+      :mod:`collections.abc` subpackage (e.g., ``typing.Iterable[T]``) are
+      reduced to that abstract base class (e.g., ``collections.abc.Iterable``).
+    * All surviving base classes that are parametrized (e.g.,
+      ``typing.Generic[S, T]``) are stripped of that parametrization (e.g.,
+      :class:`typing.Generic`).
+
+    Since there exists no counterpart to the :class:`typing.Generic` superclass,
+    the :mod:`typing` module preserves that superclass in unparametrized form.
+    Naturally, this is useless, as an unparametrized :class:`typing.Generic`
+    superclass conveys no meaningful type information. All other superclasses
+    are reduced to their non-:mod:`typing` counterparts: e.g.,
+
+        .. code-block:: python
+
+        >>> from typing import TypeVar, Generic, Iterable, List
+        >>> T = TypeVar('T')
+        >>> class UserDefinedGeneric(List[T], Iterable[T], Generic[T]): pass
+        # This is type erasure.
+        >>> UserDefinedGeneric.__mro__
+        (list, collections.abc.Iterable, Generic)
+        # This is type preservation -- except the original MRO is discarded.
+        # So, it's not preservation; it's reduction! We take what we can get.
+        >>> UserDefinedGeneric.__orig_bases__
+        (typing.List[T], typing.Iterable[T], typing.Generic[T])
+        # Guess which we prefer?
+
+    So, we prefer the generally useful ``__orig_bases__`` dunder tuple over the
+    generally useless ``__mro__`` dunder tuple. Note, however, that the latter
+    *is* still occasionally useful and thus occasionally returned by this
+    getter. For inexplicable reasons, **single-inherited protocols** (i.e.,
+    classes directly subclassing *only* the :pep:`544`-compliant
+    :attr:`typing.Protocol` abstract base class (ABC)) are *not* subject to type
+    erasure and thus constitute a notable exception to this heuristic:
+
+        .. code-block:: python
+
+        >>> from typing import Protocol
+        >>> class UserDefinedProtocol(Protocol): pass
+        >>> UserDefinedProtocol.__mro__
+        (__main__.UserDefinedProtocol, typing.Protocol, typing.Generic, object)
+        >>> UserDefinedProtocol.__orig_bases__
+        AttributeError: type object 'UserDefinedProtocol' has no attribute
+        '__orig_bases__'
+
+    Welcome to :mod:`typing` hell, where even :mod:`typing` types lie broken and
+    misshapen on the killing floor of overzealous theory-crafting purists.
+
+    Parameters
+    ----------
+    hint : object
+        Generic type hint to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Tuple[object]
+        Tuple of the one or more unerased pseudo-superclasses of this generic.
+
+    Raises
+    ------
+    exception_cls
+        If this hint is either:
+
+        * Neither a :pep:`484`- nor :pep:`585`-compliant generic.
+        * A :pep:`484`- nor :pep:`585`-compliant generic subclassing *no*
+          pseudo-superclasses.
+
+    Examples
+    --------
+        >>> import typing
+        >>> from beartype._util.hint.pep.utilpepget import (
+        ...     get_hint_pep484585_generic_bases_unerased)
+        >>> T = typing.TypeVar('T')
+        >>> class MuhIterable(typing.Iterable[T], typing.Container[T]): pass
+        >>> get_hint_pep585_generic_bases_unerased(MuhIterable)
+        (typing.Iterable[~T], typing.Container[~T])
+        >>> MuhIterable.__mro__
+        (MuhIterable,
+         collections.abc.Iterable,
+         collections.abc.Container,
+         typing.Generic,
+         object)
+    '''
+
+    # Tuple of either...
+    #
+    # Note this implicitly raises a "BeartypeDecorHintPepException" if this
+    # object is *NOT* a PEP-compliant generic. Ergo, we need not explicitly
+    # validate that above.
+    hint_pep_generic_bases_unerased = (
+        # If this is a PEP 585-compliant generic, all unerased
+        # pseudo-superclasses of this PEP 585-compliant generic.
+        #
+        # Note that this unmemoized getter accepts keyword arguments.
+        get_hint_pep585_generic_bases_unerased(
+            hint=hint,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+        if is_hint_pep585_generic(hint) else
+        # Else, this *MUST* be a PEP 484-compliant generic. In this case, all
+        # unerased pseudo-superclasses of this PEP 484-compliant generic.
+        #
+        # Note that this memoized getter prohibits keyword arguments.
+        get_hint_pep484_generic_bases_unerased(
+            hint,
+            exception_cls,
+            exception_prefix,
+        )
+    )
+
+    # If this generic subclasses *NO* pseudo-superclass, raise an exception.
+    #
+    # Note this should have already been guaranteed on our behalf by:
+    # * If this generic is PEP 484-compliant, the "typing" module.
+    # * If this generic is PEP 585-compliant, CPython or PyPy itself.
+    if not hint_pep_generic_bases_unerased:
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+        raise exception_cls(
+            f'{exception_prefix}PEP 484 or 585 generic {repr(hint)} '
+            f'subclasses no superclasses.'
+        )
+    # Else, this generic subclasses one or more pseudo-superclasses.
+
+    # Return this tuple of these pseudo-superclasses.
+    return hint_pep_generic_bases_unerased
+
+# ....................{ GETTERS ~ type                     }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep484585_generic_type(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> type:
+    '''
+    Either the passed :pep:`484`- or :pep:`585`-compliant **generic** (i.e.,
+    class superficially subclassing at least one PEP-compliant type hint that is
+    possibly *not* an actual class) if **unsubscripted** (i.e., indexed by *no*
+    arguments or type variables), the unsubscripted generic underlying this
+    generic if **subscripted** (i.e., indexed by one or more child type hints
+    and/or type variables), *or* raise an exception otherwise (i.e., if this
+    hint is *not* a generic).
+
+    Specifically, this getter returns (in order):
+
+    * If this hint originates from an **origin type** (i.e., isinstanceable
+      class such that *all* objects satisfying this hint are instances of that
+      class), this type regardless of whether this hint is already a class.
+    * Else if this hint is already a class, this hint as is.
+    * Else, raise an exception.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This getter returns false positives in edge cases.** That is, this getter
+    returns non-:data:`None` values for both generics and non-generics --
+    notably, non-generics defining the ``__origin__`` dunder attribute to an
+    isinstanceable class. Callers *must* perform subsequent tests to distinguish
+    these two cases.
+
+    Parameters
+    ----------
+    hint : object
+        Generic type hint to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    type
+        Class originating this generic.
+
+    Raises
+    ------
+    exception_cls
+        If this hint is *not* a generic.
+
+    See Also
+    --------
+    :func:`get_hint_pep484585_generic_type_or_none`
+        Further details.
+    '''
+
+    # Either this hint if this hint is an unsubscripted generic, the
+    # unsubscripted generic underlying this hint if this hint is a subscripted
+    # generic, *OR* "None" if this hint is not a generic.
+    hint_generic_type = get_hint_pep484585_generic_type_or_none(hint)
+
+    # If this hint is *NOT* a generic, raise an exception.
+    if hint_generic_type is None:
+        raise exception_cls(
+            f'{exception_prefix}PEP 484 or 585 generic {repr(hint)} '
+            f'not generic (i.e., originates from no isinstanceable class).'
+        )
+    # Else, this hint is a generic.
+
+    # Return this class.
+    return hint_generic_type
+
+
+def get_hint_pep484585_generic_type_or_none(hint: object) -> Optional[type]:
+    '''
+    Either the passed :pep:`484`- or :pep:`585`-compliant **generic** (i.e.,
+    class superficially subclassing at least one PEP-compliant type hint that is
+    possibly *not* an actual class) if **unsubscripted** (i.e., indexed by *no*
+    arguments or type variables), the unsubscripted generic underlying this
+    generic if **subscripted** (i.e., indexed by one or more child type hints
+    and/or type variables), *or* :data:`None` otherwise (i.e., if this hint is
+    *not* a generic).
+
+    Specifically, this getter returns (in order):
+
+    * If this hint originates from an **origin type** (i.e., isinstanceable
+      class such that *all* objects satisfying this hint are instances of that
+      class), this type regardless of whether this hint is already a class.
+    * Else if this hint is already a class, this hint as is.
+    * Else, :data:`None`.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This getter returns false positives in edge cases.** That is, this getter
+    returns non-:data:`None`` values for both generics and non-generics --
+    notably, non-generics defining the ``__origin__`` dunder attribute to an
+    isinstanceable class. Callers *must* perform subsequent tests to distinguish
+    these two cases.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[type]
+        Either:
+
+        * If this hint is a generic, the class originating this generic.
+        * Else, :data:`None`.
+
+    See Also
+    --------
+    :func:`get_hint_pep_origin_or_none`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_origin_or_none
+
+    # Arbitrary object originating this hint if any *OR* "None" otherwise.
+    hint_origin = get_hint_pep_origin_or_none(hint)
+    # print(f'{repr(hint)} hint_origin: {repr(hint_origin)}')
+
+    # If this origin is a type, this is the origin type originating this hint.
+    # In this case, return this type.
+    if isinstance(hint_origin, type):
+        return hint_origin
+    # Else, this origin is *NOT* a type.
+    #
+    # Else if this hint is already a type, this type is effectively already its
+    # origin type. In this case, return this type as is.
+    elif isinstance(hint, type):
+        return hint
+    # Else, this hint is *NOT* a type. In this case, this hint originates from
+    # *NO* origin type.
+
+    # Return the "None" singleton.
+    return None
+
+# ....................{ FINDERS                            }....................
+def find_hint_pep484585_generic_module_base_first(
+    # Mandatory parameters.
+    hint: object,
+    module_name: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> type:
+    '''
+    Iteratively find and return the first **unerased superclass** (i.e.,
+    unerased pseudo-superclass that is an actual superclass) transitively
+    defined under the third-party package or module with the passed name
+    subclassed by the unsubscripted generic type underlying the passed
+    :pep:`484`- or :pep:`585`-compliant **generic** (i.e., object that may *not*
+    actually be a class despite subclassing at least one PEP-compliant type hint
+    that also may *not* actually be a class).
+
+    This finder is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator). Although doing so *would* dramatically
+    improve the efficiency of this finder, doing so:
+
+    * Would require all passed parameters be passed positionally, which becomes
+      rather cumbersome given the number of requisite parameters.
+    * Is (currently) unnecessary, as all callers of this function are themselves
+      already memoized.
+
+    Motivation
+    ----------
+    This finder is typically called to reduce **descriptive generics** (i.e.,
+    generics defined in third-party packages intended to be used *only* as
+    descriptive type hints rather than actually instantiated as objects as most
+    generics are) to the isinstanceable classes those generics describe.
+    Although the mere existence of descriptive generics should be considered to
+    be a semantic (if not syntactic) violation of :pep:`484`, the widespread
+    proliferation of descriptive generics leaves :mod:`beartype` with little
+    choice but to grin wanly and bear the pain they subject us to. As example,
+    this finder is currently called elsewhere to:
+
+    * Reduce Pandera type hints (e.g., `pandera.typing.DataFrame[...]`) to the
+      Pandas types they describe (e.g., `pandas.DataFrame`).
+    * Reduce NumPy type hints (e.g., `numpy.typing.NDArray[...]`) to the
+      NumPy types they describe (e.g., `numpy.ndarray`).
+
+    See examples below for further discussion.
+
+    Parameters
+    ----------
+    hint : object
+        Generic type hint to be inspected.
+    module_name : str
+        Fully-qualified name of the third-party package or module to find the
+        first class in this generic type hint of.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    type
+        First unerased superclass transitively defined under this package or
+        module subclassed by the unsubscripted generic type underlying this
+        generic type hint.
+
+    Examples
+    --------
+        >>> from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+        ...     find_hint_pep484585_generic_base_first_in_module)
+
+        # Reduce a Pandera type hint to the Pandas type it describes.
+        >>> from pandera import DataFrameModel
+        >>> from pandera.typing import DataFrame
+        >>> class MuhModel(DataFrameModel): pass
+        >>> find_hint_pep484585_generic_base_first_in_module(
+        ...     hint=DataFrame[MuhModel], module_name='pandas', ...)
+        <class 'pandas.DataFrame'>
+    '''
+    assert isinstance(module_name, str), f'{repr(module_name)} not string.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodget import get_object_module_name_or_none
+
+    # Either:
+    # * If this generic is unsubscripted, this unsubscripted generic type as is.
+    # * If this generic is subscripted, the unsubscripted generic type
+    #   underlying this subscripted generic (e.g., the type
+    #   "pandera.typing.pandas.DataFrame" given the type hint
+    #   "pandera.typing.DataFrame[...]").
+    hint_type = get_hint_pep484585_generic_type(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # Fully-qualified name of the module to be searched for suffixed by a "."
+    # delimiter. This is a micro-optimization improving lookup speed below.
+    module_name_prefix = f'{module_name}.'
+
+    # Tuple of the one or more unerased pseudo-superclasses which this
+    # unsubscripted generic type originally subclassed prior to type erasure.
+    #
+    # Note that we could also inspect the method-resolution order (MRO) of this
+    # type via the "hint.__mro__" dunder tuple, but that doing so would only
+    # needlessly reduce the efficiency of the following iteration by
+    # substantially increasing the number of iterations required to find the
+    # desired superclass and thus the worst-case complexity of that iteration.
+    hint_type_bases = get_hint_pep484585_generic_bases_unerased(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # For each unerased pseudo-superclass of this unsubscripted generic type...
+    for hint_base in hint_type_bases:
+        # If this pseudo-superclass is *NOT* an actual superclass, silently
+        # ignore this non-superclass and continue to the next pseudo-superclass.
+        if not isinstance(hint_base, type):
+            continue
+        # Else, this pseudo-superclass is an actual superclass.
+
+        # Fully-qualified name of the module declaring this superclass if any
+        # *OR* "None" otherwise (i.e., if this type is only defined in-memory).
+        hint_base_module_name = get_object_module_name_or_none(hint_base)
+
+        # If this module exists *AND* either...
+        if hint_base_module_name and (
+            # This module is the desired module itself *OR*...
+            hint_base_module_name == module_name_prefix or
+            # This module is a submodule of the desired module...
+            hint_base_module_name.startswith(module_name_prefix)
+        # Then return this superclass.
+        ):
+            # print(f'Found generic {repr(hint)} type {repr(hint_type)} "{module_name}" superclass {repr(hint_base)}!')
+            return hint_base
+        # Else, this is *NOT* the desired module. In this case, continue to the
+        # next superclass.
+    # Else, *NO* superclass of this generic resides in the desired module.
+
+    # Raise an exception of the passed type.
+    raise exception_cls(
+        f'{exception_prefix}PEP 484 or 585 generic {repr(hint)} '
+        f'type {repr(hint_type)} subclasses no "{module_name}" type '
+        f'(i.e., type with module name prefixed by "{module_name}" not '
+        f'found in method resolution order (MRO) {repr(hint_type.__mro__)}).'
+    )
+
+# ....................{ ITERATORS                          }....................
+#FIXME: Unit test us up, please.
+def iter_hint_pep484585_generic_bases_unerased_tree(
+    # Mandatory parameters.
+    hint: object,
+    conf: BeartypeConf,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep484585Exception,
+    exception_prefix: str = '',
+) -> Iterable:
+    '''
+    Breadth-first search (BFS) generator iteratively yielding the one or more
+    unignorable unerased transitive pseudo-superclasses originally declared as
+    superclasses prior to their type erasure of the passed :pep:`484`- or
+    :pep:`585`-compliant generic.
+
+    This generator yields the full tree of all pseudo-superclasses by
+    transitively visiting both all direct pseudo-superclasses of this generic
+    *and* all indirect pseudo-superclasses transitively superclassing all direct
+    pseudo-superclasses of this generic. For efficiency, this generator is
+    internally implemented with an efficient imperative First In First Out
+    (FILO) queue rather than an inefficient (and dangerous, due to both
+    unavoidable stack exhaustion and avoidable infinite recursion) tree of
+    recursive function calls.
+
+    Motivation
+    ----------
+    Ideally, a BFS would *not* be necessary. Instead, pseudo-superclasses
+    visited by this BFS should be visitable as is via whatever external parent
+    BFS is currently iterating over the tree of all transitive type hints (e.g.,
+    our code generation algorithm implemented by the
+    :func:`beartype._check.code.codemake.make_func_pith_code` function).
+    That's how we transitively visit all other kinds of type hints, right?
+    Sadly, that simple solution fails to scale to all possible edge cases that
+    arise with generics. Why? Because our code generation algorithm sensibly
+    requires that *only* unignorable hints may be enqueued onto its outer BFS.
+    Generics confound that constraint. Some pseudo-superclasses are
+    paradoxically:
+
+    * Ignorable from the perspective of code generation. *No* type-checking code
+      should be generated for these pseudo-superclasses. See reasons below.
+    * Unignorable from the perspective of algorithm visitation. These
+      pseudo-superclasses generate *no* code but may themselves subclass other
+      pseudo-superclasses for which type-checking code should be generated and
+      which must thus be visited by our outer BFS.
+
+    Paradoxical pseudo-superclasses include:
+
+    * User-defined :pep:`484`-compliant subgenerics (i.e., user-defined generics
+      subclassing one or more parent user-defined generic superclasses).
+    * User-defined :pep:`544`-compliant subprotocols (i.e., user-defined
+      protocols subclassing one or more parent user-defined protocol
+      superclasses).
+
+    Consider this example :pep:`544`-compliant subprotocol:
+
+    .. code-block:: pycon
+
+       >>> import typing as t
+       >>> class UserProtocol(t.Protocol[t.AnyStr]): pass
+       >>> class UserSubprotocol(UserProtocol[str], t.Protocol): pass
+       >>> UserSubprotocol.__orig_bases__
+       (UserProtocol[str], typing.Protocol)  # <-- good
+       >>> UserProtocolUnerased = UserSubprotocol.__orig_bases__[0]
+       >>> UserProtocolUnerased is UserProtocol
+       False
+       >>> isinstance(UserProtocolUnerased, type)
+       False  # <-- bad
+
+    :pep:`585`-compliant generics suffer no such issues:
+
+    .. code-block:: pycon
+
+       >>> from beartype._util.hint.pep.proposal.utilpep585 import is_hint_pep585_builtin_subscripted
+       >>> class UserGeneric(list[int]): pass
+       >>> class UserSubgeneric(UserGeneric[int]): pass
+       >>> UserSubgeneric.__orig_bases__
+       (UserGeneric[int],)
+       >>> UserGenericUnerased = UserSubgeneric.__orig_bases__[0]
+       >>> isinstance(UserGenericUnerased, type)
+       True  # <-- good
+       >>> UserGenericUnerased.__mro__
+       (UserGeneric, list, object)
+       >>> is_hint_pep585_builtin_subscripted(UserGenericUnerased)
+       True
+
+    Iteratively walking up the unerased inheritance hierarchy for any such
+    paradoxical generic or protocol subclass (e.g., ``UserSubprotocol`` but
+    *not* ``UserSubgeneric`` above) would visit a user-defined generic or
+    protocol pseudo-superclass subscripted by type variables. Due to poorly
+    defined obscurities in the :mod:`typing` implementation, that
+    pseudo-superclass is *not* actually a class but rather an instance of a
+    private :mod:`typing` class (e.g., :class:`typing._SpecialForm`). This
+    algorithm would then detect that pseudo-superclass as neither a generic nor
+    a :mod:`typing` object and thus raise an exception. Fortunately, that
+    pseudo-superclass conveys no meaningful intrinsic semantics with respect to
+    type-checking; its only use is to register its own pseudo-superclasses (one
+    or more of which could convey meaningful intrinsic semantics with respect to
+    type-checking) for visitation by this BFS.
+
+    Parameters
+    ----------
+    hint : object
+        Generic type hint to be inspected.
+    conf : BeartypeConf
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object).
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep484585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Iterable
+        Breadth-first search (BFS) generator iteratively yielding the one or
+        more unignorable unerased transitive pseudo-superclasses originally
+        declared as superclasses prior to their type erasure of this generic.
+
+    Raises
+    ------
+    exception_cls
+        If this hint is *not* a generic.
+
+    See Also
+    --------
+    :func:`get_hint_pep484585_generic_type_or_none`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._check.convert.convsanify import (
+        sanify_hint_child_if_unignorable_or_none)
+    from beartype._util.hint.pep.proposal.utilpep585 import (
+        is_hint_pep585_builtin_subscripted)
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign_or_none
+    from beartype._util.hint.pep.utilpeptest import is_hint_pep_typing
+
+    # Tuple of the one or more unerased pseudo-superclasses originally listed as
+    # superclasses prior to their type erasure by this generic.
+    hint_bases_direct = get_hint_pep484585_generic_bases_unerased(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # print(f'generic {hint} hint_bases_direct: {hint_bases_direct}')
+
+    # Fixed list of the one or more unerased transitive pseudo-superclasses
+    # originally listed as superclasses prior to their type erasure by this
+    # generic that have yet to be visited by the breadth-first search (BFS) over
+    # these superclasses performed below.
+    hint_bases = acquire_fixed_list(size=FIXED_LIST_SIZE_MEDIUM)
+
+    # 0-based index of the currently visited pseudo-superclass of this list.
+    hint_bases_index_curr = 0
+
+    # 0-based index of one *PAST* the last pseudo-superclass of this list.
+    hint_bases_index_past_last = len(hint_bases_direct)
+
+    # Initialize this list to these direct pseudo-superclasses of this generic.
+    hint_bases[0:hint_bases_index_past_last] = hint_bases_direct
+    # print(f'generic pseudo-superclasses [initial]: {repr(hint_bases_direct}')
+
+    # While the 0-based index of the next visited pseudo-superclass does *NOT*
+    # exceed that of the last pseudo-superclass in this list, there remains one
+    # or more pseudo-superclasses to be visited in this BFS.
+    while hint_bases_index_curr < hint_bases_index_past_last:
+        # Unignorable sane pseudo-superclass sanified from this possibly
+        # ignorable insane pseudo-superclass *OR* "None" otherwise (i.e.,
+        # if this pseudo-superclass is ignorable).
+        hint_base = sanify_hint_child_if_unignorable_or_none(
+            hint=hint_bases[hint_bases_index_curr],
+            conf=conf,
+            #FIXME: Possibly also pass this, please. Ignorable for now. *shrug*
+            # cls_stack=cls_stack,
+            exception_prefix=exception_prefix,
+        )
+        # print(f'generic {hint} base: {repr(hint_base)}')
+
+        # If this pseudo-superclass is unignorable...
+        if hint_base is not None:
+            # Sign identifying this pseudo-superclass if any *OR* "None".
+            hint_base_sign = get_hint_pep_sign_or_none(hint_base)
+
+            #FIXME: Unit test up this branch, please.
+            # If this pseudo-superclass is...
+            if (
+                # A PEP-compliant generic *AND*...
+                hint_base_sign is HintSignGeneric and
+                # Is neither...
+                not (
+                    # A PEP 585-compliant superclass *NOR*...
+                    is_hint_pep585_builtin_subscripted(hint_base) and
+                    # A PEP 484- or 544-compliant superclass defined by the
+                    # "typing" module...
+                    is_hint_pep_typing(hint_base)
+                )
+            ):
+            # Then this pseudo-superclass is a user-defined PEP 484-compliant
+            # generic or 544-compliant protocol. In this case, generate *NO*
+            # type-checking code for this pseudo-superclass; we only enqueue all
+            # parent pseudo-superclasses of this pseudo-superclasses for
+            # visitation by later iteration of this inner BFS.
+            #
+            # See "hints_bases" for explanatory commentary.
+                # Tuple of the one or more parent pseudo-superclasses of this
+                # child pseudo-superclass.
+                hint_base_bases = get_hint_pep484585_generic_bases_unerased(
+                    hint=hint_base,
+                    exception_cls=exception_cls,
+                    exception_prefix=exception_prefix,
+                )
+
+                # 0-based index of the last pseudo-superclass of this list
+                # *BEFORE* adding onto this list.
+                hint_bases_index_past_last_prev = hint_bases_index_past_last
+
+                # 0-based index of the last pseudo-superclass of this list
+                # *AFTER* adding onto this list.
+                hint_bases_index_past_last += len(hint_base_bases)
+
+                # Enqueue these superclasses onto this list.
+                hint_bases[
+                    hint_bases_index_past_last_prev:
+                    hint_bases_index_past_last
+                ] = hint_base_bases
+            # Else, this pseudo-superclass is neither an ignorable user-defined
+            # PEP 484-compliant generic *NOR* an ignorable 544-compliant
+            # protocol.
+            #
+            # If this pseudo-superclass is *NOT* an isinstanceable type
+            # conveying *NO* meaningful semantics, this pseudo-superclass is
+            # unignorable. Yield this unignorable pseudo-superclass.
+            elif hint_base_sign is not None:
+                yield hint_base
+            # Else, this pseudo-superclass is an isinstanceable type conveying
+            # *NO* meaningful semantics and is thus effectively ignorable. Why?
+            # Because the caller already type-checks this pith against the
+            # generic subclassing this superclass and thus this superclass as
+            # well in an isinstance() call (e.g., in the
+            # "CODE_PEP484585_GENERIC_PREFIX" snippet leveraged by the
+            # "beartype._check.code.codemake" submodule).
+        # Else, this pseudo-superclass is ignorable.
+        # else:
+        #     print(f'Ignoring generic {repr(hint)} base {repr(hint_base)}...')
+        #     print(f'Is generic {hint} base {repr(hint_base)} type? {isinstance(hint_base, type)}')
+
+        # Nullify the previously visited pseudo-superclass in this list.
+        hint_bases[hint_bases_index_curr] = None
+
+        # Increment the 0-based index of the next visited pseudo-superclass in
+        # this list *BEFORE* visiting that pseudo-superclass but *AFTER*
+        # performing all other logic for the current pseudo-superclass.
+        hint_bases_index_curr += 1
+
+    # Release this list. Pray for salvation, for we find none here.
+    release_fixed_list(hint_bases)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484585/utilpep484585ref.py
@@ -0,0 +1,641 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`- and :pep:`585`-compliant **forward reference type hint
+utilities** (i.e., callables generically applicable to both :pep:`484`- and
+:pep:`585`-compliant forward reference type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintForwardRefException
+from beartype.typing import (
+    Optional,
+    Tuple,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.cls.datacls import (
+    TYPE_BUILTIN_NAME_TO_TYPE,
+    TYPES_PEP484585_REF,
+)
+from beartype._data.hint.datahinttyping import (
+    Pep484585ForwardRef,
+    TypeException,
+    TypeStack,
+)
+from beartype._data.module.datamodpy import BUILTINS_MODULE_NAME
+from beartype._util.module.utilmodget import get_object_module_name_or_none
+from beartype._util.module.utilmodtest import is_module
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_10
+from beartype._util.text.utiltextlabel import label_callable
+from collections.abc import (
+    Callable,
+    Sequence,
+)
+
+# ....................{ VALIDATORS                         }....................
+#FIXME: Validate that this forward reference string is *NOT* the empty string.
+#FIXME: Validate that this forward reference string is a syntactically valid
+#"."-delimited concatenation of Python identifiers. We already have logic
+#performing that validation somewhere, so let's reuse that here, please.
+#Right. So, we already have an is_identifier() tester; now, we just need to
+#define a new die_unless_identifier() validator.
+def die_unless_hint_pep484585_ref(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintForwardRefException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is either a :pep:`484`- or
+    :pep:`585`-compliant **forward reference type hint** (i.e., object
+    referring to a user-defined class that typically has yet to be defined).
+
+    Equivalently, this validator raises an exception if this object is neither:
+
+    * A string whose value is the syntactically valid name of a class.
+    * An instance of the :class:`typing.ForwardRef` class. The :mod:`typing`
+      module implicitly replaces all strings subscripting :mod:`typing` objects
+      (e.g., the ``MuhType`` in ``List['MuhType']``) with
+      :class:`typing.ForwardRef` instances containing those strings as instance
+      variables, for nebulous reasons that make little justifiable sense but
+      what you gonna do 'cause this is 2020. *Fight me.*
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintForwardRefException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is *not* a forward reference type hint.
+    '''
+
+    # If this object is *NOT* a forward reference type hint, raise an exception.
+    if not isinstance(hint, TYPES_PEP484585_REF):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not exception subclass.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not forward reference '
+            f'(i.e., neither string nor "typing.ForwardRef" object).'
+        )
+    # Else, this object is a forward reference type hint.
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep484585_ref_names(
+    # Mandatory parameters.
+    hint: Pep484585ForwardRef,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintForwardRefException,
+    exception_prefix: str = '',
+) -> Tuple[Optional[str], str]:
+    '''
+    Possibly undefined fully-qualified module name and possibly qualified
+    classname referred to by the passed **forward reference type hint** (i.e.,
+    object indirectly referring to a user-defined class that typically has yet
+    to be defined).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation mostly reduces to an
+    efficient one-liner.
+
+    Caveats
+    -------
+    **Callers are recommended to call the higher-level**
+    :func:`.get_hint_pep484585_ref_names_relative_to` **getter rather than this
+    lower-level getter,** which fails to guarantee canonicalization and is thus
+    considerably less safe.
+
+    Parameters
+    ----------
+    hint : object
+        Forward reference to be introspected.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintForwardRefException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Tuple[Optional[str], str]
+        2-tuple ``(ref_module_name, ref_name)`` where:
+
+        * ``ref_module_name`` is the possibly undefined fully-qualified module
+          name referred to by this forward reference, defined as either:
+
+          * If this forward reference is a :class:`typing.ForwardRef` object
+            passed a module name at instantiation time via the ``module``
+            parameter, this module name.
+          * Else, :data:`None`.
+
+        * ``ref_name`` is the possibly qualified classname referred to by this
+          forward reference.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * This forward reference is *not* actually a forward reference.
+        * This forward reference is **relative** (i.e., contains *no* ``.``
+          delimiters) and either:
+
+          * Neither the passed callable nor class define the ``__module__``
+            dunder attribute.
+          * The passed callable and/or class define the ``__module__``
+            dunder attribute, but the values of those attributes all refer to
+            unimportable modules that do *not* appear to physically exist.
+
+    See Also
+    --------
+    :func:`.get_hint_pep484585_ref_name`
+        Lower-level getter returning possibly relative forward references.
+    '''
+
+    # If this is *NOT* a forward reference, raise an exception.
+    die_unless_hint_pep484585_ref(hint)
+    # Else, this is a forward reference.
+
+    # Possibly unqualified basename of the class to which reference refers.
+    hint_name: str = None  # type: ignore[assignment]
+
+    # Fully-qualified name of the module to which this reference is relative if
+    # this reference is relative to an importable module *OR* "None" otherwise
+    # (i.e., if this reference is either absolute and thus not relative to a
+    # module *OR* relative to an unimportable module).
+    #
+    # Note that, although *ALL* callables and classes should define the
+    # "__module__" instance variable underlying the call to this getter, *SOME*
+    # callables and classes do not. For this reason, we intentionally:
+    # * Call the get_object_module_name_or_none() getter rather than
+    #   get_object_module_name().
+    # * Explicitly detect "None".
+    # * Raise a human-readable exception.
+    #
+    # Doing so produces significantly more readable exceptions than merely
+    # calling get_object_module_name(). Problematic objects include:
+    # * Objects defined in Sphinx-specific "conf.py" configuration files. In all
+    #   likelihood, Sphinx is running these files in some sort of arcane and
+    #   non-standard manner (over which beartype has *NO* control).
+    hint_module_name: Optional[str] = None
+
+    # If this reference is a string, the classname of this reference is this
+    # reference itself.
+    if isinstance(hint, str):
+        hint_name = hint
+    # Else, this reference is *NOT* a string. By process of elimination, this
+    # reference *MUST* be a "typing.ForwardRef" instance. In this case...
+    else:
+        # Forward reference classname referred to by this reference.
+        hint_name = hint.__forward_arg__
+
+        # If the active Python interpreter targets >= Python 3.10, then this
+        # "typing.ForwardRef" object defines an optional "__forward_module__:
+        # Optional[str] = None" dunder attribute whose value is either:
+        # * If Python passed the "module" parameter when instantiating this
+        #   "typing.ForwardRef" object, the value of that parameter -- which is
+        #   presumably the fully-qualified name of the module to which this
+        #   presumably relative forward reference is relative to.
+        # * Else, "None".
+        #
+        # Note that:
+        # * This requires violating privacy encapsulation by accessing dunder
+        #   attributes unique to "typing.ForwardRef" objects. Sad, yet true.
+        # * This object defines a significant number of other
+        #   "__forward_"-prefixed dunder instance variables, which exist *ONLY*
+        #   to enable the blatantly useless typing.get_type_hints() function to
+        #   avoid repeatedly (and thus inefficiently) reevaluating the same
+        #   forward reference. *sigh*
+        # * Technically, this dunder attribute has been defined since at least
+        #   Python >= 3.9.18. Sadly, one or more unknown earlier patch releases
+        #   of the Python 3.9 development cycle do *NOT* support this. This is
+        #   currently only safely usable under Python >= 3.10 -- all patch
+        #   releases of which are known to define this dunder attribute.
+        #
+        # In this case...
+        if IS_PYTHON_AT_LEAST_3_10:
+            # Fully-qualified name of the module to which this presumably
+            # relative forward reference is relative to if any *OR* "None"
+            # otherwise (i.e., if *NO* such name was passed at forward reference
+            # instantiation time).
+            hint_module_name = hint.__forward_module__
+        # Else, the active Python interpreter targets < Python 3.9 and thus
+        # fails to define the  "__forward_module__" dunder attribute.
+
+    # Return metadata describing this forward reference relative to this module.
+    return hint_module_name, hint_name
+
+
+def get_hint_pep484585_ref_names_relative_to(
+    # Mandatory parameters.
+    hint: Pep484585ForwardRef,
+
+    # Optional parameters.
+    cls_stack: TypeStack = None,
+    func: Optional[Callable] = None,
+    exception_cls: TypeException = BeartypeDecorHintForwardRefException,
+    exception_prefix: str = '',
+) -> Tuple[Optional[str], str]:
+    '''
+    Possibly undefined fully-qualified module name and possibly qualified
+    classname referred to by the passed **forward reference type hint** (i.e.,
+    object indirectly referring to a user-defined class that typically has yet
+    to be defined), canonicalized relative to the module declaring the passed
+    type stack and/or callable (in that order) if this classname is unqualified.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as the implementation mostly reduces to an
+    efficient one-liner.
+
+    Caveats
+    -------
+    This getter preferentially canonicalizes this forward reference if relative
+    against the fully-qualified name of the module defining (in order):
+
+    #. The passed class stack if *not* :data:`None`.
+    #. The passed callable.
+
+    This getter thus prioritizes classes over callables. Why? Because classes
+    are more likely to define ``__module__`` dunder attributes referring to
+    importable modules that physically exist. Why? Because dynamically
+    synthesizing in-memory callables residing in imaginary and thus unimportable
+    modules is trivial; dynamically synthesizing in-memory classes residing in
+    imaginary and thus unimportable modules is less trivial.
+
+    Consider the standard use case for :mod:`beartype`: beartype import hooks
+    declared by the :mod:`beartype.claw` subpackage. Although hooks directly
+    apply the :func:`beartype.beartype` decorator to classes and functions
+    residing in importable modules that physically exist, that decorator then
+    dynamically iterates over the methods of those classes. That iteration is
+    dynamic and iterates over methods that both physically exist and only
+    dynamically exist in-memory in unimportable modules.
+
+    Does this edge case arise in real-world code? All too frequently. For
+    unknown reasons, the :class:`typing.NamedTuple` superclass dynamically
+    generates dunder methods (e.g., ``__new__``) whose ``__module__`` dunder
+    attributes erroneously refer to imaginary and thus unimportable modules
+    ``named_{subclass_name}`` for the unqualified basename ``{subclass_name}``
+    of the current user-defined class subclassing :class:`typing.NamedTuple`
+    despite that user-defined class residing in an importable module: e.g.,
+
+    .. code-block:: pycon
+
+       >>> from beartype import beartype
+       >>> from typing import NamedTuple
+
+       >>> @beartype
+       ... class NamelessTupleIsBlameless(NamedTuple):
+       ...     forward_ref: 'UndefinedType'
+
+       >>> NamelessTupleIsBlameless.__module__
+       '__main__'                        # <-- makes sense
+       >>> NamelessTupleIsBlameless.__new__.__module__
+       'named_NamelessTupleIsBlameless'  # <-- lol wut
+
+    If this getter erroneously prioritized callables over classes *and* blindly
+    accepted imaginary modules as valid, this getter would erroneously resolve
+    the relative forward reference ``'UndefinedType'`` to
+    ``'named_NamelessTupleIsBlameless.UndefinedType'`` rather than to
+    ``'__main__.UndefinedType'``. And... this is why @leycec is currently bald.
+
+    Parameters
+    ----------
+    hint : object
+        Forward reference to be canonicalized.
+    cls_stack : TypeStack
+        Either:
+
+        * If this forward reference annotates a method of a class, the
+          corresponding **type stack** (i.e., tuple of the one or more
+          :func:`beartype.beartype`-decorated classes lexically containing that
+          method). If this forward reference is unqualified (i.e., relative),
+          this getter then canonicalizes this reference against that class.
+        * Else, :data:`None`.
+
+        Defaults to :data:`None`.
+    func : Optional[Callable]
+        Either:
+
+        * If this forward reference annotates a callable, that callable.
+          If this forward reference is also unqualified (i.e., relative), this
+          getter then canonicalizes this reference against that callable.
+        * Else, :data:`None`.
+
+        Defaults to :data:`None`.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintForwardRefException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Tuple[Optional[str], str]
+        2-tuple ``(ref_module_name, ref_name)`` where:
+
+        * ``ref_module_name`` is the possibly undefined fully-qualified module
+          name referred to by this forward reference, defined as either:
+
+          * If this forward reference is a :class:`typing.ForwardRef` object
+            passed a module name at instantiation time via the ``module``
+            parameter *or* a type stack or callable defining a module name via
+            the ``__module`` dunder attribute are passed, this module name.
+          * Else, :data:`None`.
+
+        * ``ref_name`` is the possibly qualified classname referred to by this
+          forward reference.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * This forward reference is *not* actually a forward reference.
+        * This forward reference is **relative** (i.e., contains *no* ``.``
+          delimiters) and either:
+
+          * Neither the passed callable nor class define the ``__module__``
+            dunder attribute.
+          * The passed callable and/or class define the ``__module__``
+            dunder attribute, but the values of those attributes all refer to
+            unimportable modules that do *not* appear to physically exist.
+
+    See Also
+    --------
+    :func:`.get_hint_pep484585_ref_names`
+        Lower-level getter returning possibly relative forward references.
+    '''
+
+    # Possibly undefined fully-qualified module name and possibly unqualified
+    # classname referred to by this forward reference.
+    hint_module_name, hint_ref_name = get_hint_pep484585_ref_names(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # If either...
+    if (
+        # This reference was instantiated with a module name *OR*...
+        hint_module_name or
+        # This classname contains one or more "." characters and is thus already
+        # (...hopefully) fully-qualified...
+        '.' in hint_ref_name
+    # Then this classname is either absolute *OR* relative to some module. In
+    # either case, the class referred to by this reference can now be
+    # dynamically imported at a later time. In this case...
+    ):
+        # Return this metadata as is.
+        return hint_module_name, hint_ref_name
+    # Else, this classname is relative to a module whose fully-qualified name
+    # has yet to be decided.
+    #
+    # If this reference does *NOT* annotate a callable, then this reference also
+    # does *NOT* annotate a method of a class (i.e., "cls is None"). Why?
+    # Because a method is a callable. In this case...
+    elif not func:
+        # If a builtin type with this classname exists, assume this reference
+        # refers to this builtin type exposed by the standard "builtins" module.
+        if hint_ref_name in TYPE_BUILTIN_NAME_TO_TYPE:
+            hint_module_name = BUILTINS_MODULE_NAME
+        # Else, this reference does *NOT* refer to a builtin type. In this
+        # case, there exists *NO* owner module against which to canonicalize
+        # this relative reference. This edge case occurs when this getter is
+        # transitively called by a high-level "beartype.door" runtime
+        # type-checker (e.g., is_bearable(), die_if_unbearable()). In this case,
+        # raise an exception.
+        else:
+            raise exception_cls(
+                f'{exception_prefix}type hint relative forward reference '
+                f'"{hint_ref_name}" currently only type-checkable in '
+                f'type hints annotating '
+                f'@beartype-decorated callables and classes. '
+                f'For your own safety and those of the codebases you love, '
+                f'consider canonicalizing this '
+                f'relative forward reference into an '
+                f'absolute forward reference '
+                f'(e.g., replace "{hint_ref_name}" with '
+                f'"{{your_package}}.{{your_submodule}}.{hint_ref_name}").'
+            )
+    # Else, this reference annotates a callable and is thus relative to the
+    # module defining this callable.
+
+    # Validate sanity.
+    assert isinstance(cls_stack, NoneTypeOr[Sequence]), (
+        f'{repr(cls_stack)} neither sequence nor "None".')
+    assert isinstance(func, NoneTypeOr[Callable]), (
+        f'{repr(func)} neither callable nor "None".')
+
+    # If this reference annotates a method of a class...
+    if cls_stack:
+        # Class currently being decorated by @beartype.
+        cls = cls_stack[-1]
+
+        # Fully-qualified name of the module defining that class.
+        hint_module_name = get_object_module_name_or_none(cls)
+    # Else, this reference does *NOT* annotate a method of a class.
+
+    # If it is *NOT* the case that...
+    if not (
+        # That class is declared by a module *AND*...
+        hint_module_name and
+        # That module is importable...
+        is_module(hint_module_name)
+    # Fallback to...
+    ):
+        # Fully-qualified name of the callable annotated by this reference.
+        hint_module_name = get_object_module_name_or_none(func)
+
+        # If it is *NOT* the case that...
+        if not (
+            # That callable is declared by a module *AND*...
+            hint_module_name and
+            # That module is importable...
+            is_module(hint_module_name)
+        # Fallback to...
+        ):
+            # If a builtin type with this name exists, assume this reference
+            # refers to this builtin type exposed by the "builtins" module.
+            #
+            # Note that this edge case is shockingly common *AND* distinct from
+            # the above similar edge case. Why? The "typing.NamedTuple"
+            # superclass, which dynamically generates subclass dunder methods
+            # (e.g., __new__()) residing in unimportable fake modules with the
+            # name "named_{subclass_name}".
+            if hint_ref_name in TYPE_BUILTIN_NAME_TO_TYPE:
+                hint_module_name = BUILTINS_MODULE_NAME
+            # Else, this reference does *NOT* refer to a builtin type. In this
+            # case, there exists *NO* owner module against which to canonicalize
+            # this relative reference. Raise an exception, please.
+            else:
+                # Exception message to be raised.
+                exception_message = (
+                    f'{exception_prefix}type hint relative forward reference '
+                    f'"{hint_ref_name}" unresolvable relative to'
+                )
+
+                # If this reference annotates a method of a class...
+                if cls_stack:
+                    # Fully-qualified name of the module defining that class.
+                    type_module_name = get_object_module_name_or_none(cls)  # pyright: ignore
+
+                    # Append this message by...
+                    exception_message += (
+                        # Substring describing this class *AND*...
+                        f':\n* {repr(cls)} ' +  # pyright: ignore
+                        (
+                            # If that class defines a "__module__" dunder
+                            # attribute, substring describing that module.
+                            f'in unimportable module "{type_module_name}".'
+                            if type_module_name else
+                            # Else, that class defines *NO* such attribute. In
+                            # this case, a substring describing that failure.
+                            'with undefined "__module__" attribute.'
+                        ) +
+                        # Substring suffixing this item and prefixing the next
+                        # item.
+                        '\n* '
+                    )
+                # Else, this reference annotates a global or local function. In
+                # this case, append a substring prefixing the next item.
+                else:
+                    exception_message += ' '
+
+                # Append this message by an appropriate substring defined as
+                # the dynamic concatenation of...
+                exception_message += (
+                    # Substring describing this callable if callable is actually
+                    # callable or falling back to its representation otherwise
+                    # *AND*...
+                    (
+                        f'{label_callable(func)} '
+                        if callable(func) else
+                        f'{repr(func)} '
+                    ) +
+                    # Substring describing this module.
+                    (
+                        f'in unimportable module "{hint_module_name}".'
+                        if hint_module_name else
+                        'with undefined "__module__" attribute.'
+                    )
+                )
+
+                # Raise this exception.
+                raise exception_cls(exception_message)
+        # Else, that function is declared by an importable module.
+    # Else, that class is declared by an importable module.
+    #
+    # In either case, at least one of either that class or function is declared
+    # by an importable module.
+
+    # Return metadata describing this forward reference relative to this module.
+    return hint_module_name, hint_ref_name
+
+# ....................{ IMPORTERS                          }....................
+#FIXME: Unit test us up, please.
+def import_pep484585_ref_type(
+    # Mandatory parameters.
+    hint: Pep484585ForwardRef,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintForwardRefException,
+    exception_prefix: str = '',
+    **kwargs
+) -> type:
+    '''
+    Class referred to by the passed :pep:`484` or :pep:`585`-compliant
+    **forward reference type hint** (i.e., object indirectly referring to a
+    user-defined class that typically has yet to be defined) canonicalized if
+    this hint is unqualified relative to the module declaring the first of
+    whichever of the passed owner type and/or callable is *not* :data:`None`.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the passed object is typically a
+    :func:`beartype.beartype`-decorated callable passed exactly once to this
+    function.
+
+    Parameters
+    ----------
+    hint : Pep484585ForwardRef
+        Forward reference type hint to be resolved.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintForwardRefException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.get_hint_pep484585_ref_names_relative_to` getter.
+
+    Returns
+    -------
+    type
+        Class referred to by this forward reference.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * This forward reference is *not* actually a forward reference.
+        * This forward reference is **relative** (i.e., contains *no* ``.``
+          delimiters) and either:
+
+          * Neither the passed callable nor class define the ``__module__``
+            dunder attribute.
+          * The passed callable and/or class define the ``__module__``
+            dunder attribute, but the values of those attributes all refer to
+            unimportable modules that do *not* appear to physically exist.
+        * The object referred to by this forward reference is either:
+
+          * Undefined.
+          * Defined but not a class.
+
+    See Also
+    --------
+    :func:`.get_hint_pep484585_ref_names_relative_to`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._check.forward.reference.fwdrefmake import (
+        make_forwardref_indexable_subtype)
+
+    # Possibly undefined fully-qualified module name and possibly unqualified
+    # classname referred to by this forward reference relative to this type
+    # stack and callable.
+    hint_module_name, hint_ref_name = get_hint_pep484585_ref_names_relative_to(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+        **kwargs
+    )
+
+    # Forward reference proxy referring to this class.
+    hint_ref = make_forwardref_indexable_subtype(
+        hint_module_name, hint_ref_name)
+
+    # Return the class dynamically imported from this proxy.
+    return hint_ref.__type_beartype__
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/pep484585/utilpep484585type.py
@@ -0,0 +1,253 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`484`- and :pep:`585`-compliant **dual type hint utilities**
+(i.e., callables generically applicable to both :pep:`484`- and
+:pep:`585`-compliant type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep484585Exception
+from beartype.typing import (
+    Tuple,
+    TypeVar,
+    Union,
+)
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignForwardRef,
+    HintSignType,
+    HintSignUnion,
+)
+from beartype._data.hint.datahinttyping import Pep484585ForwardRef
+from beartype._util.cls.pep.utilpep3119 import (
+    die_unless_type_issubclassable,
+    die_unless_object_issubclassable,
+)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585 import (
+    get_hint_pep484585_args)
+from typing import (
+    Type as typing_Type,  # <-- intentional to distinguish from "type" below
+)
+
+# ....................{ HINTS ~ private                    }....................
+_HINT_PEP484585_SUBCLASS_ARGS_1_UNION = Union[
+    type, Tuple[type], TypeVar, Pep484585ForwardRef,]
+'''
+Union of the types of all permissible :pep:`484`- or :pep:`585`-compliant
+**subclass type hint arguments** (i.e., PEP-compliant child type hints
+subscripting (indexing) a subclass type hint).
+'''
+
+# ....................{ GETTERS                            }....................
+def get_hint_pep484585_type_superclass(
+    hint: object,
+    exception_prefix: str,
+) -> _HINT_PEP484585_SUBCLASS_ARGS_1_UNION:
+    '''
+    **Issubclassable superclass(es)** (i.e., class whose metaclass does *not*
+    define a ``__subclasscheck__()`` dunder method that raises an exception,
+    tuple of such classes, or forward reference to such a class) subscripting
+    the passed :pep:`484`- or :pep:`585`-compliant **subclass type hint**
+    (i.e., hint constraining objects to subclass that superclass).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    _HINT_PEP484585_SUBCLASS_ARGS_1_UNION
+        Argument subscripting this subclass type hint, guaranteed to be either:
+
+        * An issubclassable class.
+        * A tuple of issubclassable classes.
+        * A :pep:`484`-compliant forward reference to an issubclassable class
+          that typically has yet to be declared (i.e.,
+          :class:`typing.ForwardRef` instance).
+        * A :pep:`484`-compliant type variable constrained to classes (i.e.,
+          :class:`typing.TypeVar` instance).
+        * A :pep:`585`-compliant union of two or more issubclassable classes.
+        * A :pep:`484`-compliant type variable constrained to classes (i.e.,
+          :class:`typing.TypeVar` instance).
+
+    Raises
+    ------
+    BeartypeDecorHintPep3119Exception
+        If this superclass subscripting this type hint is *not*
+        **issubclassable** (i.e., class whose metaclass defines a
+        ``__subclasscheck__()`` dunder method raising an exception).
+    BeartypeDecorHintPep484585Exception
+        If this hint is either:
+
+        * Neither a :pep:`484`- nor :pep:`585`-compliant subclass type hint.
+        * A :pep:`484`- or :pep:`585`-compliant subclass type hint subscripted
+          by one argument that is neither a class, union of classes, nor
+          forward reference to a class.
+    BeartypeDecorHintPep585Exception
+        If this hint is either:
+
+        * A :pep:`585`-compliant subclass type hint subscripted by either:
+
+          * *No* arguments.
+          * Two or more arguments.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_args,
+        get_hint_pep_sign,
+        get_hint_pep_sign_or_none,
+    )
+
+    # If this is neither a PEP 484- *NOR* PEP 585-compliant subclass type hint,
+    # raise an exception.
+    if get_hint_pep_sign(hint) is not HintSignType:
+        raise BeartypeDecorHintPep484585Exception(
+            f'{exception_prefix}{repr(hint)} '
+            f'neither PEP 484 nor 585 subclass type hint.'
+        )
+    # Else, this is a subclass type hint.
+
+    # Superclass subscripting this hint.
+    hint_superclass = get_hint_pep484585_args(
+        hint=hint, args_len=1, exception_prefix=exception_prefix)
+
+    # Sign identifying this superclass.
+    hint_superclass_sign = get_hint_pep_sign_or_none(hint_superclass)
+
+    # If this superclass is actually a union of superclasses...
+    if hint_superclass_sign is HintSignUnion:
+        # Efficiently reduce this superclass to the tuple of superclasses
+        # subscripting and thus underlying this union.
+        hint_superclass = get_hint_pep_args(hint_superclass)
+
+        # If any item of this tuple is *NOT* an issubclassable class, raise an
+        # exception.
+        # print(f'hint_superclass union arg: {hint_superclass}')
+        die_unless_object_issubclassable(
+            obj=hint_superclass, exception_prefix=exception_prefix)  # type: ignore[arg-type]
+    # Else, this superclass is *NOT* a union of superclasses.
+    #
+    # If this superclass is actually a forward reference to a superclass,
+    # silently accept this reference as is. This conditional exists only to
+    # avoid raising a subsequent exception.
+    elif hint_superclass_sign is HintSignForwardRef:
+        pass
+    # Else, this superclass is *NOT* a forward reference to a superclass.
+    #
+    # If this superclass is a class...
+    elif isinstance(hint_superclass, type):
+        die_unless_type_issubclassable(
+            cls=hint_superclass, exception_prefix=exception_prefix)
+        # Else, this superclass is issubclassable.
+    # Else, this superclass is of an unexpected type. In this case, raise an
+    # exception.
+    #
+    # Note that PEP 585-compliant subclass type hints infrequently trigger this
+    # edge case. Although the "typing" module explicitly validates the
+    # arguments subscripting PEP 484-compliant type hints, the CPython
+    # interpreter applies *NO* such validation to PEP 585-compliant subclass
+    # type hints. For example, PEP 585-compliant subclass type hints are
+    # subscriptable by the empty tuple, which is technically an argument:
+    #     >>> type[()].__args__
+    #     ()   # <---- thanks fer nuthin
+    else:
+        raise BeartypeDecorHintPep484585Exception(
+            f'{exception_prefix}PEP 484 or 585 subclass type hint '
+            f'{repr(hint)} child type hint {repr(hint_superclass)} neither '
+            f'class, union of classes, nor forward reference to class.'
+        )
+
+    # Return this superclass.
+    return hint_superclass  # type: ignore[return-value]
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Unit test us up.
+def reduce_hint_pep484585_type(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`484`- or :pep:`585`-compliant **subclass type
+    hint** (i.e., hint constraining objects to subclass that superclass) to the
+    :class:`type` superclass if that hint is subscripted by an ignorable child
+    type hint (e.g., :attr:`typing.Any`, :class:`type`) *or* preserve this hint
+    as is otherwise (i.e., if that hint is *not* subscripted by an ignorable
+    child type hint).
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Subclass type hint to be reduced.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Raises
+    ------
+    BeartypeDecorHintPep484585Exception
+        If this hint is neither a :pep:`484`- nor :pep:`585`-compliant subclass
+        type hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhinttest import is_hint_ignorable
+
+    # If this hint is the unsubscripted PEP 484-compliant subclass type hint,
+    # immediately reduce this hint to the "type" superclass.
+    #
+    # Note that this is *NOT* merely a nonsensical optimization. The
+    # implementation of the unsubscripted PEP 484-compliant subclass type hint
+    # significantly differs across Python versions. Under some but *NOT* all
+    # supported Python versions (notably, Python 3.7 and 3.8), the "typing"
+    # module subversively subscripts this hint by a type variable; under all
+    # others, this hint remains unsubscripted. In the latter case, passing this
+    # hint to the subsequent get_hint_pep484585_args() call would erroneously
+    # raise an exception.
+    if hint is typing_Type:
+        return type
+    # Else, this hint is *NOT* the unsubscripted PEP 484-compliant subclass
+    # type hint.
+
+    # Superclass subscripting this hint.
+    #
+    # Note that we intentionally do *NOT* call the high-level
+    # get_hint_pep484585_type_superclass() getter here, as the
+    # validation performed by that function would raise exceptions for
+    # various child type hints that are otherwise permissible (e.g.,
+    # "typing.Any").
+    hint_superclass = get_hint_pep484585_args(
+        hint=hint, args_len=1, exception_prefix=exception_prefix)
+
+    # If this argument is either...
+    if (
+        # An ignorable type hint (e.g., "typing.Any") *OR*...
+        is_hint_ignorable(hint_superclass) or
+        # The "type" superclass, which is effectively ignorable in this
+        # context of subclasses, as *ALL* classes necessarily subclass
+        # that superclass.
+        hint_superclass is type
+    ):
+        # Reduce this subclass type hint to the "type" superclass.
+        hint = type
+    # Else, this argument is unignorable and thus irreducible.
+
+    # Return this possibly reduced type hint.
+    return hint
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep544.py
@@ -0,0 +1,643 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`544`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from abc import abstractmethod
+from beartype.roar import BeartypeDecorHintPep544Exception
+from beartype.typing import (
+    Any,
+    BinaryIO,
+    Dict,
+    IO,
+    Optional,
+    TextIO,
+)
+from beartype._data.module.datamodtyping import TYPING_MODULE_NAMES
+from beartype._util.cls.utilclstest import is_type_builtin_or_fake
+from typing import Protocol as typing_Protocol  # <-- unoptimized protocol
+
+# ....................{ TESTERS                            }....................
+def is_hint_pep544_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed :pep:`484`-compliant type hint is ignorable.
+
+    Specifically, this tester returns :data:`True` only if this hint is a
+    parametrization of the :class:`typing.Protocol` abstract base class (ABC) by
+    one or more type variables. As the name implies, this ABC is generic and
+    thus fails to impose any meaningful constraints. Since a type variable in
+    and of itself also fails to impose any meaningful constraints, these
+    parametrizations are safely ignorable in all possible contexts: e.g.,
+
+    .. code-block:: python
+
+       from typing import Protocol, TypeVar
+       T = TypeVar('T')
+       def noop(param_hint_ignorable: Protocol[T]) -> T: pass
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`544`-compliant type hint is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhintget import get_hint_repr
+
+    # Machine-readable representation of this hint.
+    hint_repr = get_hint_repr(hint)
+
+    # If this representation contains a relevant substring suggesting that this
+    # hint might be the "Protocol" superclass directly parametrized by type
+    # variables (e.g., "typing.Protocol[S, T]")...
+    if 'Protocol[' in hint_repr:
+        # For the fully-qualified name of each typing module...
+        for typing_module_name in TYPING_MODULE_NAMES:
+            # If this hint is the "Protocol" superclass defined by this module
+            # directly parametrized by one or more type variables (e.g.,
+            # "typing.Protocol[S, T]"), ignore this superclass by returning
+            # true. This superclass can *ONLY* be parametrized by type
+            # variables; a string test thus suffices.
+            #
+            # For unknown and uninteresting reasons, *ALL* possible objects
+            # satisfy the "Protocol" superclass. Ergo, this superclass and *ALL*
+            # parametrizations of this superclass are synonymous with the
+            # "object" root superclass.
+            if hint_repr.startswith(f'{typing_module_name}.Protocol['):
+                return True
+            # Else, this hint is *NOT* such a "Protocol" superclass. In this
+            # case, continue to the next typing module.
+        # Else, this hint is *NOT* the "Protocol" superclass directly
+        # parametrized by one or more type variables.
+    # Else, this representation contains such *NO* such substring.
+
+    # Return false, as *ALL* other "Protocol" subclasses are unignorable.
+    return False
+
+
+def is_hint_pep484_generic_io(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a functionally useless
+    :pep:`484`-compliant :mod:`typing` **IO generic superclass** (i.e., either
+    :class:`typing.IO` itself *or* a subclass of :class:`typing.IO` defined by
+    the :mod:`typing` module effectively unusable at runtime due to botched
+    implementation details) that is losslessly replaceable with a useful
+    :pep:`544`-compliant :mod:`beartype` **IO protocol** (i.e., either
+    :class:`_Pep544IO` itself *or* a subclass of that class defined by this
+    submodule intentionally designed to be usable at runtime).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :pep:`484`-compliant IO generic
+        base class.
+
+    See Also
+    --------
+    :class:`_Pep544IO`
+        Further commentary.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_origin_or_none)
+
+    # Return true only if this hint is either...
+    return (
+        # An unsubscripted PEP 484-compliant IO generic base class
+        # (e.g., "typing.IO") *OR*....
+        (isinstance(hint, type) and hint in _HINTS_PEP484_IO_GENERIC) or
+        # A subscripted PEP 484-compliant IO generic base class
+        # (e.g., "typing.IO[str]") *OR*....
+        get_hint_pep_origin_or_none(hint) in _HINTS_PEP484_IO_GENERIC
+    )
+
+
+def is_hint_pep544_protocol(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a :pep:`544`-compliant
+    **protocol** (i.e., subclass of the :class:`typing.Protocol` superclass).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :pep:`544`-compliant protocol.
+    '''
+
+    # Return true only if this hint is...
+    return (
+        # A type *AND*...
+        isinstance(hint, type) and
+        # A PEP 544-compliant protocol *AND*...
+        issubclass(hint, typing_Protocol) and  # type: ignore[arg-type]
+        # *NOT* a builtin type. For unknown reasons, some but *NOT* all
+        # builtin types erroneously present themselves to be PEP
+        # 544-compliant protocols under Python >= 3.8: e.g.,
+        #     >>> from typing import Protocol
+        #     >>> issubclass(str, Protocol)
+        #     False        # <--- this makes sense
+        #     >>> issubclass(int, Protocol)
+        #     True         # <--- this makes no sense whatsoever
+        #
+        # Since builtin types are obviously *NOT* PEP 544-compliant
+        # protocols, explicitly exclude all such types. Why, Guido? Why?
+        #
+        # Do *NOT* ignore fake builtins for the purposes of this test. Why?
+        # Because even fake builtins (e.g., "type(None)") erroneously
+        # masquerade as PEP 544-compliant protocols! :o
+        not is_type_builtin_or_fake(hint)  # pyright: ignore
+    )
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep484_generic_io_to_pep544_protocol(
+    hint: Any, exception_prefix: str) -> Any:
+    '''
+    :pep:`544`-compliant :mod:`beartype` **IO protocol** (i.e., either
+    :class:`._Pep544IO` itself *or* a subclass of that class defined by this
+    submodule intentionally designed to be usable at runtime) corresponding to
+    the passed :pep:`484`-compliant :mod:`typing` **IO generic base class**
+    (i.e., either :class:`typing.IO` itself *or* a subclass of
+    :class:`typing.IO` defined by the :mod:`typing` module effectively unusable
+    at runtime due to botched implementation details).
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner thanks to caching internally performed by this
+    reducer.
+
+    Parameters
+    ----------
+    hint : type
+        :pep:`484`-compliant :mod:`typing` IO generic base class to be replaced
+        by the corresponding :pep:`544`-compliant :mod:`beartype` IO protocol.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    Returns
+    -------
+    Protocol
+        :pep:`544`-compliant :mod:`beartype` IO protocol corresponding to this
+        :pep:`484`-compliant :mod:`typing` IO generic base class.
+
+    Raises
+    ------
+    BeartypeDecorHintPep544Exception
+        If this object is *not* a :pep:`484`-compliant IO generic base class.
+    '''
+
+    # If this object is *NOT* a PEP 484-compliant "typing" IO generic,
+    # raise an exception.
+    if not is_hint_pep484_generic_io(hint):
+        raise BeartypeDecorHintPep544Exception(
+            f'{exception_prefix}type hint {repr(hint)} not '
+            f'PEP 484 IO generic base class '
+            f'(i.e., "typing.IO", "typing.BinaryIO", or "typing.TextIO").'
+        )
+    # Else, this object is *NOT* a PEP 484-compliant "typing" IO generic.
+    #
+    # If this dictionary has yet to be initialized, this submodule has yet to be
+    # initialized. In this case, do so.
+    #
+    # Note that this initialization is intentionally deferred until required.
+    # Why? Because this initialization performs somewhat space- and
+    # time-intensive work -- including importation of the "beartype.vale"
+    # subpackage, which we strictly prohibit importing from global scope.
+    elif not _HINT_PEP484_IO_GENERIC_TO_PEP544_PROTOCOL:
+        _init()
+    # In any case, this dictionary is now initialized.
+
+    # PEP 544-compliant IO protocol implementing this PEP 484-compliant IO
+    # generic if any *OR* "None" otherwise.
+    pep544_protocol = _HINT_PEP484_IO_GENERIC_TO_PEP544_PROTOCOL.get(hint)
+
+    # If *NO* PEP 544-compliant IO protocol implements this generic...
+    if pep544_protocol is None:
+        # Avoid circular import dependencies.
+        from beartype._util.hint.pep.utilpepget import (
+            get_hint_pep_origin_or_none,
+            get_hint_pep_typevars,
+        )
+
+        # Tuple of zero or more type variables parametrizing this hint.
+        hint_typevars = get_hint_pep_typevars(hint)
+
+        #FIXME: Unit test us up, please.
+        # If this hint is unparametrized, raise an exception.
+        if not hint_typevars:
+            raise BeartypeDecorHintPep544Exception(
+                f'{exception_prefix}PEP 484 IO generic base class '
+                f'{repr(hint)} invalid (i.e., not subscripted (indexed) by '
+                f'either "str", "bytes", "typing.Any", or "typing.AnyStr").'
+            )
+        # Else, this hint is parametrized and thus defines the "__origin__"
+        # dunder attribute whose value is the type originating this hint.
+
+        #FIXME: Attempt to actually handle this type variable, please.
+        # Reduce this parametrized hint (e.g., "typing.IO[typing.AnyStr]") to
+        # the equivalent unparametrized hint (e.g., "typing.IO"), effectively
+        # ignoring the type variable parametrizing this hint.
+        hint_unparametrized: type = get_hint_pep_origin_or_none(hint)  # type: ignore[assignment]
+
+        # PEP 544-compliant IO protocol implementing this unparametrized PEP
+        # 484-compliant IO generic. For efficiency, we additionally cache this
+        # mapping under the original parametrized hint to minimize the cost of
+        # similar reductions under subsequent annotations.
+        pep544_protocol = \
+            _HINT_PEP484_IO_GENERIC_TO_PEP544_PROTOCOL[hint] = \
+            _HINT_PEP484_IO_GENERIC_TO_PEP544_PROTOCOL[hint_unparametrized]
+    # Else, some PEP 544-compliant IO protocol implements this generic.
+
+    # Return this protocol.
+    return pep544_protocol
+
+# ....................{ PRIVATE ~ mappings                 }....................
+_HINTS_PEP484_IO_GENERIC = frozenset((IO, BinaryIO, TextIO,))
+'''
+Frozen set of all :mod:`typing` **IO generic base class** (i.e., either
+:class:`typing.IO` itself *or* a subclass of :class:`typing.IO` defined by the
+:mod:`typing` module).
+'''
+
+
+# Conditionally initialized by the _init() function below.
+_HINT_PEP484_IO_GENERIC_TO_PEP544_PROTOCOL: Dict[type, Any] = {}
+'''
+Dictionary mapping from each :mod:`typing` **IO generic base class** (i.e.,
+either :class:`typing.IO` itself *or* a subclass of :class:`typing.IO` defined
+by the :mod:`typing` module) to the associated :mod:`beartype` **IO protocol**
+(i.e., either :class:`_Pep544IO` itself *or* a subclass of :class:`_Pep544IO`
+defined by this submodule).
+'''
+
+# ....................{ PRIVATE ~ classes                  }....................
+# Conditionally initialized by the _init() function below.
+_Pep544IO: Any = None  # type: ignore[assignment]
+'''
+:pep:`544`-compliant protocol base class for :class:`_Pep544TextIO` and
+:class:`_Pep544BinaryIO`.
+
+This is an abstract, generic version of the return of open().
+
+NOTE: This does not distinguish between the different possible classes (text
+vs. binary, read vs. write vs. read/write, append-only, unbuffered). The TextIO
+and BinaryIO subclasses below capture the distinctions between text vs. binary,
+which is pervasive in the interface; however we currently do not offer a way to
+track the other distinctions in the type system.
+
+Design
+------
+This base class intentionally duplicates the contents of the existing
+:class:`typing.IO` generic base class by substituting the useless
+:class:`typing.Generic` superclass of the latter with the useful
+:class:`typing.Protocol` superclass of the former. Why? Because *no* stdlib
+classes excluding those defined by the :mod:`typing` module itself subclass
+:class:`typing.IO`. However, :class:`typing.IO` leverages neither the
+:class:`abc.ABCMeta` metaclass *nor* the :class:`typing.Protocol` superclass
+needed to support structural subtyping. Therefore, *no* stdlib objects
+(including those returned by the :func:`open` builtin) satisfy either
+:class:`typing.IO` itself or any subclasses of :class:`typing.IO` (e.g.,
+:class:`typing.BinaryIO`, :class:`typing.TextIO`). Therefore,
+:class:`typing.IO` and all subclasses thereof are functionally useless for all
+practical intents. The conventional excuse `given by Python maintainers to
+justify this abhorrent nonsensicality is as follows <typeshed_>`__:
+
+    There are a lot of "file-like" classes, and the typing IO classes are meant
+    as "protocols" for general files, but they cannot actually be protocols
+    because the file protocol isn't very well defined—there are lots of methods
+    that exist on some but not all filelike classes.
+
+Like most :mod:`typing`-oriented confabulation, that, of course, is bollocks.
+Refactoring the family of :mod:`typing` IO classes from inveterate generics
+into pragmatic protocols is both technically trivial and semantically useful,
+because that is exactly what :mod:`beartype` does. It works. It necessitates
+modifying three lines of existing code. It preserves backward compatibility. In
+short, it should have been done a decade ago. If the file protocol "isn't very
+well defined," the solution is to define that protocol with a rigorous type
+hierarchy satisfying all possible edge cases. The solution is *not* to pretend
+that no solutions exist, that the existing non-solution suffices, and instead
+do nothing. Welcome to :mod:`typing`, where no one cares that nothing works as
+advertised (or at all)... *and no one ever will.*
+
+.. _typeshed:
+   https://github.com/python/typeshed/issues/3225#issuecomment-529277448
+'''
+
+
+# Conditionally initialized by the _init() function below.
+_Pep544BinaryIO: Any = None  # type: ignore[assignment]
+'''
+Typed version of the return of :func:`open` in binary mode.
+'''
+
+
+# Conditionally initialized by the _init() function below.
+_Pep544TextIO: Any = None  # type: ignore[assignment]
+'''
+Typed version of the return of :func:`open` in text mode.
+'''
+
+# ....................{ INITIALIZERS                       }....................
+def _init() -> None:
+    '''
+    Initialize this submodule.
+    '''
+
+    # ..................{ IMPORTS                            }..................
+    # Defer Python version-specific imports.
+    from beartype._util.api.utilapityping import import_typing_attr_or_none
+    from beartype.typing import (
+        AnyStr,
+        List,
+        Protocol,
+    )
+
+    # ..................{ GLOBALS                            }..................
+    # Global attributes to be redefined below.
+    global \
+        _Pep544BinaryIO, \
+        _Pep544IO, \
+        _Pep544TextIO
+
+    # ..................{ PROTOCOLS ~ protocol               }..................
+    # Note that these classes are intentionally *NOT* declared at global scope;
+    # instead, these classes are declared *ONLY* if the active Python
+    # interpreter targets Python >= 3.8.
+
+    # PEP-compliant type hint matching file handles opened in either text or
+    # binary mode.
+    # @runtime_checkable
+    class _Pep544IO(Protocol[AnyStr]):
+        # The body of this class is copied wholesale from the existing
+        # non-functional "typing.IO" class.
+
+        __slots__: tuple = ()
+
+        @property
+        @abstractmethod
+        def mode(self) -> str:
+            pass
+
+        @property
+        @abstractmethod
+        def name(self) -> str:
+            pass
+
+        @abstractmethod
+        def close(self) -> None:
+            pass
+
+        @property
+        @abstractmethod
+        def closed(self) -> bool:
+            pass
+
+        @abstractmethod
+        def fileno(self) -> int:
+            pass
+
+        @abstractmethod
+        def flush(self) -> None:
+            pass
+
+        @abstractmethod
+        def isatty(self) -> bool:
+            pass
+
+        @abstractmethod
+        def read(self, n: int = -1) -> AnyStr:
+            pass
+
+        @abstractmethod
+        def readable(self) -> bool:
+            pass
+
+        @abstractmethod
+        def readline(self, limit: int = -1) -> AnyStr:
+            pass
+
+        @abstractmethod
+        def readlines(self, hint: int = -1) -> List[AnyStr]:
+            pass
+
+        @abstractmethod
+        def seek(self, offset: int, whence: int = 0) -> int:
+            pass
+
+        @abstractmethod
+        def seekable(self) -> bool:
+            pass
+
+        @abstractmethod
+        def tell(self) -> int:
+            pass
+
+        @abstractmethod
+        def truncate(self, size: Optional[int] = None) -> int:
+            pass
+
+        @abstractmethod
+        def writable(self) -> bool:
+            pass
+
+        @abstractmethod
+        def write(self, s: AnyStr) -> int:
+            pass
+
+        @abstractmethod
+        def writelines(self, lines: List[AnyStr]) -> None:
+            pass
+
+        @abstractmethod
+        def __enter__(self) -> '_Pep544IO[AnyStr]':  # pyright: ignore
+            pass
+
+        @abstractmethod
+        def __exit__(self, cls, value, traceback) -> None:
+            pass
+
+
+    # PEP-compliant type hint matching file handles opened in text rather than
+    # binary mode.
+    #
+    # Note that PEP 544 explicitly requires *ALL* protocols (including
+    # protocols subclassing protocols) to explicitly subclass the "Protocol"
+    # superclass, in violation of both sanity and usability. (Thanks, guys.)
+    # @runtime_checkable
+    class _Pep544TextIO(_Pep544IO[str], Protocol):
+        # The body of this class is copied wholesale from the existing
+        # non-functional "typing.TextIO" class.
+
+        __slots__: tuple = ()
+
+        @property
+        @abstractmethod
+        def buffer(self) -> _Pep544BinaryIO:  # pyright: ignore
+            pass
+
+        @property
+        @abstractmethod
+        def encoding(self) -> str:
+            pass
+
+        @property
+        @abstractmethod
+        def errors(self) -> Optional[str]:
+            pass
+
+        @property
+        @abstractmethod
+        def line_buffering(self) -> bool:
+            pass
+
+        @property
+        @abstractmethod
+        def newlines(self) -> Any:
+            pass
+
+        @abstractmethod
+        def __enter__(self) -> '_Pep544TextIO':  # pyright: ignore
+            pass
+
+    # ..................{ PROTOCOLS ~ validator              }..................
+    # PEP-compliant type hint matching file handles opened in binary rather
+    # than text mode.
+    #
+    # If PEP 593 (e.g., "typing.Annotated") and thus beartype validators are
+    # unusable, this hint falls back to ambiguously matching the abstract
+    # "typing.IO" protocol ABC. This will yield false positives (i.e., fail to
+    # raise exceptions) for @beartype-decorated callables annotated as
+    # accepting binary file handles erroneously passed text file handles, which
+    # is non-ideal but certainly preferable to raising exceptions at decoration
+    # time on each such callable.
+    #
+    # If PEP 593 (e.g., "typing.Annotated") and thus beartype validators are
+    # usable, this hint matches the abstract "typing.IO" protocol ABC but *NOT*
+    # the concrete "typing.TextIO" subprotocol subclassing that ABC. Whereas
+    # the concrete "typing.TextIO" subprotocol unambiguously matches *ONLY*
+    # file handles opened in text mode, the concrete "typing.BinaryIO"
+    # subprotocol ambiguously matches file handles opened in both text *AND*
+    # binary mode. As the following hypothetical "_Pep544BinaryIO" subclass
+    # demonstrates, the "typing.IO" and "typing.BinaryIO" APIs are identical
+    # except for method annotations:
+    #     class _Pep544BinaryIO(_Pep544IO[bytes], Protocol):
+    #         # The body of this class is copied wholesale from the existing
+    #         # non-functional "typing.BinaryIO" class.
+    #
+    #         __slots__: tuple = ()
+    #
+    #         @abstractmethod
+    #         def write(self, s: Union[bytes, bytearray]) -> int:
+    #             pass
+    #
+    #         @abstractmethod
+    #         def __enter__(self) -> '_Pep544BinaryIO':
+    #             pass
+    #
+    # Sadly, the method annotations that differ between these APIs are
+    # insufficient to disambiguate file handles at runtime. Why? Because most
+    # file handles are C-based and thus lack *ANY* annotations whatsoever. With
+    # respect to C-based file handles, these APIs are therefore identical.
+    # Ergo, the "typing.BinaryIO" subprotocol is mostly useless at runtime.
+    #
+    # Note, however, that file handles are necessarily *ALWAYS* opened in
+    # either text or binary mode. This strict dichotomy implies that any file
+    # handle (i.e., object matching the "typing.IO" protocol) *NOT* opened in
+    # text mode (i.e., not matching the "typing.TextIO" protocol) must
+    # necessarily be opened in binary mode instead.
+    _Pep544BinaryIO = _Pep544IO
+
+    #FIXME: Safely replace this with "from typing import Annotated" after
+    #dropping Python 3.8 support.
+    # "typing.Annotated" type hint factory safely imported from whichever of
+    # the "typing" or "typing_extensions" modules declares this attribute if
+    # one or more do *OR* "None" otherwise (i.e., if none do).
+    typing_annotated = import_typing_attr_or_none('Annotated')
+
+    # If this factory is importable.
+    if typing_annotated is not None:
+        # Defer heavyweight imports.
+        from beartype.vale import IsInstance
+
+        # Expand this hint to unambiguously match binary file handles by
+        # subscripting this factory with a beartype validator doing so.
+        _Pep544BinaryIO = typing_annotated[
+            _Pep544IO, ~IsInstance[_Pep544TextIO]]
+    # Else, this factory is unimportable. In this case, accept this hint's
+    # default ambiguously matching both binary and text files.
+
+    # ..................{ MAPPINGS                           }..................
+    # Dictionary mapping from each "typing" IO generic base class to the
+    # associated IO protocol defined above.
+    #
+    # Note this global is intentionally modified in-place rather than
+    # reassigned to a new dictionary. Why? Because the higher-level
+    # reduce_hint_pep484_generic_io_to_pep544_protocol() function calling this
+    # lower-level initializer has already imported this global.
+    _HINT_PEP484_IO_GENERIC_TO_PEP544_PROTOCOL.update({
+        # Unsubscripted mappings.
+        IO:        _Pep544IO,
+        BinaryIO:  _Pep544BinaryIO,
+        TextIO:    _Pep544TextIO,
+
+        # Subscripted mappings, leveraging the useful observation that these
+        # classes all self-cache by design: e.g.,
+        #     >>> import typing
+        #     >>> typing.IO[str] is typing.IO[str]
+        #     True
+        #
+        # Note that we intentionally map:
+        # * "IO[Any]" to the unsubscripted "_Pep544IO" rather than the
+        #   subscripted "_Pep544IO[Any]". Although the two are semantically
+        #   equivalent, the latter is marginally more space- and time-efficient
+        #   to generate code for and thus preferable.
+        # * "IO[bytes]" to the unsubscripted "_Pep544Binary" rather than the
+        #   subscripted "_Pep544IO[bytes]". Why? Because the former applies
+        #   meaningful runtime constraints, whereas the latter does *NOT*.
+        # * "IO[str]" to the unsubscripted "_Pep544Text" rather than the
+        #   subscripted "_Pep544IO[str]" -- for the same reason.
+        #
+        # Note that we intentionally avoid mapping parametrizations of "IO" by
+        # type variables. Since there exist a countably infinite number of
+        # such parametrizations, the parent
+        # reduce_hint_pep484_generic_io_to_pep544_protocol() function calling
+        # this function handles such parametrizations mostly intelligently.
+        IO[Any]:   _Pep544IO,
+        IO[bytes]: _Pep544BinaryIO,
+        IO[str]:   _Pep544TextIO,
+    })
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep557.py
@@ -0,0 +1,113 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`557`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep557Exception
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.hint.pep.sign.datapepsigns import HintSignPep557DataclassInitVar
+
+# ....................{ GETTERS                            }....................
+def get_hint_pep557_initvar_arg(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep557Exception,
+    exception_prefix: str = '',
+) -> object:
+    '''
+    PEP-compliant child type hint subscripting the passed :pep:`557`-compliant
+    **dataclass initialization-only instance variable type hint** (i.e.,
+    subscription of the :class:`dataclasses.InitVar` type hint factory).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintPep557Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    ----------
+    object
+        PEP-compliant child type hint subscripting this parent type hint.
+
+    Raises
+    ----------
+    BeartypeDecorHintPep557Exception
+        If this object is *not* a dataclass initialization-only instance
+        variable type hint.
+    '''
+    
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign_or_none
+
+    # Sign uniquely identifying this hint if this hint is identifiable *OR*
+    # "None" otherwise.
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # If this hint is *NOT* a dataclass initialization-only instance variable
+    # type hint, raise an exception.
+    if hint_sign is not HintSignPep557DataclassInitVar:
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not '
+            f'PEP 557-compliant "dataclasses.TypeVar" instance.'
+        )
+    # Else, this hint is such a hint.
+
+    # Return the child type hint subscripting this parent type hint. Yes, this
+    # hint exposes this child via a non-standard instance variable rather than
+    # the "__args__" dunder tuple standardized by PEP 484.
+    return hint.type  # type: ignore[attr-defined]
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep557_initvar(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`557`-compliant **dataclass initialization-only
+    instance variable type hint** (i.e., subscription of the
+    :class:`dataclasses.InitVar` type hint factory) to the child type hint
+    subscripting this parent hint -- which is otherwise functionally useless
+    from the admittedly narrow perspective of runtime type-checking.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type variable to be reduced.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    ----------
+    object
+        Lower-level type hint currently supported by :mod:`beartype`.
+    '''
+
+    # Reduce this "typing.InitVar[{hint}]" type hint to merely "{hint}".
+    return get_hint_pep557_initvar_arg(
+        hint=hint, exception_prefix=exception_prefix)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep585.py
@@ -0,0 +1,394 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`585`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep585Exception
+from beartype.typing import (
+    Any,
+    Set,
+)
+from beartype._cave._cavefast import HintGenericSubscriptedType
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+from beartype._util.utilobject import Iota
+from beartype._data.hint.datahinttyping import TupleTypes
+
+# ....................{ HINTS                              }....................
+HINT_PEP585_TUPLE_EMPTY = (
+    tuple[()] if IS_PYTHON_AT_LEAST_3_9 else Iota())  # type: ignore[misc]
+'''
+:pep:`585`-compliant empty fixed-length tuple type hint if the active Python
+interpreter supports at least Python 3.9 and thus :pep:`585` *or* a unique
+placeholder object otherwise to guarantee failure when comparing arbitrary
+objects against this object via equality tests.
+'''
+
+# ....................{ RAISERS                            }....................
+def die_unless_hint_pep585_generic(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep585Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a :pep:`585`-compliant
+    **generic** (i.e., class superficially subclassing at least one subscripted
+    :pep:`585`-compliant pseudo-superclass).
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is *not* a :pep:`585`-compliant generic.
+    '''
+
+    # If this object is *NOT* a PEP 585-compliant generic, raise an exception.
+    if not is_hint_pep585_generic(hint):
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not PEP 585 generic.')
+    # Else, this object is a PEP 585-compliant generic.
+
+# ....................{ TESTERS                            }....................
+# If the active Python interpreter targets at least Python >= 3.9 and thus
+# supports PEP 585, correctly declare this function.
+if IS_PYTHON_AT_LEAST_3_9:
+    def is_hint_pep585_builtin_subscripted(hint: object) -> bool:
+
+        # Avoid circular import dependencies.
+        from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+            is_hint_pep484585_generic)
+
+        # Return true only if this hint...
+        return (
+            # Is either a PEP 484- or -585-compliant subscripted generic or
+            # PEP 585-compliant builtin *AND*...
+            isinstance(hint, HintGenericSubscriptedType) and
+            # Is *NOT* a PEP 484- or -585-compliant subscripted generic.
+            not is_hint_pep484585_generic(hint)
+        )
+
+
+    @callable_cached
+    def is_hint_pep585_generic(hint: object) -> bool:  # pyright: ignore[reportGeneralTypeIssues]
+
+        # Avoid circular import dependencies.
+        from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+            get_hint_pep484585_generic_type_or_none)
+
+        # If this hint is *NOT* a type, reduce this hint to the object
+        # originating this hint if any. See the comparable
+        # is_hint_pep484_generic() tester for further details.
+        hint = get_hint_pep484585_generic_type_or_none(hint)
+
+        # Tuple of all pseudo-superclasses originally subclassed by the passed
+        # hint if this hint is a generic *OR* false otherwise.
+        hint_bases_erased = getattr(hint, '__orig_bases__', False)
+
+        # If this hint subclasses *NO* pseudo-superclasses, this hint *CANNOT*
+        # be a generic. In this case, immediately return false.
+        if not hint_bases_erased:
+            return False
+        # Else, this hint subclasses one or more pseudo-superclasses.
+
+        # For each such pseudo-superclass...
+        #
+        # Unsurprisingly, PEP 585-compliant generics have absolutely *NO*
+        # commonality with PEP 484-compliant generics. While the latter are
+        # trivially detectable as subclassing "typing.Generic" after type
+        # erasure, the former are *NOT*. The only means of deterministically
+        # deciding whether or not a hint is a PEP 585-compliant generic is if:
+        # * That class defines both the __class_getitem__() dunder method *AND*
+        #   the "__orig_bases__" instance variable. Note that this condition in
+        #   and of itself is insufficient to decide PEP 585-compliance as a
+        #   generic. Why? Because these dunder attributes have been standardized
+        #   under various PEPs and may thus be implemented by *ANY* arbitrary
+        #   classes.
+        # * The "__orig_bases__" instance variable is a non-empty tuple.
+        # * One or more objects listed in that tuple are PEP 585-compliant
+        #   C-based subscripted generics (e.g., "list[str]").
+        #
+        # Note we could technically also test that this hint defines the
+        # __class_getitem__() dunder method. Since this condition suffices to
+        # ensure that this hint is a PEP 585-compliant generic, however, there
+        # exists little benefit to doing so.
+        for hint_base_erased in hint_bases_erased:  # type: ignore[union-attr]
+            # If this pseudo-superclass is itself a PEP 585-compliant C-based
+            # subscripted generic (e.g., "list[str]"), return true.
+            if is_hint_pep585_builtin_subscripted(hint_base_erased):
+                return True
+            # Else, this pseudo-superclass is *NOT* PEP 585-compliant. In this
+            # case, continue to the next pseudo-superclass.
+
+        # Since *NO* such pseudo-superclasses are PEP 585-compliant, this hint
+        # is *NOT* a PEP 585-compliant generic. In this case, return false.
+        return False
+
+# Else, the active Python interpreter targets at most Python < 3.9 and thus
+# fails to support PEP 585. In this case, fallback to declaring this function
+# to unconditionally return False.
+else:
+    def is_hint_pep585_builtin_subscripted(hint: object) -> bool:
+        return False
+
+    def is_hint_pep585_generic(hint: object) -> bool:
+        return False
+
+# ....................{ TESTERS ~ doc                      }....................
+# Docstring for this function regardless of implementation details.
+is_hint_pep585_builtin_subscripted.__doc__ = '''
+    :data:`True` only if the passed object is a :pep:`585`-compliant
+    **subscripted builtin type hint** (i.e., C-based type hint instantiated by
+    subscripting either a concrete builtin container class like :class:`list` or
+    :class:`tuple` *or* an abstract base class (ABC) declared by the
+    :mod:`collections.abc` submodule like :class:`collections.abc.Iterable` or
+    :class:`collections.abc.Sequence`).
+
+    This tester additionally returns :data:`True` for third-party type hints
+    whose types subclass the :class:`types.GenericAlias` superclass, including:
+
+    * ``numpy.typing.NDArray[...]`` type hints.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This tester returns** :data:`False` for :pep:`585`-compliant generics,
+    which fail to satisfy the same API as all other :pep:`585`-compliant type
+    hints. Why? Because :pep:`560`-type erasure erases the low-level superclass
+    detected by this tester on :pep:`585`-compliant generics immediately after
+    those generics are declared, preventing their subsequent detection as
+    :pep:`585`-compliant. Instead, :pep:`585`-compliant generics are only
+    detectable by calling either:
+
+    * The high-level PEP-agnostic
+      :func:`beartype._util.hint.pep.utilpeptest.is_hint_pep484585_generic`
+      tester.
+    * The low-level :pep:`585`-specific :func:`.is_hint_pep585_generic` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :pep:`585`-compliant type hint.
+    '''
+
+
+is_hint_pep585_generic.__doc__ = '''
+    :data:`True` only if the passed object is a :pep:`585`-compliant **generic**
+    (i.e., object that may *not* actually be a class originally subclassing at
+    least one subscripted :pep:`585`-compliant pseudo-superclass).
+
+    This tester is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :pep:`585`-compliant generic.
+    '''
+
+# ....................{ GETTERS                            }....................
+def get_hint_pep585_generic_bases_unerased(
+    # Mandatory parameters.
+    hint: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep585Exception,
+    exception_prefix: str = '',
+) -> tuple:
+    '''
+    Tuple of all unerased :pep:`585`-compliant **pseudo-superclasses** (i.e.,
+    :mod:`typing` objects originally listed as superclasses prior to their
+    implicit type erasure under :pep:`560`) of the passed :pep:`585`-compliant
+    **generic** (i.e., class subclassing at least one non-class
+    :pep:`585`-compliant object).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep585Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Tuple[object]
+        Tuple of the one or more unerased pseudo-superclasses of this
+        :pep:`585`-compliant generic.
+
+    Raises
+    ------
+    exception_cls
+        If this hint is *not* a :pep:`585`-compliant generic.
+
+    See Also
+    --------
+    :func:`beartype._util.hint.pep.proposal.pep484585.utilpep484585generic.get_hint_pep484585_generic_bases_unerased`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+        get_hint_pep484585_generic_type_or_none)
+
+    # If this hint is *NOT* a class, reduce this hint to the object originating
+    # this hint if any. See the is_hint_pep484_generic() tester for details.
+    hint = get_hint_pep484585_generic_type_or_none(hint)
+
+    # If this hint is *NOT* a PEP 585-compliant generic, raise an exception.
+    die_unless_hint_pep585_generic(
+        hint=hint,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # Return the tuple of all unerased pseudo-superclasses of this generic.
+    # While the "__orig_bases__" dunder instance variable is *NOT* guaranteed
+    # to exist for PEP 484-compliant generic types, this variable is guaranteed
+    # to exist for PEP 585-compliant generic types. Thanks for small favours.
+    return hint.__orig_bases__
+
+
+@callable_cached
+def get_hint_pep585_generic_typevars(hint: object) -> TupleTypes:
+    '''
+    Tuple of all **unique type variables** (i.e., subscripted :class:`TypeVar`
+    instances of the passed :pep:`585`-compliant generic listed by the caller
+    at hint declaration time ignoring duplicates) if any *or* the empty tuple
+    otherwise.
+
+    This getter is memoized for efficiency.
+
+    Motivation
+    ----------
+    The current implementation of :pep:`585` under at least Python 3.9 is
+    fundamentally broken with respect to parametrized generics. While `PEP
+    484`_-compliant generics properly propagate type variables from
+    pseudo-superclasses to subclasses, :pep:`585` fails to do so. This function
+    "fills in the gaps" by recovering these type variables from parametrized
+    :pep:`585`-compliant generics by iteratively constructing a new tuple from
+    the type variables parametrizing all pseudo-superclasses of this generic.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Tuple[TypeVar, ...]
+        Either:
+
+        * If this :pep:`585`-compliant generic defines a ``__parameters__``
+          dunder attribute, the value of that attribute.
+        * Else, the empty tuple.
+
+    Raises
+    ------
+    BeartypeDecorHintPep585Exception
+        If this hint is *not* a :pep:`585`-compliant generic.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_typevars
+
+    # Tuple of all pseudo-superclasses of this PEP 585-compliant generic.
+    hint_bases = get_hint_pep585_generic_bases_unerased(hint)
+
+    # Set of all type variables parametrizing these pseudo-superclasses.
+    #
+    # Note the following inefficient iteration *CANNOT* be reduced to an
+    # efficient set comprehension, as each get_hint_pep_typevars() call returns
+    # a tuple of type variables rather than single type variable to be added to
+    # this set.
+    hint_typevars: Set[type] = set()
+
+    # For each such pseudo-superclass, add all type variables parametrizing
+    # this pseudo-superclass to this set.
+    for hint_base in hint_bases:
+        # print(f'hint_base_typevars: {hint_base} [{get_hint_pep_typevars(hint_base)}]')
+        hint_typevars.update(get_hint_pep_typevars(hint_base))
+
+    # Return this set coerced into a tuple.
+    return tuple(hint_typevars)
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Unit test us up, please.
+def reduce_hint_pep585_builtin_subscripted_unknown(
+    hint: object, *args, **kwargs) -> type:
+    '''
+    Reduce the passed :pep:`585`-compliant **unrecognized subscripted builtin
+    type hints** (i.e., C-based type hints that are *not* isinstanceable types,
+    instantiated by subscripting pure-Python origin classes subclassing the
+    C-based :class:`types.GenericAlias` superclass such that those classes are
+    unrecognized by :mod:`beartype` and thus *not* type-checkable as is) to
+    their unsubscripted origin classes (which are almost always pure-Python
+    isinstanceable types and thus type-checkable as is).
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be reduced.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    type
+        Unsubscripted origin class originating this unrecognized subscripted
+        builtin type hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_origin_type
+
+    # Pure-Python origin class originating this unrecognized subscripted builtin
+    # type hint if this hint originates from such a class *OR* raise an
+    # exception otherwise (i.e., if this hint originates from *NO* such class).
+    origin_type = get_hint_pep_origin_type(hint)
+
+    # Return this origin.
+    return origin_type
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep586.py
@@ -0,0 +1,204 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`586`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep586Exception
+from beartype.typing import Any
+from beartype._data.cls.datacls import TYPES_PEP586_ARG
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.hint.pep.sign.datapepsigns import HintSignLiteral
+from beartype._util.text.utiltextjoin import join_delimited_disjunction_types
+
+# ....................{ VALIDATORS                         }....................
+def die_unless_hint_pep586(
+    # Mandatory parameters.
+    hint: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep586Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is a
+    :pep:`586`-compliant type hint (i.e., subscription of either the
+    :attr:`typing.Literal` or :attr:`typing_extensions.Literal` type hint
+    factories).
+
+    Ideally, the :attr:`typing.Literal` singleton would internally validate the
+    literal objects subscripting that singleton at subscription time (i.e., in
+    the body of the ``__class_getitem__()`` dunder method). Whereas *all* other
+    :mod:`typing` attributes do just that, :attr:`typing.Literal` permissively
+    accepts all possible arguments like a post-modern philosopher hopped up on
+    too much tenure. For inexplicable reasons, :pep:`586` explicitly requires
+    third-party type checkers (that's us) to validate these hints rather than
+    standardizing that validation in the :mod:`typing` module. Weep, Guido!
+
+    Caveats
+    -------
+    **This function is slow** and should thus be called only once per
+    visitation of a :pep:`586`-compliant type hint. Specifically, this function
+    is O(n) for n the number of arguments subscripting this hint.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep586Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object either:
+
+        * Is *not* a subscription of either the :attr:`typing.Literal` or
+          :attr:`typing_extensions.Literal` type hint factories.
+        * Subscripts either factory with zero arguments via the empty tuple,
+          which these factories sadly fails to guard against.
+        * Subscripts either factory with one or more arguments that are *not*
+          **valid literals**, defined as the set of all:
+
+          * Booleans.
+          * Byte strings.
+          * Integers.
+          * Unicode strings.
+          * :class:`enum.Enum` members.
+          * The :data:`None` singleton.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_args,
+        get_hint_pep_sign,
+    )
+
+    # If this hint is *NOT* PEP 586-compliant, raise an exception.
+    if get_hint_pep_sign(hint) is not HintSignLiteral:
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not PEP 586-compliant '
+            f'(e.g., "typing.Literal[...]", "typing_extensions.Literal[...]").'
+        )
+    # Else, this hint is PEP 586-compliant.
+
+    # Tuple of zero or more literal objects subscripting this hint.
+    hint_literals = get_hint_pep_args(hint)
+
+    # If this hint is unsubscripted...
+    if not hint_literals:
+        # Exception message to be raised.
+        exception_message = f'{exception_prefix}PEP 586 type hint {repr(hint)} '
+
+        # If this hint defines the standard "__args__" dunder attribute, this
+        # hint *MUST* have been subscripted by the the empty tuple. Ideally, the
+        # "typing.Literal" factory would guard against this itself. It does not;
+        # thus, we do. Construct an appropriate message.
+        if hasattr(hint_literals, '__args__'):
+            exception_message += (
+                'subscripted by empty tuple, '
+                'which is not a valid literal object.'
+            )
+        # Else, this hint fails to define the standard "__args__" dunder
+        # attribute. In this case, this hint *MUST* be the unsubscripted
+        # "typing.Literal" factory -- which conveys *NO* meaningful semantics
+        # and is thus invalid as a type hint. Construct an appropriate message.
+        else:
+            exception_message += (
+                'unsubscripted (i.e., subscripted by no literal objects).')
+
+        # Raise this exception.
+        raise exception_cls(exception_message)
+    # If this hint is subscripted by one or more literal objects.
+
+    # For each argument subscripting this hint...
+    #
+    # Sadly, despite PEP 586 imposing strict restrictions on the types of
+    # objects permissible as arguments subscripting the "typing.Literal"
+    # singleton, PEP 586 explicitly offloads the odious chore of enforcing those
+    # restrictions onto third-party type checkers by intentionally implementing
+    # that singleton to permissively accept *ALL* possible objects when
+    # subscripted:
+    #     Although the set of parameters Literal[...] may contain at type check
+    #     time is very small, the actual implementation of typing.Literal will
+    #     not perform any checks at runtime.
+    for hint_literal_index, hint_literal in enumerate(hint_literals):
+        # If this argument is invalid as a literal argument...
+        if not isinstance(hint_literal, TYPES_PEP586_ARG):
+            # Human-readable concatenation of the types of all valid literal
+            # arguments, delimited by commas and/or "or".
+            hint_literal_types = join_delimited_disjunction_types(
+                TYPES_PEP586_ARG)
+
+            # Raise an exception.
+            raise exception_cls(
+                f'{exception_prefix}PEP 586 type hint {repr(hint)} '
+                f'argument {hint_literal_index} '
+                f'{repr(hint_literal)} not {hint_literal_types}.'
+            )
+        # Else, this argument is valid as a literal argument.
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep586_literals(
+    # Mandatory parameters.
+    hint: Any,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep586Exception,
+    exception_prefix: str = '',
+) -> tuple:
+    '''
+    Tuple of zero or more literal objects subscripting the passed
+    :pep:`586`-compliant type hint (i.e., subscription of either the
+    :attr:`typing.Literal` or :attr:`typing_extensions.Literal` type hint
+    factories).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This low-level getter performs no validation of the contents of this
+    tuple.** Consider calling the high-level :func:`die_unless_hint_pep586`
+    validator to do so before leveraging this tuple elsewhere.
+
+    Parameters
+    ----------
+    hint : object
+        :pep:`586`-compliant type hint to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep586Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    tuple
+        Tuple of zero or more literal objects subscripting this hint.
+
+    Raises
+    ------
+    exception_cls
+        If this object is *not* a :pep:`586`-compliant type hint.
+    '''
+
+    # If this hint is *NOT* PEP 586-compliant, raise an exception.
+    die_unless_hint_pep586(hint=hint, exception_prefix=exception_prefix)
+    # Else, this hint is PEP 586-compliant.
+
+    # Return the standard tuple of all literals subscripting this hint.
+    return hint.__args__
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep589.py
@@ -0,0 +1,178 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`589`-compliant **typed dictionary** (i.e.,
+:class:`typing.TypedDict` subclass) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.datahinttyping import MappingStrToAny
+from beartype._util.cls.utilclstest import is_type_subclass
+from beartype._util.py.utilpyversion import IS_PYTHON_3_8
+
+# ....................{ TESTERS                            }....................
+# The implementation of the "typing.TypedDict" attribute substantially varies
+# across Python interpreter *AND* "typing" implementation. Specifically:
+# * The "typing.TypedDict" attribute under Python >= 3.9 is *NOT* actually a
+#   superclass but instead a factory function masquerading as a superclass by
+#   setting the subversive "__mro_entries__" dunder attribute to a tuple
+#   containing a private "typing._TypedDict" superclass. This superclass
+#   necessarily defines the three requisite dunder attributes.
+# * The "typing_extensions.TypedDict" attribute under Python < 3.8 is actually a
+#   superclass also necessarily defining the three requisite dunder attributes.
+# * The "typing.TypedDict" attribute under *ONLY* Python 3.8 is also actually a
+#   superclass that *ONLY* defines the requisite "__annotations__" dunder
+#   attribute. The two remaining dunder attributes are only conditionally
+#   defined and thus *CANNOT* be unconditionally assumed to exist.
+#
+# In all three cases, passing the passed hint and that superclass to the
+# issubclass() builtin fails, as the metaclass of that superclass prohibits
+# issubclass() checks. I am throwing up in my mouth as I write this.
+#
+# Unfortunately, all of the above complications are further complicated by the
+# "dict" type under Python >= 3.10. For unknown reasons, Python >= 3.10 adds
+# spurious "__annotations__" dunder attributes to "dict" subclasses -- even if
+# those subclasses annotate *NO* class or instance variables. While a likely
+# bug, we have little choice but to at least temporarily support this insanity.
+def is_hint_pep589(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a :pep:`589`-compliant **typed
+    dictionary** (i.e., :class:`typing.TypedDict` subclass).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator). Although the implementation inefficiently
+    performs three calls to the :func:`hasattr` builtin (which inefficiently
+    calls the :func:`getattr` builtin and catches the :exc:`AttributeError`
+    exception to detect false cases), callers are expected to instead (in
+    order):
+
+    #. Call the memoized
+       :func:`beartype._util.hint.pep.utilpepget.get_hint_pep_sign_or_none`
+       getter, which internally calls this unmemoized tester.
+    #. Compare the object returned by that getter against the
+       :attr:`beartype._util.data.hint.pep.sign.datapepsigns.HintSignTypedDict`
+       sign.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be tested.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a typed dictionary.
+    '''
+
+    # If this hint is *NOT* a "dict" subclass, this hint *CANNOT* be a typed
+    # dictionary. By definition, typed dictionaries are "dict" subclasses.
+    #
+    # Note that PEP 589 actually lies about the type of typed dictionaries:
+    #     Methods are not allowed, since the runtime type of a TypedDict object
+    #     will always be just dict (it is never a subclass of dict).
+    #
+    # This is *ABSOLUTELY* untrue. PEP 589 authors plainly forgot to implement
+    # this constraint. Contrary to the above:
+    # * All typed dictionaries are subclasses of "dict".
+    # * The type of typed dictionaries is the private "typing._TypedDictMeta"
+    #   metaclass across all Python versions (as of this comment).
+    #
+    # This is where we generously and repeatedly facepalm ourselves.
+    if not is_type_subclass(hint, dict):
+        return False
+    # Else, this hint is a "dict" subclass and thus *MIGHT* be a typed
+    # dictionary.
+
+    # Return true *ONLY* if this "dict" subclass defines all three dunder
+    # attributes guaranteed to be defined by all typed dictionaries. Although
+    # slow, this is still faster than the MRO-based approach delineated above.
+    #
+    # Note that *ONLY* the Python 3.8-specific implementation of
+    # "typing.TypedDict" fails to unconditionally define the
+    # "__required_keys__" and "__optional_keys__" dunder attributes. Ergo, if
+    # the active Python interpreter targets exactly Python 3.8, we relax this
+    # test to *ONLY* test for the "__annotations__" dunder attribute.
+    # Specifically, we return true only if...
+    #
+    # Technically, this test can also be performed by inefficiently violating
+    # privacy encapsulation. Specifically, this test could perform an O(k) walk
+    # up the class inheritance tree of the passed class (for k the number of
+    # superclasses of that class), iteratively comparing each such superclass
+    # for against the "typing.TypeDict" superclass. That is, this tester could
+    # crazily reimplement the issubclass() builtin in pure-Python. Since the
+    # implementation of typed dictionaries varies substantially across Python
+    # versions, doing so would require version-specific tests in addition to
+    # unsafely violating privacy encapsulation and inefficiently violating
+    # constant-time guarantees.
+    #
+    # Technically, the current implementation of this test is susceptible to
+    # false positives in unlikely edge cases. Specifically, this test queries
+    # for dunder attributes and thus erroneously returns true for user-defined
+    # "dict" subclasses *NOT* subclassing the "typing.TypedDict" superclass but
+    # nonetheless declaring the same dunder attributes declared by that
+    # superclass. Since the likelihood of any user-defined "dict" subclass
+    # accidentally defining these attributes is vanishingly small *AND* since
+    # "typing.TypedDict" usage is largely discouraged in the typing community,
+    # this error is unlikely to meaningfully arise in real-world use cases.
+    # Ergo, it is preferable to implement this test portably, safely, and
+    # efficiently rather than accommodate this error.
+    #
+    # In short, the current approach of is strongly preferable.
+    return (
+        # This "dict" subclass defines these "TypedDict" attributes *AND*...
+        hasattr(hint, '__annotations__') and
+        hasattr(hint, '__total__') and
+        # Either...
+        (
+            # The active Python interpreter targets exactly Python 3.8 and
+            # thus fails to unconditionally define the remaining attributes
+            # *OR*...
+            IS_PYTHON_3_8 or
+            # The active Python interpreter targets any other Python version
+            # and thus unconditionally defines the remaining attributes.
+            (
+                hasattr(hint, '__required_keys__') and
+                hasattr(hint, '__optional_keys__')
+            )
+        )
+    )
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Remove *AFTER* deeply type-checking typed dictionaries. For now,
+#shallowly type-checking such hints by reduction to untyped dictionaries
+#remains the sanest temporary work-around.
+def reduce_hint_pep589(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`589`-compliant **typed dictionary** (i.e.,
+    :class:`typing.TypedDict` subclass) to a lower-level type hint currently
+    supported by :mod:`beartype`.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as reducers cannot be memoized.
+
+    Parameters
+    ----------
+    hint : object
+        Typed dictionary to be reduced.
+    exception_prefix : str, optional
+        Substring prefixing exception messages raised by this reducer.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        Lower-level type hint currently supported by :mod:`beartype`.
+    '''
+
+    # Silently ignore all child type hints annotating this dictionary by
+    # reducing this hint to a "Mapping" type hint. Yes, "Mapping" rather than
+    # "dict". By PEP 589 edict:
+    #     First, any TypedDict type is consistent with Mapping[str, object].
+    return MappingStrToAny
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep591.py
@@ -0,0 +1,101 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`591`-compliant **type hint** (i.e., objects created by
+subscripting the :obj:`typing.Final` type hint factory) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep591Exception
+# from beartype._util.py.utilpyversion import IS_PYTHON_3_8
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Remove *AFTER* deeply type-checking "Final[...]" type hints. For now,
+#shallowly type-checking such hints by reduction to their subscripted arguments
+#remains the sanest temporary work-around.
+def reduce_hint_pep591(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`591`-compliant **final type hint** (i.e.,
+    subscription of the :obj:`typing.Final` type hint factory) to a lower-level
+    type hint currently supported by :mod:`beartype`.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Final type hint to be reduced.
+    exception_prefix : str, optional
+        Human-readable substring prefixing exception messages raised by this
+        function.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    ----------
+    object
+        Lower-level type hint currently supported by :mod:`beartype`.
+
+    Raises
+    ----------
+    BeartypeDecorHintPep591Exception
+        If this hint is subscripted by two or more child type hints.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+
+    # Tuple of zero or more child type hints subscripting this type hint.
+    hint_args = get_hint_pep_args(hint)
+
+    # Number of child type hints subscripting this type hint.
+    hint_args_len = len(hint_args)
+
+    # If this hint is unsubscripted, reduce this hint to the ignorable type hint
+    # "object".
+    #
+    # Note that PEP 591 bizarrely permits the "typing.Final" type hint factory
+    # to remain unsubscripted:
+    #     * With no type annotation. Example:
+    #           ID: Final = 1
+    #       The typechecker should apply its usual type inference mechanisms to
+    #       determine the type of ID (here, likely, int). Note that unlike for
+    #       generic classes this is not the same as Final[Any].
+    #
+    # Since runtime type-checkers *NEVER* infer types, this permissiveness
+    # substantially reduces the usability of this edge case at runtime.
+    # Nevertheless, this is a valid edge case. Technically, we could emit a
+    # non-fatal warning to recommend the user explicitly type each unsubscripted
+    # "typing.Final" type hint. Pragmatically, doing so would only harass large
+    # codebases attempting to migrate to @beartype. Doing nothing is preferable.
+    if hint_args_len == 0:
+        hint = object
+    # If, this hint is subscripted by exactly one child type hint, reduce this
+    # hint to that child hint.
+    elif hint_args_len == 1:
+        hint = hint_args[0]
+    # Else, this hint is subscripted by two or more child type hints. In this
+    # case, raise an exception.
+    #
+    # Note that "typing.Final" already prohibits subscription by two or more
+    # arguments. Ergo, this should *NEVER* happen: e.g.,
+    #     >>> import typing
+    #     >>> typing.Final[int, float]
+    #     TypeError: typing.Final accepts only single type. Got (<class 'int'>,
+    #     <class 'float'>).
+    else:
+        raise BeartypeDecorHintPep591Exception(
+            f'{exception_prefix}PEP 591 type hint {repr(hint)} '
+            f'erroneously subscripted by {hint_args_len} child type hints.'
+        )
+
+    # Return this reduced hint.
+    return hint
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep593.py
@@ -0,0 +1,334 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`593`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep593Exception
+from beartype.typing import (
+    Any,
+    Optional,
+    Tuple,
+)
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.hint.pep.sign.datapepsigns import HintSignAnnotated
+from beartype._data.hint.datahinttyping import TypeException
+
+# ....................{ RAISERS                            }....................
+#FIXME: Pass "exception_prefix" to all calls of this validator.
+def die_unless_hint_pep593(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPep593Exception,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type unless the passed object is a
+    :pep:`593`-compliant **type metahint** (i.e., subscription of either the
+    :attr:`typing.Annotated` or :attr:`typing_extensions.Annotated` type hint
+    factories).
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+    exception_cls : TypeException
+        Type of exception to be raised. Defaults to
+        :exc:`BeartypeDecorHintPep593Exception`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPep593Exception
+        If this object is *not* a :pep:`593`-compliant type metahint.
+    '''
+
+    # If this hint is *NOT* PEP 593-compliant, raise an exception.
+    if not is_hint_pep593(hint):
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not PEP 593-compliant '
+            f'(e.g., "typing.Annotated[...]", '
+            f'"typing_extensions.Annotated[...]").'
+        )
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up.
+def is_hint_pep593(hint: Any) -> bool:
+    '''
+    :data:`True` only if the passed object is a :pep:`593`-compliant **type
+    metahint** (i.e., subscription of either the :attr:`typing.Annotated` or
+    :attr:`typing_extensions.Annotated` type hint factories).
+
+    Parameters
+    ----------
+    hint : Any
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :pep:`593`-compliant type
+        metahint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign_or_none
+
+    # Return true only if this hint is PEP 593-compliant.
+    return get_hint_pep_sign_or_none(hint) is HintSignAnnotated
+
+
+def is_hint_pep593_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed :pep:`593`-compliant type hint is ignorable.
+
+    Specifically, this tester returns :data:`True` only if either:
+
+    * The first subscripted argument of this hint is an ignorable type hint
+      (e.g., :obj:`typing.Any`).
+    * The second subscripted argument is *not* a beartype validator (e.g.,
+      ``typing.Annotated[typing.Any, bool]``).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`593`-compliant type hint is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhinttest import is_hint_ignorable
+    # print(f'!!!!!!!Received 593 hint: {repr(hint)} [{repr(hint_sign)}]')
+
+    # Return true only if...
+    return (
+        # The first argument subscripting this annotated type hint is ignorable
+        # (e.g., the "Any" in "Annotated[Any, 50, False]") *AND*...
+        is_hint_ignorable(get_hint_pep593_metahint(hint)) and
+        # The second argument subscripting this annotated type hint is *NOT* a
+        # beartype validator and thus also ignorable (e.g., the "50" in
+        # "Annotated[Any, 50, False]").
+        not is_hint_pep593_beartype(hint)
+    )
+
+# ....................{ TESTERS ~ beartype                 }....................
+def is_hint_pep593_beartype(hint: Any) -> bool:
+    '''
+    :data:`True` only if the second argument subscripting the passed
+    :pep:`593`-compliant :attr:`typing.Annotated` type hint is
+    :mod:`beartype`-specific (e.g., instance of the :class:`BeartypeValidator`
+    class produced by subscripting (indexing) the :class:`Is` class).
+
+    Parameters
+    ----------
+    hint : Any
+        :pep:`593`-compliant type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if the first argument subscripting this hint is
+        :mod:`beartype`-specific.
+
+    Raises
+    ------
+    BeartypeDecorHintPep593Exception
+        If this object is *not* a :pep:`593`-compliant type metahint.
+    '''
+
+    # Defer heavyweight imports.
+    from beartype.vale._core._valecore import BeartypeValidator
+
+    # If this object is *NOT* a PEP 593-compliant type metahint, raise an
+    # exception.
+    die_unless_hint_pep593(hint)
+    # Else, this object is a PEP 593-compliant type metahint.
+
+    # Attempt to...
+    try:
+        # Tuple of one or more arbitrary objects annotating this metahint.
+        hint_metadata = get_hint_pep593_metadata(hint)
+
+        # Return true only if the first such object is a beartype validator.
+        # Note this object is guaranteed to exist by PEP 593 design.
+        # print(f'Checking first PEP 593 type hint {repr(hint)} arg {repr(hint_metadata[0])}...')
+        return isinstance(hint_metadata[0], BeartypeValidator)
+    # If the metaclass of the first argument subscripting this hint overrides
+    # the __isinstancecheck__() dunder method to raise an exception, silently
+    # ignore this exception by returning false instead.
+    except:
+        return False
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep593_metadata(
+    hint: Any, exception_prefix: str = '') -> Tuple[Any, ...]:
+    '''
+    Tuple of one or more arbitrary objects annotating the passed
+    :pep:`593`-compliant **type metahint** (i.e., subscription of the
+    :attr:`typing.Annotated` singleton).
+
+    Specifically, this getter returns *all* arguments subscripting this
+    metahint excluding the first, which conveys its own semantics and is thus
+    returned by the :func:`get_hint_pep593_metahint` getter.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        `PEP 593`-compliant type metahint to be inspected.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    type
+        Tuple of one or more arbitrary objects annotating this metahint.
+
+    Raises
+    ------
+    BeartypeDecorHintPep593Exception
+        If this object is *not* a :pep:`593`-compliant type metahint.
+
+    See Also
+    --------
+    :func:`get_hint_pep593_metahint`
+        Related getter.
+    '''
+
+    # If this object is *NOT* a metahint, raise an exception.
+    die_unless_hint_pep593(hint=hint, exception_prefix=exception_prefix)
+    # Else, this object is a metahint.
+
+    # Return the tuple of one or more objects annotating this metahint. By
+    # design, this tuple is guaranteed to be non-empty: e.g.,
+    #     >>> from typing import Annotated
+    #     >>> Annotated[int]
+    #     TypeError: Annotated[...] should be used with at least two
+    #     arguments (a type and an annotation).
+    return hint.__metadata__
+
+
+#FIXME: Unit test us up, please.
+def get_hint_pep593_metahint(hint: Any, exception_prefix: str = '') -> Any:
+    '''
+    PEP-compliant type hint annotated by the passed :pep:`593`-compliant **type
+    metahint** (i.e., subscription of the :attr:`typing.Annotated` singleton).
+
+    Specifically, this getter returns the first argument subscripting this
+    metahint. By design, this argument is guaranteed to be a PEP-compliant type
+    hint. Note that although that hint *may* be a standard class, this is *not*
+    necessarily the case.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        :pep:`593`-compliant type metahint to be inspected.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Any
+        PEP-compliant type hint annotated by this metahint.
+
+    Raises
+    ----------
+    BeartypeDecorHintPep593Exception
+        If this object is *not* a :pep:`593`-compliant type metahint.
+
+    See Also
+    ----------
+    :func:`get_hint_pep593_metadata`
+        Related getter.
+    '''
+
+    # If this object is *NOT* a metahint, raise an exception.
+    die_unless_hint_pep593(hint=hint, exception_prefix=exception_prefix)
+    # Else, this object is a metahint.
+
+    # Return the PEP-compliant type hint annotated by this metahint.
+    #
+    # Note that most edge-case PEP-compliant type hints store their data in
+    # hint-specific dunder attributes (e.g., "__supertype__" for new type
+    # aliases, "__forward_arg__" for forward references). Some, however,
+    # coopt and misuse standard dunder attributes commonly used for
+    # entirely different purposes. PEP 593-compliant type metahints are the
+    # latter sort, preferring to store their class in the standard
+    # "__origin__" attribute commonly used to store the origin type of type
+    # hints originating from a standard class rather than in a
+    # metahint-specific dunder attribute.
+    return hint.__origin__
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep593(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`593`-compliant **type metahint** (i.e., subscription
+    of either the :attr:`typing.Annotated` or
+    :attr:`typing_extensions.Annotated` type hint factories) to a lower-level
+    type hint if this metahint contains *no* **beartype validators** (i.e.,
+    subscriptions of :mod:`beartype.vale` factories) and is thus ignorable.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be reduced.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        Lower-level type hint currently supported by :mod:`beartype`.
+    '''
+    # print(f'Reducing non-beartype PEP 593 type hint {repr(hint)}...')
+
+    # Return either...
+    return (
+        # If this metahint is beartype-specific, preserve this hint as is for
+        # subsequent handling elsewhere;
+        hint
+        if is_hint_pep593_beartype(hint) else
+        # Else, this metahint is beartype-agnostic and thus irrelevant to us. In
+        # this case, ignore all annotations on this hint by reducing this hint
+        # to the lower-level hint it annotates.
+        get_hint_pep593_metahint(hint=hint, exception_prefix=exception_prefix)
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep604.py
@@ -0,0 +1,207 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`604`-compliant type hint utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_10
+
+# ....................{ VERSIONS                           }....................
+# If the active Python interpreter targets Python >= 3.10 and thus supports PEP
+# 604, define testers requiring this level of support...
+if IS_PYTHON_AT_LEAST_3_10:
+    # ....................{ IMPORTS                        }....................
+    # Defer version-specific imports.
+    from beartype.roar import BeartypeDecorHintPep604Exception
+    from beartype._cave._cavefast import (
+        HintPep604Type,
+        HintPep604Types,
+    )
+
+    # ....................{ RAISERS                        }....................
+    #FIXME: Unit test us up, please.
+    def die_if_hint_pep604_inconsistent(hint: object) -> None:
+
+        # Avoid circular import dependencies.
+        from beartype._util.hint.utilhintget import get_hint_repr
+
+        # If this hint is invalid as an item of a PEP 604-compliant new union,
+        # silently reduce to a noop.
+        if not isinstance(hint, HintPep604Types):
+            return
+        # Else, this hint is valid as an item of a PEP 604-compliant new union.
+
+        # Machine-readable representation of this hint.
+        hint_repr = get_hint_repr(hint)
+
+        # If this representation is prefixed by the "<" character, this
+        # representation is assumed to be (at least *SOMEWHAT*) standardized and
+        # thus internally consistent. This includes:
+        # * Standard classes (e.g., "<class 'bool'>").
+        # * @beartype-specific forward reference subclasses (e.g., "<forwardref
+        #   UndeclaredClass(__beartype_scope__='some_package')>").
+        #
+        # This is *NOT* simply an optimization. Standardized representations
+        # *MUST* be excluded from consideration, as the representations of new
+        # unions containing these hints is *NOT* prefixed by "<": e.g.,
+        #     >>> repr(bool)
+        #     <class 'bool'>
+        #     >>> bool | None
+        #     bool | None
+        if hint_repr[0] == '<':
+            return
+        # Else, this representation is *NOT* prefixed by the "<" character.
+
+        # Arbitrary PEP 604-compliant new union defined as the conjunction
+        # of this hint with an arbitrary builtin type guaranteed to exist.
+        #
+        # Note that order is significant.
+        hint_pep604 = hint | int  # type: ignore[operator]
+
+        # Machine-readable representation of this new union.
+        hint_pep604_repr = get_hint_repr(hint_pep604)
+
+        # If the representation of this new union is *NOT* prefixed by the
+        # representation of this hint, raise an exception.
+        if not hint_pep604_repr.startswith(hint_repr):
+            raise BeartypeDecorHintPep604Exception(
+                f'Type hint {hint_repr} inconsistent with respect to '
+                f'repr() strings. Since @beartype requires consistency '
+                f'between type hints and repr() strings, this hint is '
+                f'unsupported by @beartype. Consider reporting this issue '
+                f'to the third-party developer implementing this hint: e.g.,\n'
+                f'\t>>> repr({hint_repr})\n'
+                f'\t{hint_repr}  # <-- this is fine\n'
+                f'\t>>> repr({hint_repr} | int)\n'
+                f'\t{hint_pep604_repr}  # <-- *THIS IS REALLY SUPER BAD*\n'
+                f'\n'
+                f'\t# Ideally, that output should instead resemble:\n'
+                f'\t>>> repr({hint_repr} | int)\n'
+                f'\t{hint_repr} | int  # <-- what @beartype wants!'
+            )
+        # Else, the representation of this new union is prefixed by the
+        # representation of this hint as expected.
+
+    # ....................{ TESTERS                        }....................
+    def is_hint_pep604(hint: object) -> bool:
+
+        # Release the werecars, Bender!
+        return isinstance(hint, HintPep604Type)
+# Else, the active Python interpreter targets Python < 3.10 and thus fails to
+# support PEP 604. In this case, define fallback functions.
+#
+# Tonight, we howl at the moon. Tomorrow, the one-liner!
+else:
+    def die_if_hint_pep604_inconsistent(hint: object) -> None:
+        pass
+
+    def is_hint_pep604(hint: object) -> bool:
+        return False
+
+
+die_if_hint_pep604_inconsistent.__doc__ = (
+    '''
+    Raise an exception if the passed object is a :pep:`604`-compliant
+    **inconsistent type hint** (i.e., object permissible as an item of a
+    :pep:`604`-compliant new union whose machine-readable representation is
+    *not* the machine-readable representation of this hint in new unions).
+
+    Motivation
+    ----------
+    This raiser protects the :mod:`beartype` codebase against inconsistencies in
+    poorly implemented third-party type hints whose **machine-readable
+    representations** (i.e., strings returned by passing those hints to the
+    :func:`repr` builtin) differ from their representations in new unions
+    containing those hints.
+
+    Ideally, *no* such inconsistencies would ever exist. For unknown reasons,
+    some third-party type hints induce such inconsistencies. :mod:`nptyping` is
+    the canonical example. Type hint factories published by :mod:`nptyping`
+    dynamically create in-memory classes all sharing the same fully-qualified
+    names despite being distinct classes. Ye who code, grok and weep: e.g.,
+
+    .. code-block:: pycon
+
+       # Define two typical "nptyping" type hints.
+       >>> from nptyping import Float64, NDArray, Shape
+       >>> foo = NDArray[Shape["N, N"], Float64]
+       >>> bar = NDArray[Shape["*"], Float64]
+
+       >>> repr(foo)
+       NDArray[Shape["N, N"], Float64]  # <-- this is sane
+       >>> repr(bar)
+       NDArray[Shape["*"], Float64]  # <-- this is sane, too
+
+       >>> foo == bar
+       False    # <-- still sane
+       >>> foo.__name__
+       NDArray  # <-- this is insane
+       >>> bar.__name__
+       NDArray  # <-- still insane after all these years
+
+       >>> foo | None == bar | None
+       False           # <-- back to sane
+       >>> repr(foo | None)
+       NDArray | None  # <-- big yikes
+       >>> repr(bar | None)
+       NDArray | None  # <-- yikes intensifies
+
+    ``foo`` and ``bar`` are distinct type hints matching different NumPy arrays;
+    their representations are likewise distinct. The new unions of those hints
+    with :data:`None` are also distinct type hints; nonetheless, the
+    representations of those new unions **are the exact same.**
+
+    This raiser detects this inconsistency by raising an exception from the
+    :func:`beartype.beartype` decorator. If we failed to do so, then
+    :func:`beartype.beartype` would behave non-deterministically when presented
+    with such hints. Consider the following decoration:
+
+    .. code-block:: python
+
+       @beartype
+       def bad_func(first_array: foo | None, second_array: bar | None) -> None:
+           ...
+
+    Given that decoration, :func:`beartype.beartype` would (in order):
+
+    #. Cache the first new union ``foo | None`` under the string representation
+       ``"NDArray | None"``.
+    #. Erroneously replace the second new union ``bar | None`` with the
+       previously cached new union ``foo | None``. Why? Because those two new
+       unions share the same representations. From the limited perspective of
+       :mod:`beartype`, those two new unions are effectively the same new union
+       and thus can be safely de-duplicated. *This is why we facepalm.*
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Raises
+    ------
+    bool
+        :data:`True` only if this object is a :pep:`604`-compliant union.
+    ''')
+
+
+is_hint_pep604.__doc__ = (
+    '''
+    :data:`True` only if the passed object is a :pep:`604`-compliant **union**
+    (i.e., ``|``-delimited disjunction of two or more isinstanceable types).
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a :pep:`604`-compliant union.
+    ''')
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep613.py
@@ -0,0 +1,102 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`613`-compliant **type alias** (i.e., :obj:`typing.TypeAlias`
+type hint singleton) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep613DeprecationWarning
+from beartype._util.error.utilerrwarn import issue_warning
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep613(
+    hint: object, exception_prefix: str, *args, **kwargs) -> object:
+    '''
+    Reduce the passed :pep:`613`-compliant **type alias** (i.e.,
+    :obj:`typing.TypeAlias` type hint singleton) to the ignorable
+    :class:`object` superclass.
+
+    This reducer effectively ignores *all* :obj:`typing.TypeAlias` type hint
+    singleton, which convey *no* meaningful metadata or semantics. Frankly, it's
+    unclear why :pep:`613` even exists. The CPython developer community felt
+    similarly, which is why :pep:`695` type aliases deprecate :pep:`613`.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as reducers cannot be memoized.
+
+    Parameters
+    ----------
+    hint : object
+        Typed dictionary to be reduced.
+    exception_prefix : str, optional
+        Substring prefixing exception messages raised by this reducer.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        Lower-level type hint currently supported by :mod:`beartype`.
+
+    Warns
+    -----
+    BeartypeDecorHintPep613DeprecationWarning
+        :pep:`613`-compliant type aliases have been officially deprecated by
+        :pep:`695`-compliant type aliases.
+    '''
+
+    # Emit a non-fatal deprecation warning.
+    issue_warning(
+        cls=BeartypeDecorHintPep613DeprecationWarning,
+        message=(
+            f'{exception_prefix}PEP 613 type hint {repr(hint)} '
+            f'deprecated by PEP 695. Consider either:\n'
+            f'* Requiring Python >= 3.12 and refactoring PEP 613 type aliases '
+            f'into PEP 695 type aliases. Note that Python < 3.12 will hate you '
+            f'for this: e.g.,\n'
+            f'    # Instead of this...\n'
+            f'    from typing import TypeAlias\n'
+            f'    alias_name: TypeAlias = alias_value\n'
+            f'\n'
+            f'    # ..."just" do this. Congrats. You destroyed your codebase.\n'
+            f'    type alias_name = alias_value\n'
+            f'* Refactoring PEP 613 type aliases into PEP 484 '
+            f'"typing.NewType"-based type aliases. Note that static '
+            f'type-checkers (e.g., mypy, pyright, Pyre) will hate you for '
+            f'this: e.g.,\n'
+            f'    # Instead of this...\n'
+            f'    from typing import TypeAlias\n'
+            f'    alias_name: TypeAlias = alias_value\n'
+            f'\n'
+            f'    # ..."just" do this. Congrats. You destroyed your codebase.\n'
+            f'    from typing import NewType\n'
+            f'    alias_name = NewType("alias_name", alias_value)\n'
+            f'\n'
+            f'Combine the above two approaches via The Ultimate Type Alias '
+            f'(TUTA), a hidden ninja technique that supports all Python '
+            f'versions and static type-checkers but may cause coworker heads '
+            f'to pop off like in that one Kingsman scene:\n'
+            f'    # Instead of this...\n'
+            f'    from typing import TypeAlias\n'
+            f'    alias_name: TypeAlias = alias_value\n'
+            f'\n'
+            f'    # ..."just" do this. If you think this sucks, know that you are not alone.\n'
+            f'    from typing import TYPE_CHECKING, NewType, TypeAlias  # <-- sus af\n'
+            f'    from sys import version_info  # <-- code just got real\n'
+            f'    if TYPE_CHECKING:  # <-- if static type-checking, then PEP 613\n'
+            f'        alias_name: TypeAlias = alias_value  # <-- grimdark coding style\n'
+            f'    elif version_info >= (3, 12):  # <-- if Python >= 3.12, then PEP 695\n'
+            f'        exec("type alias_name = alias_value")  # <-- eldritch abomination\n'
+            f'    else:  # <-- if Python < 3.12, then PEP 484\n'
+            f'        alias_name = NewType("alias_name", alias_value)  # <-- coworker gives up here\n'
+        ),
+    )
+
+    # Reduce *ALL* PEP 613 type hints to an arbitrary ignorable type hint.
+    return object
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep647.py
@@ -0,0 +1,84 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`647`-compliant **type hint** (i.e., objects created by
+subscripting the :obj:`typing.Final` type hint factory) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep647Exception
+from beartype.typing import (
+    Optional,
+    Type,
+)
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Unit test us up, please.
+def reduce_hint_pep647(
+    hint: object,
+    pith_name: Optional[str],
+    exception_prefix: str,
+    *args, **kwargs
+) -> Type[bool]:
+    '''
+    Reduce the passed :pep:`647`-compliant **type guard** (i.e.,
+    subscription of the :obj:`typing.TypeGuard` type hint factory) to the
+    builtin :class:`bool` class as advised by :pep:`647` when performing
+    runtime type-checking if this hint annotates the return of some callable
+    (i.e., if ``pith_name`` is ``"return"``) *or* raise an exception otherwise
+    (i.e., if this hint annotates the return of *no* callable).
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    ``@callable_cached`` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Final type hint to be reduced.
+    pith_name : Optional[str]
+        Either:
+
+        * If this hint annotates a parameter of some callable, the name of that
+          parameter.
+        * If this hint annotates the return of some callable, ``"return"``.
+        * Else, :data:`None`.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    Type[bool]
+        Builtin :class:`bool` class.
+
+    Raises
+    ------
+    BeartypeDecorHintPep647Exception
+        If this type guard does *not* annotate the return of some callable
+        (i.e., if ``arg_kind`` is *not* :data:`True`).
+    '''
+
+    # If this type guard annotates the return of some callable, reduce this type
+    # guard to the builtin "bool" class. Sadly, type guards are useless at
+    # runtime and exist exclusively as a means of superficially improving the
+    # computational intelligence of (...wait for it) static type-checkers.
+    if pith_name == ARG_NAME_RETURN:
+        return bool
+    # Else, this type guard does *NOT* annotate the return of some callable.
+
+    # Raise an exception. Type guards are contextually valid *ONLY* as top-level
+    # return annotations.
+    raise BeartypeDecorHintPep647Exception(
+        f'{exception_prefix}PEP 647 type hint {repr(hint)} '
+        f'invalid in this type hint context (i.e., '
+        f'{repr(hint)} valid only as non-nested return annotation).'
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep673.py
@@ -0,0 +1,109 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`673`-compliant **self type hint** (i.e., the
+:obj:`typing.Self` type hint singleton) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDecorHintPep673Exception
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.hint.datahinttyping import TypeStack
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Unit test us up, please.
+def reduce_hint_pep673(
+    hint: object,
+    cls_stack: TypeStack,
+    exception_prefix: str,
+    *args, **kwargs
+) -> type:
+    '''
+    Reduce the passed :pep:`673`-compliant **self type hint** (i.e.,
+    the :obj:`typing.Self` type hint singleton) to the **currently decorated
+    class** (i.e., the most deeply nested class on the passed type stack,
+    signifying the class currently being decorated by :func:`beartype.beartype`)
+    if any *or* raise an exception otherwise (i.e., if *no* class is currently
+    being decorated).
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as reducers cannot be memoized.
+
+    Parameters
+    ----------
+    hint : object
+        Self type hint to be reduced.
+    cls_stack : TypeStack, optional
+        **Type stack** (i.e., either tuple of zero or more arbitrary types *or*
+        :data:`None`). Defaults to :data:`None`. See also the
+        :func:`beartype._decor.decormain.beartype_object` decorator.
+    exception_prefix : str, optional
+        Human-readable substring prefixing exception messages raised by this
+        reducer.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    type
+        Most deeply nested class on this type stack.
+
+    Raises
+    ------
+    BeartypeDecorHintPep673Exception
+        If either:
+
+        * ``cls_stack`` is :data:`None`.
+        * ``cls_stack`` is non-:data:`None` but empty.
+    '''
+    assert isinstance(cls_stack, NoneTypeOr[tuple]), (
+        f'{repr(cls_stack)} neither tuple nor "None".')
+
+    # If either no type stack *OR* an empty type stack was passed, *NO* class is
+    # currently being decorated by @beartype. It follows that either:
+    # * @beartype is currently decorating a function or method directly.
+    # * A statement-level runtime type-checker (e.g.,
+    #   beartype.door.is_bearable()) is currently being called.
+    #
+    # However, the "typing.Self" type hint *CANNOT* be reliably resolved outside
+    # of a class context. Although @beartype could attempt to heuristically
+    # differentiate functions from methods via the first passed argument, Python
+    # itself does *NOT* require that argument of a method to be named "self";
+    # such a heuristic would catastrophically fail in common edge cases. Our
+    # only recourse is to raise an exception encouraging the user to refactor
+    # their code to decorate classes rather than methods.
+    if not cls_stack:
+        # We didn't make crazy. We only document it.
+        raise BeartypeDecorHintPep673Exception(
+            f'{exception_prefix}PEP 673 type hint "{repr(hint)}" '
+            f'invalid outside @beartype-decorated class. '
+            f'PEP 673 type hints are valid only inside classes decorated by '
+            f'@beartype. If this hint annotates a method decorated by '
+            f'@beartype, instead decorate the class declaring this method by '
+            f'@beartype: e.g.,\n'
+            f'\n'
+            f'    # Instead of decorating methods by @beartype like this...\n'
+            f'    class BadClassIsBad(object):\n'
+            f'        @beartype\n'
+            f'        def awful_method_is_awful(self: Self) -> Self:\n'
+            f'            return self\n'
+            f'\n'
+            f'    # ...decorate classes by @beartype instead - like this!\n'
+            f'    @beartype\n'
+            f'    class GoodClassIsGood(object):\n'
+            f'        def wonderful_method_is_wonderful(self: Self) -> Self:\n'
+            f'            return self\n'
+            f'\n'
+            f"This has been a message of the Bearhugger Broadcasting Service."
+        )
+    # Else, a non-empty type stack was passed.
+
+    # Reduce this hint to the currently decorated class (i.e., the most deeply
+    # nested class on this type stack, signifying the class currently being
+    # decorated by @beartype.beartype).
+    return cls_stack[-1]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep675.py
@@ -0,0 +1,38 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`675`-compliant **literal string type hint** (i.e., objects
+created by subscripting the :obj:`typing.Final` type hint factory) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Type
+
+# ....................{ REDUCERS                           }....................
+#FIXME: Unit test us up, please.
+def reduce_hint_pep675(*args, **kwargs) -> Type[str]:
+    '''
+    Reduce the passed :pep:`675`-compliant **literal string type hint** (i.e.,
+    :obj:`typing.LiteralString` singleton) to the builtin :class:`str` class as
+    advised by :pep:`675` when performing runtime type-checking.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as reducers cannot be memoized.
+
+    Parameters
+    ----------
+    All passed arguments are silently ignored.
+
+    Returns
+    -------
+    Type[str]
+        Builtin :class:`str` class.
+    '''
+
+    # Unconditionally reduce this hint to the builtin "str" class.
+    return str
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/proposal/utilpep695.py
@@ -0,0 +1,498 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide :pep:`695`-compliant **type alias** (i.e., objects created via the
+``type`` statement under Python >= 3.12) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Consider generalizing @beartype's PEP 695 implementation to additionally
+#support local type aliases (i.e., defined in the local scope of a callable
+#rather than at global scope) containing one or more unquoted forward
+#references. Currently, @beartype intentionally fails to support this: e.g.,
+#    type global_alias = ...
+#    die_if_unbearable('lolwut', global_alias)  # <-- this is fine
+#
+#    def muh_func(...) -> ...:
+#        type local_alias = ...
+#        die_if_unbearable('lolwut', local_alias)  # <-- raises an exception
+#
+#The reasons are obscure. Very well. CPython's current implementation of local
+#type aliases is probably very buggy. An upstream issue describing this
+#bugginess should be submitted. When doing so, please publicly declare that PEP
+#695 appears to have been poorly tested. As evidence, note that PEP 695 itself
+#advises use of the following idiom:
+#    # A type alias that includes a forward reference
+#    type AnimalOrVegetable = Animal | "Vegetable"
+#
+#*THAT DOES NOT ACTUALLY WORK AT RUNTIME.* Nobody tested that. This is why I
+#facepalm. Notably, PEP 604-compliant new-style unions prohibit strings. They
+#probably shouldn't, but they've *ALWAYS* behaved that way, and nobody's updated
+#them to behave more intelligently -- probably because doing so would require
+#updating the isinstance() builtin (which also accepts PEP 604-compliant
+#new-style unions) to behave more intelligiently and ain't nobody goin' there:
+#e.g.,
+#
+#    $ python3.12
+#    >>> type AnimalOrVegetable = "Animal" | "Vegetable"
+#    >>> AnimalOrVegetable.__value__
+#    Traceback (most recent call last):
+#      Cell In[3], line 1
+#        AnimalOrVegetable.__value__
+#      Cell In[2], line 1 in AnimalOrVegetable
+#        type AnimalOrVegetable = "Animal" | "Vegetable"
+#    TypeError: unsupported operand type(s) for |: 'str' and 'str'
+#
+#For further details, see the comment below prefixed by:
+#           # If that module fails to define this alias as a global variable,
+#
+#Since CPython is unlikely to resolve its bugginess anytime soon, it inevitably
+#falls to @beartype to resolve this. Thankfully, @beartype *CAN* resolve this.
+#Unthankfully, doing so will require @beartype to implement a new PEP
+#695-specific AST transform from the "beartype.claw" subpackage augmenting *ALL*
+#PEP 695-compliant local type aliases (so, probably *ALL* type aliases
+#regardless of scope for simplicity) as follows:
+#    # "beartype.claw" should transform this...
+#    type {alias_name} = {alias_value}
+#
+#    # ...into this.
+#    from beartype._util.hint.pep.proposal.utilpep695 import (
+#        iter_hint_pep695_forwardrefs as
+#        __iter_hint_pep695_forwardref_beartype__
+#    )
+#    type {alias_name} = {alias_value}
+#    for __hint_pep695_forwardref_beartype__ in (
+#        __iter_hint_pep695_forwardref_beartype__({alias_name})):
+#        # If the current scope is module scope, prefer an efficient
+#        # non-exec()-based solution. Note that this optimization does *NOT*
+#        # generalize to other scopes, for obscure reasons delineated here:
+#        #     https://stackoverflow.com/a/8028772/2809027
+#        if globals() is locals():
+#            globals()[__hint_pep695_forwardref_beartype__.__name_beartype__] =
+#                __hint_pep695_forwardref_beartype__)
+#        # Else, the current scope is *NOT* module scope. In this case,
+#        # fallback to an inefficient exec()-based solution.
+#        else:
+#            exec(f'{__hint_pep695_forwardref_beartype__.__name_beartype__} = __hint_pep695_forwardref_beartype__')
+#
+#    #FIXME: Technically, this *ONLY* needs to be done if the
+#    #iter_hint_pep695_forwardrefs() iterator returned something. *shrug*
+#    # Intentionally redefine this alias. Although this appears to be an
+#    # inefficient noop, this is in fact an essential operation. Why?
+#    # Because the prior successful access of the "__value__" dunder
+#    # variable silently cached and thus froze the value of this alias.
+#    # However, alias values are *NOT* necessarily safely freezable at
+#    # alias definition time. The canonical example of alias values that
+#    # are *NOT* safely freezable at alias definition time are mutually
+#    # recursive aliases (i.e., aliases whose values circularly refer to
+#    # one another): e.g.,
+#    #     type a = b
+#    #     type b = a
+#    #
+#    # PEP 695 provides no explicit means of uncaching alias values.
+#    # Our only recourse is to repetitiously redefine this alias.
+#    type {alias_name} = {alias_value}
+#
+#We're currently unclear whether anyone actually cares about this. Ergo, we
+#adopted the quick-and-dirty approach of raising exceptions instead. Yikes!
+
+# ....................{ IMPORTS                            }....................
+from beartype.meta import URL_ISSUES
+from beartype.roar import BeartypeDecorHintPep695Exception
+from beartype.typing import (
+    Iterable,
+    Optional,
+)
+from beartype._cave._cavefast import HintPep695Type
+from beartype._check.forward.reference.fwdrefmeta import BeartypeForwardRefMeta
+from beartype._check.forward.reference.fwdrefmake import (
+    make_forwardref_indexable_subtype)
+from beartype._util.error.utilerrget import get_name_error_attr_name
+from beartype._util.module.utilmodget import get_module_imported_or_none
+
+# ....................{ TESTERS                            }....................
+def is_hint_pep695_ignorable(hint: HintPep695Type) -> bool:
+    '''
+    :data:`True` only if the passed :pep:`695`-compliant **type alias** (i.e.,
+    object created by a statement of the form ``type {alias_name} =
+    {alias_value}``) is ignorable.
+
+    Specifically, this tester ignores the passed type alias if the lower-level
+    type hint aliased by this alias is itself deeply ignorable.
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : HintPep695Type
+        Type alias to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this :pep:`695`-compliant type alias is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhinttest import is_hint_ignorable
+
+    # Return true only if this hint aliases an ignorable child type hint.
+    return is_hint_ignorable(get_hint_pep695_alias(hint))
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep695_alias(
+    hint: HintPep695Type, exception_prefix: str = '') -> object:
+    '''
+    **Non-alias type hint** (i.e., type hint that is *not* a
+    :pep:`695`-compliant type alias) encapsulated by the passed
+    :pep:`695`-compliant **type alias** (i.e., object created by a statement of
+    the form ``type {alias_name} = {alias_value}``).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), for subtle reasons pertaining to unquoted
+    forward references. Notably, memoizing this getter would prevent the
+    external caller of the higher-level :func:`.iter_hint_pep695_forwardrefs`
+    iterator calling this lower-level getter from externally modifying this type
+    alias by forcefully injecting forward reference proxies into this alias.
+
+    Parameters
+    ----------
+    hint : HintPep695Type
+        Type alias to be inspected.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    object
+        Unaliased type hint encapsulated by this type alias.
+
+    Raises
+    ------
+    BeartypeDecorHintPep695Exception
+        If this type hint is *not* a PEP 695-compliant type alias.
+    NameError
+        If this type alias contains one or more **unquoted forward references**
+        to undefined types.
+    '''
+
+    # If this hint is *NOT* a PEP 695-compliant type alias, raise an exception.
+    if not isinstance(hint, HintPep695Type):
+        raise BeartypeDecorHintPep695Exception(
+            f'{exception_prefix}type hint {repr(hint)} '
+            f'not PEP 695 type alias.'
+        )
+    # Else, this hint is a PEP 695-compliant type alias.
+
+    # While the Universe continues infinitely expanding...
+    while True:
+        # Reduce this type alias to the type hint aliased by this alias, which
+        # itself is possibly a nested type alias. Oh, it happens.
+        #
+        # Note that doing so implicitly raises a "NameError" if this alias
+        # contains one or more unquoted forward references to undefined types.
+        hint = hint.__value__  # type: ignore[attr-defined]
+
+        # If this type hint is *NOT* a nested type alias, break this iteration.
+        if not isinstance(hint, HintPep695Type):
+            break
+        # Else, this type hint is a nested type alias. In this case, continue
+        # iteratively unwrapping this nested type alias.
+
+    # Return this unaliased type alias.
+    return hint
+
+# ....................{ ITERATORS                          }....................
+def iter_hint_pep695_forwardrefs(
+    # Mandatory parameters.
+    hint: HintPep695Type,
+
+    # Optional parameters.
+    exception_prefix: str = '',
+) -> Iterable[BeartypeForwardRefMeta]:
+    '''
+    Iteratively create and yield one **forward reference proxy** (i.e.,
+    :class:`beartype._check.forward.reference.fwdrefabc.BeartypeForwardRefABC`
+    subclass) for each unquoted relative forward reference in the passed
+    :pep:`695`-compliant **type alias** (i.e., object created by a statement of
+    the form ``type {alias_name} = {alias_value}``) to the underlying type hint
+    lazily referred to by this type alias.
+
+    This iterator is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as this iterator is intended to be
+    called only once per type alias in userspace code dynamically instrumented
+    by beartype import hook abstract syntax tree (AST) node transformers.
+    Since those transformers are expected to replace *all* unquoted relative
+    forward references in this type alias with corresponding forward reference
+    proxies, calling this iterator again on any type alias instrumented in this
+    way *should* silently reduce to a noop.
+
+    Parameters
+    ----------
+    hint : HintPep695Type
+        Type alias to be iterated over.
+    exception_prefix : str, optional
+        Human-readable substring prefixing exception messages raised by this
+        reducer. Defaults to the empty string.
+
+    Yields
+    ------
+    BeartypeForwardRefMeta
+        Forward reference proxy encapsulating the next unquoted relative forward
+        reference in this :pep:`695`-compliant type alias.
+
+    Raises
+    ------
+    BeartypeDecorHintPep695Exception
+        If this type hint is *not* a PEP 695-compliant type alias.
+    '''
+
+    # Unqualified basename of the previous undeclared attribute in this alias.
+    hint_ref_name_prev: Optional[str] = None
+
+    # While this type alias still contains one or more forward references to
+    # attributes *NOT* defined by the module declaring this type alias...
+    while True:
+        # Attempt to...
+        try:
+            # print(f'type {hint.__name__} = {hint.__value__}')
+
+            # Reduce this alias to the type hint it lazily refers to. If this
+            # alias contains *NO* forward references to undeclared attributes,
+            # this reduction *SHOULD* succeed. Let's pretend we mean that.
+            #
+            # Note that get_hint_pep695_alias() is memoized and thus
+            # intentionally called with positional arguments.
+            get_hint_pep695_alias(hint, exception_prefix)
+
+            # This reduction raised *NO* exception and thus succeeded. In this
+            # case, immediately halt iteration.
+            break
+        # If doing so raises a builtin "NameError" exception, this alias
+        # contains one or more forward references to undeclared attributes. In
+        # this case...
+        except NameError as exception:
+            # Unqualified basename of this alias (i.e., name of the global or
+            # local variable assigned to by the left-hand side of this alias).
+            hint_name = repr(hint)
+
+            # Fully-qualified name of the external third-party module defining
+            # this alias.
+            hint_module_name = hint.__module__
+            # print(f'hint_module_name: {hint_module_name}')
+
+            # If this alias defines *NO* module name, raise an exception.
+            #
+            # Note that this should *NEVER* happen. Nonetheless, static
+            # type-checkers like mypy insist this can happen. It almost
+            # certainly can't. Nonetheless, let's dot our i's and cross our t's.
+            if not hint_module_name:
+                raise BeartypeDecorHintPep695Exception(
+                    f'{exception_prefix}PEP 695 type alias "{hint_name}" '
+                    f'module undefined (i.e., "__module__" attribute '
+                    f'either "None" or the empty string).'
+                ) from exception
+            # Else, this alias defines a module name.
+
+            # That module as its previously imported object.
+            hint_module = get_module_imported_or_none(hint_module_name)
+
+            # Unqualified basename of the next remaining undeclared attribute
+            # contained in this alias relative to that module.
+            hint_ref_name = get_name_error_attr_name(exception)
+            # print(f'hint: {hint}; hint_ref_name: {hint_ref_name}')
+
+            # If this attribute is the same as that of the prior iteration of
+            # this "while" loop, then that iteration *MUST* have failed to
+            # define this attribute as a global variable of that module. In this
+            # case, raise an exception.
+            #
+            # Note that this should *NEVER* happen. Of course, this frequently
+            # happens. Specifically, this happens whenever the caller defines a
+            # callable defining type alias as a local variable containing one or
+            # more unquoted relative forward reference to user-defined classes
+            # that have yet to be defined. Why? Because CPython's low-level
+            # C-based implementation of PEP 695-compliant type aliases currently
+            # fails to properly resolve unquoted relative forward references
+            # defined in a local rather than global scope: e.g.,
+            #    >>> def foo():
+            #    ...     type bar = wut
+            #    ...     globals()['wut'] = str
+            #    ...     print(bar.__value__)
+            #    ...     class wut(object): pass  # <-- causes madness; WTF!?!?
+            #    >>> foo()
+            #    NameError: cannot access free variable 'wut' where it is not
+            #    associated with a value in enclosing scope
+            #
+            # Why does this matter? Because the abstract syntax tree (AST)
+            # transformation implemented by "beartype.claw" import hooks
+            # dynamically declares the objects that these forward references
+            # refer. Due to deficiencies [read: bugs] in CPython's type alias
+            # implementation, local type aliases remain unable to resolve either
+            # global *OR* local referees that are defined dynamically. Ergo, we
+            # have no recourse but to detect this edge case and raise a
+            # human-readable exception advising the caller with recommendations.
+            if hint_ref_name == hint_ref_name_prev:
+                raise BeartypeDecorHintPep695Exception(
+                    f'{exception_prefix}PEP 695 local type alias "{hint_name}" '
+                    f'unquoted relative forward reference "{hint_ref_name}" '
+                    f"unsupported, due to severe deficiencies in CPython's "
+                    f'runtime implementation of PEP 695 local type aliases '
+                    f"outside beartype's control. Consider either:\n"
+                    f'* Refactoring this local type alias into a '
+                    f'global type alias:\n'
+                    f'      # Instead of a local type alias '
+                    f'defined in a callable like this...\n'
+                    f'      def muh_func(...) -> ...:\n'
+                    f'          type {hint_name} = ...\n'
+                    f'\n'
+                    f'      # Prefer a global type alias defined at module scope.\n'
+                    f'      type {hint_name} = ...\n'
+                    f'* Quoting this forward reference in this type alias:\n'
+                    f'      # Instead of an unquoted forward reference '
+                    f'like this...\n'
+                    f'      type {hint_name} = ... {hint_ref_name} ...\n'
+                    f'\n'
+                    f'      # Prefer a quoted forward reference.\n'
+                    f'      type {hint_name} = ... "{hint_ref_name}" ...'
+                ) from exception
+            # Else, this attribute differs from that of the prior iteration of
+            # this "while" loop.
+            #
+            # If that module paradoxically claims to already define this
+            # attribute as a global variable, raise an exception.
+            #
+            # Note that this should *NEVER* happen. Of course, this will happen.
+            elif hasattr(hint_module, hint_ref_name):
+                raise BeartypeDecorHintPep695Exception(  # pragma: no cover
+                    f'{exception_prefix}PEP 695 type alias "{hint_name}" '
+                    f'unquoted relative forward reference "{hint_ref_name}" '
+                    f'already defined in module "{hint_module_name}", '
+                    f'despite purportedly being undefined. '
+                    f'In theory, this should never happen. '
+                    f'Of course, this happened. You suddenly feel the '
+                    f'horrifying urge to report this grievous failure to the '
+                    f'beartype issue tracker:\n\t{URL_ISSUES}'
+                ) from exception
+            # Else, that module does *NOT* yet define this attribute.
+
+            # Forward reference proxy to this undeclared attribute.
+            #
+            # Note that:
+            # * This call is intentionally passed only positional parameters to
+            #   satisfy the @callable_cached decorator memoizing this function.
+            # * A full-blown forward reference proxy rather than a trivial
+            #   stringified forward reference (i.e., the relative name of the
+            #   undefined attribute being referred to, equivalent to
+            #   "hint_ref_name") is required here. Why? Subscription. A
+            #   stringified forward reference *CANNOT* be subscripted by
+            #   arbitrary child type hints; a forward reference proxy can be.
+            hint_ref = make_forwardref_indexable_subtype(
+                hint_module_name, hint_ref_name)
+
+            # Yield this forward reference proxy to the caller.
+            yield hint_ref
+
+            # Store the unqualified basename of this previously undeclared
+            # attribute for detection by the next iteration of this loop.
+            hint_ref_name_prev = hint_ref_name
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep695(
+    hint: HintPep695Type,
+    exception_prefix: str,
+    *args, **kwargs
+) -> object:
+    '''
+    Reduce the passed :pep:`695`-compliant **type alias** (i.e., object created
+    by a statement of the form ``type {alias_name} = {alias_value}``) to the
+    underlying type hint lazily referred to by this type alias.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as reducers cannot be memoized.
+
+    Parameters
+    ----------
+    hint : object
+        Type alias to be reduced.
+    exception_prefix : str
+        Human-readable substring prefixing exception messages raised by this
+        reducer.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        Underlying type hint lazily referred to by this type alias.
+
+    Raises
+    ------
+    BeartypeDecorHintPep695Exception
+        If this type alias contains one or more unquoted relative forward
+        references to undefined attributes. Note that this *only* occurs when
+        callers avoid beartype import hooks in favour of manually decorating
+        callables and classes with the :func:`beartype.beartype` decorator.
+    '''
+
+    # Underlying type hint to be returned.
+    hint_aliased: object = None
+
+    # Attempt to...
+    try:
+        # Reduce this alias to the type hint it lazily refers to. If this alias
+        # contains *NO* forward references to undeclared attributes, this
+        # reduction *SHOULD* succeed. Let's pretend we mean that.
+        #
+        # Note that get_hint_pep695_alias() is memoized and thus
+        # intentionally called with positional arguments.
+        hint_aliased = get_hint_pep695_alias(hint, exception_prefix)
+    # If doing so raises a builtin "NameError" exception, this alias contains
+    # one or more forward references to undeclared attributes. In this case...
+    except NameError as exception:
+        # Unqualified basename of this alias (i.e., name of the global or local
+        # variable assigned to by the left-hand side of this alias).
+        hint_name = repr(hint)
+
+        # Fully-qualified name of the third-party module defining this alias.
+        hint_module_name = hint.__module__
+        # print(f'hint_module_name: {hint_module_name}')
+
+        # Unqualified basename of the next remaining undeclared attribute
+        # contained in this alias relative to that module.
+        hint_ref_name = get_name_error_attr_name(exception)
+        # print(f'hint: {hint}; hint_ref_name: {hint_ref_name}')
+
+        # Raise a human-readable exception describing this issue.
+        raise BeartypeDecorHintPep695Exception(
+            f'{exception_prefix}PEP 695 type alias "{hint_name}" '
+            f'unquoted relative forward reference {repr(hint_ref_name)} in '
+            f'module "{hint_module_name}" unsupported outside '
+            f'"beartype.claw" import hooks. Consider either:\n'
+            f'* Quoting this forward reference in this type alias: e.g.,\n'
+            f'      # Instead of an unquoted forward reference...\n'
+            f'      type {hint_name} = ... {hint_ref_name} ...\n'
+            f'\n'
+            f'      # Prefer a quoted forward reference.\n'
+            f'      type {hint_name} = ... "{hint_ref_name}" ...\n'
+            f'* Applying "beartype.claw" import hooks to '
+            f'module "{hint_module_name}": e.g.,\n'
+            f'      # In your "this_package.__init__" submodule:\n'
+            f'      from beartype.claw import beartype_this_package\n'
+            f'      beartype_this_package()'
+        ) from exception
+    # Else, doing so raised *NO* exceptions, implying this alias contains *NO*
+    # forward references to undeclared attributes.
+
+    # Return this underlying type hint.
+    return hint_aliased
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/utilpepget.py
@@ -0,0 +1,1101 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-compliant type hint getter utilities** (i.e., callables
+querying arbitrary objects for attributes specific to PEP-compliant type
+hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.meta import URL_ISSUES
+from beartype.roar import (
+    BeartypeDecorHintPepException,
+    BeartypeDecorHintPepSignException,
+)
+from beartype.roar._roarexc import _BeartypeUtilTypeException
+from beartype.typing import (
+    Any,
+    Optional,
+    # Union,
+)
+from beartype._data.hint.datahinttyping import (
+    # HintSignTrie,
+    TypeException,
+)
+from beartype._data.hint.pep.datapeprepr import (
+    HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN,
+    HINT_REPR_PREFIX_ARGS_1_OR_MORE_TO_SIGN,
+    HINT_REPR_PREFIX_TRIE_ARGS_0_OR_MORE_TO_SIGN,
+    HINT_TYPE_NAME_TO_SIGN,
+)
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignGeneric,
+    HintSignNewType,
+    HintSignTypedDict,
+    HintSignPep585BuiltinSubscriptedUnknown,
+)
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_ORIGIN_ISINSTANCEABLE,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.hint.pep.proposal.pep484.utilpep484newtype import (
+    is_hint_pep484_newtype_pre_python310)
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585generic import (
+    is_hint_pep484585_generic)
+from beartype._util.hint.pep.proposal.utilpep585 import (
+    get_hint_pep585_generic_typevars,
+    is_hint_pep585_builtin_subscripted,
+    is_hint_pep585_generic,
+)
+from beartype._util.hint.pep.proposal.utilpep589 import is_hint_pep589
+from beartype._util.hint.pep.proposal.utilpep604 import (
+    die_if_hint_pep604_inconsistent)
+from beartype._util.py.utilpyversion import (
+    # IS_PYTHON_AT_LEAST_3_10,
+    IS_PYTHON_AT_MOST_3_9,
+    IS_PYTHON_AT_LEAST_3_9,
+)
+from beartype._data.hint.datahinttyping import TupleTypes
+
+# ....................{ GETTERS ~ args                     }....................
+# If the active Python interpreter targets Python >= 3.9, implement this
+# getter to directly access the "__args__" dunder attribute.
+if IS_PYTHON_AT_LEAST_3_9:
+    def get_hint_pep_args(hint: object) -> tuple:
+
+        # Return the value of the "__args__" dunder attribute if this hint
+        # defines this attribute *OR* "None" otherwise.
+        hint_args = getattr(hint, '__args__', None)
+
+        # If this hint does *NOT* define this attribute, return the empty tuple.
+        if hint_args is None:
+            return ()
+        # Else, this hint defines this attribute.
+        #
+        # If this hint appears to be unsubscripted, then this hint *WAS*
+        # actually subscripted by the empty tuple (e.g., "tuple[()]",
+        # "typing.Tuple[()]"). Why? Because:
+        # * Python 3.11 made the unfortunate decision of ambiguously conflating
+        #   unsubscripted type hints (e.g., "tuple", "typing.Tuple") with type
+        #   hints subscripted by the empty tuple, preventing downstream
+        #   consumers from reliably distinguishing these two orthogonal cases.
+        # * Python 3.9 made a similar decision but constrained to only PEP
+        #   585-compliant empty tuple type hints (i.e., "tuple[()]"). PEP
+        #   484-compliant empty tuple type hints (i.e., "typing.Tuple[()]")
+        #   continued to correctly declare an "__args__" dunder attribute of
+        #   "((),)" until Python 3.11.
+        #
+        # Disambiguate these two cases on behalf of callers by returning a tuple
+        # containing only the empty tuple rather than returning the empty tuple.
+        elif not hint_args:
+            return _HINT_ARGS_EMPTY_TUPLE
+        # Else, this hint is either subscripted *OR* is unsubscripted but not
+        # PEP 585-compliant.
+
+        # In this case, return this tuple as is.
+        return hint_args
+# Else, the active Python interpreter targets Python < 3.9. In this case,
+# implement this getter to directly access the "__args__" dunder attribute.
+else:
+    def get_hint_pep_args(hint: object) -> tuple:
+
+        # Under python < 3.9, unparametrized generics have the attribute
+        # "_special" set to True despite the actual "__args__" typically being a
+        # "TypeVar" instance. Because we want to differentiate between
+        # unparametrized and parametrized generics, check whether the hint is
+        # "_special" and if so, we return the empty tuple instead of that
+        # "TypeVar" instance.
+        if getattr(hint, '_special', False):
+            return ()
+
+        # Return the value of the "__args__" dunder attribute if this hint
+        # defines this attribute *OR* the empty tuple otherwise.
+        return getattr(hint, '__args__', ())
+
+
+# Document this function regardless of implementation details above.
+get_hint_pep_args.__doc__ = '''
+    Tuple of all **typing arguments** (i.e., subscripted objects of the passed
+    PEP-compliant type hint listed by the caller at hint declaration time)
+    if any *or* the empty tuple otherwise.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This getter should always be called in lieu of attempting to directly
+    access the low-level** ``__args__`` **dunder attribute.** Various
+    singleton objects defined by the :mod:`typing` module (e.g.,
+    :attr:`typing.Any`, :attr:`typing.NoReturn`) fail to define this attribute,
+    guaranteeing :class:`AttributeError` exceptions from all general-purpose
+    logic attempting to directly access this attribute. Thus this function,
+    which "fills in the gaps" by implementing this oversight.
+
+    **This getter never lies, unlike the comparable**
+    :func:`get_hint_pep_typevars` **getter.** Whereas
+    :func:`get_hint_pep_typevars` synthetically propagates type variables from
+    child to parent type hints (rather than preserving the literal type
+    variables subscripting this type hint), this getter preserves the literal
+    arguments subscripting this type hint if any. Notable cases where the two
+    differ include:
+
+    * Generic classes subclassing pseudo-superclasses subscripted by one or
+      more type variables (e.g., ``class MuhGeneric(Generic[S, T])``).
+    * Unions subscripted by one or more child type hints subscripted by one or
+      more type variables (e.g., ``Union[str, Iterable[Tuple[S, T]]]``).
+
+    Parameters
+    ----------
+    hint : object
+        PEP-compliant type hint to be inspected.
+
+    Returns
+    -------
+    tuple
+        Either:
+
+        * If this hint defines an ``__args__`` dunder attribute, the value of
+          that attribute.
+        * Else, the empty tuple.
+
+    Examples
+    --------
+        >>> import typing
+        >>> from beartype._util.hint.pep.utilpepget import (
+        ...     get_hint_pep_args)
+        >>> get_hint_pep_args(typing.Any)
+        ()
+        >>> get_hint_pep_args(typing.List[int, str, typing.Dict[str, str]])
+        (int, str, typing.Dict[str, str])
+    '''
+
+# ....................{ GETTERS ~ typevars                 }....................
+# If the active Python interpreter targets Python >= 3.9, implement this
+# function to either directly access the "__parameters__" dunder attribute for
+# type hints that are not PEP 585-compliant generics *OR* to synthetically
+# reconstruct that attribute for PEP 585-compliant generics. *sigh*
+if IS_PYTHON_AT_LEAST_3_9:
+    def get_hint_pep_typevars(hint: object) -> TupleTypes:
+
+        # Value of the "__parameters__" dunder attribute on this object if this
+        # object defines this attribute *OR* "None" otherwise.
+        hint_pep_typevars = getattr(hint, '__parameters__', None)
+
+        # If this object defines *NO* such attribute...
+        if hint_pep_typevars is None:
+            # Return either...
+            return (
+                # If this hint is a PEP 585-compliant generic, the tuple of all
+                # typevars declared on pseudo-superclasses of this generic.
+                get_hint_pep585_generic_typevars(hint)
+                if is_hint_pep585_generic(hint) else
+                # Else, the empty tuple.
+                ()
+            )
+        # Else, this object defines this attribute.
+
+        # Return this attribute.
+        return hint_pep_typevars
+# Else, the active Python interpreter targets Python < 3.9. In this case,
+# implement this function to directly access the "__parameters__" dunder
+# attribute.
+else:
+    def get_hint_pep_typevars(hint: object) -> TupleTypes:
+
+        # Value of the "__parameters__" dunder attribute on this object if this
+        # object defines this attribute *OR* the empty tuple otherwise. Note:
+        # * The "typing._GenericAlias.__parameters__" dunder attribute tested
+        #   here is defined by the typing._collect_type_vars() function at
+        #   subscription time. Yes, this is insane. Yes, this is PEP 484.
+        # * This trivial test implicitly handles superclass parametrizations.
+        #   Thankfully, the "typing" module percolates the "__parameters__"
+        #   dunder attribute from "typing" pseudo-superclasses to user-defined
+        #   subclasses during PEP 560-style type erasure. Finally: they did
+        #   something slightly right.
+        return getattr(hint, '__parameters__', ())
+
+
+# Document this function regardless of implementation details above.
+get_hint_pep_typevars.__doc__ = '''
+    Tuple of all **unique type variables** (i.e., subscripted :class:`TypeVar`
+    instances of the passed PEP-compliant type hint listed by the caller at
+    hint declaration time ignoring duplicates) if any *or* the empty tuple
+    otherwise.
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This function should always be called in lieu of attempting to directly
+    access the low-level** ``__parameters__`` **dunder attribute.** Various
+    singleton objects defined by the :mod:`typing` module (e.g.,
+    :attr:`typing.Any`, :attr:`typing.NoReturn`) fail to define this attribute,
+    guaranteeing :class:`AttributeError` exceptions from all general-purpose
+    logic attempting to directly access this attribute. Thus this function,
+    which "fills in the gaps" by implementing this oversight.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Tuple[TypeVar, ...]
+        Either:
+
+        * If this object defines a ``__parameters__`` dunder attribute, the
+          value of that attribute.
+        * Else, the empty tuple.
+
+    Examples
+    --------
+        >>> import typing
+        >>> from beartype._util.hint.pep.utilpepget import (
+        ...     get_hint_pep_typevars)
+        >>> S = typing.TypeVar('S')
+        >>> T = typing.TypeVar('T')
+        >>> get_hint_pep_typevars(typing.Any)
+        ()
+        >>> get_hint_pep_typevars(typing.List[T, int, S, str, T])
+        (T, S)
+    '''
+
+# ....................{ GETTERS ~ sign                     }....................
+def get_hint_pep_sign(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPepSignException,
+    exception_prefix: str = '',
+) -> HintSign:
+    '''
+    **Sign** (i.e., :class:`HintSign` instance) uniquely identifying the passed
+    PEP-compliant type hint if PEP-compliant *or* raise an exception otherwise
+    (i.e., if this hint is *not* PEP-compliant).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`.BeartypeDecorHintPepSignException`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    dict
+        Sign uniquely identifying this hint.
+
+    Raises
+    ------
+    exception_cls
+        If this hint is either:
+
+        * PEP-compliant but *not* uniquely identifiable by a sign.
+        * PEP-noncompliant.
+        * *Not* a hint (i.e., neither PEP-compliant nor -noncompliant).
+
+    See Also
+    --------
+    :func:`get_hint_pep_sign_or_none`
+        Further details.
+    '''
+
+    # Sign uniquely identifying this hint if recognized *OR* "None" otherwise.
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # If this hint is unrecognized...
+    if hint_sign is None:
+        assert isinstance(exception_cls, type), (
+            f'{exception_cls} not exception type.')
+        assert isinstance(exception_prefix, str), (
+            f'{exception_prefix} not string.')
+
+        # Avoid circular import dependencies.
+        from beartype._util.hint.nonpep.utilnonpeptest import die_if_hint_nonpep
+
+        # If this hint is PEP-noncompliant, raise an exception.
+        die_if_hint_nonpep(
+            hint=hint,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+        # Else, this hint is *NOT* PEP-noncompliant. Since this hint was
+        # unrecognized, this hint *MUST* necessarily be a PEP-compliant type
+        # hint currently unsupported by the @beartype decorator.
+
+        # Raise an exception indicating this.
+        #
+        # Note that we intentionally avoid calling the
+        # die_if_hint_pep_unsupported() function here, which calls the
+        # is_hint_pep_supported() function, which calls this function.
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} '
+            f'currently unsupported by beartype. '
+            f'You suddenly feel encouraged to submit a feature request '
+            f'for this hint to our friendly issue tracker at:\n'
+            f'\t{URL_ISSUES}'
+        )
+    # Else, this hint is recognized.
+
+    # Return the sign uniquely identifying this hint.
+    return hint_sign
+
+
+#FIXME: Revise us up the docstring, most of which is now obsolete.
+@callable_cached
+def get_hint_pep_sign_or_none(hint: Any) -> Optional[HintSign]:
+    '''
+    **Sign** (i.e., :class:`HintSign` instance) uniquely identifying the passed
+    PEP-compliant type hint if PEP-compliant *or* ``None`` otherwise (i.e., if
+    this hint is *not* PEP-compliant).
+
+    This getter function associates the passed hint with a public attribute of
+    the :mod:`typing` module effectively acting as a superclass of this hint
+    and thus uniquely identifying the "type" of this hint in the broadest sense
+    of the term "type". These attributes are typically *not* actual types, as
+    most actual :mod:`typing` types are private, fragile, and prone to extreme
+    violation (or even removal) between major Python versions. Nonetheless,
+    these attributes are sufficiently unique to enable callers to distinguish
+    between numerous broad categories of :mod:`typing` behaviour and logic.
+
+    Specifically, if this hint is:
+
+    * A :pep:`585`-compliant **builtin** (e.g., C-based type
+      hint instantiated by subscripting either a concrete builtin container
+      class like :class:`list` or :class:`tuple` *or* an abstract base class
+      (ABC) declared by the :mod:`collections.abc` submodule like
+      :class:`collections.abc.Iterable` or :class:`collections.abc.Sequence`),
+      this function returns ::class:`beartype.cave.HintGenericSubscriptedType`.
+    * A **generic** (i.e., subclass of the :class:`typing.Generic` abstract
+      base class (ABC)), this function returns :class:`HintSignGeneric`. Note
+      this includes :pep:`544`-compliant **protocols** (i.e., subclasses of the
+      :class:`typing.Protocol` ABC), which implicitly subclass the
+      :class:`typing.Generic` ABC as well.
+    * A **forward reference** (i.e., string or instance of the concrete
+      :class:`typing.ForwardRef` class), this function returns
+      :class:`HintSignTypeVar`.
+    * A **type variable** (i.e., instance of the concrete
+      :class:`typing.TypeVar` class), this function returns
+      :class:`HintSignTypeVar`.
+    * Any other class, this function returns that class as is.
+    * Anything else, this function returns the unsubscripted :mod:`typing`
+      attribute dynamically retrieved by inspecting this hint's **object
+      representation** (i.e., the non-human-readable string returned by the
+      :func:`repr` builtin).
+
+    This getter is memoized for efficiency.
+
+    Motivation
+    ----------
+    Both :pep:`484` and the :mod:`typing` module implementing :pep:`484` are
+    functionally deficient with respect to their public APIs. Neither provide
+    external callers any means of deciding the categories of arbitrary
+    PEP-compliant type hints. For example, there exists no general-purpose
+    means of identifying a parametrized subtype (e.g., ``typing.List[int]``) as
+    a parametrization of its unparameterized base type (e.g., ``type.List``).
+    Thus this function, which "fills in the gaps" by implementing this
+    oversight.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    dict
+        Sign uniquely identifying this hint.
+
+    Raises
+    ------
+    BeartypeDecorHintPepException
+        If this hint is *not* PEP-compliant.
+
+    Examples
+    --------
+        >>> import typing
+        >>> from beartype._util.hint.pep.utilpepget import (
+        ...     get_hint_pep_sign_or_none)
+
+        >>> get_hint_pep_sign_or_none(typing.Any)
+        typing.Any
+        >>> get_hint_pep_sign_or_none(typing.Union[str, typing.Sequence[int]])
+        typing.Union
+
+        >>> T = typing.TypeVar('T')
+        >>> get_hint_pep_sign_or_none(T)
+        HintSignTypeVar
+
+        >>> class Genericity(typing.Generic[T]): pass
+        >>> get_hint_pep_sign_or_none(Genericity)
+        HintSignGeneric
+
+        >>> class Duplicity(typing.Iterable[T], typing.Container[T]): pass
+        >>> get_hint_pep_sign_or_none(Duplicity)
+        HintSignGeneric
+    '''
+
+    # ..................{ IMPORTS                            }..................
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhintget import get_hint_repr
+
+    # ..................{ SYNOPSIS                           }..................
+    # For efficiency, this tester identifies the sign of this type hint with
+    # multiple phases performed in descending order of average time complexity
+    # (i.e., expected efficiency).
+    #
+    # Note that we intentionally avoid validating this type hint to be
+    # PEP-compliant (e.g., by calling the die_unless_hint_pep() validator).
+    # Why? Because this getter is the lowest-level hint validation function
+    # underlying all higher-level hint validation functions! Calling the latter
+    # here would thus induce infinite recursion, which would be very bad.
+
+    # ..................{ PHASE ~ classname                  }..................
+    # This phase attempts to map from the fully-qualified classname of this
+    # hint to a sign identifying *ALL* hints that are instances of that class.
+    #
+    # Since the "object.__class__.__qualname__" attribute is both guaranteed to
+    # exist and be efficiently accessible for all hints, this phase is the
+    # fastest and thus performed first. Although this phase identifies only a
+    # small subset of hints, those hints are extremely common.
+    #
+    # More importantly, some of these classes are implemented as maliciously
+    # masquerading as other classes entirely -- including __repr__() methods
+    # synthesizing erroneous machine-readable representations. To avoid false
+    # positives, this phase *MUST* thus be performed before repr()-based tests
+    # regardless of efficiency concerns: e.g.,
+    #     # Under Python >= 3.10:
+    #     >>> import typing
+    #     >>> bad_guy_type_hint = typing.NewType('List', bool)
+    #     >>> bad_guy_type_hint.__module__ = 'typing'
+    #     >>> repr(bad_guy_type_hint)
+    #     typing.List   # <---- this is genuine bollocks
+    #
+    # Likewise, some of these classes define __repr__() methods prefixed by the
+    # machine-readable representations of their children. Again, to avoid false
+    # positives, this phase *MUST* thus be performed before repr()-based tests
+    # regardless of efficiency concerns: e.g.,
+    #     # Under Python >= 3.10:
+    #     >>> repr(tuple[str, ...] | bool)
+    #     tuple[str, ...] | bool  # <---- this is fine but *NOT* a tuple!
+
+    # Class of this hint.
+    hint_type = hint.__class__
+
+    #FIXME: Is this actually the case? Do non-physical classes dynamically
+    #defined at runtime actually define these dunder attributes as well?
+    # Fully-qualified name of this class. Note that *ALL* classes are
+    # guaranteed to define the dunder attributes accessed here.
+    hint_type_name = f'{hint_type.__module__}.{hint_type.__qualname__}'
+
+    # Sign identifying this hint if this hint is identifiable by its classname
+    # *OR* "None" otherwise.
+    hint_sign = HINT_TYPE_NAME_TO_SIGN.get(hint_type_name)
+
+    # If this hint is identifiable by its classname, return this sign.
+    if hint_sign:
+        return hint_sign
+    # Else, this hint is *NOT* identifiable by its classname.
+
+    # ..................{ PHASE ~ repr : str                 }..................
+    # This phase attempts to map from the unsubscripted machine-readable
+    # representation of this hint to a sign identifying *ALL* hints of that
+    # representation.
+    #
+    # Since doing so requires both calling the repr() builtin on this hint
+    # *AND* munging the string returned by that builtin, this phase is
+    # significantly slower than the prior phase and thus *NOT* performed first.
+    # Although slow, this phase identifies the largest subset of hints.
+
+    # Machine-readable representation of this hint.
+    hint_repr = get_hint_repr(hint)
+
+    # Parse this representation into:
+    # * "hint_repr_prefix", the substring of this representation preceding the
+    #   first "[" delimiter if this representation contains that delimiter *OR*
+    #   this representation as is otherwise.
+    # * "hint_repr_subscripted", the "[" delimiter if this representation
+    #   contains that delimiter *OR* the empty string otherwise.
+    #
+    # Note that the str.partition() method has been profiled to be the
+    # optimally efficient means of parsing trivial prefixes like these.
+    hint_repr_prefix, hint_repr_subscripted, _ = hint_repr.partition('[')
+
+    # Sign identifying this possibly unsubscripted hint if this hint is
+    # identifiable by its possibly unsubscripted representation *OR* "None".
+    hint_sign = HINT_REPR_PREFIX_ARGS_0_OR_MORE_TO_SIGN.get(hint_repr_prefix)
+
+    # If this hint is identifiable by its possibly unsubscripted
+    # representation, return this sign.
+    if hint_sign:
+        return hint_sign
+    # Else, this hint is *NOT* identifiable by its possibly unsubscripted
+    # representation.
+    #
+    # If this representation (and thus this hint) is subscripted...
+    elif hint_repr_subscripted:
+        # Sign identifying this necessarily subscripted hint if this hint is
+        # identifiable by its necessarily subscripted representation *OR*
+        # "None" otherwise.
+        hint_sign = HINT_REPR_PREFIX_ARGS_1_OR_MORE_TO_SIGN.get(
+            hint_repr_prefix)
+
+        # If this hint is identifiable by its necessarily subscripted
+        # representation, return this sign.
+        if hint_sign:
+            return hint_sign
+        # Else, this hint is *NOT* identifiable by its necessarily subscripted
+        # representation.
+
+        # # If this hint is inconsistent with respect to PEP 604-style new unions,
+        # # raise an exception. Although awkward, this is ultimately the ideal
+        # # location for this validation. Why? Because this validation:
+        # # * *ONLY* applies to hints permissible as items of PEP 604-compliant
+        # #   new unions; this means classes and subscripted generics. If this
+        # #   hint is identifiable by its classname, this hint is neither a class
+        # #   *NOR* subscripted generic. Since this hint is *NOT* identifiable by
+        # #   its classname, however, this hint could still be either a class *OR*
+        # #   subscripted generic. It's best not to ask.
+        # # * Does *NOT* apply to well-known type hints detected above (e.g.,
+        # #   those produced by Python itself, the standard library, and
+        # #   well-known third-party type hint factories), which are all
+        # #   guaranteed to be consistent with respect to PEP 604.
+        # die_if_hint_pep604_inconsistent(hint)
+    # Else, this representation (and thus this hint) is unsubscripted.
+
+    # ..................{ PHASE ~ repr : trie                }..................
+    # This phase attempts to (in order):
+    #
+    # 1. Split the unsubscripted machine-readable representation of this hint on
+    #    the "." delimiter into an iterable of module names.
+    # 2. Iteratively look up each such module name in a trie mapping from these
+    #    names to a sign identifying *ALL* hints in that module.
+    #
+    # Note that:
+    # * This phase is principally intended to ignore PEP-noncompliant type hints
+    #   defined by third-party packages in an efficient and robust manner. Well,
+    #   reasonably efficient and robust anyway. *sigh*
+    # * This phase must be performed *BEFORE* the subsequent phase that detects
+    #   generics. Generics defined in modules mapped by tries should
+    #   preferentially be identified as their module-specific signs rather than
+    #   as generics. (See the prior note.)
+    #
+    # Since doing so requires splitting a string and iterating over substrings,
+    # this phase is significantly slower than prior phases and thus performed
+    # almost last. Since this phase identifies an extremely small subset of
+    # hints, efficiency is (mostly) incidental.
+
+    # Iterable of module names split from the unsubscripted machine-readable
+    # representation of this hint. For example, doing so splits
+    # 'pandera.typing.DataFrame[DataFrameSchema()]' into
+    # '("pandera", "typing", "DataFrame",)'.
+    hint_repr_module_names = hint_repr_prefix.split('.')
+
+    # Possibly nested trie describing the current module name in this iterable.
+    hint_repr_module_name_trie = HINT_REPR_PREFIX_TRIE_ARGS_0_OR_MORE_TO_SIGN
+
+    # For each module name in this iterable...
+    for hint_repr_module_name in hint_repr_module_names:
+        # Possibly nested trie describing this module name in this iterable.
+        hint_repr_module_name_trie = hint_repr_module_name_trie.get(  # type: ignore
+            hint_repr_module_name)
+
+        # If this trie does *NOT* exist, this module is *NOT* mapped to a sign.
+        # In this case, immediately halt iteration.
+        if hint_repr_module_name_trie is None:
+            break
+        # Else, this trie exists. In this case, this module *MIGHT* be mapped to
+        # a sign. Further inspection is required, however.
+        #
+        # If this trie is actually a target sign, this module maps to this sign.
+        # In this case, return this sign.
+        elif hint_repr_module_name_trie.__class__ is HintSign:
+            return hint_repr_module_name_trie  # type: ignore[return-value]
+        # Else, this trie is another nested trie. In this case, continue
+        # iterating deeper into this trie.
+    # Else, this hint is *NOT* identified by a trie of module names.
+
+    # ..................{ PHASE ~ manual                     }..................
+    # This phase attempts to manually identify the signs of all hints *NOT*
+    # efficiently identifiably by the prior phases.
+    #
+    # For minor efficiency gains, the following tests are intentionally ordered
+    # in descending likelihood of a match.
+
+    # If this hint is a PEP 484- or 585-compliant generic (i.e., user-defined
+    # class superficially subclassing at least one PEP 484- or 585-compliant
+    # type hint), return that sign. However, note that:
+    # * Generics *CANNOT* be detected by the general-purpose logic performed
+    #   above, as the "typing.Generic" ABC does *NOT* define a __repr__()
+    #   dunder method returning a string prefixed by the "typing." substring.
+    #   Ergo, we necessarily detect generics with an explicit test instead.
+    # * *ALL* PEP 484-compliant generics and PEP 544-compliant protocols are
+    #   guaranteed by the "typing" module to subclass this ABC regardless of
+    #   whether those generics originally did so explicitly. How? By type
+    #   erasure, the gift that keeps on giving:
+    #     >>> import typing as t
+    #     >>> class MuhList(t.List): pass
+    #     >>> MuhList.__orig_bases__
+    #     (typing.List)
+    #     >>> MuhList.__mro__
+    #     (__main__.MuhList, list, typing.Generic, object)
+    # * *NO* PEP 585-compliant generics subclass this ABC unless those generics
+    #   are also either PEP 484- or 544-compliant. Indeed, PEP 585-compliant
+    #   generics subclass *NO* common superclass.
+    # * Generics are *NOT* necessarily classes, despite originally being
+    #   declared as classes. Although *MOST* generics are classes, some are
+    #   shockingly *NOT*: e.g.,
+    #       >>> from typing import Generic, TypeVar
+    #       >>> S = TypeVar('S')
+    #       >>> T = TypeVar('T')
+    #       >>> class MuhGeneric(Generic[S, T]): pass
+    #       >>> non_class_generic = MuhGeneric[S, T]
+    #       >>> isinstance(non_class_generic, type)
+    #       False
+    #
+    # Ergo, the "typing.Generic" ABC uniquely identifies many but *NOT* all
+    # generics. While non-ideal, the failure of PEP 585-compliant generics to
+    # subclass a common superclass leaves us with little alternative.
+    if is_hint_pep484585_generic(hint):
+        return HintSignGeneric
+    # Else, this hint is *NOT* a PEP 484- or 585-compliant generic.
+    #
+    # If this hint is a PEP 589-compliant typed dictionary, return that sign.
+    elif is_hint_pep589(hint):
+        return HintSignTypedDict
+    # Else, this hint is *NOT* a PEP 589-compliant typed dictionary.
+    #
+    # If the active Python interpreter targets Python < 3.10 (and thus defines
+    # PEP 484-compliant "NewType" type hints as closures returned by that
+    # function that are sufficiently dissimilar from all other type hints to
+    # require unique detection) *AND* this hint is such a hint, return the
+    # corresponding sign.
+    #
+    # Note that these hints *CANNOT* be detected by the general-purpose logic
+    # performed above, as the __repr__() dunder methods of the closures created
+    # and returned by the NewType() closure factory function return a standard
+    # representation rather than a string prefixed by "typing.": e.g.,
+    #     >>> import typing as t
+    #     >>> repr(t.NewType('FakeStr', str))
+    #     '<function NewType.<locals>.new_type at 0x7fca39388050>'
+    elif IS_PYTHON_AT_MOST_3_9 and is_hint_pep484_newtype_pre_python310(hint):
+        return HintSignNewType
+
+    # ..................{ ERROR                              }..................
+    # Else, this hint is unrecognized. In this case, this hint is of unknown
+    # third-party origin and provenance.
+
+    # If this hint is inconsistent with respect to PEP 604-style new unions,
+    # raise an exception. Although awkward, this is ultimately the ideal context
+    # for this validation. Why? Because this validation:
+    # * *ONLY* applies to hints permissible as items of PEP 604-compliant new
+    #   unions; this means classes and subscripted builtins. If this hint is
+    #   identifiable by its classname, this hint is neither a class *NOR* a
+    #   subscripted builtin. Since this hint is *NOT* identifiable by its
+    #   classname, however, this hint could still be either a class *OR*
+    #   subscripted builtin. It's best not to ask.
+    # * Does *NOT* apply to well-known type hints detected above (e.g., those
+    #   produced by Python itself, the standard library, and well-known
+    #   third-party type hint factories), which are all guaranteed to be
+    #   consistent with respect to PEP 604.
+    die_if_hint_pep604_inconsistent(hint)
+    # Else, this hint is consistent with respect to PEP 604-style new unions.
+
+    #FIXME: Unit test us up, please.
+    # If this hint is an unrecognized subscripted builtin type hint (i.e.,
+    # C-based type hint instantiated by subscripting a pure-Python origin class
+    # unrecognized by @beartype and thus PEP-noncompliant), return this sign.
+    # Examples include "os.PathLike[...]" and "weakref.weakref[...]" type hints.
+    #
+    # This is a last-ditch fallback preferable to merely returning "None", which
+    # conveys substantially less semantics and would imply this object to be an
+    # isinstanceable class, which subscripted builtin type hints are *NOT*.
+    if is_hint_pep585_builtin_subscripted(hint):
+        return HintSignPep585BuiltinSubscriptedUnknown
+    # Else, this hint is *NOT* an unrecognized subscripted builtin type hint.
+
+    # Return "None".
+    return None
+
+# ....................{ GETTERS ~ origin                   }....................
+def get_hint_pep_origin_or_none(hint: Any) -> Optional[Any]:
+    '''
+    **Unsafe origin object** (i.e., arbitrary object originating the passed
+    PEP-compliant type hint but *not* necessarily an isinstanceable class such
+    that all objects satisfying this hint are instances of this class)
+    originating this hint if this hint originates from an object *or*
+    :data:`None` otherwise (i.e., if this hint originates from *no* such
+    object).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **The high-level** :func:`get_hint_pep_origin_type_isinstanceable` getter
+    should always be called in lieu of this low-level function.** Whereas the
+    former is guaranteed to return either an isinstanceable class or
+    :data:`None`, this getter enjoys no such guarantees and instead returns an
+    arbitrary object that may or may not actually be an instanceable class.
+
+    If this getter *must* be called, **this getter should always be called in
+    lieu of attempting to directly access the low-level** ``__origin__``
+    **dunder attribute.** Various :mod:`typing` objects either fail to define
+    this attribute or define this attribute non-orthogonally, including objects:
+
+    * Failing to define this attribute altogether (e.g., :attr:`typing.Any`,
+      :attr:`typing.NoReturn`).
+    * Defining this attribute to be their unsubscripted :mod:`typing` type hint
+      factories (e.g., :attr:`typing.Optional`, :attr:`typing.Union`).
+    * Defining this attribute to be their actual origin types.
+
+    Since the :mod:`typing` module neither guarantees the existence of this
+    attribute nor imposes a uniform semantic on this attribute when defined,
+    that attribute is *not* safely directly accessible. Thus this getter, which
+    "fills in the gaps" by implementing this oversight.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[Any]
+        Either:
+
+        * If this hint originates from an arbitrary object, that object.
+        * Else, :data:`None`.
+
+    Examples
+    --------
+    .. code-block:: pycon
+
+       >>> import typing
+       >>> from beartype._util.hint.pep.utilpepget import (
+       ...     get_hint_pep_origin_or_none)
+
+       # This is sane.
+       >>> get_hint_pep_origin_or_none(typing.List)
+       list
+       >>> get_hint_pep_origin_or_none(typing.List[int])
+       list
+       >>> get_hint_pep_origin_or_none(typing.Union)
+       None
+       >>> get_hint_pep_origin_or_none(typing.Union[int])
+       None
+
+       # This is insane.
+       >>> get_hint_pep_origin_or_none(typing.Union[int, str])
+       Union
+
+       # This is crazy.
+       >>> typing.Union.__origin__
+       AttributeError: '_SpecialForm' object has no attribute '__origin__'
+
+       # This is balls crazy.
+       >>> typing.Union[int].__origin__
+       AttributeError: type object 'int' has no attribute '__origin__'
+
+       # This is balls cray-cray -- the ultimate evolution of crazy.
+       >>> typing.Union[int, str].__origin__
+       typing.Union
+    '''
+
+    # Return this hint's origin object if any *OR* "None" otherwise.
+    return getattr(hint, '__origin__', None)
+
+# ....................{ GETTERS ~ origin : type            }....................
+#FIXME: Unit test us up, please.
+def get_hint_pep_origin_type(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    #FIXME: This should probably be a new "BeartypeDecorHintPepOriginException"
+    #type, instead. But it's unclear whether users will even ever see this
+    #exception. So, for now, laziness prevails. Huzzah! *sigh*
+    exception_cls: TypeException = _BeartypeUtilTypeException,
+    exception_prefix: str = '',
+) -> type:
+    '''
+    **Origin type** (i.e., class such that *all* objects satisfying the passed
+    PEP-compliant type hint are instances of this class) originating this hint
+    if this hint originates from such a type *or* raise an exception otherwise
+    (i.e., if this hint does *not* originate from such a type).
+
+    This getter is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+    exception_cls : TypeException, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilTypeException`.
+    exception_prefix : str, optional
+        Human-readable substring prefixing the representation of this object in
+        the exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    type
+        Type originating this hint.
+
+    Raises
+    -------
+    exception_cls
+        If this hint either:
+
+        * Does *not* originate from another object.
+        * Originates from an object that is *not* a type.
+
+    See Also
+    --------
+    :func:`.get_hint_pep_origin_or_none`
+        Further details.
+    '''
+
+    # Origin type originating this hint if any *OR* "None" otherwise.
+    hint_origin = get_hint_pep_origin_type_or_none(hint)
+
+    # If *NO* origin type originates this hint...
+    if hint_origin is None:
+        assert isinstance(exception_cls, type), (
+            f'{exception_cls} not exception type.')
+        assert isinstance(exception_prefix, str), (
+            f'{exception_prefix} not string.')
+
+        # Origin non-type originating this hint if any *OR* "None" otherwise.
+        hint_origin = get_hint_pep_origin_or_none(hint)
+
+        # If this hint does *NOT* originate from another object, raise an
+        # appropriate exception.
+        if hint_origin is None:
+            raise exception_cls(
+                f'{exception_prefix}type hint {repr(hint)} '
+                f'originates from no other object.'
+            )
+        # Else, this hint originates from another object. By definition, this
+        # object *CANNOT* be a type.
+
+        # Raise an appropriate exception.
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} '
+            f'originates from non-type {repr(hint_origin)}.'
+        )
+    # Else, this origin type originates this hint.
+
+    # Return this origin type.
+    return hint_origin
+
+
+#FIXME: Unit test us up, please.
+@callable_cached
+def get_hint_pep_origin_type_or_none(hint: Any) -> Optional[type]:
+    '''
+    **Origin type** (i.e., class such that *all* objects satisfying the passed
+    PEP-compliant type hint are instances of this class) originating this hint
+    if this hint originates from such a type *or* :data:`None` otherwise (i.e.,
+    if this hint does *not* originate from such a type).
+
+    This getter is memoized for efficiency.
+
+    Caveats
+    -------
+    **This high-level getter should always be called in lieu of the low-level**
+    :func:`get_hint_pep_origin_or_none` **getter on attempting to
+    directly access the low-level** ``__origin__`` **dunder attribute.**
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    Optional[type]
+        Either:
+
+        * If this hint originates from a type, that type.
+        * Else, :data:`None`.
+
+    See Also
+    --------
+    :func:`.get_hint_pep_origin_or_none`
+        Further details.
+    '''
+
+    # Origin type originating this hint if any *OR* "None" otherwise,
+    # initialized to the arbitrary object set as the "hint.__origin__" dunder
+    # attribute if this hint defines that attribute.
+    hint_origin: Optional[type] = get_hint_pep_origin_or_none(hint)  # type: ignore[assignment]
+
+    # If this origin is *NOT* a type...
+    #
+    # Ideally, this attribute would *ALWAYS* be a type for all possible
+    # PEP-compliant type hints. For unknown reasons, type hint factories defined
+    # by the standard "typing" module often set their origins to those same type
+    # hint factories, despite those factories *NOT* being types. Why? Frankly,
+    # we have no idea and neither does anyone else. Behold, true horror:
+    #    >>> import typing
+    #    >>> typing.Literal[1, 2].__origin__
+    #    typing.Literal  # <-- do you even know what you are doing, python?
+    #    >>> typing.Optional[int].__origin__
+    #    typing.Union  # <-- wut? this is insane, python.
+    if not isinstance(hint_origin, type):
+        # Default this origin type to either...
+        hint_origin = (
+            # If this hint is itself a type, this hint could be euphemistically
+            # said to originate from "itself." In this case, this hint.
+            #
+            # Look. Just go with it. We wave our hands in the air.
+            hint if isinstance(hint, type) else
+            # Else, this hint is *NOT* a type. Default to "None". No choice, yo!
+            None
+        )
+    # Else, this origin is a type.
+
+    # Return this origin type.
+    return hint_origin
+
+
+#FIXME: Is this even required or desired anymore? Can't we just replace all
+#calls to this frankly non-ideal getter with calls to a dramatically superior
+#get_hint_pep_origin_type() getter? Excise us up, please.
+def get_hint_pep_origin_type_isinstanceable(hint: object) -> type:
+    '''
+    **Isinstanceable origin type** (i.e., class passable as the second argument
+    to the :func:`isinstance` builtin such that *all* objects satisfying the
+    passed PEP-compliant type hint are instances of this class) originating
+    this hint if this hint originates from such a type *or* raise an exception
+    otherwise (i.e., if this hint does *not* originate from such a type).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    type
+        Standard origin type originating this hint.
+
+    Raises
+    ------
+    BeartypeDecorHintPepException
+        If this hint does *not* originate from a standard origin type.
+
+    See Also
+    --------
+    :func:`get_hint_pep_origin_type_isinstanceable_or_none`
+        Related getter.
+    '''
+
+    # Origin type originating this object if any *OR* "None" otherwise.
+    hint_origin_type = get_hint_pep_origin_type_isinstanceable_or_none(hint)
+
+    # If this type does *NOT* exist, raise an exception.
+    if hint_origin_type is None:
+        raise BeartypeDecorHintPepException(
+            f'Type hint {repr(hint)} not isinstanceable (i.e., does not '
+            f'originate from isinstanceable class).'
+        )
+    # Else, this type exists.
+
+    # Return this type.
+    return hint_origin_type
+
+
+#FIXME: Is this even required or desired anymore? Can't we just replace all
+#calls to this frankly non-ideal getter with calls to the dramatically superior
+#get_hint_pep_origin_type_or_none() getter? Excise us up, please.
+def get_hint_pep_origin_type_isinstanceable_or_none(
+    hint: Any) -> Optional[type]:
+    '''
+    **Standard origin type** (i.e., isinstanceable class declared by Python's
+    standard library such that *all* objects satisfying the passed
+    PEP-compliant type hint are instances of this class) originating this hint
+    if this hint originates from such a type *or* :data:`None` otherwise (i.e.,
+    if this hint does *not* originate from such a type).
+
+    This getter is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **This high-level getter should always be called in lieu of the low-level**
+    :func:`get_hint_pep_origin_or_none` **getter or attempting to
+    directly access the low-level** ``__origin__`` **dunder attribute.**
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[type]
+        Either:
+
+        * If this hint originates from a standard origin type, that type.
+        * Else, :data:`None`.
+
+    See Also
+    --------
+    :func:`get_hint_pep_origin_type_isinstanceable`
+        Related getter.
+    :func:`get_hint_pep_origin_or_none`
+        Further details.
+    '''
+
+    # Sign uniquely identifying this hint if any *OR* "None" otherwise.
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # Return either...
+    return (
+        # If this sign originates from an origin type, that type;
+        get_hint_pep_origin_or_none(hint)
+        if hint_sign in HINT_SIGNS_ORIGIN_ISINSTANCEABLE else
+        # Else, "None".
+        None
+    )
+
+# ....................{ PRIVATE ~ args                     }....................
+_HINT_ARGS_EMPTY_TUPLE = ((),)
+'''
+Tuple containing only the empty tuple, to be returned from the
+:func:`get_hint_pep_args` getter when passed either:
+
+* A :pep:`585`-compliant type hint subscripted by the empty tuple (e.g.,
+  ``tuple[()]``).
+* A :pep:`484`-compliant type hint subscripted by the empty tuple (e.g.,
+  ``typing.Tuple[()]``) under Python >= 3.11, which applied the :pep:`585`
+  approach throughout the :mod:`typing` module.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/utilpepreduce.py
@@ -0,0 +1,100 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-compliant type hint reducer** (i.e., callable converting a
+PEP-compliant type hint satisfying various constraints into another
+PEP-compliant type hint) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+# from beartype._data.hint.datahinttyping import (
+#     Pep484TowerComplex,
+#     Pep484TowerFloat,
+# )
+from beartype._conf.confcls import BeartypeConf
+from beartype._util.hint.utilhinttest import die_unless_hint
+
+# ....................{ REDUCERS                           }....................
+def reduce_hint_pep_unsigned(
+    hint: object,
+    conf: BeartypeConf,
+    exception_prefix: str,
+    **kwargs
+) -> object:
+    '''
+    Reduce the passed **unsigned PEP-compliant type hint** (i.e., type hint
+    compliant with standards but identified by *no* sign, implying this hint to
+    almost certainly be an isinstanceable type) if this hint satisfies various
+    conditions to another (possibly signed) PEP-compliant type hint.
+
+    Specifically:
+
+    * If the passed configuration enables support for the :pep:`484`-compliant
+      implicit numeric tower *and* this hint is:
+
+      * The builtin :class:`float` type, this reducer expands this type to the
+        ``float | int`` union of types.
+      * The builtin :class:`complex` type, this reducer expands this type to the
+        ``complex | float | int`` union of types.
+
+    This reducer is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Final type hint to be reduced.
+    exception_prefix : str
+        Human-readable label prefixing the representation of this object in the
+        exception message.
+
+    All remaining passed arguments are silently ignored.
+
+    Returns
+    -------
+    object
+        PEP-compliant type hint reduced from this... PEP-compliant type hint.
+    '''
+
+    # FIXME: Preserved in perpetuity. Although currently unused, this logic will
+    # probably be desired again at some point. *shrug*
+    # assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+    #
+    # # If...
+    # if (
+    #     # This configuration enables support for the PEP 484-compliant
+    #     # implicit numeric tower *AND*...
+    #     conf.is_pep484_tower and
+    #     # This hint is either the builtin "float" or "complex" classes
+    #     # governed by this tower...
+    #     (hint is float or hint is complex)
+    # # Then expand this hint to the corresponding numeric tower.
+    # ):
+    #     # Expand this hint to match...
+    #     hint = (
+    #         # If this hint is the builtin "float" class, both the builtin
+    #         # "float" and "int" classes;
+    #         Pep484TowerFloat
+    #         if hint is float else
+    #         # Else, this hint is the builtin "complex" class by the above
+    #         # condition; in this case, the builtin "complex", "float", and
+    #         # "int" classes.
+    #         Pep484TowerComplex
+    #     )
+    # # Else, this hint is truly unidentifiable.
+    # else:
+
+    # If this hint is *NOT* a valid type hint, raise an exception.
+    #
+    # Note this function call is effectively memoized and thus fast.
+    die_unless_hint(hint=hint, exception_prefix=exception_prefix)
+    # Else, this hint is a valid type hint.
+
+    # Return this hint as is unmodified.
+    return hint
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/pep/utilpeptest.py
@@ -0,0 +1,831 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-compliant type hint tester** (i.e., callable validating an
+arbitrary object to be a PEP-compliant type hint) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeDecorHintPepException,
+    BeartypeDecorHintPepUnsupportedException,
+    BeartypeDecorHintPep484Exception,
+)
+from beartype.typing import (
+    Dict,
+    NoReturn,
+)
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignAnnotated,
+    HintSignGeneric,
+    HintSignOptional,
+    HintSignNewType,
+    HintSignPep695TypeAlias,
+    HintSignProtocol,
+    HintSignTypeVar,
+    HintSignUnion,
+)
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_SUPPORTED,
+    HINT_SIGNS_TYPE_MIMIC,
+)
+from beartype._data.module.datamodtyping import TYPING_MODULE_NAMES
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.hint.pep.proposal.pep484.utilpep484 import (
+    is_hint_pep484_typevar_ignorable,
+    is_hint_pep484585_generic_ignorable,
+    is_hint_pep484604_union_ignorable,
+)
+from beartype._util.hint.pep.proposal.pep484.utilpep484newtype import (
+    is_hint_pep484_newtype_ignorable)
+from beartype._util.hint.pep.proposal.utilpep544 import is_hint_pep544_ignorable
+from beartype._util.hint.pep.proposal.utilpep593 import is_hint_pep593_ignorable
+from beartype._util.hint.pep.proposal.utilpep695 import is_hint_pep695_ignorable
+from beartype._util.module.utilmodget import get_object_module_name_or_none
+from beartype._util.utilobject import get_object_type_unless_type
+from collections.abc import Callable
+
+# ....................{ EXCEPTIONS                         }....................
+def die_if_hint_pep(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPepException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception of the passed type if the passed object is a
+    **PEP-compliant type hint** (i.e., :mod:`beartype`-agnostic annotation
+    compliant with annotation-centric PEPs).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_cls : Type[Exception], optional
+        Type of the exception to be raised by this function. Defaults to
+        :exc:`.BeartypeDecorHintPepException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is a PEP-compliant type hint.
+    '''
+
+    # If this hint is PEP-compliant...
+    if is_hint_pep(hint):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not type.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        # Raise an exception of this class.
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} is PEP-compliant '
+            f'(e.g., rather than isinstanceable class).'
+        )
+
+
+def die_unless_hint_pep(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_cls: TypeException = BeartypeDecorHintPepException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **PEP-compliant type
+    hint** (i.e., :mod:`beartype`-agnostic annotation compliant with
+    annotation-centric PEPs).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_cls : Type[Exception], optional
+        Type of the exception to be raised by this function. Defaults to
+        :class:`.BeartypeDecorHintPepException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this object is *not* a PEP-compliant type hint.
+    '''
+
+    # If this hint is *NOT* PEP-compliant, raise an exception.
+    if not is_hint_pep(hint):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not type.')
+        assert isinstance(exception_prefix, str), (
+            f'{repr(exception_prefix)} not string.')
+
+        raise exception_cls(
+            f'{exception_prefix}type hint {repr(hint)} not PEP-compliant.')
+
+# ....................{ EXCEPTIONS ~ supported             }....................
+#FIXME: *DANGER.* This function makes beartype more fragile. Instead, refactor
+#all or most calls to this function into calls to the
+#warn_if_hint_pep_unsupported() function; then, consider excising this as well
+#as exception classes (e.g., "BeartypeDecorHintPepUnsupportedException").
+def die_if_hint_pep_unsupported(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception if the passed object is a **PEP-compliant unsupported
+    type hint** (i.e., :mod:`beartype`-agnostic annotation compliant with
+    annotation-centric PEPs currently *not* supported by the
+    :func:`beartype.beartype` decorator).
+
+    This validator is effectively (but technically *not*) memoized. See the
+    :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+
+    Caveats
+    -------
+    **This validator only shallowly validates this object.** If this object is a
+    subscripted PEP-compliant type hint (e.g., ``Union[str, List[int]]``), this
+    validator ignores all subscripted arguments (e.g., ``List[int]``) on this
+    hint and may thus return false positives for hints that are directly
+    supported but whose subscripted arguments are not. To deeply validate this
+    object, iteratively call this validator during a recursive traversal (such
+    as a breadth-first search) over each subscripted argument of this object.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPepException
+        If this object is *not* a PEP-compliant type hint.
+    BeartypeDecorHintPepUnsupportedException
+        If this object is a PEP-compliant type hint but is currently
+        unsupported by the :func:`beartype.beartype` decorator.
+    BeartypeDecorHintPep484Exception
+        If this object is the PEP-compliant :attr:`typing.NoReturn` type hint,
+        which is contextually valid in only a single use case and thus
+        supported externally by the :mod:`beartype._decor.wrap.wrapmain`
+        submodule rather than with general-purpose automation.
+    '''
+
+    # If this object is a supported PEP-compliant type hint, reduce to a noop.
+    #
+    # Note that this memoized call is intentionally passed positional rather
+    # than keyword parameters to maximize efficiency.
+    if is_hint_pep_supported(hint):
+        return
+    # Else, this object is *NOT* a supported PEP-compliant type hint. In this
+    # case, subsequent logic raises an exception specific to the passed
+    # parameters.
+
+    # If this hint is *NOT* PEP-compliant, raise an exception.
+    die_unless_hint_pep(hint=hint, exception_prefix=exception_prefix)
+    assert isinstance(exception_prefix, str), (
+        f'{repr(exception_prefix)} not string.')
+
+    # Else, this hint is PEP-compliant.
+    #
+    # If this is the PEP 484-compliant "typing.NoReturn" type hint permitted
+    # *ONLY* as a return annotation, raise an exception specific to this hint.
+    if hint is NoReturn:
+        raise BeartypeDecorHintPep484Exception(
+            f'{exception_prefix}PEP 484 type hint "{repr(hint)}" '
+            f'invalid in this type hint context (i.e., '
+            f'"{repr(hint)}" valid only as non-nested return annotation).'
+        )
+    # Else, this is any PEP-compliant type hint other than "typing.NoReturn".
+
+    # In this case, raise a general-purpose exception.
+    #
+    # Note that, by definition, the sign uniquely identifying this hint *SHOULD*
+    # be in the "HINT_SIGNS_SUPPORTED" set. Regardless of whether it is or not,
+    # we raise a similar exception in either case. Ergo, there is *NO* practical
+    # benefit to validating that expectation here.
+    raise BeartypeDecorHintPepUnsupportedException(
+        f'{exception_prefix}type hint {repr(hint)} '
+        f'currently unsupported by @beartype.'
+    )
+
+# ....................{ WARNINGS                           }....................
+#FIXME: Unit test us up.
+#FIXME: Actually use us in place of die_if_hint_pep_unsupported().
+#FIXME: Actually, it's unclear whether we still require or desire this. See
+#"_pephint" commentary for further details.
+# def warn_if_hint_pep_unsupported(
+#     # Mandatory parameters.
+#     hint: object,
+#
+#     # Optional parameters.
+#     exception_prefix: str = 'Annotated',
+# ) -> bool:
+#     '''
+#     Return ``True`` and emit a non-fatal warning only if the passed object is a
+#     **PEP-compliant unsupported type hint** (i.e., :mod:`beartype`-agnostic
+#     annotation compliant with annotation-centric PEPs currently *not* supported
+#     by the :func:`beartype.beartype` decorator).
+#
+#     This validator is effectively (but technically *not*) memoized. See the
+#     :func:`beartype._util.hint.utilhinttest.die_unless_hint` validator.
+#
+#     Parameters
+#     ----------
+#     hint : object
+#         Object to be validated.
+#     exception_prefix : Optional[str]
+#         Human-readable label prefixing this object's representation in the
+#         warning message emitted by this function. Defaults to the empty string.
+#
+#     Returns
+#     ----------
+#     bool
+#         ``True`` only if this PEP-compliant type hint is currently supported by
+#         that decorator.
+#
+#     Raises
+#     ----------
+#     BeartypeDecorHintPepException
+#         If this object is *not* a PEP-compliant type hint.
+#
+#     Warnings
+#     ----------
+#     BeartypeDecorHintPepUnsupportedWarning
+#         If this object is a PEP-compliant type hint currently unsupported by
+#         that decorator.
+#     '''
+#
+#     # True only if this object is a supported PEP-compliant type hint.
+#     #
+#     # Note that this memoized call is intentionally passed positional rather
+#     # than keyword parameters to maximize efficiency.
+#     is_hint_pep_supported_test = is_hint_pep_supported(hint)
+#
+#     # If this object is an unsupported PEP-compliant type hint...
+#     if not is_hint_pep_supported_test:
+#         assert isinstance(exception_prefix, str), f'{repr(exception_prefix)} not string.'
+#
+#         # If this hint is *NOT* PEP-compliant, raise an exception.
+#         die_unless_hint_pep(hint=hint, exception_prefix=exception_prefix)
+#
+#         # Else, this hint is PEP-compliant. In this case, emit a warning.
+#         warn(
+#             (
+#                 f'{exception_prefix}PEP type hint {repr(hint)} '
+#                 f'currently unsupported by @beartype.'
+#             ),
+#             BeartypeDecorHintPepUnsupportedWarning
+#         )
+#
+#     # Return true only if this object is a supported PEP-compliant type hint.
+#     return is_hint_pep_supported_test
+
+# ....................{ TESTERS                            }....................
+def is_hint_pep(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a **PEP-compliant type hint**
+    (i.e., object either directly defined by the :mod:`typing` module *or* whose
+    type subclasses one or more classes directly defined by the :mod:`typing`
+    module).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Motivation
+    ----------
+    Standard Python types allow callers to test for compliance with protocols,
+    interfaces, and abstract base classes by calling either the
+    :func:`isinstance` or :func:`issubclass` builtins. This is the
+    well-established Pythonic standard for deciding conformance to an API.
+
+    Insanely, :pep:`484` *and* the :mod:`typing` module implementing :pep:`484`
+    reject community standards by explicitly preventing callers from calling
+    either the :func:`isinstance` or :func:`issubclass` builtins on most but
+    *not* all :pep:`484` objects and types. Moreover, neither :pep:`484` nor
+    :mod:`typing` implement public APIs for testing whether arbitrary objects
+    comply with :pep:`484` or :mod:`typing`.
+
+    Thus this function, which "fills in the gaps" by implementing this
+    laughably critical oversight.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a PEP-compliant type hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_sign_or_none)
+
+    # Sign uniquely identifying this hint if this hint is PEP-compliant *OR*
+    # "None" otherwise (i.e., if this hint is *NOT* PEP-compliant).
+    hint_sign = get_hint_pep_sign_or_none(hint)
+    # print(f'hint: {repr(hint)}; sign: {repr(hint_sign)}')
+
+    # Return true *ONLY* if this hint is uniquely identified by a sign and thus
+    # PEP-compliant.
+    return hint_sign is not None
+
+
+#FIXME: Currently unused but preserved for posterity. *shrug*
+# def is_hint_pep_deprecated(hint: object) -> bool:
+#     '''
+#     :data:`True` only if the passed PEP-compliant type hint is **deprecated**
+#     (i.e., obsoleted by an equivalent PEP-compliant type hint standardized by a
+#     more recently released PEP).
+#
+#     This tester is intentionally *not* memoized (e.g., by the
+#     ``callable_cached`` decorator), as this tester is currently *only* called at
+#     test time from our test suite.
+#
+#     Parameters
+#     ----------
+#     hint : object
+#         PEP-compliant type hint to be inspected.
+#
+#     Returns
+#     -------
+#     bool
+#         :data:`True` only if this PEP-compliant type hint is deprecated.
+#     '''
+#
+#     # Avoid circular import dependencies.
+#     from beartype._util.hint.pep.utilpepget import get_hint_pep_sign
+#
+#     # Sign uniquely identifying this hint.
+#     hint_sign = get_hint_pep_sign(hint)
+#
+#     # Return true only if either...
+#     return (
+#         # This sign is that of an unconditionally deprecated type hint *OR*...
+#         hint_sign in HINT_SIGNS_DEPRECATED or
+#         # This is a PEP 484-compliant type hint (e.g., "typing.List[str]")
+#         # conditionally deprecated by an equivalent PEP 585-compliant type hint
+#         # (e.g., "list[str]") under Python >= 3.9.
+#         #
+#         # Note that, in this case, the sign of this hint does *NOT* convey
+#         # enough metadata to ascertain whether this hint is deprecated. Ergo, a
+#         # non-trivial tester dedicated to this discernment is required: e.g.,
+#         # * "list[str]" has the sign "HintSignList" but is *NOT* deprecated.
+#         # * "typing.List[str]" has the sign "HintSignList" but is deprecated.
+#         is_hint_pep484_deprecated(hint)
+#     )
+
+
+def is_hint_pep_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed PEP-compliant type hint is **deeply
+    ignorable** (i.e., shown to be ignorable only after recursively inspecting
+    the contents of this hint).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``callable_cached`` decorator), as this tester is only safely callable by
+    the memoized parent
+    :func:`beartype._util.hint.utilhinttest.is_hint_ignorable` tester.
+
+    Parameters
+    ----------
+    hint : object
+        PEP-compliant type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this PEP-compliant type hint is deeply ignorable.
+
+    Warns
+    -----
+    BeartypeDecorHintPepIgnorableDeepWarning
+        If this object is a deeply ignorable PEP-compliant type hint. Why?
+        Because deeply ignorable PEP-compliant type hints convey *no*
+        meaningful semantics but superficially appear to do so. Consider
+        ``Union[str, List[int], NewType('MetaType', Annotated[object, 53])]``,
+        for example; this PEP-compliant type hint effectively reduces to
+        :obj:`typing.Any` and thus conveys *no* meaningful semantics despite
+        superficially appearing to do so.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign
+    # print(f'Testing PEP hint {repr(hint)} deep ignorability...')
+
+    # Sign uniquely identifying this hint.
+    hint_sign = get_hint_pep_sign(hint)
+
+    # Ignorer (i.e., callable testing whether this hint is ignorable) if an
+    # ignorer for hints of this sign was registered *OR* "None" otherwise (i.e.,
+    # if *NO* ignorer was registered, in which case this hint is unignorable).
+    is_hint_ignorable = _HINT_SIGN_TO_IS_HINT_IGNORABLE.get(hint_sign)
+
+    # Return either...
+    return (
+        # If an ignorer for hints of this sign was registered, the boolean
+        # returned when passing this ignorer this hint);
+        is_hint_ignorable(hint)
+        if is_hint_ignorable else
+        # Else, *NO* ignorer for hints of this sign was registered, implying
+        # this hint to be unignorable. Return false.
+        False
+    )
+
+
+@callable_cached
+def is_hint_pep_supported(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a **PEP-compliant supported type
+    hint** (i.e., :mod:`beartype`-agnostic annotation compliant with
+    annotation-centric PEPs currently supported by the
+    :func:`beartype.beartype` decorator).
+
+    This tester is memoized for efficiency.
+
+    Caveats
+    -------
+    **This tester only shallowly inspects this object.** If this object is a
+    subscripted PEP-compliant type hint (e.g., ``Union[str, List[int]]``), this
+    tester ignores all subscripted arguments (e.g., ``List[int]``) on this hint
+    and may thus return false positives for hints that are directly supported
+    but whose subscripted arguments are not.
+
+    To deeply inspect this object, iteratively call this tester during a
+    recursive traversal over each subscripted argument of this object.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a supported PEP-compliant type hint.
+    '''
+
+    # If this hint is *NOT* PEP-compliant, immediately return false.
+    if not is_hint_pep(hint):
+        return False
+    # Else, this hint is PEP-compliant.
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_sign
+
+    # Sign uniquely identifying this hint.
+    hint_sign = get_hint_pep_sign(hint)
+
+    # Return true only if this sign is supported.
+    return hint_sign in HINT_SIGNS_SUPPORTED
+
+# ....................{ TESTERS ~ typing                   }....................
+#FIXME: Replace all hardcoded "'typing" strings throughout the codebase with
+#access of "TYPING_MODULE_NAMES" instead. We only see one remaining in:
+#* beartype._util.hint.pep.proposal.pep484.utilpep484.py
+#Thankfully, nobody really cares about generalizing this one edge case to
+#"testing_extensions", so it's mostly fine for various definitions of fine.
+@callable_cached
+def is_hint_pep_typing(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is an attribute of a **typing
+    module** (i.e., module officially declaring attributes usable for creating
+    PEP-compliant type hints accepted by both static and runtime type checkers).
+
+    This tester is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is an attribute of a typing module.
+    '''
+    # print(f'is_hint_pep_typing({repr(hint)}')
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import (
+        get_hint_pep_sign_or_none)
+
+    # Return true only if this hint is either...
+    return (
+        # Any PEP-compliant type hint defined by a typing module (except those
+        # maliciously masquerading as another type entirely) *OR*...
+        get_object_module_name_or_none(hint) in TYPING_MODULE_NAMES or
+        # Any PEP-compliant type hint defined by a typing module maliciously
+        # masquerading as another type entirely.
+        get_hint_pep_sign_or_none(hint) in HINT_SIGNS_TYPE_MIMIC
+    )
+
+
+def is_hint_pep_type_typing(hint: object) -> bool:
+    '''
+    :data:`True` only if either the passed object is defined by a **typing
+    module** (i.e., module officially declaring attributes usable for creating
+    PEP-compliant type hints accepted by both static and runtime type checkers)
+    if this object is a class *or* the class of this object is defined by a
+    typing module otherwise (i.e., if this object is *not* a class).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`.callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if either:
+
+        * If this object is a class, this class is defined by a typing module.
+        * Else, the class of this object is defined by a typing module.
+    '''
+
+    # This hint if this hint is a class *OR* this hint's class otherwise.
+    hint_type = get_object_type_unless_type(hint)
+    # print(f'pep_type_typing({repr(hint)}): {get_object_module_name(hint_type)}')
+
+    # Return true only if this type is defined by a typing module.
+    #
+    # Note that this implementation could probably be reduced to the
+    # leading portion of the body of the get_hint_pep_sign_or_none()
+    # function testing this object's representation. While certainly more
+    # compact and convenient than the current approach, that refactored
+    # approach would also be considerably more fragile, failure-prone, and
+    # subject to whimsical "improvements" in the already overly hostile
+    # "typing" API. Why? Because the get_hint_pep_sign_or_none() function:
+    # * Parses the machine-readable string returned by the __repr__()
+    #   dunder method of "typing" types. Since that string is *NOT*
+    #   standardized by PEP 484 or any other PEP, "typing" authors remain
+    #   free to violate this pseudo-standard in any manner and at any time
+    #   of their choosing.
+    # * Suffers common edge cases for "typing" types whose __repr__()
+    #   dunder methods fail to comply with the non-standard implemented by
+    #   their sibling types. This includes the common "TypeVar" type.
+    # * Calls this tester function to decide whether the passed object is a
+    #   PEP-compliant type hint or not before subjecting that object to
+    #   further introspection, which would clearly complicate implementing
+    #   this tester function in terms of that getter function.
+    #
+    # In contrast, the current approach only tests the standard
+    # "__module__" dunder attribute and is thus significantly more robust
+    # against whimsical destruction by "typing" authors. Note that there
+    # might exist an alternate means of deciding this boolean, documented
+    # here merely for completeness:
+    #     try:
+    #         isinstance(obj, object)
+    #         return False
+    #     except TypeError as type_error:
+    #         return str(type_error).endswith(
+    #             'cannot be used with isinstance()')
+    #
+    # The above effectively implements an Aikido throw by using the fact
+    # that "typing" types prohibit isinstance() calls against those types.
+    # While clever (and deliciously obnoxious), the above logic:
+    # * Requires catching exceptions in the common case and is thus *MUCH*
+    #   less efficient than the preferable approach implemented here.
+    # * Assumes that *ALL* "typing" types prohibit such calls. Sadly, only
+    #   a proper subset of these types prohibit such calls.
+    # * Assumes that those "typing" types that do prohibit such calls raise
+    #   exceptions with reliable messages across *ALL* Python versions.
+    #
+    # In short, there is no general-purpose clever solution. *sigh*
+    return hint_type.__module__ in TYPING_MODULE_NAMES
+
+# ....................{ TESTERS ~ args                     }....................
+#FIXME: Overkill. Replace directly with a simple test, please.
+#
+#Note that the corresponding unit test should be preserved, as that test is
+#essential to ensuring sanity across type hints and Python versions.
+def is_hint_pep_args(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a **subscripted PEP-compliant type
+    hint** (i.e., PEP-compliant type hint directly indexed by one or more
+    objects).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`.callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Caveats
+    -------
+    **Callers should not assume that the objects originally subscripting this
+    hint are still accessible.** Although *most* hints preserve their
+    subscripted objects over their lifetimes, a small subset of edge-case hints
+    erase those objects at subscription time. This includes:
+
+    * :pep:`585`-compliant empty tuple type hints (i.e., ``tuple[()]``), which
+      despite being explicitly subscripted erroneously erase that subscription
+      at subscription time. This does *not* extend to :pep:`484`-compliant
+      empty tuple type hints (i.e., ``typing.Tuple[()]``), which correctly
+      preserve that subscripted empty tuple.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a subscripted PEP-compliant type
+        hint.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_args
+
+    # Return true only if this hint is subscripted by one or more arguments.
+    return bool(get_hint_pep_args(hint))
+
+# ....................{ TESTERS ~ typevars                 }....................
+#FIXME: Overkill. Replace directly with a simple test, please.
+#
+#Note that the corresponding unit test should be preserved, as that test is
+#essential to ensuring sanity across type hints and Python versions.
+def is_hint_pep_typevars(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a PEP-compliant type hint
+    parametrized by one or more **type variables** (i.e., instances of the
+    :class:`TypeVar` class).
+
+    This tester detects both:
+
+    * **Direct parametrizations** (i.e., cases in which this object itself is
+      directly parametrized by type variables).
+    * **Superclass parametrizations** (i.e., cases in which this object is
+      indirectly parametrized by one or more superclasses of its class being
+      directly parametrized by type variables).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    :func:`callable_cached` decorator), as the implementation trivially reduces
+    to an efficient one-liner.
+
+    Semantics
+    ---------
+    **Generics** (i.e., PEP-compliant type hints whose classes subclass one or
+    more public :mod:`typing` pseudo-superclasses) are often but *not* always
+    typevared. For example, consider the untypevared generic:
+
+    .. code-block:: pycon
+
+       >>> from typing import List
+       >>> class UntypevaredGeneric(List[int]): pass
+       >>> UntypevaredGeneric.__mro__
+       (__main__.UntypevaredGeneric, list, typing.Generic, object)
+       >>> UntypevaredGeneric.__parameters__
+       ()
+
+    Likewise, typevared hints are often but *not* always generic. For example,
+    consider the typevared non-generic:
+
+    .. code-block:: pycon
+
+       >>> from typing import List, TypeVar
+       >>> TypevaredNongeneric = List[TypeVar('T')]
+       >>> type(TypevaredNongeneric).__mro__
+       (typing._GenericAlias, typing._Final, object)
+       >>> TypevaredNongeneric.__parameters__
+       (~T,)
+
+    Parameters
+    ----------
+    hint : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a PEP-compliant type hint
+        parametrized by one or more type variables.
+
+    Examples
+    --------
+    .. code-block:: pycon
+
+       >>> import typing
+       >>> from beartype._util.hint.pep.utilpeptest import (
+       ...     is_hint_pep_typevars)
+       >>> T = typing.TypeVar('T')
+       >>> class UserList(typing.List[T]): pass
+       # Unparametrized type hint.
+       >>> is_hint_pep_typevars(typing.List[int])
+       False
+       # Directly parametrized type hint.
+       >>> is_hint_pep_typevars(typing.List[T])
+       True
+       # Superclass-parametrized type hint.
+       >>> is_hint_pep_typevars(UserList)
+       True
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.utilpepget import get_hint_pep_typevars
+
+    # Return true only if this hint is parametrized by one or more type
+    # variables, trivially detected by testing whether the tuple of all type
+    # variables parametrizing this hint is non-empty.
+    return bool(get_hint_pep_typevars(hint))
+
+# ....................{ PRIVATE ~ dicts                    }....................
+# Note that this type hints would ideally be defined with the mypy-specific
+# "callback protocol" pseudostandard, documented here:
+#     https://mypy.readthedocs.io/en/stable/protocols.html#callback-protocols
+#
+# Doing so would enable static type-checkers to type-check that the values of
+# this dictionary are valid ignorer functions. Sadly, that pseudostandard is
+# absurdly strict to the point of practical uselessness. Attempting to conform
+# to that pseudostandard would require refactoring *ALL* ignorer functions to
+# explicitly define the same signature. However, we have intentionally *NOT*
+# done that. Why? Doing so would substantially increase the fragility of this
+# API by preventing us from readily adding and removing infrequently required
+# parameters (e.g., "cls_stack", "pith_name"). Callback protocols suck, frankly.
+_HINT_SIGN_TO_IS_HINT_IGNORABLE: Dict[HintSign, Callable] = {
+    # ..................{ PEP 484                            }..................
+    # Ignore *ALL* PEP 484-compliant "NewType"-style type aliases aliasing
+    # ignorable type hints.
+    HintSignNewType: is_hint_pep484_newtype_ignorable,
+
+    # Ignore *ALL* PEP 484-compliant type variables.
+    HintSignTypeVar: is_hint_pep484_typevar_ignorable,
+
+    # ..................{ PEP (484|585)                      }..................
+    # Ignore *ALL* PEP 484- and 585-compliant "Generic[...]" subscriptions.
+    HintSignGeneric: is_hint_pep484585_generic_ignorable,
+
+    # ..................{ PEP (484|604)                      }..................
+    # Ignore *ALL* PEP 484- and 604-compliant unions subscripted by one or more
+    # ignorable type hints.
+    HintSignOptional: is_hint_pep484604_union_ignorable,
+    HintSignUnion:    is_hint_pep484604_union_ignorable,
+
+    # ..................{ PEP 544                            }..................
+    # Ignore *ALL* PEP 544-compliant "typing.Protocol[...]" subscriptions.
+    HintSignProtocol: is_hint_pep544_ignorable,
+
+    # ..................{ PEP 593                            }..................
+    # Ignore *ALL* PEP 593-compliant "typing.Annotated[...]" type hints except
+    # those indexed by one or more beartype validators.
+    HintSignAnnotated: is_hint_pep593_ignorable,
+
+    # ..................{ PEP 695                            }..................
+    # Ignore *ALL* PEP 695-compliant type aliases aliasing ignorable type hints.
+    HintSignPep695TypeAlias: is_hint_pep695_ignorable,
+}
+'''
+Dictionary mapping from each sign uniquely identifying PEP-compliant type hints
+to that sign's **ignorer** (i.e., low-level function testing whether the passed
+type hint identified by that sign is deeply ignorable).
+
+Each value of this dictionary is expected to have a signature resembling:
+
+.. code-block:: python
+
+   def is_hint_pep{pep_number}_ignorable(hint: object) -> bool: ...
+
+Note that:
+
+* Ignorers do *not* need to validate the passed type hint as being of the
+  expected sign. By design, an ignorer is only ever passed a type hint of the
+  expected sign.
+* Ignorers should *not* be memoized (e.g., by the
+  `callable_cached`` decorator). Since the higher-level
+  :func:`.is_hint_pep_ignorable` function that is the sole entry point to
+  calling all lower-level ignorers is itself effectively memoized, ignorers
+  themselves neither require nor benefit from memoization.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/utilhintfactory.py
@@ -0,0 +1,154 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **type hint factories** (i.e., low-level classes and callables
+dynamically creating and returning PEP-compliant type hints, typically as a
+runtime fallback when the currently installed versions of the standard
+:mod:`typing` module and third-party :mod:`typing_extensions` modules do *not*
+officially support those factories).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Generic,
+    Type,
+)
+from beartype._data.hint.datahinttyping import T
+from beartype._util.cache.utilcachecall import callable_cached
+
+# ....................{ METACLASSES                        }....................
+class _TypeHintTypeFactoryMeta(type):
+    '''
+    **Type hint type factory metaclass** (i.e., the root :class:`type` metaclass
+    augmented with caching to memoize singleton instances of the
+    :class:`TypeHintTypeFactory` class declared below).
+
+    This metaclass is superior to the usual approach of implementing the
+    singleton design pattern: overriding the :meth:`__new__` method of a
+    singleton class to conditionally create a new instance of that class only if
+    an instance has *not* already been created. Why? Because that approach
+    unavoidably re-calls the :meth:`__init__` method of a previously initialized
+    singleton instance on each instantiation of that class. Doing so is
+    generally considered harmful.
+
+    This metaclass instead guarantees that the :meth:`__init__` method of a
+    singleton instance is only called exactly once on the first instantiation of
+    that class.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    @callable_cached
+    def __call__(cls, type_factory: type) -> 'TypeHintTypeFactory':  # type: ignore[override]
+        '''
+        Instantiate the passed singleton class with the passed arbitrary type.
+
+        Parameters
+        ----------
+        cls : Type['TypeHintTypeFactory']
+            :class:`TypeHintTypeFactory` class to be instantiated.
+        type_factory : type
+            Arbitrary type to instantiate that class with.
+        '''
+
+        # Create and return a new memoized singleton instance of the
+        # "TypeHintTypeFactory" class specific to this arbitrary type.
+        return super().__call__(type_factory)
+
+# ....................{ CLASSES                            }....................
+class TypeHintTypeFactory(Generic[T], metaclass=_TypeHintTypeFactoryMeta):
+    '''
+    **Type hint type factory** (i.e., high-level object unconditionally
+    returning an arbitrary type when subscripted by any arbitrary object).
+
+    This factory is principally intended to serve as a graceful runtime fallback
+    when the currently installed versions of the standard :mod:`typing` module
+    and third-party :mod:`typing_extensions` modules do *not* declare the
+    desired PEP-compliant type hint factory. See the examples below.
+
+    Instances of this class are implicitly memoized as singletons as a
+    negligible space and time optimization that costs us nothing and gains us a
+    negligible something.
+
+    Examples
+    --------
+    Consider the :pep:`647`-compliant :attr:`typing.TypeGuard` type hint
+    factory, which is only available under Python >= 3.10 or from
+    :mod:`typing_extensions` if optionally installed; if neither of those two
+    conditions apply, this factory may be trivially used as a fake ``TypeGuard``
+    stand-in returning the builtin :class:`bool` type when subscripted --
+    exactly as advised by :pep:`647` itself: e.g.,
+
+    .. code-block:
+
+       from beartype.typing import TYPE_CHECKING
+       from beartype._util.hint.utilhintfactory import TypeHintTypeFactory
+       from beartype._util.api.utilapityping import (
+           import_typing_attr_or_fallback)
+
+       if TYPE_CHECKING:
+           from typing_extensions import TypeGuard
+       else:
+           TypeGuard = import_typing_attr_or_fallback(
+               'TypeGuard', TypeHintTypeFactory(bool))
+
+       # This signature gracefully reduces to the following at runtime under
+       # Python <= 3.10 if "typing_extensions" is *NOT* installed:
+       #     def is_obj_list(obj: object) -> bool:
+       def is_obj_list(obj: object) -> TypeGuard[list]:
+           return isinstance(obj, list)
+
+    Attributes
+    ----------
+    _type_factory : Type[T]
+        Arbitrary type to be returned from the :meth:`__getitem__` method.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # @beartype decorations. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_type_factory',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, type_factory: Type[T]) -> None:
+        '''
+        Initialize this type hint type factory.
+
+        Parameters
+        ----------
+        type_factory : Type[T]
+            Arbitrary type to be returned from the :meth:`__getitem__` method.
+        '''
+        assert isinstance(type_factory, type), f'{repr(type_factory)} not type.'
+
+        # Classify all passed parameters.
+        self._type_factory = type_factory
+
+    # ..................{ DUNDERS                            }..................
+    def __getitem__(self, index: object) -> Type[T]:
+        '''
+        Return the arbitrary type against which this type hint type factory was
+        originally initialized when subscripted by the passed arbitrary object.
+
+        Parameters
+        ----------
+        index : object
+            Arbitrary object. Although this is typically a PEP-compliant type
+            hint, this factory imposes *no* constraints on this object.
+
+        Returns
+        -------
+        Type[T]
+            Arbitrary type previously passed to the :meth:`__init__` method.
+        '''
+
+        # Return this type, silently ignoring the passed object entirely. Hah!
+        return self._type_factory
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/utilhintget.py
@@ -0,0 +1,57 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-agnostic type hint getter utilities** (i.e., callables
+validating querying type hints supported by :mod:`beartype`, regardless of
+whether those hints comply with PEP standards or not).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.pep.datapeprepr import HINTS_REPR_IGNORABLE_SHALLOW
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.hint.nonpep.utilnonpeptest import (
+    die_unless_hint_nonpep,
+    is_hint_nonpep,
+)
+from beartype._util.hint.pep.utilpeptest import (
+    die_if_hint_pep_unsupported,
+    is_hint_pep,
+    is_hint_pep_supported,
+)
+
+# ....................{ TESTERS                            }....................
+#FIXME: Call this getter everywhere we currently call "repr(hint*)", please.
+@callable_cached
+def get_hint_repr(hint: object) -> str:
+    '''
+    **Representation** (i.e., machine-readable string returned by the
+    :func:`repr` builtin when passed this hint) of this PEP-agnostic type hint.
+
+    This getter is memoized for efficiency. Indeed, since the implementation of
+    this getter trivially reduces to just ``repr(hint)``, memoization is the
+    entire reason for the existence of this getter.
+
+    Motivation
+    ----------
+    **This getter should always be called to efficiently obtain the
+    representation of any type hint.** The comparatively less efficient
+    :func:`repr` builtin should *never* be called to do so.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be represented.
+
+    Returns
+    ----------
+    str
+        Representation of this hint.
+    '''
+
+    # Return the machine-readable representation of this hint.
+    return repr(hint)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/hint/utilhinttest.py
@@ -0,0 +1,344 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **PEP-agnostic type hint tester utilities** (i.e., callables
+validating arbitrary objects to be type hints supported by :mod:`beartype`,
+regardless of whether those hints comply with PEP standards or not).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.pep.datapeprepr import HINTS_REPR_IGNORABLE_SHALLOW
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.hint.nonpep.utilnonpeptest import (
+    die_unless_hint_nonpep,
+    is_hint_nonpep,
+)
+from beartype._util.hint.pep.utilpeptest import (
+    die_if_hint_pep_unsupported,
+    is_hint_pep,
+    is_hint_pep_supported,
+)
+
+# ....................{ RAISERS                            }....................
+def die_unless_hint(
+    # Mandatory parameters.
+    hint: object,
+
+    # Optional parameters.
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed object is a **supported type hint**
+    (i.e., object supported by the :func:`beartype.beartype` decorator as a
+    valid type hint annotating callable parameters and return values).
+
+    Specifically, this function raises an exception if this object is neither:
+
+    * A **supported PEP-compliant type hint** (i.e., :mod:`beartype`-agnostic
+      annotation compliant with annotation-centric PEPs currently supported
+      by the :func:`beartype.beartype` decorator).
+    * A **PEP-noncompliant type hint** (i.e., :mod:`beartype`-specific
+      annotation intentionally *not* compliant with annotation-centric PEPs).
+
+    Efficiency
+    ----------
+    This validator is effectively (but technically *not*) memoized. The passed
+    ``exception_prefix`` parameter is usually unique to each call to this
+    validator; memoizing this validator would uselessly consume excess space
+    *without* improving time efficiency. Instead, this validator first calls the
+    memoized :func:`is_hint_pep` tester. If that tester returns ``True``, this
+    validator immediately returns ``True`` and is thus effectively memoized;
+    else, this validator inefficiently raises a human-readable exception without
+    memoization. Since efficiency is mostly irrelevant in exception handling,
+    this validator remains effectively memoized.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    BeartypeDecorHintPepUnsupportedException
+        If this object is a PEP-compliant type hint currently unsupported by
+        the :func:`beartype.beartype` decorator.
+    BeartypeDecorHintNonpepException
+        If this object is neither a:
+
+        * Supported PEP-compliant type hint.
+        * Supported PEP-noncompliant type hint.
+    '''
+
+    # If this object is a supported type hint, reduce to a noop.
+    if is_hint(hint):
+        return
+    # Else, this object is *NOT* a supported type hint. In this case,
+    # subsequent logic raises an exception specific to the passed parameters.
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with is_hint() below.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # If this hint is PEP-compliant *AND* currently unsupported by @beartype,
+    # raise an exception.
+    if is_hint_pep(hint):
+        die_if_hint_pep_unsupported(
+            hint=hint, exception_prefix=exception_prefix)
+    # Else, this hint is *NOT* PEP-compliant. In this case...
+
+    # If this PEP-noncompliant hint but still currently unsupported by
+    # @beartype, raise an exception.
+    die_unless_hint_nonpep(hint=hint, exception_prefix=exception_prefix)
+
+# ....................{ TESTERS                            }....................
+@callable_cached
+def is_hint(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a **supported type hint** (i.e.,
+    object supported by the :func:`beartype.beartype` decorator as a valid type
+    hint annotating callable parameters and return values).
+
+    This tester is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Object to be validated.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is either:
+
+        * A **PEP-compliant type hint** (i.e., :mod:`beartype`-agnostic
+          annotation compliant with annotation-centric PEPs).
+        * A **PEP-noncompliant type hint** (i.e., :mod:`beartype`-specific
+          annotation intentionally *not* compliant with annotation-centric
+          PEPs).
+
+    Raises
+    ------
+    TypeError
+        If this object is **unhashable** (i.e., *not* hashable by the builtin
+        :func:`hash` function and thus unusable in hash-based containers like
+        dictionaries and sets). All supported type hints are hashable.
+    '''
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # BEGIN: Synchronize changes here with die_unless_hint() above.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Return true only if...
+    return (
+        # This is a PEP-compliant type hint supported by @beartype *OR*...
+        is_hint_pep_supported(hint) if is_hint_pep(hint) else
+        # This is a PEP-noncompliant type hint, which by definition is
+        # necessarily supported by @beartype.
+        is_hint_nonpep(hint=hint, is_str_valid=True)
+    )
+
+
+@callable_cached
+def is_hint_ignorable(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed type hint is **ignorable** (i.e., conveys
+    *no* meaningful semantics despite superficially appearing to do so).
+
+    This tester is memoized for efficiency.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this type hint is ignorable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhintget import get_hint_repr
+
+    # Machine-readable representation of this hint.
+    hint_repr = get_hint_repr(hint)
+
+    # If this hint is shallowly ignorable, return true.
+    if hint_repr in HINTS_REPR_IGNORABLE_SHALLOW:
+        return True
+    # Else, this hint is *NOT* shallowly ignorable.
+    #
+    # If this hint is PEP-compliant...
+    elif is_hint_pep(hint):
+        # Avoid circular import dependencies.
+        from beartype._util.hint.pep.utilpeptest import (
+            is_hint_pep_ignorable)
+
+        # Defer to the function testing whether this hint is an ignorable
+        # PEP-compliant type hint.
+        return is_hint_pep_ignorable(hint)
+    # Else, this hint is PEP-noncompliant and thus *NOT* deeply ignorable.
+
+    # Since this hint is also *NOT* shallowly ignorable, this hint is
+    # unignorable. In this case, return false.
+    return False
+
+
+#FIXME: Unit test us up, please.
+def is_hint_uncached(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed type hint is **uncached** (i.e., hint *not*
+    already internally cached by its parent class or module).
+
+    Caveats
+    -------
+    This function *cannot* be meaningfully memoized, since the passed type hint
+    is *not* guaranteed to be cached somewhere. Only functions passed cached
+    type hints can be meaningfully memoized. Since this high-level function
+    internally defers to unmemoized low-level functions that are ``O(n)`` for
+    ``n`` the size of the inheritance hierarchy of this hint, this function
+    should be called sparingly.
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this type hint is uncached.
+
+    See Also
+    ----------
+    :func:`beartype._check.convert.convcoerce.coerce_hint_any`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.pep.proposal.utilpep585 import (
+        is_hint_pep585_builtin_subscripted)
+    from beartype._util.hint.pep.proposal.utilpep604 import is_hint_pep604
+
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Avoid detecting the kind of this hint by calling any of the
+    # get_hint_pep_sign_*() family of memoized getters. Doing so would consume
+    # excess time and space when this hint is uncached, as passing this hint to
+    # any of those getters would then cache against a hint that it is
+    # functionally useless to cache against.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Return true only if this hint is either...
+    return (
+        # PEP 585-compliant (e.g., "list[str]"), this hint is *NOT* self-caching
+        # (e.g., "list[str] is not list[str]").
+        #
+        # Note that this additionally includes all third-party type hints that
+        # derive from the "types.GenericAlias" superclass, including:
+        # * "numpy.typing.NDArray[...]" type hints.
+        is_hint_pep585_builtin_subscripted(hint) or
+        # PEP 604-compliant (e.g., "int | str"), this hint is *NOT* self-caching
+        # (e.g., "int | str is not int | str").
+        #
+        # Note that this hint could also be implicitly cached by coercing this
+        # non-self-caching PEP 604-compliant union into a self-caching PEP
+        # 484-compliant union (e.g., from "int | str" to "Union[int, str]").
+        # Since doing so would consume substantially more time for *NO* tangible
+        # gain, we strongly prefer the current trivial and efficient approach.
+        is_hint_pep604(hint)
+    )
+
+# ....................{ TESTERS ~ needs                    }....................
+@callable_cached
+def is_hint_needs_cls_stack(hint: object) -> bool:
+    '''
+    :data:`True` only if the passed type hint is **type stack-dependent** (i.e.,
+    if :mod:`beartype` requires the tuple of all classes lexically declaring the
+    class variables or methods annotated by this hint to generate code
+    type-checking this hint).
+
+    This tester returns :data:`False` for most hints; only a small subset of
+    hints are type stack-dependent. This includes:
+
+    * :pep:`673`-compliant self type hint (i.e., :obj:`typing.Self`), which is
+      contextually valid *only* inside a lexical class declaration.
+
+    This tester is memoized for efficiency.
+
+    Motivation
+    ----------
+    **This tester should only be called to decide whether memoized callables
+    should be passed a type stack.** Passing memoized callables a type stack
+    substantially reduces the likelihood of a cache hit and thus the
+    average-case efficiency of calls to those callables. Notably:
+
+    * Most type hints do *not* require a type stack.
+    * Most type hints annotate class variables and methods of differing classes
+      and thus do *not* share the same type stack.
+
+    Ergo, passing memoized callables both a type hint *and* a type stack
+    effectively unmemoizes those callables. Thankfully, callers can elide this
+    inefficiency by calling this tester first; when this tester returns:
+
+    * :data:`False`, the caller can safely pass memoized callables a type hint
+      and :data:`None` for the type stack, thus preserving memoization. This is
+      the common case and thus absolutely worth optimizing for.
+    * :data:`True`, the caller has *no* choice but to pass memoized callables
+      both a type hint *and* a type stack. Grr!
+
+    Parameters
+    ----------
+    hint : object
+        Type hint to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this type hint is type stack-dependent.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.hint.utilhintget import get_hint_repr
+
+    # Machine-readable representation of this hint.
+    hint_repr = get_hint_repr(hint)
+
+    # Return true only if this representation embeds the representation of
+    # either:
+    # * A PEP 673-compliant self type hint (i.e., "typing.Self").
+    #
+    # Note:
+    # * The fully-qualified names of exact typing modules (e.g., "typing",
+    #   "typing_extensions") is intentionally ignored. Although we could
+    #   certainly explicitly test for both, doing so would only needlessly
+    #   reduce efficiency. By omitting explicit tests for both, this tester
+    #   intentionally returns false positives for extremely edge case hints
+    #   whose representations contain syntactically related but semantically
+    #   unrelated substrings (e.g., "typing.Literal['.Self']", which is clearly
+    #   *NOT* a PEP 673-compliant self type hint but erroneously matched as one
+    #   by this heuristic). This is non-ideal but thankfully ignorable. See the
+    #   "Motivation" section of the docstring for further commentary.
+    # * This string is intentionally *NOT* preceded by a "." delimiter (e.g., as
+    #   ".Self" rather than "Self"). Previously, this string was intentionally
+    #   preceded by a "." delimiter; doing so satisfied most edge cases while
+    #   reducing the likelihood of a false positive. Sadly, doing so also failed
+    #   to match "Self" type hints stringified by PEP 563. Grrr!
+    # * That the "in" operator is known to be the fastest means of performing
+    #   substring matching in Python. Indeed:
+    #   * "in" is faster than the str.find() method *SUBSTANTIALLY* faster than
+    #     the re.match() function, which is an entire of magnitude slower than
+    #     "in".
+    #   * re.match() only begins to catch up to "in" when concurrently testing
+    #     for more than 10 or so substrings (e.g., r'(0|1|2|3|4|5|6|7|8|9)').
+    #
+    # See also the extensive timings documented at this StackOverflow question:
+    #     https://stackoverflow.com/questions/4901523/whats-a-faster-operation-re-match-search-or-str-find
+    return 'Self' in hint_repr
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/kind/map/utilmapfrozen.py
@@ -0,0 +1,222 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **frozen dictionary class hierarchy** (i.e., private classes
+implementing immutable mappings, preserving :math:`O(1)` complexity while
+prohibiting modification).
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeKindFrozenDictException
+from beartype.typing import (
+    NoReturn,
+    SupportsIndex,
+    Tuple,
+)
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+from beartype._util.utilobject import get_object_type_basename
+from collections.abc import Mapping
+
+# ....................{ CLASSES                            }....................
+#FIXME: Unit test us up, please.
+class FrozenDict(dict):
+    '''
+    **Frozen dictionary** (i.e., immutable mapping preserving :math:`O(1)`
+    complexity while prohibiting modification).
+
+    Instances of this dictionary are safely hashable and thus suitable for
+    passing as parameters to memoized callables and classes (e.g., our core
+    :class:`beartype.BeartypeConf` class).
+
+    See Also
+    --------
+    https://stackoverflow.com/q/1151658/2809027
+        StackOverflow question lightly inspiring this implementation.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # @beartype decorations. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = ('_hash',)
+
+    # ..................{ CLASS METHODS                      }..................
+    @classmethod
+    def fromkeys(cls, *args, **kwargs) -> 'FrozenDict':
+
+        # Create and return a new immutable dictionary encapsulating the mutable
+        # dictionary created and returned by the superclass method.
+        #
+        # Note that this implementation intentionally calls the dict.fromkeys()
+        # class method directly rather than calling super().fromkey(). While
+        # seemingly equivalent, the latter implicitly calls the __setitem__()
+        # dunder method of this subclass, which then raises an exception.
+        return cls(dict.fromkeys(*args, **kwargs))
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, *args, **kwargs) -> None:
+
+        # Instantiate this immutable dictionary with all passed parameters.
+        super().__init__(*args, **kwargs)
+
+        # Precompute the hash for this immutable dictionary at instantiation
+        # time for both efficiency and safety.
+        frozen_items = frozenset(self.items())  # <-- clever stuff
+        self._hash = hash(frozen_items)  # <---- more clever stuff
+
+    # ..................{ DUNDERS                            }..................
+    def __hash__(self) -> int:  # type: ignore[override]
+        '''
+        Hash of all key-value pairs in this immutable dictionary.
+
+        Defining this method satisfies the :class:`collections.abc.Hashable`
+        abstract base class (ABC), enabling this dictionary to be used as in
+        hashable containers (e.g., dictionaries, sets).
+        '''
+
+        # Return the precomputed hash for this immutable dictionary.
+        return self._hash
+
+
+    def __reduce_ex__(self, protocol: SupportsIndex) -> Tuple[type, object]:
+        '''
+        Pickle this immutable dictionary.
+
+        Parameters
+        ----------
+        protocol : SupportsIndex
+            Pickle protocol under which to pickle this immutable dictionary.
+
+        Returns
+        -------
+        Tuple[type, object]
+            2-tuple suitable for pickling this immutable dictionary.
+        '''
+
+        # Dark magic is both dark and magical.
+        return (type(self), (dict(self),))
+
+
+    def __repr__(self) -> str:
+        '''
+        Machine-readable representation of this immutable dictionary.
+        '''
+
+        # Standard "dict"-based representation of the mutable dictionary
+        # encapsulated by this immutable dictionary.
+        dict_repr = super().__repr__()
+
+        # Fully-qualified name of the possible subclass of this dictionary.
+        type_name = get_object_type_basename(self)
+
+        # Return an appropriate representation of this immutable dictionary.
+        return f'{type_name}({dict_repr})'
+
+
+    def __or__(self, other: Mapping) -> 'FrozenDict':
+        '''
+        Create and return a new immutable dictionary containing all key-value
+        pairs contained in both the current and passed immutable dictionaries.
+
+        Parameters
+        ----------
+        other: Mapping
+            Possibly mutable dictionary to be added to this immutable
+            dictionary.
+
+        Returns
+        -------
+        FrozenDict
+            Immutable dictionary adding the current and passed dictionaries.
+
+        Raises
+        ------
+        BeartypeKindFrozenDictException
+            If the passed dictionary is *not* actually a dictionary.
+        '''
+
+        # If the passed dictionary is *NOT* a dictionary, raise an exception.
+        if not isinstance(other, Mapping):
+            raise BeartypeKindFrozenDictException(
+                f'Non-dictionary {repr(other)} not addable to '
+                f'immutable dictionary {repr(self)}.'
+            )
+        # Else, the passed dictionary is a dictionary.
+
+        # Type of immutable dictionary to be created and returned.
+        cls = type(self)
+
+        # Standard dictionary uniting this and the passed dictionaries.
+        dict_united: dict = None  # type: ignore[assignment]
+
+        # If the active Python interpreter targets Python >= 3.9, the standard
+        # "dict" class defines the __or__() dunder method. In this case...
+        if IS_PYTHON_AT_LEAST_3_9:
+            # Trivially defer to that method to implement this method.
+            dict_united = super().__or__(dict(other))  # type: ignore[misc]
+        # Else, the active Python interpreter targets Python 3.8. In this case,
+        # implement this operation manually via a dictionary merger.
+        else:
+            # Mutable dictionary uniting these two immutable dictionaries,
+            # initialized to the contents of the current immutable dictionary.
+            dict_united = dict(self)
+
+            # For each key-value pair in the passed immutable dictionary...
+            for other_key, other_value in other.items():
+                # Add this key-value pair to this mutable dictionary.
+                dict_united[other_key] = other_value
+
+        # Create and return a new immutable dictionary wrapping this dictionary.
+        return cls(dict_united)
+
+    # ..................{ MUTATORS                           }..................
+    # Override all mutators (i.e., "dict" methods attempting to modify the
+    # current immutable dictionary) to raise exceptions instead.
+    def __setitem__(self, key, value) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} '
+            f'key {repr(key)} not settable to {repr(value)}.'
+        )
+
+
+    def __delitem__(self, key) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} '
+            f'key {repr(key)} not deletable.'
+        )
+
+
+    def clear(self) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} not clearable.')
+
+
+    def pop(self, key, default = None) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} '
+            f'key {repr(key)} with default {repr(default)} not poppable.'
+        )
+
+
+    def popitem(self) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} not poppable.')
+
+
+    def setdefault(self, key, default = None) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} '
+            f'key {repr(key)} with default {repr(default)} not settable.'
+        )
+
+
+    def update(self, *args, **kwargs) -> NoReturn:
+        raise BeartypeKindFrozenDictException(
+            f'Immutable dictionary {repr(self)} '
+            f'not updatable from positional arguments {repr(args)} '
+            f'and keyword arguments {repr(kwargs)}.'
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/kind/map/utilmapset.py
@@ -0,0 +1,257 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **dictionary mutators** (i.e., low-level callables modifying the
+contents of passed dictionaries in various general-purpose ways).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilMappingException
+from beartype.typing import Sequence
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+from beartype._util.text.utiltextrepr import represent_object
+from collections.abc import (
+    Sequence as SequenceABC,
+    Mapping,
+    MutableMapping,
+)
+
+# ....................{ MERGERS                            }....................
+def merge_mappings(*mappings: Mapping) -> Mapping:
+    '''
+    Safely merge all passed mappings if these mappings contain no **key-value
+    collisions** (i.e., if these mappings either contain different keys *or*
+    share one or more key-value pairs) *or* raise an exception otherwise (i.e.,
+    if these mappings contain one or more key-value collisions).
+
+    Since this function only safely merges mappings and thus *never* silently
+    overrides any key-value pair of either mapping, order is insignificant;
+    this function returns the same mapping regardless of the order in which
+    these mappings are passed.
+
+    Caveats
+    -------
+    This function creates and returns a new mapping of the same type as that of
+    the first mapping. That type *must* define an ``__init__()`` method with
+    the same signature as the standard :class:`dict` type; if this is *not* the
+    case, an exception is raised.
+
+    Parameters
+    ----------
+    mappings: tuple[Mapping]
+        Tuple of two or more mappings to be safely merged.
+
+    Returns
+    -------
+    Mapping
+        Mapping of the same type as that of the first mapping created by safely
+        merging these mappings.
+
+    Raises
+    ------
+    _BeartypeUtilMappingException
+        If either:
+
+        * No mappings are passed.
+        * Only one mappings are passed.
+        * Two or more mappings are passed, but these mappings contain one or
+          more key-value collisions.
+
+    See Also
+    --------
+    :func:`.die_if_mappings_two_items_collide`
+        Further details.
+    '''
+
+    # Return either...
+    return (
+        # If only two mappings are passed, defer to a function optimized for
+        # merging two mappings.
+        merge_mappings_two(mappings[0], mappings[1])
+        if len(mappings) == 2 else
+        # Else, three or more mappings are passed. In this case, defer to a
+        # function optimized for merging three or more mappings.
+        merge_mappings_two_or_more(mappings)
+    )
+
+
+def merge_mappings_two(mapping_a: Mapping, mapping_b: Mapping) -> Mapping:
+    '''
+    Safely merge the two passed mappings if these mappings contain no key-value
+    collisions *or* raise an exception otherwise.
+
+    Parameters
+    ----------
+    mapping_a: Mapping
+        First mapping to be merged.
+    mapping_b: Mapping
+        Second mapping to be merged.
+
+    Returns
+    -------
+    Mapping
+        Mapping of the same type as that of the first mapping created by safely
+        merging these mappings.
+
+    Raises
+    ------
+    _BeartypeUtilMappingException
+        If these mappings contain one or more key-value collisions.
+
+    See Also
+    --------
+    :func:`beartype._util.kind.map.utilmaptest.die_if_mappings_two_items_collide`
+        Further details.
+    '''
+
+    # If the first mapping is empty, return the second mapping as is.
+    if not mapping_a:
+        return mapping_b
+    # Else, the first mapping is non-empty.
+    #
+    # If the second mapping is empty, return the first mapping as is.
+    elif not mapping_b:
+        return mapping_a
+    # Else, both mappings are non-empty.
+
+    # Avoid circular import dependencies.
+    from beartype._util.kind.map.utilmaptest import (
+        die_if_mappings_two_items_collide)
+
+    # If these mappings contain a key-value collision, raise an exception.
+    die_if_mappings_two_items_collide(mapping_a, mapping_b)
+    # Else, these mappings contain *NO* key-value collisions.
+
+    # Merge these mappings. Since no unsafe collisions exist, the order in
+    # which these mappings are merged is irrelevant.
+    return (
+        # If the active Python interpreter targets Python >= 3.9 and thus
+        # supports "PEP 584 -- Add Union Operators To dict", merge these
+        # mappings with the faster and terser dict union operator.
+        mapping_a | mapping_b  # type: ignore[operator]
+        if IS_PYTHON_AT_LEAST_3_9 else
+        # Else, merge these mappings by creating and returning a new mapping of
+        # the same type as that of the first mapping initialized from a slower
+        # and more verbose dict unpacking operation.
+        type(mapping_a)(mapping_a, **mapping_b)  # type: ignore[call-arg]
+    )
+
+
+def merge_mappings_two_or_more(mappings: Sequence[Mapping]) -> Mapping:
+    '''
+    Safely merge the one or more passed mappings if these mappings contain no
+    key-value collisions *or* raise an exception otherwise.
+
+    Parameters
+    ----------
+    mappings: SequenceABC[Mapping]
+        SequenceABC of two or more mappings to be safely merged.
+
+    Returns
+    -------
+    Mapping
+        Mapping of the same type as that of the first mapping created by safely
+        merging these mappings.
+
+    Raises
+    ------
+    _BeartypeUtilMappingException
+        If these mappings contain one or more key-value collisions.
+
+    See Also
+    --------
+    :func:`beartype._util.kind.map.utilmaptest.die_if_mappings_two_items_collide`
+        Further details.
+    '''
+    assert isinstance(mappings, SequenceABC), f'{repr(mappings)} not sequence.'
+
+    # Number of passed mappings.
+    MAPPINGS_LEN = len(mappings)
+
+    # If less than two mappings are passed, raise an exception.
+    if MAPPINGS_LEN < 2:
+        # If only one mapping is passed, raise an appropriate exception.
+        if MAPPINGS_LEN == 1:
+            raise _BeartypeUtilMappingException(
+                f'Two or more mappings expected, but only one mapping '
+                f'{represent_object(mappings[0])} passed.')
+        # Else, no mappings are passed. Raise an appropriate exception.
+        else:
+            raise _BeartypeUtilMappingException(
+                'Two or more mappings expected, but no mappings passed.')
+    # Else, two or more mappings are passed.
+    assert isinstance(mappings[0], Mapping), (
+        f'First mapping {repr(mappings[0])} not mapping.')
+
+    # Merged mapping to be returned, initialized to the merger of the first two
+    # passed mappings.
+    mapping_merged = merge_mappings_two(mappings[0], mappings[1])
+
+    # If three or more mappings are passed...
+    if MAPPINGS_LEN > 2:
+        # For each of the remaining mappings...
+        for mapping in mappings[2:]:
+            # Merge this mapping into the merged mapping to be returned.
+            mapping_merged = merge_mappings_two(mapping_merged, mapping)
+    # Else, only two mappings are passed. In these case, these mappings have
+    # already been merged above.
+
+    # Return this merged mapping.
+    return mapping_merged
+
+# ....................{ UPDATERS                           }....................
+def update_mapping(mapping_trg: MutableMapping, mapping_src: Mapping) -> None:
+    '''
+    Safely update in-place the first passed mapping with all key-value pairs of
+    the second passed mapping if these mappings contain no **key-value
+    collisions** (i.e., if these mappings either only contain different keys
+    *or* share one or more key-value pairs) *or* raise an exception otherwise
+    (i.e., if these mappings contain one or more of the same keys associated
+    with different values).
+
+    Parameters
+    ----------
+    mapping_trg: MutableMapping
+        Target mapping to be safely updated in-place with all key-value pairs
+        of ``mapping_src``. This mapping is modified by this function and
+        *must* thus be mutable.
+    mapping_src: Mapping
+        Source mapping to be safely merged into ``mapping_trg``. This mapping
+        is *not* modified by this function and may thus be immutable.
+
+    Raises
+    ------
+    _BeartypeUtilMappingException
+        If these mappings contain one or more key-value collisions.
+
+    See Also
+    --------
+    :func:`beartype._util.kind.map.utilmaptest.die_if_mappings_two_items_collide`
+        Further details.
+    '''
+    assert isinstance(mapping_trg, MutableMapping), (
+        f'{repr(mapping_trg)} not mutable mapping.')
+    assert isinstance(mapping_src, Mapping), (
+        f'{repr(mapping_src)} not mapping.')
+
+    # If the second mapping is empty, silently reduce to a noop.
+    if not mapping_src:
+        return
+    # Else, the second mapping is non-empty.
+
+    # Avoid circular import dependencies.
+    from beartype._util.kind.map.utilmaptest import (
+        die_if_mappings_two_items_collide)
+
+    # If these mappings contain a key-value collision, raise an exception.
+    die_if_mappings_two_items_collide(mapping_trg, mapping_src)
+    # Else, these mappings contain *NO* key-value collisions.
+
+    # Update the former mapping from the latter mapping. Since no unsafe
+    # collisions exist, this update is now guaranteed to be safe.
+    mapping_trg.update(mapping_src)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/kind/map/utilmaptest.py
@@ -0,0 +1,204 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **dictionary testers** (i.e., low-level callables testing and
+validating the contents of passed dictionaries in various general-purpose ways).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilMappingException
+from beartype.typing import AbstractSet
+from collections.abc import (
+    Hashable,
+    Mapping,
+    Set,
+)
+
+# ....................{ VALIDATORS                         }....................
+def die_if_mappings_two_items_collide(
+    mapping_a: Mapping, mapping_b: Mapping) -> None:
+    '''
+    Raise an exception if the two passed mappings contain a **key-value
+    collision** (i.e., the same key such that the values associated with that
+    key in these mappings differ).
+
+    A key-value collision occurs when any key ``ka`` and associated value
+    ``va`` of the first mapping and any key ``kb`` and associated value ``vb``
+    of the second mapping satisfy ``ka == kb && va != vb``. Equivalently, a
+    key-value collision occurs when any common keys shared between both
+    mappings are associated with different values.
+
+    Parameters
+    ----------
+    mapping_a: Mapping
+        First mapping to be inspected.
+    mapping_b: Mapping
+        Second mapping to be inspected.
+
+    Raises
+    ------
+    _BeartypeUtilMappingException
+        If these mappings contain one or more key-value collisions.
+    '''
+    assert isinstance(mapping_a, Mapping), f'{repr(mapping_a)} not mapping.'
+    assert isinstance(mapping_b, Mapping), f'{repr(mapping_b)} not mapping.'
+
+    # For each key of the first mapping...
+    for mapping_a_key in mapping_a:
+        # If...
+        #
+        # Note this simplistic detection logic has been exhaustively optimized
+        # with iterative profiling to be the most performant solution. Notably,
+        # alternative solutions calling dictionary methods (e.g., dict.items(),
+        # dict.get()) are *DRAMATICALLY* slower -- which is really fascinating.
+        # CPython appears to have internally optimized pure dictionary syntax.
+        if (
+            # This key resides in the second mapping as well *AND*...
+            mapping_a_key in mapping_b and
+            # This key unsafely maps to a different value in the second
+            # mapping...
+            mapping_a[mapping_a_key] is not mapping_b[mapping_a_key]
+        ):
+        # Immediately short-circuit this iteration to raise an exception below.
+        # Merging these mappings would silently and thus unsafely override the
+        # values associated with these keys in the first mapping with the
+        # values associated with these keys in the second mapping.
+            break
+    # Else, all key collisions are safe (i.e., all shared keys are associated
+    # with the same values in both mappings). Since merging these mappings as
+    # is will *NOT* silently and thus unsafely override any values of either
+    # mapping, accept these mappings as is.
+    #
+    # Note that this awkward branching structure has been profiled to be
+    # optimally efficient, for reasons that honestly elude us. Notably, this
+    # structure is faster than:
+    # * The equivalent "any(...)" generator comprehension -- suggesting we
+    #   should similarly unroll *ALL* calls to the any() and all() builtins in
+    #   our critical performance path. Thanks, CPython.
+    # * The equivalent test against items intersection, which has the
+    #   additional caveat of raising an exception when one or more mapping
+    #   items are unhashable and is thus substantially more fragile: e.g.,
+    #       if len(mapping_keys_shared) == len(mapping_a.items() & mapping_b.items()):
+    #           return
+    else:
+        return
+
+    # Set of all key collisions (i.e., keys residing in both mappings). Since
+    # keys are necessarily hashable, this set intersection is guaranteed to be
+    # safe and thus *NEVER* raise a "TypeError" exception.
+    #
+    # Note that omitting the keys() method call on the latter but *NOT* former
+    # mapping behaves as expected and offers a helpful microoptimization.
+    mapping_keys_shared = mapping_a.keys() & mapping_b  # type: ignore[operator]
+
+    # Set of all keys in all item collisions (i.e., items residing in both
+    # mappings). Equivalently, this is the set of all safe key collisions (i.e.,
+    # all shared keys associated with the same values in both mappings).
+    #
+    # Ideally, we would efficiently intersect these items as follows:
+    #     mapping_items_shared = mapping_a.items() & mapping_b.items()
+    # Sadly, doing so raises a "TypeError" if one or more values of these
+    # mappings are unhashable -- as they typically are in common use cases
+    # throughout this codebase. Ergo, we fallback to a less efficient but
+    # considerably more robust alternative supporting unhashable values.
+    mapping_keys_shared_safe = {
+        # For each possibly unsafe key collision (i.e., shared key associated
+        # with possibly different values in both mappings), this key...
+        mapping_key_shared
+        for mapping_key_shared in mapping_keys_shared
+        # If this key maps to the same value in both mappings and is thus safe.
+        if (
+            mapping_a[mapping_key_shared] is
+            mapping_b[mapping_key_shared]
+        )
+    }
+
+    # Dictionary of all unsafe key-value pairs (i.e., pairs such that merging
+    # these keys would silently override the values associated with these keys
+    # in either the first or second mappings) from these mappings.
+    mapping_a_unsafe = dict(
+        (key_shared_unsafe, mapping_a[key_shared_unsafe])
+        for key_shared_unsafe in mapping_keys_shared
+        if key_shared_unsafe not in mapping_keys_shared_safe
+    )
+    mapping_b_unsafe = dict(
+        (key_shared_unsafe, mapping_b[key_shared_unsafe])
+        for key_shared_unsafe in mapping_keys_shared
+        if key_shared_unsafe not in mapping_keys_shared_safe
+    )
+
+    # Raise a human-readable exception.
+    exception_message = (
+        f'Mappings not safely mergeable due to key-value collisions:\n'
+        f'~~~~[ mapping_a collisions ]~~~~\n{repr(mapping_a_unsafe)}\n'
+        f'~~~~[ mapping_b collisions ]~~~~\n{repr(mapping_b_unsafe)}'
+    )
+    # print(exception_message)
+    raise _BeartypeUtilMappingException(exception_message)
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_mapping_keys_all(
+    mapping: Mapping, keys: AbstractSet[Hashable]) -> bool:
+    '''
+    :data:`True` only if the passed mapping contains *all* of the passed keys.
+
+    Parameters
+    ----------
+    mapping: Mapping
+        Mapping to be tested.
+    keys: AbstractSet[Hashable]
+        Set of one or more keys to test this mapping against.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this mapping contains *all* of these keys.
+    '''
+    assert isinstance(mapping, Mapping), f'{repr(mapping)} not mapping.'
+    assert isinstance(keys, Set), f'{repr(keys)} not set.'
+    assert bool(keys), 'Keys empty.'
+
+    # Return true only if this mapping contains *ALL* of these keys,
+    # equivalent to efficiently testing whether this set of one or more keys is
+    # a strict subset of the set of all keys in this mapping.
+    #
+    # Note that we intentionally do *NOT* call the set.issubclass() method here.
+    # Even standard set types that otherwise satisfy the "collections.abc.Set"
+    # protocol do *NOT* necessarily define that method.
+    return keys <= mapping.keys()
+
+
+#FIXME: Unit test us up, please.
+def is_mapping_keys_any(
+    mapping: Mapping, keys: AbstractSet[Hashable]) -> bool:
+    '''
+    :data:`True` only if the passed mapping contains *any* (i.e., one or more,
+    at least one) of the passed keys.
+
+    Parameters
+    ----------
+    mapping: Mapping
+        Mapping to be tested.
+    keys: AbstractSet[Hashable]
+        Set of one or more keys to test this mapping against.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this mapping contains *any* of these keys.
+    '''
+    assert isinstance(mapping, Mapping), f'{repr(mapping)} not mapping.'
+    assert isinstance(keys, Set), f'{repr(keys)} not set.'
+    assert bool(keys), 'Keys empty.'
+
+    # Return true only if this mapping contains one or more of these keys,
+    # equivalent to efficiently testing whether the set intersection between
+    # this set of one or more keys *AND* the set of all keys in this mapping is
+    # a non-empty set.
+    return bool(keys & mapping.keys())
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/module/utilmoddeprecate.py
@@ -0,0 +1,186 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python module deprecation** utilities (i.e., callables
+deprecating arbitrary module attributes in a reusable fashion).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid circular import dependencies, avoid importing from *ANY*
+# package-specific submodule either here or in the body of any callable defined
+# by this submodule. This submodule is typically called from the "__init__"
+# submodules of public subpackages.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.typing import Any, Dict
+from beartype._util.utilobject import SENTINEL
+from warnings import warn
+
+# ....................{ IMPORTERS                          }....................
+def deprecate_module_attr(
+    attr_deprecated_name: str,
+    attr_deprecated_name_to_nondeprecated_name: Dict[str, str],
+    attr_nondeprecated_name_to_value: Dict[str, Any],
+) -> object:
+    '''
+    Dynamically retrieve a deprecated attribute with the passed unqualified
+    name mapped by the passed dictionary to a corresponding non-deprecated
+    attribute from the submodule with the passed dictionary of globally scoped
+    attributes and emit a non-fatal deprecation warning on each
+    such retrieval if that submodule defines this attribute *or* raise an
+    exception otherwise.
+
+    This function is intended to be called by :pep:`562`-compliant globally
+    scoped ``__getattr__()`` dunder functions, which the Python interpreter
+    implicitly calls under Python >= 3.7 *after* failing to directly retrieve
+    an explicit attribute with this name from that submodule.
+
+    Parameters
+    ----------
+    attr_deprecated_name : str
+        Unqualified name of the deprecated attribute to be retrieved.
+    attr_deprecated_name_to_nondeprecated_name : Dict[str, str]
+        Dictionary mapping from the unqualified name of each deprecated
+        attribute retrieved by this function to either:
+
+        * If that submodule defines a corresponding non-deprecated attribute,
+          the unqualified name of that attribute.
+        * If that submodule is deprecating that attribute *without* defining a
+          corresponding non-deprecated attribute, ``None``.
+    attr_nondeprecated_name_to_value : Dict[str, object]
+        Dictionary mapping from the unqualified name to value of each
+        module-scoped attribute defined by the caller's submodule, typically
+        passed as the ``globals()`` builtin. This function intentionally does
+        *not* implicitly inspect this dictionary from the call stack, as call
+        stack inspection is non-portable under Python.
+
+    Returns
+    ----------
+    object
+        Value of this deprecated attribute.
+
+    Warns
+    ----------
+    DeprecationWarning
+        If this attribute is deprecated.
+
+    Raises
+    ----------
+    AttributeError
+        If this attribute is unrecognized and thus erroneous.
+    ImportError
+        If the passed ``attr_nondeprecated_name_to_value`` dictionary fails to
+        define the non-deprecated variant of the passed deprecated attribute
+        mapped to by the passed ``attr_deprecated_name_to_nondeprecated_name``
+        dictionary.
+
+    See Also
+    ----------
+    https://www.python.org/dev/peps/pep-0562/#id8
+        :pep:`562`-compliant dunder function inspiring this implementation.
+    '''
+    assert isinstance(attr_deprecated_name, str), (
+        f'{repr(attr_deprecated_name)} not string.')
+    assert isinstance(attr_deprecated_name_to_nondeprecated_name, dict), (
+        f'{repr(attr_deprecated_name_to_nondeprecated_name)} not dictionary.')
+    assert isinstance(attr_nondeprecated_name_to_value, dict), (
+        f'{repr(attr_nondeprecated_name_to_value)} not dictionary.')
+
+    # Fully-qualified name of the caller's submodule. Since all physical
+    # submodules (i.e., those defined on-disk) define this dunder attribute
+    # *AND* this function is only ever called by such submodules, this
+    # attribute is effectively guaranteed to exist.
+    MODULE_NAME = attr_nondeprecated_name_to_value['__name__']
+
+    # Unqualified name of the non-deprecated attribute originating this
+    # deprecated attribute if this attribute is deprecated *OR* the sentinel.
+    attr_nondeprecated_name = attr_deprecated_name_to_nondeprecated_name.get(
+        attr_deprecated_name, SENTINEL)
+
+    # If this attribute is deprecated...
+    if attr_nondeprecated_name is not SENTINEL:
+        assert isinstance(attr_nondeprecated_name, str), (
+            f'{repr(attr_nondeprecated_name)} not string.')
+
+        # Value of the non-deprecated attribute originating this deprecated
+        # attribute if the former exists *OR* the sentintel.
+        attr_nondeprecated_value = attr_nondeprecated_name_to_value.get(
+            attr_nondeprecated_name, SENTINEL)
+
+        # If that module fails to define this non-deprecated attribute, raise
+        # an exception.
+        #
+        # Note that:
+        # * This should *NEVER* happen but surely will. In fact, this just did.
+        # * This intentionally raises an beartype-agnostic "ImportError"
+        #   exception rather than a beartype-specific exception. Why? Because
+        #   this function is *ONLY* ever called by the module-scoped
+        #   __getattr__() dunder function in the "__init__.py" submodules
+        #   defining public namespaces of public packages. In turn, that
+        #   __getattr__() dunder function is only ever implicitly called by
+        #   Python's non-trivial import machinery. For unknown reasons, that
+        #   machinery silently ignores *ALL* exceptions raised by that
+        #   __getattr__() dunder function and thus raised by this function
+        #   *EXCEPT* "ImportError" exceptions. Of necessity, we have *NO*
+        #   recourse but to defer to Python's poorly documented API constraints.
+        if attr_nondeprecated_value is SENTINEL:
+            raise ImportError(
+                f'Deprecated attribute '
+                f'"{attr_deprecated_name}" in submodule "{MODULE_NAME}" '
+                f'originates from missing non-deprecated attribute '
+                f'"{attr_nondeprecated_name}" not defined by that submodule.'
+            )
+        # Else, that module defines this non-deprecated attribute.
+
+        # Substring suffixing the warning message emitted below.
+        warning_suffix = ''
+
+        # If this deprecated attribute originates from a public non-deprecated
+        # attribute, inform users of the existence of the latter.
+        if not attr_nondeprecated_name.startswith('_'):
+            warning_suffix = (
+                f' Please globally replace all references to this '
+                f'attribute with its non-deprecated equivalent '
+                f'"{attr_nondeprecated_name}" from the same submodule.'
+            )
+        # Else, this deprecated attribute originates from a private
+        # non-deprecated attribute. In this case, avoid informing users of the
+        # existence of the latter.
+
+        # Emit a non-fatal warning of the standard "DeprecationWarning"
+        # category, which CPython filters (ignores) by default.
+        #
+        # Note that we intentionally:
+        # * Do *NOT* emit a non-fatal warning of our non-standard
+        #   "BeartypeDecorHintPepDeprecationWarning" category, which applies
+        #   *ONLY* to PEP-compliant type hint deprecations.
+        # * Do *NOT* call the higher-level issue_warning() function, which would
+        #   erroneously declare that this deprecation originates from the
+        #   external caller rather than this codebase itself.
+        warn(
+            (
+                f'Deprecated attribute '
+                f'"{attr_deprecated_name}" in submodule "{MODULE_NAME}" '
+                f'scheduled for removal under a future release.'
+                f'{warning_suffix}'
+            ),
+            DeprecationWarning,
+        )
+
+        # Return the value of this deprecated attribute.
+        return attr_nondeprecated_value
+    # Else, this attribute is *NOT* deprecated. Since Python called this dunder
+    # function, this attribute is undefined and thus erroneous.
+
+    # Raise the same exception raised by Python on accessing a non-existent
+    # attribute of a module *NOT* defining this dunder function.
+    #
+    # Note that Python's non-trivial import machinery silently coerces this
+    # "AttributeError" exception into an "ImportError" exception. Just do it!
+    raise AttributeError(
+        f"module '{MODULE_NAME}' has no attribute '{attr_deprecated_name}'")
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/module/utilmodget.py
@@ -0,0 +1,393 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python module getter** (i.e., callables dynamically retrieving
+modules and/or attributes in modules) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._cave._cavefast import ModuleType
+from beartype.roar._roarexc import _BeartypeUtilModuleException
+from beartype.typing import Optional
+from inspect import findsource
+from pathlib import Path
+from sys import modules as sys_modules
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_module_imported_or_none(module_name: str) -> Optional[ModuleType]:
+    '''
+    Previously imported module, package, or C extension with the passed
+    fully-qualified name if previously imported *or* :data:`None` otherwise
+    (i.e., if that module, package, or C extension has yet to be imported).
+
+    Parameters
+    ----------
+    module_name : str
+        Fully-qualified name of the previously imported module to be returned.
+
+    Returns
+    -------
+    Either:
+
+    * If a module, package, or C extension with this fully-qualified name has
+      already been imported, that module, package, or C extension.
+    * Else, :data:`None`.
+    '''
+
+    # Donkey One-liner Country: Codebase Freeze!
+    return sys_modules.get(module_name)
+
+# ....................{ GETTERS ~ object                   }....................
+def get_object_module_or_none(obj: object) -> Optional[ModuleType]:
+    '''
+    Module declaring the passed object if this object defines the ``__module__``
+    dunder instance variable *or* :data:`None` otherwise.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[ModuleType]
+        Either:
+
+        * Module declaring this object if this object declares a ``__module__``
+          dunder attribute.
+        * :data:`None` otherwise.
+    '''
+
+    # Fully-qualified name of the module defining this object if any or "None".
+    module_name = get_object_module_name_or_none(obj)
+
+    # Return either:
+    # * If a module defines this object, that module.
+    # * Else, "None".
+    return get_module_imported_or_none(module_name) if module_name else None
+
+
+def get_object_module(obj: object) -> ModuleType:
+    '''
+    Module declaring the passed object if this object defines the ``__module__``
+    dunder instance variable *or* raise an exception otherwise (i.e., if this
+    object does *not* define that variable).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    ModuleType
+        Module declaring this object.
+
+    Raises
+    ------
+    _BeartypeUtilModuleException
+        If this object does *not* define the ``__module__`` dunder attribute.
+    '''
+
+    # Fully-qualified name of the module defining this object if any *OR* raise
+    # an exception otherwise.
+    module_name = get_object_module_name(obj)
+
+    # Module defining this object if any *OR* "None" otherwise.
+    module = get_module_imported_or_none(module_name)
+
+    # If this module was *NOT* previously imported despite this object existing
+    # and thus having been imported from something, this object deceptively lies
+    # about its module. In this case, raise an exception.
+    if module is None:
+        raise _BeartypeUtilModuleException(
+            f'{repr(obj)} module "{module_name}" not found.')
+    # If this module was previously imported.
+
+    # Return this module.
+    return module
+
+# ....................{ GETTERS ~ object : line            }....................
+def get_object_module_line_number_begin(obj: object) -> int:
+    '''
+    **Line number** (i.e., 1-based index) of the first line of the source code
+    of the module declaring the passed object if this object is either a
+    callable or class *or* raise an exception otherwise (i.e., if this object is
+    neither a callable nor class).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    int
+        1-based index of the first line of the source code of the module
+        declaring the passed object.
+
+    Raises
+    ------
+    _BeartypeUtilModuleException
+        If this object is neither a callable nor class.
+    '''
+
+    # If this object is a class, defer to the standard "inspect" module.
+    #
+    # Note that:
+    # * Deciding whether an object is a class is slightly faster than deciding
+    #   whether an object is a callable. The former trivially reduces to a
+    #   single isinstance() call against a single superclass; the latter is
+    #   considerably less trivial. Ergo, this object is tested as a class first.
+    # * Deciding the line number of the first line declaring an arbitrary class
+    #   in its underlying source code module file is highly non-trivial (and in
+    #   fact requires extremely slow AST-based parsing). For maintainability and
+    #   robustness, we defer to the well-tested standard "inspect" module
+    #   despite the performance hit in doing so.
+    if isinstance(obj, type):
+        _, cls_source_line_number_start = findsource(obj)
+        return cls_source_line_number_start
+    # Else, this object is *NOT* a class.
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunccodeobj import get_func_codeobj_or_none
+
+    # Code object underlying this object if this object is a pure-Python
+    # callable *OR* "None" otherwise.
+    #
+    # Note this is the canonical means of deciding whether an arbitrary object
+    # is a pure-Python callable, as our is_func_python() function demonstrates.
+    func_codeobj = get_func_codeobj_or_none(obj)
+
+    # If this object is a pure-Python callable, return the line number of the
+    # first line declaring this object in its underlying source code file.
+    if func_codeobj is not None:
+        return func_codeobj.co_firstlineno
+    # Else, this object is neither a pure-Python callable *NOR* a class.
+
+    # In this case, raise an exception.
+    raise _BeartypeUtilModuleException(
+        f'{repr(obj)} neither callable nor class.')
+
+# ....................{ GETTERS ~ object : name            }....................
+#FIXME: Unit test us up, please.
+def get_object_module_name(obj: object) -> str:
+    '''
+    **Fully-qualified name** (i.e., ``.``-delimited name prefixed by the
+    declaring package) of the module declaring the passed object if this
+    object defines the ``__module__`` dunder instance variable *or* raise an
+    exception otherwise (i.e., if this object does *not* define that variable).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    str
+        Fully-qualified name of the module declaring this object.
+
+    Raises
+    ------
+    _BeartypeUtilModuleException
+        If this object does *not* define the ``__module__`` dunder attribute.
+    '''
+
+    # Fully-qualified name of the module declaring this object if this object
+    # defines the "__module__" dunder instance variable *OR* "None" otherwise.
+    module_name = get_object_module_name_or_none(obj)
+
+    # If this object defines *NO* "__module__" dunder instance variable, raise
+    # an exception.
+    if module_name is None:
+        raise _BeartypeUtilModuleException(
+            f'{repr(obj)} "__module__" dunder attribute undefined '
+            f'(e.g., due to being neither class nor callable).'
+        )
+    # Else, this fully-qualified module name exists.
+
+    # Return this name.
+    return module_name
+
+
+#FIXME: Unit test us up, please.
+def get_object_module_name_or_none(obj: object) -> Optional[str]:
+    '''
+    **Fully-qualified name** (i.e., ``.``-delimited name prefixed by the
+    declaring package) of the module declaring the passed object if this object
+    defines the ``__module__`` dunder instance variable *or* :data:`None`
+    otherwise.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * Fully-qualified name of the module declaring this object if this
+          object declares a ``__module__`` dunder attribute.
+        * :data:`None` otherwise.
+    '''
+
+    # Let it be, speaking one-liners of wisdom.
+    return getattr(obj, '__module__', None)
+
+# ....................{ GETTERS ~ object : type : name     }....................
+#FIXME: Unit test us up, please.
+def get_object_type_module_name_or_none(obj: object) -> Optional[str]:
+    '''
+    **Fully-qualified name** (i.e., ``.``-delimited name prefixed by the
+    declaring package) of the module declaring either the passed object if this
+    object is a class *or* the class of this object otherwise (i.e., if this
+    object is *not* a class) if this class declares the ``__module__`` dunder
+    instance variable *or* :data:`None` otherwise.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * Fully-qualified name of the module declaring the type of this object
+          if this type declares a ``__module__`` dunder attribute.
+        * :data:`None` otherwise.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.utilobject import get_object_type_unless_type
+
+    # Make it so, ensign.
+    return get_object_module_name_or_none(get_object_type_unless_type(obj))
+
+# ....................{ GETTERS ~ module : dir             }....................
+#FIXME: Unit test us up.
+def get_module_dir(module: ModuleType) -> Path:
+    '''
+    High-level :class:`Path` object encapsulating the absolute dirname of the
+    parent directory containing the passed module if this module is physically
+    defined on-disk *or* raise an exception otherwise (i.e., if this module is
+    abstractly defined only in-memory).
+
+    Parameters
+    ----------
+    module : ModuleType
+        Module to be inspected.
+
+    Returns
+    -------
+    Path
+        High-level :class:`Path` object encapsulating the absolute dirname of
+        the parent directory containing this on-disk module.
+
+    Raises
+    ------
+    _BeartypeUtilModuleException
+        If this module *only* resides in memory.
+    '''
+
+    # Absolute filename of this module if this module is physically defined
+    # on-disk *OR* raise an exception otherwise (i.e., if this module is
+    # abstractly defined only in-memory).
+    module_filename = get_module_filename(module)
+
+    # High-level "Path" object encapsulating this file and the parent directory
+    # directly containing this file.
+    module_file = Path(module_filename)
+    module_dir = module_file.parent
+
+    # Return this "Path" object.
+    return module_dir
+
+# ....................{ GETTERS ~ module : file            }....................
+#FIXME: Unit test us up.
+def get_module_filename(module: ModuleType) -> str:
+    '''
+    Absolute filename of the passed module if this module is physically defined
+    on-disk *or* raise an exception otherwise (i.e., if this module is
+    abstractly defined only in-memory).
+
+    Parameters
+    ----------
+    module : ModuleType
+        Module to be inspected.
+
+    Returns
+    -------
+    str
+        Absolute filename of this on-disk module.
+
+    Raises
+    ------
+    _BeartypeUtilModuleException
+        If this module *only* resides in memory.
+
+    See Also
+    --------
+    :func:`get_module_filename_or_none`
+        Further details.
+    '''
+
+    # Absolute filename of this module if on-disk *OR* "None" otherwise.
+    module_filename = get_module_filename_or_none(module)
+
+    # If this module resides *ONLY* in memory, raise an exception.
+    if module_filename is None:
+        raise _BeartypeUtilModuleException(
+            f'Module {repr(module)} file not found '
+            f'(e.g., due to either being a namespace (sub)package or '
+            f'a dynamically defined in-memory module).'
+        )
+    # Else, this module resides on disk.
+
+    # Return this filename.
+    return module_filename
+
+
+#FIXME: Unit test us up.
+def get_module_filename_or_none(module: ModuleType) -> Optional[str]:
+    '''
+    Absolute filename of the passed module if this module is physically defined
+    on-disk *or* :data:`None` otherwise (i.e., if this module is abstractly
+    defined only in-memory).
+
+    Specifically, this getter returns either:
+
+    * If this module is actually a package, the absolute filename of the
+      ``"__init__.py"`` submodule directly contained in this package.
+    * Else, the absolute filename of this module as provided by the `__file__`
+      dunder attribute of this in-memory module object.
+
+    In either case, the filename returned by this getter (if any) necessarily
+    refers to a file rather than a directory.
+
+    Parameters
+    ----------
+    module : ModuleType
+        Module to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * Absolute filename of this module if this module resides on disk.
+        * :data:`None` if this module *only* resides in memory.
+    '''
+
+    # Thus spake Onelinerthustra.
+    return getattr(module, '__file__', None)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/module/utilmodimport.py
@@ -0,0 +1,510 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python module importer** utilities (i.e., callables dynamically
+importing modules and/or attributes from modules).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeModuleUnimportableWarning
+from beartype.roar._roarexc import _BeartypeUtilModuleException
+from beartype.typing import (
+    Any,
+    Optional,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._data.cls.datacls import TYPE_BUILTIN_NAME_TO_TYPE
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._util.error.utilerrwarn import issue_warning
+from beartype._util.text.utiltextidentifier import die_unless_identifier
+from beartype._util.utilobject import SENTINEL
+from importlib import import_module as importlib_import_module
+from types import ModuleType
+
+# ....................{ IMPORTERS                          }....................
+#FIXME: Preserved until requisite, which shouldn't be long.
+#FIXME: Unit test us up, please.
+# def import_module(
+#     # Mandatory parameters.
+#     module_name: str,
+#
+#     # Optional parameters.
+#     exception_cls: TypeException = _BeartypeUtilModuleException,
+# ) -> ModuleType:
+#     '''
+#     Dynamically import and return the module, package, or C extension with the
+#     passed fully-qualified name if importable *or* raise an exception
+#     otherwise (i.e., if that module, package, or C extension is unimportable).
+#
+#     Parameters
+#     ----------
+#     module_name : str
+#         Fully-qualified name of the module to be imported.
+#     exception_cls : type
+#         Type of exception to be raised by this function. Defaults to
+#         :class:`_BeartypeUtilModuleException`.
+#
+#     Raises
+#     ----------
+#     exception_cls
+#         If no module with this name exists.
+#     Exception
+#         If a module with this name exists *but* that module is unimportable
+#         due to raising module-scoped exceptions at importation time. Since
+#         modules may perform arbitrary Turing-complete logic at module scope,
+#         callers should be prepared to handle *any* possible exception.
+#     '''
+#     assert isinstance(exception_cls, type), (
+#         f'{repr(exception_cls)} not type.')
+#
+#     # Module with this name if this module is importable *OR* "None" otherwise.
+#     module = import_module_or_none(module_name)
+#
+#     # If this module is unimportable, raise an exception.
+#     if module is None:
+#         raise exception_cls(
+#             f'Module "{module_name}" not found.') from exception
+#     # Else, this module is importable.
+#
+#     # Return this module.
+#     return module
+
+
+def import_module_or_none(
+    # Mandatory parameters.
+    module_name: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+    exception_prefix: str = 'Module attribute ',
+) -> Optional[ModuleType]:
+    '''
+    Dynamically import and return the module, package, or C extension with the
+    passed fully-qualified name if importable *or* return :data:`None` otherwise
+    (i.e., if that module, package, or C extension is unimportable).
+
+    For safety, this function also emits a non-fatal warning when that module,
+    package, or C extension exists but is still unimportable (e.g., due to
+    raising an exception at module scope).
+
+    Parameters
+    ----------
+    module_name : str
+        Fully-qualified name of the module to be imported.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    Either:
+
+    * If a module, package, or C extension with this fully-qualified name is
+      importable, that module, package, or C extension.
+    * Else, :data:`None`.
+
+    Raises
+    ------
+    exception_cls
+        If this name is *not* a syntactically valid Python identifier.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a module with this name exists *but* that module is unimportable
+        due to raising module-scoped exceptions at importation time.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodget import get_module_imported_or_none
+
+    # If this module name is *NOT* a syntactically valid Python identifier,
+    # raise an exception.
+    die_unless_identifier(
+        text=module_name,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this module name is a syntactically valid Python identifier.
+
+    # Module cached with "sys.modules" if this module has already been imported
+    # elsewhere under the active Python interpreter *OR* "None" otherwise.
+    module = get_module_imported_or_none(module_name)
+
+    # If this module has already been imported, return this cached module.
+    if module is not None:
+        return module
+    # Else, this module has yet to be imported.
+
+    # Attempt to dynamically import and return this module.
+    try:
+        return importlib_import_module(module_name)
+    # If this module does *NOT* exist, return "None".
+    except ModuleNotFoundError:
+        pass
+    # If this module exists but raises unexpected exceptions from module scope,
+    # first emit a non-fatal warning notifying the user and then return "None".
+    except Exception as exception:
+        issue_warning(
+            cls=BeartypeModuleUnimportableWarning,
+            message=(
+                f'Ignoring module "{module_name}" importation exception:\n'
+                f'    {exception.__class__.__name__}: {exception}'
+            ),
+        )
+
+    # Inform the caller that this module is unimportable.
+    return None
+
+# ....................{ IMPORTERS ~ attr                   }....................
+def import_module_attr(
+    # Mandatory parameters.
+    attr_name: str,
+
+    # Optional parameters.
+    module_name: Optional[str] = None,
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+    exception_prefix: str = 'Module attribute ',
+) -> Any:
+    '''
+    Dynamically import and return the **module attribute** (i.e., object
+    declared at module scope) with the passed possibly unqualified name from
+    the module with the passed fully-qualified name if importable *or* raise an
+    exception otherwise.
+
+    Parameters
+    ----------
+    attr_name : str
+        Possibly unqualified name of the module attribute to be imported.
+    module_name: Optional[str]
+        Either:
+
+        * If this attribute name is unqualified (i.e., contains *no* ``.``
+          delimiters), the fully-qualified name of the module declaring this
+          attribute.
+        * Else, this parameter is silently ignored.
+
+        Defaults to :data:`None`, in which case this attribute name must be
+        either fully-qualified *or* the unqualified name of a builtin type.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    object
+        The module attribute with this fully-qualified name.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * This attribute or module name is syntactically invalid.
+        * *No* module with this name exists.
+        * A module with by this name exists *but* that module declares no
+          attribute by this name.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a module prefixed by this name exists *but* that module is
+        unimportable due to module-scoped side effects at importation time.
+
+    See Also
+    --------
+    :func:`.import_module_attr_or_sentinel`
+        Further commentary.
+    '''
+
+    # Attribute with this name dynamically imported from that module if
+    # importable *OR* the sentinel placeholder otherwise (i.e., if this
+    # attribute is unimportable).
+    module_attr = import_module_attr_or_sentinel(
+        attr_name=attr_name,
+        module_name=module_name,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+
+    # If this attribute is unimportable...
+    if module_attr is SENTINEL:
+        assert isinstance(exception_cls, type), f'{exception_cls} not type.'
+        assert isinstance(exception_prefix, str), (
+            f'{exception_prefix} not string.')
+
+        # Avoid circular import dependencies.
+        from beartype._util.module.utilmodtest import is_module
+
+        # Exception message to be raised.
+        exception_message = f'{exception_prefix}"{attr_name}" unimportable'
+
+        # If this attribute name contains *NO* "." characters, this is an
+        # unqualified basename. In this case...
+        if '.' not in attr_name:
+            # If either no module name was passed *OR* only an empty module name
+            # was passed, then an empty module name was passed *AND* this
+            # attribute contains no "." characters. Ergo, this is an unqualified
+            # basename. Moreover, since the above importation failed, this
+            # attribute is *NOT* the name of a builtin type. Explain this edge
+            # case with an appropriate substring.
+            if not module_name:
+                exception_message += (
+                    ', as:\n'
+                    '* Not relative to a package or module '
+                    '(i.e., contains no "." delimiters).\n'
+                    '* Not the name of a builtin type (e.g., "int", "str").'
+                )
+            # Else, a non-empty module name was passed.
+            #
+            # If this module is importable, append an appropriate substring.
+            elif is_module(module_name):
+                exception_message += f' from module "{module_name}".'
+            # Else, this module is unimportable. Append an appropriate
+            # substring.
+            else:
+                exception_message += (
+                    f' from unimportable module "{module_name}".')
+        # Else, this attribute name contains one or more "." characters. In
+        # this case...
+        else:
+            # Fully-qualified name of the module declaring this attribute.
+            module_name, _, _ = attr_name.rpartition('.')
+
+            # If this module is importable, append an appropriate substring.
+            if is_module(module_name):
+                exception_message += '.'
+            # Else, this module is unimportable. Append an appropriate
+            # substring.
+            else:
+                exception_message += (
+                    f' from unimportable module "{module_name}".')
+
+        # Raise this exception.
+        raise exception_cls(exception_message)
+    # Else, this module declares this attribute.
+
+    # Else, return this attribute.
+    return module_attr
+
+
+#FIXME: Fix up all tests of this function, please.
+def import_module_attr_or_sentinel(
+    # Mandatory parameters.
+    attr_name: str,
+
+    # Optional parameters.
+    module_name: Optional[str] = None,
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+    exception_prefix: str = 'Module attribute ',
+) -> Any:
+    '''
+    Dynamically import and return the **module attribute** (i.e., object
+    declared at module scope) with the passed possibly unqualified name from
+    the module with the passed fully-qualified name if importable *or* the
+    placeholder :data:`.SENTINEL` otherwise.
+
+    This importer expects this attribute name to be either:
+
+    * **Fully-qualified** (i.e., contain one or more ``.`` delimiters), in which
+      case this module name is silently ignored and may thus be :data:`None` or
+      the empty string *or*...
+    * **Unqualified** (i.e., contain *no* ``.`` delimiters), in which case
+      either:
+
+      * This module name *must* be a non-empty string *or*...
+      * This unqualified attribute name *must* be that of a **builtin type**
+        (e.g., ``"int"``, ``"str"``).
+
+    Parameters
+    ----------
+    attr_name : str
+        Possibly unqualified name of the module attribute to be imported.
+    module_name: Optional[str]
+        Either:
+
+        * If this attribute name is unqualified (i.e., contains *no* ``.``
+          delimiters), the fully-qualified name of the module declaring this
+          attribute.
+        * Else, this parameter is silently ignored.
+
+        Defaults to :data:`None`, in which case ``attr_name`` must be either
+        fully-qualified *or* the unqualified name of a builtin type.
+    exception_cls : Type[Exception]
+        Type of exception to be raised by this function. Defaults to
+        :class:`._BeartypeUtilModuleException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to the empty string.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If *no* module with this name exists, :data:`.SENTINEL`.
+        * If a module with by this name exists *but* that module declares no
+          attribute by this name, :data:`.SENTINEL`.
+        * Else, the module attribute with this fully-qualified name.
+
+    Raises
+    ------
+    exception_cls
+        If this name is syntactically invalid.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a module prefixed by this name exists *but* that module is
+        unimportable due to module-scoped side effects at importation time.
+    '''
+    assert isinstance(module_name, NoneTypeOr[str]), (
+        f'{repr(module_name)} neither string nor "None".')
+
+    # If this attribute name is *NOT* a syntactically valid Python identifier,
+    # raise an exception.
+    die_unless_identifier(
+        text=attr_name,
+        exception_cls=exception_cls,
+        exception_prefix=exception_prefix,
+    )
+    # Else, this attribute name is a syntactically valid Python identifier.
+
+    # True only if this attribute name contains *NO* "." characters and is thus
+    # an unqualified basename relative to this module name.
+    is_attr_name_unqualified = '.' not in attr_name
+
+    # Unqualified basename of this attribute, defaulting to this attribute name.
+    attr_basename = attr_name
+
+    # If this attribute name is an unqualified basename...
+    if is_attr_name_unqualified:
+        # If either no module name was passed *OR* only an empty module name was
+        # passed...
+        if not module_name:
+            # Builtin type with this name if any *OR* the sentinel otherwise
+            # (i.e., if *NO* builtin type with this name exists).
+            module_attr = TYPE_BUILTIN_NAME_TO_TYPE.get(attr_name, SENTINEL)
+
+            # Return this object.
+            return module_attr
+        # Else, a non-empty module name was passed.
+    # Else, this attribute name contains one or more "." characters.
+    else:
+        # Fully-qualified name of the module declaring this attribute *AND* the
+        # unqualified basename of this attribute relative to this module,
+        # efficiently split from the passed name.
+        #
+        # Note that:
+        # * This silently overrides the passed module name with the module name
+        #   prefixing the name of this attribute, which is presumed to be
+        #   authoritative. The passed module name is only an optional fallback
+        #   in the event that this attribute name contains *NO* "." characters.
+        # * By the prior validation, this split is guaranteed to be safe.
+        module_name, _, attr_basename = attr_name.rpartition('.')
+    # In any case:
+    # * "module_name" is now a non-empty string.
+    # * "attr_basename" is now an unqualified basename.
+
+    # Module with this fully-qualified name if importable *OR* "None" otherwise.
+    module = import_module_or_none(module_name)
+
+    # If that module is unimportable, return "None".
+    if module is None:
+        return SENTINEL
+    # Else, that module is importable.
+
+    # Attribute with this name if that module declares this attribute *OR* the
+    # sentinel otherwise.
+    module_attr = getattr(module, attr_basename, SENTINEL)
+
+    # If...
+    if (
+        # That module does not declare this attribute *AND*...
+        module_attr is SENTINEL and
+        # This attribute name is an unqualified basename...
+        is_attr_name_unqualified
+    # Then this attribute was imported relative to this module. In this case,
+    # this attribute could still be the name of a builtin type.
+    ):
+        # Builtin type with this name if any *OR* the sentinel otherwise
+        # (i.e., if *NO* builtin type with this name exists).
+        #
+        # Note that this edge case is distinct from the prior edge case and thus
+        # *MUST* be handled distinctly. Why? Because this module *COULD* have
+        # globally overridden a builtin type by declaring a global attribute of
+        # the same name. Although extremely unlikely (and strongly frowned
+        # upon), Python *DOES* permit insanity like:
+        #     # In some user-defined module at global scope...
+        #     class int(object): ...  # <-- by all the gods never do this
+        module_attr = TYPE_BUILTIN_NAME_TO_TYPE.get(attr_basename, SENTINEL)
+        # print(f'Attempting to import "{attr_basename}" as builtin type {repr(module_attr)}...')
+        # print(f'TYPE_BUILTIN_NAME_TO_TYPE: {TYPE_BUILTIN_NAME_TO_TYPE}')
+    # Else, either that module declared this attribute *OR* this attribute name
+    # is fully-qualified and thus not the name of a builtin type. In either
+    # case, return this attribute as is.
+
+    # Return this attribute.
+    return module_attr
+
+
+def import_module_attr_or_none(*args, **kwargs) -> Any:
+    '''
+    Dynamically import and return the **module attribute** (i.e., object
+    declared at module scope) with the passed fully-qualified name if importable
+    *or* :data:`None` otherwise.
+
+    Caveats
+    -------
+    **This importer ambiguously returns false negatives in edge cases and is
+    thus mildly unsafe.** Consider calling the unambiguous
+    :func:`.import_module_attr_or_sentinel` importer instead. Why? Because this
+    importer returns :data:`None` both when this attribute is unimportable *and*
+    when this attribute is importable but has a value of :data:`None`.
+    Nonetheless, this importer remains convenient for various use cases in which
+    this distinction is mostly irrelevant.
+
+    Parameters
+    ----------
+    All parameters are passed as is to the lower-level
+    :func:`.import_module_attr_or_sentinel` importer.
+
+    Returns
+    -------
+    object
+        Either:
+
+        * If *no* module prefixed this name exists, :data:`None`.
+        * If a module prefixed by this name exists *but* that module declares
+          no attribute by this name, :data:`None`.
+        * Else, the module attribute with this fully-qualified name.
+
+    Raises
+    ------
+    exception_cls
+        If this name is syntactically invalid.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a module prefixed by this name exists *but* that module is
+        unimportable due to module-scoped side effects at importation time.
+    '''
+
+    # Module attribute with this name if that module declares this attribute
+    # *OR* the sentinel placeholder otherwise.
+    module_attr = import_module_attr_or_sentinel(*args, **kwargs)
+
+    # Return either this attribute if importable *OR* "None" otherwise.
+    return module_attr if module_attr is not SENTINEL else None
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/module/utilmodtest.py
@@ -0,0 +1,226 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python module tester** (i.e., callables dynamically testing
+modules and/or attributes in modules) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilModuleException
+from beartype._data.hint.datahinttyping import TypeException
+from beartype._util.text.utiltextidentifier import die_unless_identifier
+from beartype._util.text.utiltextversion import convert_str_version_to_tuple
+from importlib.metadata import version as get_module_version  # type: ignore[attr-defined]
+
+# ....................{ RAISERS                            }....................
+#FIXME: Excise us up. This function is no longer called anywhere. *sigh*
+def die_unless_module_attr_name(
+    # Mandatory parameters.
+    module_attr_name: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilModuleException,
+    exception_prefix: str = 'Module attribute name ',
+) -> None:
+    '''
+    Raise an exception unless the passed string is the fully-qualified
+    syntactically valid name of a **module attribute** (i.e., object declared
+    at module scope by a module) that may or may not actually exist.
+
+    This validator does *not* validate this attribute to actually exist -- only
+    that the name of this attribute is syntactically valid.
+
+    Parameters
+    ----------
+    module_attr_name : str
+        Fully-qualified name of the module attribute to be validated.
+    exception_cls : type, optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :class:`._BeartypeUtilModuleException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to something reasonably sane.
+
+    Raises
+    ------
+    exception_cls
+        If either:
+
+        * This name is *not* a string.
+        * This name is a string containing either:
+
+          * *No* ``.`` characters and thus either:
+
+            * Is relative to the calling subpackage and thus *not*
+              fully-qualified (e.g., ``muh_submodule``).
+            * Refers to a builtin object (e.g., ``str``). While technically
+              fully-qualified, the names of builtin objects are *not*
+              explicitly importable as is. Since these builtin objects are
+              implicitly imported everywhere, there exists *no* demonstrable
+              reason to even attempt to import them anywhere.
+
+          * One or more ``.`` characters but syntactically invalid as an
+            identifier (e.g., ``0h!muh?G0d.``).
+    '''
+    assert isinstance(exception_cls, type), f'{repr(exception_cls)} not type.'
+    assert isinstance(exception_prefix, str), (
+        f'{repr(exception_prefix)} not string.')
+
+    # If this object is *NOT* a string, raise an exception.
+    if not isinstance(module_attr_name, str):
+        raise exception_cls(
+            f'{exception_prefix}{repr(module_attr_name)} not string.')
+    # Else, this object is a string.
+    #
+    # If this string contains *NO* "." characters and thus either is relative to
+    # the calling subpackage or refers to a builtin object, raise an exception.
+    elif '.' not in module_attr_name:
+        raise exception_cls(
+            f'{exception_prefix}"{module_attr_name}" '
+            f'relative or refers to builtin object '
+            f'(i.e., due to containing no "." characters).'
+        )
+    # Else, this string contains one or more "." characters and is thus the
+    # fully-qualified name of a non-builtin type.
+    #
+    # If this string is syntactically invalid as a fully-qualified module
+    # attribute name, raise an exception.
+    else:
+        die_unless_identifier(
+            text=module_attr_name,
+            exception_cls=exception_cls,
+            exception_prefix=exception_prefix,
+        )
+    # Else, this string is syntactically valid as a fully-qualified module
+    # attribute name.
+
+# ....................{ TESTERS                            }....................
+def is_module(module_name: str) -> bool:
+    '''
+    :data:`True` only if the module or C extension with the passed
+    fully-qualified name is importable under the active Python interpreter.
+
+    Caveats
+    -------
+    **This tester dynamically imports this module as an unavoidable side effect
+    of performing this test.**
+
+    Parameters
+    ----------
+    module_name : str
+        Fully-qualified name of the module to be imported.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this module is importable.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a module with this name exists *but* that module is unimportable
+        due to raising module-scoped exceptions at importation time.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodimport import import_module_or_none
+
+    # Module with this name if this module is importable *OR* "None" otherwise.
+    module = import_module_or_none(module_name)
+
+    # Return true only if this module is importable.
+    return module is not None
+
+
+#FIXME: Unit test us up against "setuptools", the only third-party package
+#*BASICALLY* guaranteed to be importable.
+def is_module_version_at_least(module_name: str, version_minimum: str) -> bool:
+    '''
+    :data:`True` only if the module or C extension with the passed
+    fully-qualified name is both importable under the active Python interpreter
+    *and* at least as new as the passed version.
+
+    Caveats
+    -------
+    **This tester dynamically imports this module as an unavoidable side effect
+    of performing this test.**
+
+    Parameters
+    ----------
+    module_name : str
+        Fully-qualified name of the module to be imported.
+    version_minimum : str
+        Minimum version to test this module against as a dot-delimited
+        :pep:`440`-compliant version specifier (e.g., ``42.42.42rc42.post42``).
+
+    Returns
+    -------
+    bool
+        :data:`True` only if:
+
+        * This module is importable.
+        * This module's version is at least the passed version.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a module with this name exists *but* that module is unimportable
+        due to raising module-scoped exceptions at importation time.
+    '''
+    assert isinstance(version_minimum, str), (
+        f'{repr(version_minimum)} not string.')
+
+    # If this module is unimportable, return false immediately.
+    if not is_module(module_name):
+        return False
+    # Else, this module is importable.
+
+    # Current version of this module installed under the active Python
+    # interpreter if any *OR* raise an exception otherwise (which should
+    # *NEVER* happen by prior logic testing this module to be importable).
+    version_actual = get_module_version(module_name)
+
+    # Tuples of version parts parsed from version strings.
+    version_actual_parts  = convert_str_version_to_tuple(version_actual)
+    version_minimum_parts = convert_str_version_to_tuple(version_minimum)
+
+    # Return true only if this module's version satisfies this minimum.
+    return version_actual_parts >= version_minimum_parts
+
+# ....................{ TESTERS ~ package                  }....................
+#FIXME: Unit test us up, please.
+def is_package(package_name: str) -> bool:
+    '''
+    :data:`True` only if the package with the passed fully-qualified name is
+    importable under the active Python interpreter.
+
+    Caveats
+    -------
+    **This tester dynamically imports this module as an unavoidable side effect
+    of performing this test.**
+
+    Parameters
+    ----------
+    package_name : str
+        Fully-qualified name of the package to be imported.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this package is importable.
+
+    Warns
+    -----
+    BeartypeModuleUnimportableWarning
+        If a package with this name exists *but* that package is unimportable
+        due to raising module-scoped exceptions from the top-level `__init__`
+        submodule of this package at importation time.
+    '''
+
+    # Be the one liner you want to see in the world.
+    return is_module(f'{package_name}.__init__')
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/os/utilosshell.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **shell** (i.e., external low-level command-line environment
+encapsulating the active Python interpreter as a parent process of this
+interpreter) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from os import environ
+
+# ....................{ TESTERS                            }....................
+get_shell_var_value_or_none = environ.get
+'''
+String value of the shell environment variable with the passed name if the
+parent shell defines this variable *or* :data:`None` otherwise (i.e., if the
+parent shell does *not* define this variable).
+
+Caveats
+-------
+**This getter is a human-readable alias of the comparable**
+:func:`os.getenv` **function and** :meth:`os.environ.get` **method.** This
+getter exists only for disambiguity and clarity. This getter is *not* an alias
+of the :meth:`os.environ.__getitem__` dunder method, which raises a
+:exc:`KeyError` exception rather than returns :data:`None` if the parent shell
+fails to define this variable.
+
+See Also
+--------
+https://stackoverflow.com/a/41626355/2809027
+    StackOverflow answer strongly inspiring this alias.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/os/utilostest.py
@@ -0,0 +1,52 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **platform tester** (i.e., functions detecting the current
+platform the active Python interpreter is running under) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._util.cache.utilcachecall import callable_cached
+from platform import system as platform_system
+from sys import platform as sys_platform
+
+# ....................{ TESTERS                            }....................
+@callable_cached
+def is_os_linux() -> bool:
+    '''
+    ``True`` only if the current platform is a **Linux distribution.**
+
+    This tester is memoized for efficiency.
+    '''
+
+    return platform_system() == 'Linux'
+
+
+
+@callable_cached
+def is_os_macos() -> bool:
+    '''
+    ``True`` only if the current platform is **Apple macOS**, the operating
+    system previously known as "OS X."
+
+    This tester is memoized for efficiency.
+    '''
+
+    return platform_system() == 'Darwin'
+
+
+@callable_cached
+def is_os_windows_vanilla() -> bool:
+    '''
+    ``True`` only if the current platform is **vanilla Microsoft Windows**
+    (i.e., *not* running the Cygwin POSIX compatibility layer).
+
+    This tester is memoized for efficiency.
+    '''
+
+    return sys_platform == 'win32'
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/os/utilostty.py
@@ -0,0 +1,61 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **TTY** (i.e., interactive terminal expected to be reasonably
+POSIX-compliant, which even recent post-Windows 10 terminals now guarantee)
+utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+import sys
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_stdout_terminal() -> bool:
+    '''
+    :data:`True` only if standard output is currently attached to a **TTY**
+    (i.e., interactive terminal).
+
+    If this tester returns :data:`True`, the TTY to which standard output is
+    currently attached may be safely assumed to support **ANSI escape
+    sequences** (i.e., POSIX-compliant colour codes). This assumption even holds
+    under platforms that are otherwise *not* POSIX-compliant, including:
+
+    * All popular terminals (including the stock Windows Terminal) and
+      interactive development environments (IDEs) (including VSCode) bundled
+      with Microsoft Windows, beginning at Windows 10.
+
+    Caveats
+    ----------
+    **This tester is intentionally not memoized** (i.e., via the
+    :func:`beartype._util.cache.utilcachecall.callable_cached` decorator), as
+    external callers can and frequently do monkey-patch or otherwise modify the
+    value of the global :attr:`sys.stdout` output stream.
+
+    See Also
+    ----------
+    https://stackoverflow.com/questions/3818511/how-to-tell-if-python-script-is-being-run-in-a-terminal-or-via-gui
+        StackOverflow thread strongly inspiring this implementation.
+    '''
+    # print(f'sys.stdout: {repr(sys.stdout)} [{type(sys.stdout)}]')
+    # print(f'sys.stderr: {repr(sys.stderr)} [{type(sys.stderr)}]')
+
+    # One-liners for great justice.
+    #
+    # Note that:
+    # * Input and output streams are *NOT* guaranteed to define the isatty()
+    #   method. For safety, we defensively test for the existence of that method
+    #   before deferring to that method.
+    # * All popular terminals under Windows >= 10 -- including terminals bundled
+    #   out-of-the-box with Windows -- now support ANSII escape sequences. Since
+    #   older Windows versions are compelling security risks and thus ignorable
+    #   for contemporary purposes, Windows no longer needs to be excluded from
+    #   ANSII-based colourization. All praise Satya Nadella. \o/
+    return hasattr(sys.stdout, 'isatty') and sys.stdout.isatty()
+    # return hasattr(sys.stdin, 'isatty') and sys.stdin.isatty()
+    # return hasattr(sys.stderr, 'isatty') and sys.stderr.isatty()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/path/utilpathremove.py
@@ -0,0 +1,186 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **path removers** (i.e., low-level callables permanently removing
+on-disk files and directories in various reasonably safe and portable ways).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+# from beartype.roar._roarexc import _BeartypeUtilPathException
+from beartype._data.hint.datahinttyping import (
+    PathnameLike,
+    PathnameLikeTuple,
+)
+from importlib.machinery import BYTECODE_SUFFIXES
+from pathlib import Path
+
+# ....................{ REMOVERS                           }....................
+#FIXME: Unit test us up, please.
+def remove_package_bytecode_files(package_dirname: PathnameLike) -> None:
+    '''
+    Permanently, silently, and recursively remove all **bytecode files** (i.e.,
+    pure-Python bytecode compiled to platform-dependent temporary files residing
+    in temporary ``__pycache__/`` subdirectories) of both the passed package and
+    all subpackages of that package regardless of nesting depth.
+
+    Usage
+    ----------
+    This function is typically intended for usage in our test suite. Unit tests
+    exercising :mod:`beartype` functionality that dynamically modifies the
+    contents of bytecode files guarantee idempotency (i.e., reproducibility) by
+    calling this function *before* exercising that functionality. Examples
+    include :mod:`beartype.claw` import hooks that dynamically transform the
+    abstract syntax trees (ASTs) of sample modules embedded in our test suite
+    *before* permanently serializing (i.e., saving, writing) those changes back
+    to disk within those bytecode files. Preventing desynchronization between
+    the frequently changing implementations of those import hooks and those
+    bytecode files requires calling this function beforehand.
+
+    Caveats
+    ----------
+    **This function is subject to subtle race conditions if multiple threads
+    and/or processes concurrently attempt to mutate this package on the local
+    filesystem.** Since *all* filesystem-centric logic suffers similar issues,
+    we leave this issue as an exercise for the caller.
+
+    Parameters
+    ----------
+    package_dirname : PathnameLike
+        Absolute dirname of the package to remove all previously compiled
+        bytecode files from.
+    '''
+    assert isinstance(package_dirname, PathnameLikeTuple), (
+        f'{repr(package_dirname)} neither string nor "Path" object.')
+
+    # Avoid circular import dependencies.
+    from beartype._util.path.utilpathtest import die_unless_dir
+
+    # High-level "Path" object encapsulating this dirname.
+    package_dir = Path(package_dirname)
+
+    # If this directory does *NOT* exist, raise an exception.
+    die_unless_dir(package_dir)
+    # Else, this directory exists.
+
+    # For the "."-prefixed filetype of each type of platform-dependent bytecode
+    # file generated by the current platform...
+    #
+    # Note that Python-specific glob syntax does *not* support disjunction
+    # (i.e., alternation). In particular, POSIX-compliant glob disjunction
+    # syntax "{match1,...,matchN}" is unsupported. If supported, that syntax
+    # would enable this inefficient O(n) iteration to be trivially optimized
+    # into a single O(1) call to the remove_paths_globbed() function.
+    for BYTECODE_SUFFIX in BYTECODE_SUFFIXES:
+        # Permanently and silently remove *ALL* bytecode files previously
+        # compiled by Python into this "__pycache__/" subdirectory.
+        remove_paths_globbed(
+            dirname=package_dir,
+            # Note that this filetype is already prefixed by ".". *sigh*
+            glob=f'**/__pycache__/*{BYTECODE_SUFFIX}',
+        )
+
+
+#FIXME: Unit test us up, please.
+def remove_paths_globbed(dirname: PathnameLike, glob: str) -> None:
+    '''
+    Permanently, silently, and possibly recursively remove *all* target files
+    and empty directories from the source directory with the passed dirname
+    matching the passed Python-specific glob expression.
+
+    Note that Python-specific glob syntax is exactly that supported by the
+    standard :mod:`fnmatch` module *plus* the recursive glob syntax ``"**/"``.
+    Specifically, Python-specific glob syntax supports *only* the following
+    small subset of POSIX-compliant glob syntax:
+
+    * ``"*"`` matches everything.
+    * ``"?"`` matches any single character.
+    * ``"[seq]"`` matches any character in the substring ``"seq"``.
+    * ``"[!seq]"`` matches any character not in the substring ``"seq"``.
+    * ``"**/"`` matches *all* subdirectories recursively regardless of depth
+      (e.g., ``"**/*.jpg"``, recursively removing all JPEG-formatted images from
+      both this directory and all subdirectories of this directory).
+
+    Caveats
+    ----------
+    **This function silently ignores all non-empty directories matched by this
+    glob expression.** Consider an alternate approach leveraging recursive
+    directory tree traversal if requiring non-empty directory removal.
+
+    **This function is subject to subtle race conditions if multiple threads
+    and/or processes concurrently attempt to mutate this source directory.**
+    Since *all* filesystem-centric logic suffers similar issues, we leave this
+    issue as an exercise for the caller.
+
+    **This function is currently inefficiently implemented in a single-threaded
+    manner for simplicity.** This approach is appropriate when removing a small
+    number of files but inappropriate when removing a large number of files. In
+    the latter case, consider an alternate approach leveraging either
+    multithreading or multiprocessing. See also this `popular article`_.
+
+    .. _popular article:
+        https://superfastpython.com/multithreaded-file-deletion
+
+    Parameters
+    ----------
+    dirname : PathnameLike
+        Dirname of the directory to remove *all* files and empty directories
+        matching this glob from, specified as a **pathname-like** (i.e., either
+        a low-level string possibly signifying a pathname *or* a high-level
+        :class:`Path` instance definitely encapsulating a pathname).
+    glob : str
+        Python-specific glob expression matching *all* files and empty
+        directories to be removed from this directory (e.g., ``"*.jpg"``).
+
+    Raises
+    ----------
+    _BeartypeUtilPathException
+        If either:
+
+        * This directory does *not* exist.
+        * This directory exists but is *not* actually a directory.
+
+    See Also
+    ----------
+    https://stackoverflow.com/a/38189275/2809027
+        StackOverflow answer strongly inspiring this implementation.
+    '''
+    assert isinstance(dirname, PathnameLikeTuple), (
+        f'{repr(dirname)} neither string nor "Path" object.')
+    assert isinstance(glob, str), f'{repr(glob)} not string.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.path.utilpathtest import die_unless_dir
+
+    # High-level "Path" object encapsulating this dirname.
+    dirname_path = Path(dirname)
+
+    # If this directory does *NOT* exist, raise an exception.
+    die_unless_dir(dirname_path)
+    # Else, this directory exists.
+
+    # For each matching pathname globbed from this dirname as a "Path" object...
+    for pathname_globbed in dirname_path.glob(glob):
+        # print(f'Removing globbed path "{pathname_globbed}"...')
+
+        # If this pathname refers to a file...
+        if pathname_globbed.is_file():
+            #FIXME: Pass "missing_ok=True" *AFTER* dropping Python 3.7, as doing
+            #so will improve the robustness of this logic against race
+            #conditions.
+
+            # Silently remove this file if feasible *OR* raise an exception.
+            pathname_globbed.unlink()
+        # Else, this pathname does *NOT* refer to a file.
+        #
+        # If this pathname refers to a (hopefully empty) subdirectory...
+        elif pathname_globbed.is_dir():
+            # Silently remove this empty subdirectory if feasible *OR* raise an
+            # exception.
+            pathname_globbed.rmdir()
+        # Else, this pathname refers to neither a file *NOR* subdirectory. In
+        # this case, silently ignore this pathname.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/path/utilpathtest.py
@@ -0,0 +1,170 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **path testers** (i.e., low-level callables testing various aspects
+of on-disk files and directories and raising exceptions when those files and
+directories fail to satisfy various constraints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilPathException
+from beartype._data.hint.datahinttyping import (
+    PathnameLike,
+    # PathnameLikeTuple,
+    TypeException,
+)
+from os import (
+    X_OK,
+    access as is_path_permissions,
+)
+from pathlib import Path
+
+# ....................{ RAISERS ~ dir                      }....................
+#FIXME: Unit test us up, please.
+def die_unless_dir(
+    # Mandatory parameters.
+    dirname: PathnameLike,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilPathException,
+) -> None:
+    '''
+    Raise an exception of the passed type if *no* directory with the passed
+    dirname exists.
+
+    Parameters
+    ----------
+    dirname : PathnameLike
+        Dirname to be validated.
+    exception_cls : Type[Exception], optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilPathException`.
+
+    Raises
+    ------
+    exception_cls
+        If *no* directory with the passed dirname exists.
+    '''
+
+    # High-level "Path" object encapsulating this dirname.
+    dirname_path = Path(dirname)
+
+    # If either no path with this pathname exists *OR* a path with this pathname
+    # exists but this path is not a directory...
+    if not dirname_path.is_dir():
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not type.')
+
+        # If no path with this pathname exists, raise an appropriate exception.
+        if not dirname_path.exists():
+            raise exception_cls(f'Directory "{dirname_path}" not found.')
+        # Else, a path with this pathname exists.
+
+        # By elimination, a path with this pathname exists but this path is not
+        # a directory. In this case, raise an appropriate exception.
+        raise exception_cls(f'Path "{dirname_path}" not directory.')
+    # Else, a directory with this dirname exists.
+
+# ....................{ RAISERS ~ file                     }....................
+#FIXME: Unit test us up, please.
+def die_unless_file(
+    # Mandatory parameters.
+    filename: PathnameLike,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilPathException,
+) -> None:
+    '''
+    Raise an exception of the passed type if *no* file with the passed filename
+    exists.
+
+    Parameters
+    ----------
+    filename : PathnameLike
+        Dirname to be validated.
+    exception_cls : Type[Exception], optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilPathException`.
+
+    Raises
+    ------
+    exception_cls
+        If *no* file with the passed filename exists.
+    '''
+
+    # High-level "Path" object encapsulating this filename.
+    filename_path = Path(filename)
+
+    # If either no path with this pathname exists *OR* a path with this pathname
+    # exists but this path is not a file...
+    if not filename_path.is_file():
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not type.')
+
+        # If no path with this pathname exists, raise an appropriate exception.
+        if not filename_path.exists():
+            raise exception_cls(f'File "{filename_path}" not found.')
+        # Else, a path with this pathname exists.
+
+        # By elimination, a path with this pathname exists but this path is not
+        # a file. In this case, raise an appropriate exception.
+        raise exception_cls(f'Path "{filename_path}" not file.')
+    # Else, a file with this filename exists.
+
+
+#FIXME: Unit test us up, please.
+def die_unless_file_executable(
+    # Mandatory parameters.
+    filename: PathnameLike,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilPathException,
+) -> None:
+    '''
+    Raise an exception of the passed type if either no file with the passed
+    filename exists *or* this file exists but is not **executable** (i.e., the
+    current user lacks sufficient permissions to execute this file).
+
+    Parameters
+    ----------
+    filename : PathnameLike
+        Dirname to be validated.
+    exception_cls : Type[Exception], optional
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilPathException`.
+
+    Raises
+    ------
+    :exception_cls
+        If either:
+
+        * No file with the passed filename exists.
+        * This file exists but is not executable by the current user.
+    '''
+
+    # If *NO* file with this filename exists, raise an exception.
+    die_unless_file(filename=filename, exception_cls=exception_cls)
+    # Else, a file with this filename exists.
+
+    # Note that this logic necessarily leverages the low-level "os.path"
+    # submodule rather than the object-oriented "pathlib.Path" class, which
+    # currently lacks *ANY* public facilities for introspecting permissions
+    # (including executability) as of Python 3.12. This is why we sigh.
+
+    # Reduce this possible high-level "Path" object to a low-level filename.
+    filename_str = str(filename)
+
+    # If the current user has *NO* permission to execute this file...
+    if not is_path_permissions(filename_str, X_OK):
+        assert isinstance(exception_cls, type), (
+            f'{repr(exception_cls)} not type.')
+
+        # Raise an appropriate exception.
+        raise exception_cls(f'File "{filename_str}" not executable.')
+    # Else, the current user has permission to execute this file. Ergo, this
+    # file is an executable file with respect to this user.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/py/utilpyinterpreter.py
@@ -0,0 +1,201 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python interpreter** utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import (
+    _BeartypeUtilPythonInterpreterException,
+)
+from beartype._data.hint.datahinttyping import CommandWords
+from beartype._util.cache.utilcachecall import callable_cached
+from platform import python_implementation
+from sys import executable as sys_executable
+
+# ....................{ TESTERS                            }....................
+@callable_cached
+def is_python_pypy() -> bool:
+    '''
+    :data:`True` only if the active Python interpreter is **PyPy**.
+
+    This tester is memoized for efficiency.
+    '''
+
+    return python_implementation() == 'PyPy'
+
+
+
+def is_python_optimized() -> bool:
+    '''
+    :data:`True` only if the active Python interpreter is currently
+    **optimized** (i.e., either the current Python process was invoked with at
+    least one ``-O`` command-line option *or* the ``${PYTHONOPTIMIZE}``
+    environment variable is currently set to a non-zero integer).
+
+    This tester is intentionally *not* memoized (e.g., by the
+    ``@callable_cached`` decorator), as doing so would prevent this tester from
+    detecting dynamic changes to the ``PYTHONOPTIMIZE`` environment variable
+    manually applied by the external user. Technically, Python itself detects
+    *no* such changes. Pragmatically, there's *no* demonstrable justification
+    for :mod:`beartype` itself to behave similarly; since testing environment
+    variable values is both trivial *and* yields a better outcome for users,
+    this tester does so. Indeed, our userbase `explicitly requested that we do
+    so <beartype issue_>`__.
+
+    .. _beartype issue:
+       https://github.com/beartype/beartype/issues/341
+    '''
+
+    # If Python disabled the "__debug__" dunder global, either the current
+    # Python process was invoked with at least one ``-O`` command-line option
+    # *OR* the "${PYTHONOPTIMIZE}" environment variable was set to a non-zero
+    # integer at process invocation time. In either case, return true.
+    if not __debug__:  # pragma: no cover
+        return True
+    # Else, Python enabled the "__debug__" dunder global. Although the
+    # "${PYTHONOPTIMIZE}" environment variable was *NOT* set to a non-zero
+    # integer at process invocation time, that variable *COULD* have since been
+    # set by the external user (e.g., in an interactive REPL). Let's decide.
+
+    # Avoid circular import dependencies.
+    from beartype._util.os.utilosshell import get_shell_var_value_or_none
+
+    # String value of this environment variable if set *OR* "None" otherwise.
+    PYTHONOPTIMIZE_str = get_shell_var_value_or_none('PYTHONOPTIMIZE')
+
+    # If this environment variable is set...
+    if PYTHONOPTIMIZE_str is not None:
+        # print(f'Detecting ${{PYTHONOPTIMIZE}} value {PYTHONOPTIMIZE_str}...')
+
+        # Attempt to coerce this string into an integer.
+        try:
+            PYTHONOPTIMIZE_int = int(PYTHONOPTIMIZE_str)
+        # If doing so raises *ANY* exception whatsoever, return false.
+        except:
+            return False
+
+        # If this integer is non-zero, this environment variable has since been
+        # set to a non-zero integer by the user. In this case, return true.
+        if PYTHONOPTIMIZE_int > 0:
+            return True
+        # Else, this environment variable remains zeroed and thus disabled.
+    # Else, this environment variable is unset.
+
+    # Return false as a fallback.
+    return False
+
+# ....................{ GETTERS ~ path                     }....................
+@callable_cached
+def get_interpreter_command_words() -> CommandWords:
+    '''
+    **Active Python interpreter command words** (i.e., iterable of one or more
+    shell words unambiguously running the executable binary for this interpreter
+    and machine architecture).
+
+    This getter is memoized for efficiency.
+
+    Caveats
+    -------
+    **This high-level getter should always be called in lieu of the low-level**
+    :func:`.get_interpreter_filename` **getter** when attempting to rerun this
+    interpreter as a subprocess of the active Python process. Why? Because the
+    absolute filename of the executable binary for this interpreter is
+    insufficient to unambiguously run this binary under edge cases, including:
+
+    * **macOS.** Under macOS, the executable binary for this interpreter may be
+      bundled with one or more other executable binaries targeting different
+      machine architectures (e.g., 32-bit, 64-bit) in a single so-called
+      "universal binary." Distinguishing between these bundled binaries requires
+      passing this interpreter to a prefixing macOS-specific command: ``arch``.
+
+    Returns
+    -------
+    CommandWords
+        Iterable of one or more shell words unambiguously running this binary.
+    '''
+
+    #FIXME: Uncomment if required. Although this was certainly required a decade
+    #ago, it's unclear whether this is still required; indeed, given the
+    #increased prevalence of Apple Silicon, it seems likely that an entirely
+    #different macOS-specific prefix might be required now. Thus, I sigh. *sigh*
+    # # Avoid circular import dependencies.
+    # from beartype._util.os.utilostest import is_os_macos
+    #
+    # # List of such shell words.
+    # command_words = None  # type: ignore[assignment]
+    #
+    # # If the current platform is macOS, this interpreter is only unambiguously runnable via the
+    # # macOS-specific "arch" command. In this case...
+    # if is_os_macos():
+    #     # Run the "arch" command.
+    #     command_words = ['arch']
+    #
+    #     # Instruct this command to run the architecture-specific binary in
+    #     # Python's universal binary corresponding to the current architecture.
+    #     if is_wordsize_64():
+    #         command_words.append('-i386')
+    #     else:
+    #         command_words.append('-x86_64')
+    #
+    #     # Instruct this command, lastly, to run this interpreter.
+    #     command_words.append(get_interpreter_filename())
+    # # Else, this interpreter is unambiguously runnable as is.
+    # else:
+    #     command_words = [get_interpreter_filename()]
+
+    # Iterable of all interpreter shell words to be returned.
+    command_words = (get_interpreter_filename(),)
+
+    # Return this iterable.
+    return command_words
+
+
+@callable_cached
+def get_interpreter_filename() -> str:
+    '''
+    Absolute filename of the executable binary underlying the active Python
+    interpreter if Python provides this filename *or* raise an exception
+    otherwise (i.e., if Python refuses to provide this filename, typically due
+    to this filename being embedded in a frozen bundle of some sort).
+
+    This getter is memoized for efficiency.
+
+    Raises
+    ------
+    _BeartypeUtilPathException
+        If Python successfully queried this filename but no such file exists.
+    _BeartypeUtilPythonInterpreterException
+        If Python failed to query this filename.
+
+    Returns
+    -------
+    str
+        Absolute filename of this binary.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.path.utilpathtest import die_unless_file_executable
+
+    # If Python refuses to provide this filename, raise an exception.
+    #
+    # Note that this test intentionally matches both the empty string and
+    # "None", as the official documentation for "sys.executable" states:
+    #     If Python is unable to retrieve the real path to its executable,
+    #     sys.executable will be an empty string or None.
+    if not sys_executable:
+        raise _BeartypeUtilPythonInterpreterException(
+            'Absolute filename of active Python interpreter not found.')
+    # Else, Python provides this filename.
+
+    # If this file is *NOT* executable, raise an exception.
+    die_unless_file_executable(sys_executable)
+    # Else, this file is executable.
+
+    # Return this filename.
+    return sys_executable
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/py/utilpyversion.py
@@ -0,0 +1,136 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python interpreter version utilities**.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from sys import version_info
+
+# ....................{ CONSTANTS ~ at least               }....................
+IS_PYTHON_AT_LEAST_4_0 = version_info >= (4, 0)
+'''
+:data:`True` only if the active Python interpreter targets at least Python
+4.0.0.
+'''
+
+
+#FIXME: After dropping Python 3.13 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+#* Remove all decorators resembling:
+#  @skip_if_python_version_less_than('3.13.0')
+IS_PYTHON_AT_LEAST_3_13 = IS_PYTHON_AT_LEAST_4_0 or version_info >= (3, 13)
+'''
+:data:`True` only if the active Python interpreter targets at least Python
+3.12.0.
+'''
+
+#FIXME: After dropping Python 3.13 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+#* Remove all decorators resembling:
+#  @skip_if_python_version_less_than('3.12.0')
+IS_PYTHON_AT_LEAST_3_12 = IS_PYTHON_AT_LEAST_3_13 or version_info >= (3, 12)
+'''
+:data:`True` only if the active Python interpreter targets at least Python
+3.13.0.
+'''
+
+
+#FIXME: After dropping Python 3.10 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+IS_PYTHON_AT_MOST_3_11 = not IS_PYTHON_AT_LEAST_3_12
+'''
+:data:`True` only if the active Python interpreter targets at most Python
+3.11.x.
+'''
+
+
+#FIXME: After dropping Python 3.10 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+#* Remove all decorators resembling:
+#  @skip_if_python_version_less_than('3.11.0')
+IS_PYTHON_AT_LEAST_3_11 = IS_PYTHON_AT_LEAST_3_12 or version_info >= (3, 11)
+'''
+:data:`True` only if the active Python interpreter targets at least Python
+3.11.0.
+'''
+
+
+#FIXME: After dropping Python 3.9 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+IS_PYTHON_AT_MOST_3_10 = not IS_PYTHON_AT_LEAST_3_11
+'''
+:data:`True` only if the active Python interpreter targets at most Python
+3.10.x.
+'''
+
+
+#FIXME: After dropping Python 3.9 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+#* Remove all decorators resembling:
+#  @skip_if_python_version_less_than('3.10.0')
+IS_PYTHON_AT_LEAST_3_10 = IS_PYTHON_AT_LEAST_3_11 or version_info >= (3, 10)
+'''
+:data:`True` only if the active Python interpreter targets at least Python
+3.10.0.
+'''
+
+
+#FIXME: After dropping Python 3.9 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+IS_PYTHON_AT_MOST_3_9 = not IS_PYTHON_AT_LEAST_3_10
+'''
+:data:`True` only if the active Python interpreter targets at most Python 3.9.x.
+'''
+
+
+#FIXME: After dropping Python 3.8 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+#* Remove all decorators resembling:
+#  @skip_if_python_version_less_than('3.9.0')
+IS_PYTHON_AT_LEAST_3_9 = IS_PYTHON_AT_LEAST_3_10 or version_info >= (3, 9)
+'''
+:data:`True` only if the active Python interpreter targets at least Python
+3.9.0.
+'''
+
+
+#FIXME: After dropping Python 3.8 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+IS_PYTHON_AT_MOST_3_8 = not IS_PYTHON_AT_LEAST_3_9
+'''
+:data:`True` only if the active Python interpreter targets at most Python 3.8.x.
+'''
+
+
+#FIXME: After dropping Python 3.8 support:
+#* Refactor all code conditionally testing this global to be unconditional.
+#* Remove this global.
+IS_PYTHON_3_8 = version_info[:2] == (3, 8)
+'''
+:data:`True` only if the active Python interpreter targets exactly Python 3.8.x.
+'''
+
+# ....................{ GETTERS                            }....................
+def get_python_version_major_minor() -> str:
+    '''
+    ``"."``-delimited major and minor version of the active Python interpreter
+    (e.g., ``3.11``, ``3.7``), excluding the patch version of this interpreter.
+    '''
+
+    # Heroic one-liners are an inspiration to us all.
+    return f'{version_info[0]}.{version_info[1]}'
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/py/utilpyweakref.py
@@ -0,0 +1,191 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **weak reference** (i.e., references to objects explicitly
+allowing those objects to be garbage-collected at *any* time) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilPythonWeakrefException
+from beartype.typing import (
+    Tuple,
+)
+from weakref import ref as weakref_ref
+
+# ....................{ GETTERS                            }....................
+def make_obj_weakref_and_repr(obj: object) -> Tuple[object, str]:
+    '''
+    2-tuple ``(weakref, repr)`` weakly referring to the passed object.
+
+    Parameters
+    ----------
+    obj : object
+        Arbitrary object to be weakly referred to.
+
+    Returns
+    ----------
+    Tuple[object, str]
+        2-tuple ``(weakref, repr)`` weakly referring to this object such that:
+
+        * ``weakref`` is either:
+
+          * If this object supports weak references, a **weak reference** (i.e.,
+            :class:`weakref.ref` instance) to this object.
+          * If this object prohibits weak references (e.g., due to being a
+            common C-based variable-sized container like a tuple or string),
+            ``None``.
+
+        * ``repr`` is the machine-readable representation of this object,
+          truncated to ~10KB to minimize space consumption in the worst case of
+          an obscenely large object.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextrepr import represent_object
+
+    # Weak reference to this object if this object supports weak references *OR*
+    # "None" otherwise (e.g., if this object is a variable-sized container).
+    obj_weakref = None
+
+    # Machine-readable representation of this object truncated to minimize space
+    # consumption for the worst case of an obscenely large object.
+    obj_repr = represent_object(
+        obj=obj,
+        # Store at most 1KB of the full representation, which should
+        # certainly suffice for most use cases. Note that the
+        # default of 96B is far too small to be useful here.
+        max_len=1000,
+    )
+
+    # If this object is "None", substitute "None" for this non-"None"
+    # placeholder. Since the "weakref.ref" class ambiguously returns "None" when
+    # this object has already been garbage-collected, this placeholder enables
+    # subsequent calls to the get_obj_weakref_or_repr() getter to disambiguate
+    # between these two common edge cases.
+    if obj is None:
+        obj_weakref = _WEAKREF_NONE
+    # Else, this object is *NOT* "None". In this case...
+    else:
+        # Attempt to classify a weak reference to this object for safety.
+        try:
+            obj_weakref = weakref_ref(obj)
+        # If doing so raises a "TypeError", this object *CANNOT* be weakly
+        # referred to. Sadly, builtin variable-sized C-based types (e.g.,
+        # "dict", "int", "list", "tuple") *CANNOT* be weakly referred to. This
+        # constraint is officially documented by the "weakref" module:
+        #     Several built-in types such as list and dict do not directly
+        #     support weak references but can add support through subclassing.
+        #     CPython implementation detail: Other built-in types such as tuple
+        #     and int do not support weak references even when subclassed.
+        #
+        # Since this edge case is common, permitting this exception to unwind
+        # the call stack is unacceptable; likewise, even coercing this exception
+        # into non-fatal warnings would generic excessive warning spam and is
+        # thus also unacceptable. The only sane solution remaining is to
+        # silently store the machine-readable representation of this object and
+        # return that rather than this object from the "object" property.
+        except TypeError:
+            pass
+
+    return obj_weakref, obj_repr
+
+
+
+def get_weakref_obj_or_repr(obj_weakref: object, obj_repr: str) -> object:
+    '''
+    Object weakly referred to by the passed object if this object is indeed a
+    weak reference to another existing object *or* the passed machine-readable
+    representation otherwise (i.e., if this object is either ``None`` *or* is a
+    weak reference to a dead garbage-collected object).
+
+    This function is typically passed the pair of objects returned by a prior
+    call to the companion :func:`make_obj_weakref_and_repr` function.
+
+    Parameters
+    ----------
+    obj_weakref : object
+        Either:
+
+        * If the **referent** (i.e., target object being weakly referred to) is
+          the ``None`` singleton, the :data:`_WEAKREF_NONE` placeholder.
+        * Else if the referent supports weak references, a **weak reference**
+          (i.e., :class:`weakref.ref` instance) to that object.
+        * Else, ``None``.
+    obj_repr : str
+        Machine-readable representation of that object, typically truncated to
+        some number of characters to avoid worst-case space consumption.
+
+    Returns
+    ----------
+    object
+        Either:
+
+        * If this weak reference is the :data:`_WEAKREF_NONE` placeholder, the
+          ``None`` singleton.
+        * Else if this referent support weak references, either:
+
+          * If this referent is still alive (i.e., has yet to be
+            garbage-collected), this referent.
+          * Else, this referent is now dead (i.e., has already been
+            garbage-collected). In this case, the passed representation.
+
+        * Else, this referent does *not* support weak references (i.e., this
+          weak reference is ``None``). In this case, the passed representation.
+
+    Raises
+    ----------
+    _BeartypeUtilPythonWeakrefException
+        If ``obj_weakref`` is invalid: i.e., neither ``None``,
+        :data:`_WEAKREF_NONE`, nor a weak reference.
+    '''
+    assert isinstance(obj_repr, str), f'{repr(obj_repr)} not string.'
+
+    # If this weak reference is "None", the prior call to
+    # make_obj_weakref_and_repr() was passed an object that could *NOT* be
+    # weakly referred to (e.g., C-based container). In this case, fallback to
+    # the machine-readable representation of that object.
+    if obj_weakref is None:
+        return obj_repr
+    # Else, this weak reference is *NOT* "None".
+    #
+    # If this weak reference is "_WEAKREF_NONE", the prior call to
+    # make_obj_weakref_and_repr() was passed the "None" singleton. In this case,
+    # substitute this placeholder for "None". See that factory.
+    elif obj_weakref is _WEAKREF_NONE:
+        return None
+    # Else, this weak reference is *NOT* that placeholder.
+    #
+    # If this weak reference is *NOT* a weak reference, raise an exception.
+    elif not isinstance(obj_weakref, weakref_ref):
+        raise _BeartypeUtilPythonWeakrefException(
+            f'Weak reference {repr(obj_weakref)} invalid '
+            f'(i.e., neither weak reference, "None", nor "_WEAKREF_NONE").'
+        )
+    # Else, this weak reference is a weak reference.
+
+    # Object weakly referred to by this weak reference if this object is alive
+    # *OR* "None" otherwise (i.e., if this object was garbage-collected).
+    obj = obj_weakref()
+
+    # Return either...
+    return (
+        # If this object is still alive, this object;
+        obj if obj is not None else
+        # Else, this object is now dead. In this case, the machine-readable
+        # representation of this object instead.
+        obj_repr
+    )
+
+# ....................{ PROPERTIES ~ constants             }....................
+_WEAKREF_NONE = object()
+'''
+Singleton substitute for the ``None`` singleton, enabling
+:class:`BeartypeCallHintViolation` exceptions to differentiate between weak
+references to ``None`` and weak references whose referents are already dead
+(i.e., have already been garbage-collected).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/py/utilpyword.py
@@ -0,0 +1,56 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **Python word size** (i.e., bit length of Python variables of internal
+type ``Py_ssize_t`` under the active Python interpreter) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from sys import maxsize
+
+# ....................{ INTEGERS                           }....................
+SHORT_MAX_32_BIT = 1 << 32
+'''
+Maximum value of **32-bit Python shorts** (i.e., integer variables of internal
+type ``Py_ssize_t`` under 32-bit Python interpreters roughly corresponding to
+the ``long`` C type under 32-bit machines, confusingly).
+
+This value is suitable for comparison with :attr:`sys.maxsize`, the maximum
+value of such variables under the active Python interpreter.
+'''
+
+# ....................{ BOOLEANS                           }....................
+IS_WORD_SIZE_64 = maxsize > SHORT_MAX_32_BIT
+'''
+:data:`True` only if the active Python interpreter is **64-bit** (i.e., was
+compiled with a 64-bit toolchain into a 64-bit executable).
+
+Equivalently, this is :data:`True` only if the maximum value of Python shorts
+under this interpreter is larger than the maximum value of 32-bit Python shorts.
+While obtuse, this test is well-recognized by the Python community as the best
+means of testing this portably. Valid but worse alternatives include:
+
+* ``'PROCESSOR_ARCHITEW6432' in os.environ``, which depends upon optional
+  environment variables and hence is clearly unreliable.
+* ``platform.architecture()[0] == '64bit'``, which fails under:
+
+  * macOS, returning ``64bit`` even when the active Python interpreter is a
+    32-bit executable binary embedded in a so-called "universal binary."
+'''
+
+# ....................{ INTEGERS ~ more                    }....................
+WORD_SIZE = 64 if IS_WORD_SIZE_64 else 32
+'''
+Bit length of **Python shorts** (i.e., integer variables of internal type
+``Py_ssize_t`` roughly corresponding to the ``long`` C type, confusingly).
+
+This integer is guaranteed to be either:
+
+* If the active Python interpreter is 64-bit, ``64``.
+* Else, ``32``.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextansi.py
@@ -0,0 +1,377 @@
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **ANSI utilities** (i.e., low-level callables handling ANSI escape
+sequences colouring arbitrary strings).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.datahinttyping import BoolTristate
+from re import compile as re_compile
+
+# ....................{ CONSTANTS                          }....................
+ANSI_RESET = '\033[0m'
+'''
+ANSI escape sequence resetting the effect of all prior ANSI sequence sequences,
+effectively "undoing" all colors and styles applied by those sequences.
+'''
+
+# ....................{ CONSTANTS ~ color                  }....................
+COLOR_BLUE = '\033[34m'
+'''
+ANSI escape sequence colouring all subsequent characters as blue.
+'''
+
+
+COLOR_CYAN = '\033[36m'
+'''
+ANSI escape sequence colouring all subsequent characters as **cyan** (i.e.,
+light blue).
+'''
+
+
+COLOR_GREEN = '\033[32m'
+'''
+ANSI escape sequence colouring all subsequent characters as **green**.
+'''
+
+
+COLOR_MAGENTA = '\033[35m'
+'''
+ANSI escape sequence colouring all subsequent characters as **magenta** (i.e.,
+purple, dark blue).
+'''
+
+
+COLOR_RED = '\033[31m'
+'''
+ANSI escape sequence colouring all subsequent characters as **red**.
+'''
+
+
+COLOR_YELLOW = '\033[33m'
+'''
+ANSI escape sequence colouring all subsequent characters as **yellow**.
+'''
+
+# ....................{ CONSTANTS ~ style                  }....................
+STYLE_BOLD = '\033[1m'
+'''
+ANSI escape sequence stylizing all subsequent characters as bold.
+'''
+
+# ....................{ TESTERS                            }....................
+def is_str_ansi(text: str) -> bool:
+    '''
+    :data:`True` only if the passed text contains one or more ANSI escape
+    sequences.
+
+    Parameters
+    ----------
+    text : str
+        Text to be tested.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this text contains one or more ANSI escape
+        sequences.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return true only this compiled regex matching ANSI escape sequences
+    # returns a non-"None" match object when passed this text.
+    return _ANSI_REGEX.search(text) is not None
+
+# ....................{ COLOURIZERS                        }....................
+def color_hint(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = True,
+) -> str:
+    '''
+    Colour the passed substring as a type hint if the passed tri-state colouring
+    boolean instructs this function to do so.
+
+    Parameters
+    ----------
+    text : str
+        Text to be coloured as a type hint.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`True`.
+
+    Returns
+    -------
+    str
+        This text conditionally coloured as a type hint.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return either...
+    return (
+        # If this tri-state boolean instructs this function to colour this
+        # string, this string coloured with ANSI;
+        f'{STYLE_BOLD}{COLOR_GREEN}{text}{ANSI_RESET}'
+        if _is_color(is_color) else
+        # Else, this string uncoloured.
+        text
+    )
+
+
+def color_pith(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = True,
+) -> str:
+    '''
+    Colour the passed substring as a **pith representation** (i.e.,
+    machine-readable string describing the value of the object currently being
+    type-checked, typically created by the
+    :func:`beartype._util.text.utiltextrepr.represent_object` function) if the
+    passed tri-state colouring boolean instructs this function to do so.
+
+    Parameters
+    ----------
+    text : str
+        Text to be coloured as a representation.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`True`.
+
+    Returns
+    -------
+    str
+        This text conditionally coloured as a representation.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return either...
+    return (
+        # If this tri-state boolean instructs this function to colour this
+        # string, this string coloured with ANSI;
+        f'{STYLE_BOLD}{COLOR_RED}{text}{ANSI_RESET}'
+        if _is_color(is_color) else
+        # Else, this string uncoloured.
+        text
+    )
+
+
+def color_type(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = True,
+) -> str:
+    '''
+    Colour the passed substring as a simple class if the passed tri-state
+    colouring boolean instructs this function to do so.
+
+    Parameters
+    ----------
+    text : str
+        Text to be coloured as a simple class.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`True`.
+
+    Returns
+    -------
+    str
+        This text conditionally coloured as a simple class.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return either...
+    return (
+        # If this tri-state boolean instructs this function to colour this
+        # string, this string coloured with ANSI;
+        f'{STYLE_BOLD}{COLOR_YELLOW}{text}{ANSI_RESET}'
+        if _is_color(is_color) else
+        # Else, this string uncoloured.
+        text
+    )
+
+# ....................{ COLOURIZERS ~ name                 }....................
+def color_attr_name(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = True,
+) -> str:
+    '''
+    Colour the passed substring as a **Python identifier** (e.g., possibly
+    fully-qualified name of a module, class, callable, or variable name) if the
+    passed tri-state colouring boolean instructs this function to do so.
+
+    Parameters
+    ----------
+    text : str
+        Text to be coloured as a Python identifier.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`True`.
+
+    Returns
+    -------
+    str
+        This text conditionally coloured as a Python identifier.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return either...
+    return (
+        # If this tri-state boolean instructs this function to colour this
+        # string, this string coloured with ANSI;
+        f'{STYLE_BOLD}{COLOR_MAGENTA}{text}{ANSI_RESET}'
+        if _is_color(is_color) else
+        # Else, this string uncoloured.
+        text
+    )
+
+
+def color_arg_name(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = True,
+) -> str:
+    '''
+    Colour the passed substring as an **argument name** (i.e., of the parameter
+    of a :func:`beartype.beartype`-decorated callable currently being
+    type-checked) if the passed tri-state colouring boolean instructs this
+    function to do so.
+
+    Parameters
+    ----------
+    text : str
+        Text to be coloured as an argument name.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`True`.
+
+    Returns
+    -------
+    str
+        This text coloured as an argument name.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return either...
+    return (
+        # If this tri-state boolean instructs this function to colour this
+        # string, this string coloured with ANSI;
+        f'{STYLE_BOLD}{COLOR_BLUE}{text}{ANSI_RESET}'
+        if _is_color(is_color) else
+        # Else, this string uncoloured.
+        text
+    )
+
+# ....................{ STRIPPERS                          }....................
+#FIXME: Unit test up the "is_color" parameter.
+def strip_str_ansi(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Strip *all* ANSI escape sequences from the passed string if the passed
+    tri-state colouring boolean instructs this function to do so.
+
+    Specifically:
+
+    * If ``is_color is True``, this function silently reduces to a noop.
+    * If ``is_color is False``, this function unconditionally strips all ANSI
+      escape sequences from this string.
+    * If ``is_color is None``, this function conditionally strips all ANSI
+      escape sequences from this string only if standard output is currently
+      attached to an interactive terminal.
+
+    Parameters
+    ----------
+    text : str
+        Text to be stripped.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        This text conditionally stripped of ANSI.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return either...
+    return (
+        # If this tri-state boolean instructs this function to preserve all ANSI
+        # in this string, this string unmodified;
+        text
+        if _is_color(is_color) else
+        # Else, this string stripped of all ANSI.
+        _ANSI_REGEX.sub('', text)
+    )
+
+# ....................{ PRIVATE ~ constants                }....................
+_ANSI_REGEX = re_compile(r'\033\[[0-9;?]*[A-Za-z]')
+'''
+Compiled regular expression matching a single ANSI escape sequence.
+'''
+
+# ....................{ PRIVATE ~ testers                  }....................
+def _is_color(is_color: BoolTristate) -> bool:
+    '''
+    Reduce the passed tri-state colouring boolean governing ANSI usage to a
+    simple boolean.
+
+    Specifically, this tester returns either:
+
+    * :data:`True` only if the passed ``is_color`` parameter is either:
+
+      * :data:`True`.
+      * :data:`None` and standard output is currently attached to an interactive
+        POSIX-compliant terminal. Note that this is the common case, as the
+        :attr:`beartype.BeartypeConf.is_color` attribute underlying this
+        parameter typically defaults to :data:`None`.
+
+    * :data:`False` otherwise.
+
+    Parameters
+    ----------
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+    '''
+    assert isinstance(is_color, bool) or is_color is None, (  # <-- "NoneTypeOr" is unavailable here
+        f'{repr(is_color)} not tri-state boolean.')
+
+    # Avoid circular import dependencies.
+    from beartype._util.os.utilostty import is_stdout_terminal
+
+    # Return true only if the passed tri-state boolean is either...
+    return (
+        # True *OR*...
+        is_color is True or
+        # "None" and standard output is currently attached to an interactive
+        # POSIX-compliant terminal.
+        (is_color is None and is_stdout_terminal())
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextget.py
@@ -0,0 +1,109 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **string getters** (i.e., low-level callables slicing and returning
+substrings out of arbitrary strings, typically to acquire prefixes and suffixes
+satisfying various conditions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+# from beartype.roar._roarexc import _BeartypeUtilTextException
+
+# ....................{ GETTERS                            }....................
+#FIXME: Uncomment if ever needed.
+# def get_str_prefix_greedy(text: str, anchor: str) -> str:
+#     '''
+#     **Greedily anchored prefix** (i.e., substring ranging from the first
+#     character to the last instance of the passed substring) of the passed
+#     string if any *or* raise an exception otherwise (i.e., if this string
+#     contains no such substring).
+#
+#     Parameters
+#     ----------
+#     text : str
+#         String to be searched.
+#     anchor: str
+#         Substring to search this string for.
+#
+#     Returns
+#     ----------
+#     str
+#         Prefix of this string preceding the last instance of this substring.
+#
+#     Raises
+#     ----------
+#     _BeartypeUtilTextException
+#         If this string contains *no* instance of this substring.
+#
+#     See Also
+#     ----------
+#     :func:`get_str_prefix_greedy_or_none`
+#         Further details.
+#     '''
+#
+#     # Greedily anchored prefix of this string if any *OR* "None" otherwise.
+#     text_prefix_greedy = get_str_prefix_greedy_or_none(text, anchor)
+#
+#     # If this string contains *NO* such prefix, raise an exception.
+#     if text_prefix_greedy is None:
+#         raise _BeartypeUtilTextException(
+#             f'String "{text}" substring "{anchor}" not found.')
+#
+#     # Else, return this prefix.
+#     return text_prefix_greedy
+
+
+#FIXME: Uncomment if ever needed.
+# def get_str_prefix_greedy_or_none(text: str, anchor: str) -> 'Optional[str]':
+#     '''
+#     **Greedily anchored prefix** (i.e., substring ranging from the first
+#     character to the last instance of the passed substring) of the passed
+#     string if any *or* ``None`` otherwise (i.e., if this string contains no
+#     such substring).
+#
+#     Parameters
+#     ----------
+#     text : str
+#         String to be searched.
+#     anchor: str
+#         Substring to search this string for.
+#
+#     Returns
+#     ----------
+#     Optional[str]
+#         Either:
+#
+#         * If this string contains this substring, the prefix of this string
+#           preceding the last instance of this substring.
+#         * Else, ``None``.
+#
+#     Examples
+#     ----------
+#         >>> from beartype._util.text.utiltextget import (
+#         ...     get_str_prefix_greedy_or_none)
+#         >>> get_str_prefix_greedy_or_none(
+#         ...     text='Opposition...contradiction...premonition...compromise.',
+#         ...     anchor='.')
+#         Opposition...contradiction...premonition...compromise
+#         >>> get_str_prefix_greedy_or_none(
+#         ...     text='This is an anomaly. Disabled. What is true?',
+#         ...     anchor='!')
+#         None
+#     '''
+#     assert isinstance(text, str), f'{repr(text)} not string.'
+#     assert isinstance(anchor, str), f'{repr(anchor)} not string.'
+#
+#     # Return either...
+#     return (
+#         # If this string contains this substring, the substring of this string
+#         # preceding the last instance of this substring in this string.
+#         text[:text.rindex(anchor)]
+#         if anchor in text else
+#         # Else, "None".
+#         None
+#     )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextidentifier.py
@@ -0,0 +1,169 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **Python identifier utilities** (i.e., low-level callables handling
+unqualified and qualified attribute, callable, class, module, and variable
+names).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilTextIdentifierException
+from beartype._data.hint.datahinttyping import TypeException
+
+# ....................{ RAISERS                            }....................
+def die_unless_identifier(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    exception_cls: TypeException = _BeartypeUtilTextIdentifierException,
+    exception_prefix: str = '',
+) -> None:
+    '''
+    Raise an exception unless the passed string is a valid **Python attribute
+    name** (i.e., ``.``-delimited concatenation of one or more
+    :pep:`3131`-compliant syntactically valid Python identifiers, including the
+    names of attributes, callables, classes, modules, and variables).
+
+    Parameters
+    ----------
+    text : str
+        String to be validated.
+    exception_cls : Type[Exception]
+        Type of exception to be raised in the event of a fatal error. Defaults
+        to :exc:`._BeartypeUtilTextIdentifierException`.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this string in the
+        exception message. Defaults to the empty string.
+
+    Raises
+    ------
+    exception_cls
+        If this string is *not* a valid Python attribute name.
+
+    See Also
+    --------
+    :func:`.is_identifier`
+        Further details.
+    '''
+
+    # If this string is *NOT* a valid Python attribute name, raise an exception.
+    if not (isinstance(text, str) and is_identifier(text)):
+        assert isinstance(exception_cls, type), (
+            'f{repr(exception_cls)} not exception class.')
+        assert isinstance(exception_prefix, str), (
+            'f{repr(exception_prefix)} not string.')
+
+        raise exception_cls(
+            f'{exception_prefix}{repr(text)} not valid Python attribute name.')
+    # Else, this string is a valid Python attribute name.
+
+# ....................{ TESTERS                            }....................
+def is_dunder(text: str) -> bool:
+    '''
+    :data:`True` only if the passed string vaguely conforms to the name of a
+    **dunder attribute** (i.e., attribute whose name is both prefixed and
+    suffixed by ``"__"`` double underscore substrings).
+
+    Parameters
+    ----------
+    text : str
+        String to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this string conforms to a dunder attribute name.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return us up the powerful one-liner of power.
+    return text.startswith('__') and text.endswith('__')
+
+
+def is_identifier(text: str) -> bool:
+    '''
+    :data:`True` only if the passed string is a valid **Python attribute name**
+    (i.e., ``.``-delimited concatenation of one or more :pep:`3131`-compliant
+    syntactically valid Python identifiers, including the names of attributes,
+    callables, classes, modules, and variables).
+
+    This tester is suitable for detecting whether this string is the
+    fully-qualified name of an arbitrary Python object.
+
+    Caveats
+    ----------
+    **This tester is mildly slow,** due to unavoidably splitting this string on
+    ``.`` delimiters and iteratively passing each of the split substrings to
+    the :meth:`str.isidentifier` builtin. Due to the following caveat, this
+    inefficiency is unavoidable.
+
+    **This tester is not optimizable with regular expressions** -- at least,
+    not trivially. Technically, this tester *can* be optimized by leveraging
+    the "General Category" of Unicode filters provided by the third-party
+    :mod:`regex` package. Practically, doing so would require the third-party
+    :mod:`regex` package and would still almost certainly fail in edge cases.
+    Why? Because Python 3 permits Python identifiers to contain Unicode letters
+    and digits in the "General Category" of Unicode code points, which is
+    extremely non-trivial to match with the standard :mod:`re` module.
+
+    Parameters
+    ----------
+    text : str
+        String to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this string is the ``.``-delimited concatenation of
+        one or more syntactically valid Python identifiers.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # If this text contains *NO* "." delimiters and is thus expected to be an
+    # unqualified Python identifier, return true only if this is the case.
+    if '.' not in text:
+        return text.isidentifier()
+    # Else, this text contains one or more "." delimiters and is thus expected
+    # to be a qualified Python identifier.
+
+    # Return true only if *ALL* "."-delimited substrings split from this string
+    # are valid unqualified Python identifiers. Note that:
+    # * Regular expressions report false negatives. See the docstring.
+    # * Manual iteration is significantly faster than "all(...)"- and
+    #   "any(...)"-style comprehensions.
+    # * This approach correctly handles *ALL* edge cases, including when:
+    #   * This string is simply the "." character. In this case:
+    #         >>> '.'.split('.')
+    #         ['', '']
+    #     Since the empty string is *NOT* a valid Python identifier, this
+    #     iteration immediately returns false as expected.
+    # * There exists an alternative and significantly more computationally
+    #   expensive means of testing this condition, employed by the
+    #   typing.ForwardRef.__init__() method to valid the validity of the passed
+    #   relative classname:
+    #       # Needless to say, we'll never be doing this.
+    #       try:
+    #           all(
+    #               compile(identifier, '<string>', 'eval')
+    #               for identifier in text.split('.')
+    #           )
+    #           return True
+    #       except SyntaxError:
+    #           return False
+    for text_basename in text.split('.'):
+        # If this "."-delimited substring is *NOT* a valid unqualified Python
+        # identifier, return false.
+        if not text_basename.isidentifier():
+            return False
+        # Else, this "."-delimited substring is a valid unqualified Python
+        # identifier. In this case, silently continue to the next.
+
+    # Return true, since *ALL* "."-delimited substrings split from this string
+    # are valid unqualified Python identifiers.
+    return True
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextjoin.py
@@ -0,0 +1,247 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **string joining utilities** (i.e., callables joining passed
+strings into new strings delimited by passed substring delimiters).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import Iterable as typing_Iterable
+from beartype._data.hint.datahinttyping import IterableStrs
+from collections.abc import (
+    Iterable,
+    Sequence,
+)
+
+# ....................{ JOINERS                            }....................
+#FIXME: Unit test the "is_double_quoted" parameter, please.
+def join_delimited(
+    # Mandatory parameters.
+    strs: IterableStrs,
+
+    # Mandatory keyword-only parameters.
+    *,
+    delimiter_if_two: str,
+    delimiter_if_three_or_more_nonlast: str,
+    delimiter_if_three_or_more_last: str,
+
+    # Optional keyword-only parameters.
+    is_double_quoted: bool = False,
+) -> str:
+    '''
+    Concatenate the passed iterable of zero or more strings delimited by the
+    passed delimiter (conditionally depending on both the length of this
+    sequence and index of each string in this sequence), yielding a
+    human-readable string listing arbitrarily many substrings.
+
+    Specifically, this function returns either:
+
+    * If this iterable contains no strings, the empty string.
+    * If this iterable contains one string, this string as is is unmodified.
+    * If this iterable contains two strings, these strings delimited by the
+      passed ``delimiter_if_two`` delimiter.
+    * If this iterable contains three or more strings, a string listing these
+      contained strings such that:
+
+      * All contained strings except the last two are suffixed by the passed
+        ``delimiter_if_three_or_more_nonlast`` delimiter.
+      * The last two contained strings are delimited by the passed
+        ``delimiter_if_three_or_more_last`` separator.
+
+    Parameters
+    ----------
+    strs : Iterable[str]
+        Iterable of all strings to be joined.
+    delimiter_if_two : str
+        Substring separating each string contained in this iterable if this
+        iterable contains exactly two strings.
+    delimiter_if_three_or_more_nonlast : str
+        Substring separating each string *except* the last two contained in
+        this iterable if this iterable contains three or more strings.
+    delimiter_if_three_or_more_last : str
+        Substring separating each string the last two contained in this
+        iterable if this iterable contains three or more strings.
+    is_double_quoted : bool, optional
+        :data:`True` only if **double-quoting** (i.e., both prefixing and
+        suffixing by the ``"`` character) each item of this iterable. Defaults
+        to :data:`False`.
+
+    Returns
+    -------
+    str
+        Concatenation of these strings.
+
+    Examples
+    --------
+        >>> join_delimited(
+        ...     strs=('Fulgrim', 'Perturabo', 'Angron', 'Mortarion'),
+        ...     delimiter_if_two=' and ',
+        ...     delimiter_if_three_or_more_nonlast=', ',
+        ...     delimiter_if_three_or_more_last=', and ',
+        ... )
+        'Fulgrim, Perturabo, Angron, and Mortarion'
+    '''
+    assert isinstance(strs, Iterable) and not isinstance(strs, str), (
+        f'{repr(strs)} not non-string iterable.')
+    assert isinstance(delimiter_if_two, str), (
+        f'{repr(delimiter_if_two)} not string.')
+    assert isinstance(delimiter_if_three_or_more_nonlast, str), (
+        f'{repr(delimiter_if_three_or_more_nonlast)} not string.')
+    assert isinstance(delimiter_if_three_or_more_last, str), (
+        f'{repr(delimiter_if_three_or_more_last)} not string.')
+
+    # If this iterable is *NOT* a sequence, internally coerce this iterable
+    # into a sequence for subsequent indexing purposes.
+    if not isinstance(strs, Sequence):
+        strs = tuple(strs)
+    # Else, this iterable is already a sequence.
+    #
+    # In either case, this iterable is now a sequence.
+
+    # If double-quoting these strings, do so.
+    if is_double_quoted:
+        strs = tuple(f'"{text}"' for text in strs)
+    # Else, preserve these strings as is.
+
+    # Number of strings in this sequence.
+    num_strs = len(strs)
+
+    # If no strings are passed, return the empty string.
+    if num_strs == 0:
+        return ''
+    # If one string is passed, return this string as is.
+    elif num_strs == 1:
+        # This is clearly a string, yet mypy thinks it's Any
+        return strs[0]  # type: ignore[no-any-return]
+    # If two strings are passed, return these strings delimited appropriately.
+    elif num_strs == 2:
+        return f'{strs[0]}{delimiter_if_two}{strs[1]}'
+    # Else, three or more strings are passed.
+
+    # All such strings except the last two, delimited appropriately.
+    strs_nonlast = delimiter_if_three_or_more_nonlast.join(strs[0:-2])
+
+    # The last two such strings, delimited appropriately.
+    strs_last = f'{strs[-2]}{delimiter_if_three_or_more_last}{strs[-1]}'
+
+    # Return these two substrings, delimited appropriately.
+    return f'{strs_nonlast}{delimiter_if_three_or_more_nonlast}{strs_last}'
+
+# ....................{ JOINERS ~ conjunction              }....................
+#FIXME: Unit test us up, please.
+def join_delimited_conjunction(strs: IterableStrs, **kwargs) -> str:
+    '''
+    Concatenate the passed iterable of zero or more strings delimited by commas
+    and/or the conjunction "and" (conditionally depending on both the length of
+    this iterable and index of each string in this iterable), yielding a
+    human-readable string listing arbitrarily many substrings conjunctively.
+
+    Specifically, this function returns either:
+
+    * If this iterable contains no strings, the empty string.
+    * If this iterable contains one string, this string as is is unmodified.
+    * If this iterable contains two strings, these strings delimited by the
+      conjunction "and".
+    * If this iterable contains three or more strings, a string listing these
+      contained strings such that:
+
+      * All contained strings except the last two are suffixed by commas.
+      * The last two contained strings are delimited by the conjunction "and".
+
+    Parameters
+    ----------
+    strs : Iterable[str]
+        Iterable of all strings to be concatenated conjunctively.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.join_delimeted` function underlying this higher-level function.
+
+    Returns
+    -------
+    str
+        Conjunctive concatenation of these strings.
+    '''
+
+    # One of us. We accept one-liner. One of us.
+    return join_delimited(
+        strs=strs,
+        delimiter_if_two=' and ',
+        delimiter_if_three_or_more_nonlast=', ',
+        delimiter_if_three_or_more_last=', and ',
+        **kwargs
+    )
+
+# ....................{ JOINERS ~ disjunction              }....................
+def join_delimited_disjunction(strs: IterableStrs, **kwargs) -> str:
+    '''
+    Concatenate the passed iterable of zero or more strings delimited by commas
+    and/or the disjunction "or" (conditionally depending on both the length of
+    this iterable and index of each string in this iterable), yielding a
+    human-readable string listing arbitrarily many substrings disjunctively.
+
+    Specifically, this function returns either:
+
+    * If this iterable contains no strings, the empty string.
+    * If this iterable contains one string, this string as is is unmodified.
+    * If this iterable contains two strings, these strings delimited by the
+      disjunction "or".
+    * If this iterable contains three or more strings, a string listing these
+      contained strings such that:
+
+      * All contained strings except the last two are suffixed by commas.
+      * The last two contained strings are delimited by the disjunction "or".
+
+    Parameters
+    ----------
+    strs : Iterable[str]
+        Iterable of all strings to be concatenated disjunctively.
+
+    All remaining keyword parameters are passed as is to the lower-level
+    :func:`.join_delimeted` function underlying this higher-level function.
+
+    Returns
+    -------
+    str
+        Disjunctive concatenation of these strings.
+    '''
+
+    # He will join us... OR DIE! *cackling heard*
+    return join_delimited(
+        strs=strs,
+        delimiter_if_two=' or ',
+        delimiter_if_three_or_more_nonlast=', ',
+        delimiter_if_three_or_more_last=', or ',
+        **kwargs
+    )
+
+
+def join_delimited_disjunction_types(types: typing_Iterable[type]) -> str:
+    '''
+    Concatenate the human-readable classname of each class in the passed
+    iterable delimited by commas and/or the disjunction "or" (conditionally
+    depending on both the length of this iterable and index of each string in
+    this iterable), yielding a human-readable string listing arbitrarily many
+    classnames disjunctively.
+
+    Parameters
+    ----------
+    types : Iterable[type]
+        Iterable of all classes whose human-readable classnames are to be
+        concatenated disjunctively.
+
+    Returns
+    -------
+    str
+        Disjunctive concatenation of these classnames.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextlabel import label_type
+
+    # Make it so, ensign.
+    return join_delimited_disjunction(label_type(cls) for cls in types)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextlabel.py
@@ -0,0 +1,445 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **text label utilities** (i.e., low-level callables creating and
+returning human-readable strings describing prominent objects or types, intended
+to be embedded in human-readable error messages).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.hint.datahinttyping import (
+    BeartypeableT,
+    BoolTristate,
+)
+from beartype._util.utilobject import (
+    get_object_name,
+    get_object_type_name,
+)
+from collections.abc import Callable
+
+# ....................{ LABELLERS ~ beartypeable           }....................
+def label_beartypeable_kind(
+    obj: BeartypeableT,  # pyright: ignore[reportInvalidTypeVarUse]
+) -> str:
+    '''
+    Human-readable label describing the **kind** (i.e., single concise noun
+    synopsizing the category of) of the passed **beartypeable** (i.e., object
+    that is currently being or has already been decorated by the
+    :func:`beartype.beartype` decorator).
+
+    Parameters
+    ----------
+    obj : BeartypeableT
+        Beartypeable to describe the kind of.
+
+    Returns
+    -------
+    str
+        Human-readable label describing the kind of this beartypeable.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunctest import (
+        is_func_async,
+        is_func_async_generator,
+        is_func_coro,
+        is_func_python,
+        is_func_sync_generator,
+    )
+    from beartype._util.func.arg.utilfuncargget import (
+        get_func_arg_first_name_or_none)
+
+    #FIXME: Globalize magic strings for efficiency, please.
+
+    # If this object is a pure-Python class, return an appropriate string.
+    if isinstance(obj, type):
+        return 'class'
+    # Else, this object is *NOT* a pure-Python class.
+    #
+    # If this object is a pure-Python callable...
+    elif is_func_python(obj):
+        # Human-readable prefix describing the exotic nature of this callable if
+        # this is callable is exotic (e.g., coroutine or generator factory)
+        # suffixed by trailing whitespace *OR* the empty string otherwise.
+        func_prefix = ''
+
+        # Human-readable suffix describing the general nature of this callable
+        # (e.g., function, method) suffixed by trailing whitespace.
+        func_suffix = ''
+
+        # If this object is an asynchronous callable factory...
+        if is_func_async(obj):
+            # If this object is a coroutine factory, use an appropriate prefix.
+            if is_func_coro(obj):
+                func_prefix = 'coroutine factory '
+            # If this object is an asynchronous generator factory, use an
+            # appropriate prefix.
+            elif is_func_async_generator(obj):
+                func_prefix = 'asynchronous generator factory '
+            # Else, this object is an unrecognized kind of asynchronous callable
+            # factory. In this case, fallback to a generic prefix.
+            #
+            # Note that this should *NEVER* occur. Since *ALL* asynchronous
+            # callable factories are either coroutine or asynchronous generator
+            # factories, one of the above conditional branches should have been
+            # entered instead. Nonetheless, preparation prevents disasters.
+            else:  # pragma: no cover
+                func_prefix = 'asynchronous '
+        # Else, this object is a synchronous callable.
+        #
+        # If this object is an synchronous generator factory, use an appropriate
+        # prefix.
+        elif is_func_sync_generator(obj):
+            func_prefix = 'generator factory '
+        # Else, this object is a standard synchronous callable. In this case,
+        # avoid prefixing this callable by a leading substring.
+
+        # Name of the first parameter accepted by that callable if any *OR*
+        # "None" otherwise (i.e., if that callable is argumentless).
+        arg_first_name = get_func_arg_first_name_or_none(obj)
+
+        # If this is the canonical first "self" parameter typically accepted by
+        # instance methods, assume this to be an instance method.
+        #
+        # Note that this heuristic fails in uncommon edge cases -- but that
+        # that's largely irrelevant here. This function is *ONLY* intended to
+        # generate human-readable exception and warning messages. Since this is
+        # hardly mission-critical, false positives are reluctantly acceptable.
+        if arg_first_name == 'self':
+            func_suffix = 'method'
+        # Else, this is *NOT* the canonical first "self" parameter.
+        #
+        # If this is the canonical first "cls" parameter typically accepted by
+        # class methods, assume this to be a class method.
+        elif arg_first_name == 'cls':
+            func_suffix = 'class method'
+        # Else, this is neither the canonical first "self" nor "cls" parameter.
+        # In this case, this is assumed to be a non-method callable.
+        else:
+            func_suffix = 'function'
+
+        # Return the concatenation of these substrings.
+        # print(f'func_prefix: {func_prefix}; func_suffix: {func_suffix}')
+        return f'{func_prefix}{func_suffix}'
+    # Else, this object is neither a pure-Python class *NOR* callable.
+
+    # Return a sane placeholder.
+    return 'object'
+
+# ....................{ LABELLERS ~ callable               }....................
+#FIXME: Unit test up the "is_context" parameter, which is currently untested.
+def label_callable(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+    is_context: BoolTristate = None,
+) -> str:
+    '''
+    Human-readable label describing the passed **callable** (e.g., function,
+    method, property).
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+    is_context : BoolTristate
+        Either:
+
+        * :data:`True`, in which case this label is suffixed by additional
+          metadata contextually disambiguating that callable, including:
+
+          * The line number of the first line declaring that callable in its
+            underlying source code module file.
+          * The absolute filename of that file.
+
+        * :data:`False`, in which case this label is *not* suffixed by such
+          metadata.
+        * :data:`None`, in which case this label is conditionally suffixed by
+          such metadata only if that callable is a lambda function and thus
+          ambiguously lacks any semblance of an innate context.
+
+        Defaults to :data:`None`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this callable.
+    '''
+    assert callable(func), f'{repr(func)} uncallable.'
+    assert isinstance(is_context, bool) or is_context is None, (  # <-- "NoneTypeOr" is unavailable here
+        f'{repr(is_context)} not tri-state boolean.')
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.arg.utilfuncargget import (
+        get_func_args_flexible_len)
+    from beartype._util.func.utilfunccodeobj import get_func_codeobj
+    from beartype._util.func.utilfunctest import is_func_lambda
+    from beartype._util.text.utiltextansi import color_attr_name
+
+    # Substring prefixing the string to be returned, typically identifying the
+    # specialized type of that callable if that callable has a specialized type.
+    func_label_prefix = ''
+
+    # Fully-qualified name of that callable, coloured if requested.
+    func_label = color_attr_name(
+        text=f' {get_object_name(func)}()', is_color=is_color)
+
+    # Substring suffixing the string to be returned, typically contextualizing
+    # that callable with respect to its on-disk code module file.
+    func_label_suffix = ''
+
+    #FIXME: *HMM.* This branch should almost certainly be folded into the
+    #existing label_beartypeable_kind() function, which would then dramatically
+    #simplify this logic here. Let's do this, yo!
+    # If the passed callable is a pure-Python lambda function, that callable
+    # has *NO* unique fully-qualified name. In this case, return a string
+    # uniquely identifying this lambda from various code object metadata.
+    if is_func_lambda(func):
+        # Code object underlying this lambda.
+        func_codeobj = get_func_codeobj(func)
+
+        # Substring preceding the string to be returned.
+        func_label_prefix = (
+            f'lambda function of '
+            f'{get_func_args_flexible_len(func_codeobj)} argument(s)'
+        )
+
+        # If the caller failed to request an explicit contextualization, default
+        # to contextualizing this lambda function.
+        if is_context is None:
+            is_context = True
+        # Else, the caller requested an explicit contextualization. In this
+        # case, preserve that contextualization as is.
+    # Else, the passed callable is *NOT* a pure-Python lambda function and thus
+    # has a unique fully-qualified name. In this case, prefix this label with a
+    # substring describing the kind of that callable.
+    else:
+        func_label_prefix = label_beartypeable_kind(func)
+
+    # If contextualizing that callable, just do it already. Go, @beartype! Go!
+    if is_context:
+        func_label_suffix = f' {label_object_context(func)}'
+    # Else, we are *NOT* contextualizing that callable.
+
+    # Return that prefix followed by the fully-qualified name of that callable.
+    return f'{func_label_prefix}{func_label}{func_label_suffix}'
+
+# ....................{ LABELLERS ~ exception              }....................
+def label_exception(exception: Exception) -> str:
+    '''
+    Human-readable label describing the passed exception.
+
+    Caveats
+    -------
+    **The label returned by this function does not describe the traceback
+    originating this exception.** To do so, consider calling the standard
+    :func:`traceback.format_exc` function instead.
+
+    Parameters
+    ----------
+    exception : Exception
+        Exception to be labelled.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this exception.
+    '''
+    assert isinstance(exception, Exception), (
+        f'{repr(exception)} not exception.')
+
+    # Return the fully-qualified name of the class of this exception followed by
+    # this exception's message.
+    return f'{get_object_type_name(exception)}: {str(exception)}'
+
+# ....................{ LABELLERS ~ context                }....................
+#FIXME: Unit test us up, please.
+def label_object_context(obj: object) -> str:
+    '''
+    Human-readable label describing the **context** (i.e., absolute filename of
+    the module or script physically declaring the passed object *and* the
+    1-based line number of the first line declaring this object in this file) of
+    this object if this object is either a callable or class declared on-disk
+    *or* the empty string otherwise (i.e., if this object is neither a callable
+    nor class *or* is either a callable or class declared in-memory).
+
+    Parameters
+    ----------
+    func : object
+        Object to label the context of.
+
+    Returns
+    -------
+    str
+        Human-readable label describing the context of this object.
+    '''
+
+    # Defer test-specific imports.
+    from beartype._util.utilobject import get_object_filename_or_none
+    from beartype._util.module.utilmodget import (
+        get_object_module_line_number_begin)
+
+    # Absolute filename of the module or script physically declaring this object
+    # if this object was defined on-disk *OR* "None" otherwise (i.e., if this
+    # object was defined in-memory).
+    obj_filename = get_object_filename_or_none(obj)
+
+    # If this object is defined on-disk...
+    if obj_filename:
+        # Line number of the first line declaring this object in that file.
+        obj_lineno = get_object_module_line_number_begin(obj)
+
+        # Return a string describing the context of this object.
+        return f'in file "{obj_filename}" line {obj_lineno}'
+    # Else, this object was defined in-memory. In this case, avoid attempting to
+    # needlessly contextualize this object.
+
+    # Let's hear it for giving up here and going home. Yeah! Go, @beartype!
+    return ''
+
+# ....................{ LABELLERS ~ pith                   }....................
+def label_pith_value(
+    # Mandatory parameters.
+    pith: object,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the passed value of the **current pith**
+    (i.e., arbitrary object violating the current type check) *not* suffixed by
+    delimiting whitespace.
+
+    Parameters
+    ----------
+    pith : object
+        Arbitrary object violating the current type check.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this pith value.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextansi import color_pith
+    from beartype._util.text.utiltextrepr import represent_object
+
+    # Glory be to the one liner that you are about to read.
+    return color_pith(text=represent_object(pith), is_color=is_color)
+
+# ....................{ LABELLERS ~ type                   }....................
+def label_type(
+    # Mandatory parameters.
+    cls: type,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the passed class.
+
+    Parameters
+    ----------
+    cls : type
+        Class to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this class.
+    '''
+    assert isinstance(cls, type), f'{repr(cls)} not class.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.cls.utilclstest import is_type_builtin
+    from beartype._util.hint.pep.proposal.utilpep544 import (
+        is_hint_pep544_protocol)
+    from beartype._util.text.utiltextansi import color_attr_name
+
+    # Label to be returned, initialized to this class' fully-qualified name.
+    classname = get_object_type_name(cls)
+    # print(f'cls {cls} classname: {classname}')
+
+    # If this name contains *NO* periods, this class is actually a builtin type
+    # (e.g., "list"). Since builtin types are well-known and thus
+    # self-explanatory, this name requires no additional labelling. In this
+    # case, return this name as is.
+    if '.' not in classname:
+        pass
+    # Else, this name contains one or more periods but could still be a
+    # builtin indirectly accessed via the standard "builtins" module.
+    #
+    # If this name is that of a builtin type uselessly prefixed by the name of
+    # the module declaring all builtin types (e.g., "builtins.list"), reduce
+    # this name to the unqualified basename of this type (e.g., "list").
+    elif is_type_builtin(cls):
+        classname = cls.__name__
+    # Else, this is a non-builtin class. Non-builtin classes are *NOT*
+    # well-known and thus benefit from additional labelling.
+    #
+    # If this class is a PEP 544-compliant protocol supporting structural
+    # subtyping, label this protocol.
+    elif is_hint_pep544_protocol(cls):
+        # print(f'cls {cls} is protocol!')
+        classname = f'<protocol "{classname}">'
+    # Else if this class is a standard abstract base class (ABC) defined by a
+    # standard submodule also known to support structural subtyping (e.g.,
+    # "collections.abc.Hashable", "contextlib.AbstractContextManager"), label
+    # this ABC as a protocol.
+    #
+    # Note that user-defined ABCs do *NOT* generally support structural
+    # subtyping. Doing so requires esoteric knowledge of undocumented and
+    # mostly private "abc.ABCMeta" metaclass internals unlikely to be
+    # implemented by third-party developers. Thanks to the lack of both
+    # publicity and standardization, there exists *NO* general-purpose means of
+    # detecting whether an arbitrary class supports structural subtyping.
+    elif (
+        classname.startswith('collections.abc.') or
+        classname.startswith('contextlib.')
+    ):
+        classname = f'<protocol ABC "{classname}">'
+    # Else, this is a standard class. In this case, label this class as such.
+    else:
+        classname = f'<class "{classname}">'
+
+    # Return this labelled classname, possibly coloured.
+    return color_attr_name(text=classname, is_color=is_color)
+
+
+def label_object_type(obj: object) -> str:
+    '''
+    Human-readable label describing the class of the passed object.
+
+    Parameters
+    ----------
+    obj : object
+        Object whose class is to be labelled.
+
+    Returns
+    -------
+    str
+        Human-readable label describing the class of this object.
+    '''
+
+    # Tell me why, why, why I curse the sky! ...no, srsly.
+    return label_type(type(obj))
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextmunge.py
@@ -0,0 +1,330 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+"""
+Project-wide **string munging utilities** (i.e., callables transforming passed
+strings into new strings with generic string operations).
+
+This private submodule is *not* intended for importation by downstream callers.
+"""
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilTextException
+from beartype._data.kind.datakindtext import CHARS_PUNCTUATION
+
+# ....................{ CASERS                             }....................
+#FIXME: Unit test us up, please.
+def lowercase_str_char_first(text: str) -> str:
+    '''
+    Lowercase *only* the first character of the passed string.
+
+    Parameters
+    ----------
+    text : str
+        String whose first character is to be lowercased.
+
+    Returns
+    -------
+    str
+        This string with the first character lowercased.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # If...
+    if (
+        # This string contains at least two characters *AND*...
+        len(text) >= 2 and
+        # The first character of this string is uppercase...
+        text[0].isupper()
+    ):
+        # Then lowercase only this character for readability.
+        text = f'{text[0].lower()}{text[1:]}'
+
+    # Return this possibly changed string.
+    return text
+
+
+def uppercase_str_char_first(text: str) -> str:
+    '''
+    Uppercase *only* the first character of the passed string.
+
+    Whereas the standard :meth:`str.capitalize` method both uppercases the
+    first character of this string *and* lowercases all remaining characters,
+    this function *only* uppercases the first character. All remaining
+    characters remain unmodified.
+
+    Parameters
+    ----------
+    text : str
+        String whose first character is to be uppercased.
+
+    Returns
+    -------
+    str
+        This string with the first character uppercased.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # If...
+    if (
+        # This string contains at least two characters *AND*...
+        len(text) >= 2 and
+        # The first character of this string is lowercase...
+        text[0].islower()
+    ):
+        # Then uppercase only this character for readability.
+        text = f'{text[0].upper()}{text[1:]}'
+
+    # Return this possibly changed string.
+    return text
+
+# ....................{ NUMBERERS                          }....................
+def number_str_lines(text: str) -> str:
+    '''
+    Passed string munged to prefix each line of this string with the 1-based
+    number of that line padded by zeroes out to four digits for alignment.
+
+    Parameters
+    ----------
+    text : str
+        String whose lines are to be numbered.
+
+    Returns
+    -------
+    str
+        This string with all lines numbered.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # For radical benevolence!
+    return '\n'.join(
+        # Note that a format() call rather than f-string is intentionally
+        # applied here, as the former affords more functionality for string
+        # munging than the latter.
+        '(line {:0>4d}) {}'.format(text_line_number, text_line)
+        for text_line_number, text_line in enumerate(text.splitlines(), start=1)
+    )
+
+# ....................{ REPLACERS                          }....................
+def replace_str_substrs(text: str, old: str, new: str) -> str:
+    '''
+    Passed string with all instances of the passed source substring globally
+    replaced by the passed target substring if this string contains at least
+    one such instance *or* raise an exception otherwise (i.e., if this string
+    contains *no* such instance).
+
+    Caveats
+    -------
+    **This higher-level function should always be called in lieu of the
+    lower-level** :meth:`str.replace` method, which unconditionally succeeds
+    regardless of whether this subject string contains at least one instance of
+    this source substring or not.
+
+    Parameters
+    ----------
+    text : str
+        Subject string to perform this global replacement on.
+    old : str
+        Source substring of this subject string to be globally replaced.
+    new : str
+        Target substring to globally replace this source substring with in this
+        subject string.
+
+    Returns
+    -------
+    str
+        Subject string with all instances of this source substring globally
+        replaced by this target substring.
+
+    Raises
+    ------
+    _BeartypeUtilTextException
+        If this subject string contains *no* instances of this source
+        substring.
+
+    Examples
+    --------
+        >>> from beartype._util.text.utiltextmunge import replace_str_substrs
+        >>> replace_str_substrs(
+        ...     text='And now the STORM-BLAST came, and he',
+        ...     old='he', new='hat')
+        And now that STORM-BLAST came, and hat
+        >>> replace_str_substrs(
+        ...     text='I shot the ALBATROSS.', old='dross', new='drat')
+        beartype.roar._BeartypeUtilTextException: String "I shot the
+        ALBATROSS." substring "dross" not found.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+    assert isinstance(old, str), f'{repr(old)} not string.'
+    assert isinstance(new, str), f'{repr(new)} not string.'
+
+    # If this subject contains *NO* instances of this substring, raise an
+    # exception.
+    if old not in text:
+        raise _BeartypeUtilTextException(
+            f'String "{text}" substring "{old}" not found.')
+    # Else, this subject contains one or more instances of this substring.
+
+    # Return this subject with all instances of this source substring globally
+    # replaced by this target substring.
+    return text.replace(old, new)
+
+# ....................{ SUFFIXERS                          }....................
+def suffix_str_unless_suffixed(text: str, suffix: str) -> str:
+    '''
+    Passed string either suffixed by the passed suffix if this string is not
+    yet suffixed by this suffix *or* this string as is otherwise (i.e., if this
+    string is already suffixed by this suffix).
+
+    Parameters
+    ----------
+    text : str
+        String to be conditionally suffixed.
+    suffix : str
+        Suffix to be conditionally appended to this string.
+
+    Returns
+    -------
+    str
+        Either:
+
+        * If this string is *not* yet suffixed by this suffix, this string
+          suffixed by this suffix.
+        * Else, this string as is.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+    assert isinstance(suffix, str), f'{repr(suffix)} not string.'
+
+    # Suffix us up the redemption arc.
+    return text if text.endswith(suffix) else text + suffix
+
+# ....................{ TRUNCATERS                         }....................
+def truncate_str(
+    # Mandatory parameters.
+    text: str,
+
+    # Optional parameters.
+    max_len: int = 96,
+) -> str:
+    '''
+    Truncate the passed string to the passed maximum string length.
+
+    Specifically, this function returns either:
+
+    * If the length of this string is less than this maximum, this string
+      unmodified as is.
+    * Else, this string with the suffix of this string exceeding this maximum
+      replaced by an ASCII ellipsis (i.e., ``"..."`` substring).
+
+    Caveats
+    -------
+    **This function is unavoidably slow and should thus not be called from
+    optimized performance-critical code.** This function internally performs
+    mildly expensive operations, including iterating-based string munging.
+    Ideally, this function should *only* be called to create user-oriented
+    exception messages where performance is a negligible concern.
+
+    Parameters
+    ----------
+    obj : object
+        String to be truncated.
+    max_len: int, optional
+        Maximum length of the string to be returned. Defaults to a standard
+        line length of 100 characters minus output indentation of 4 characters.
+
+    Returns
+    -------
+    str
+        This string possibly truncated.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+    assert isinstance(max_len, int), f'{repr(max_len)} not integer.'
+    assert max_len >= 0, f'{max_len} < 0.'
+
+    # If this maximum length is *NOT* long enough to at least allow truncation
+    # to ellipsis (i.e., a substring of length 3). In this case, truncate this
+    # string to this length *WITHOUT* ellipsis.
+    if max_len <= 3:
+        return text[:max_len]
+    # Else, this maximum length is long enough to at least allow truncation to
+    # ellipsis (i.e., a substring of length 3).
+
+    # Length of this string.
+    text_len = len(text)
+
+    # If this string does *NOT* exceed this maximum length, this string requires
+    # *NO* truncation. In this case, return this string as is.
+    if text_len <= max_len:
+        return text
+    # Else, this string exceeds this maximum length and thus requires
+    # truncation.
+
+    # Length of this string minus one.
+    text_len_minus_1 = text_len - 1
+
+    # Length of the truncated prefix of this string to be returned below,
+    # initialized to this maximum length minus the length of the ellipsis (i.e.,
+    # 3 characters) to be injected into this string.
+    text_prefix_len = max_len - 3
+
+    # 0-based index of the last character of this string that is *NOT* a
+    # punctuation character, initialized to the length of this string.
+    text_suffix_start_index = text_len
+    # print(f'\nstring: {text}')
+    # print(f'text_len: {text_len}')
+    # print(f'max_len: {max_len}')
+    # print(f'[before backing up] text_prefix_len: {text_prefix_len}')
+    # print(f'[before backing up] text_suffix_start_index: {text_suffix_start_index}')
+
+    # While...
+    while (
+        # There exists at least one remaining character to truncate from this
+        # string *AND*...
+        text_prefix_len >= 1 and
+        # The character preceding the current trailing punctuation character of
+        # this string is also a punctuation character...
+        text[text_suffix_start_index - 1] in CHARS_PUNCTUATION
+    ):
+        # Truncate one additional character from this string.
+        text_prefix_len -= 1
+
+        # Prepend one additional trailing punctuation character onto this
+        # suffixing substring.
+        text_suffix_start_index -= 1
+    # print(f'[after backing up] text_prefix_len: {text_prefix_len}')
+    # print(f'[after backing up] text_suffix_start_index: {text_suffix_start_index}')
+
+    # While...
+    while (
+        # There exists at least one remaining trailing punctuation character to
+        # inspect in this string *AND*...
+        text_suffix_start_index <= text_len_minus_1 and
+        # The character currently prefixing this suffixing substring of
+        # trailing punctuation characters is a period...
+        text[text_suffix_start_index] == '.'
+    ):
+        # Append one additional character back onto this string.
+        text_prefix_len += 1
+
+        # Remove this period from this suffixing substring. Why? Because this
+        # period will already be included in the ellipsis injected into this
+        # string below. Look. It's complicated. Just wave your hands in the air!
+        text_suffix_start_index += 1
+    # print(f'[after eating dots] text_prefix_len: {text_prefix_len}')
+    # print(f'[after eating dots up] text_suffix_start_index: {text_suffix_start_index}')
+
+    # Truncated string to be returned, comprising...
+    text = (
+        # The prefixing substring of this string *NOT* exceeding this maximum
+        # length.
+        f'{text[:text_prefix_len]}'
+        # An ellipsis replacing the remaining truncated middle of this string.
+        f'...'
+        # The suffixing substring of trailing punctuation characters.
+        f'{text[text_suffix_start_index:]}'
+    )
+
+    # Return this truncated string.
+    return text
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextprefix.py
@@ -0,0 +1,342 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **text prefix utilities** (i.e., low-level callables creating and
+returning human-readable strings describing prominent objects or types and
+*always* suffixed by exactly one space character, intended to prefix
+human-readable error messages).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.func.datafuncarg import ARG_NAME_RETURN
+from beartype._data.hint.datahinttyping import (
+    BeartypeableT,
+    BoolTristate,
+)
+from beartype._util.text.utiltextlabel import (
+    label_callable,
+    label_type,
+)
+from collections.abc import Callable
+
+# ....................{ PREFIXERS ~ beartypeable           }....................
+#FIXME: Unit test this function with respect to classes, please.
+def prefix_beartypeable(
+    # Mandatory parameters.
+    obj: BeartypeableT,  # pyright: ignore[reportInvalidTypeVarUse]
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the passed **beartypeable** (i.e., object
+    that is currently being or has already been decorated by the
+    :func:`beartype.beartype` decorator) suffixed by delimiting whitespace.
+
+    Parameters
+    ----------
+    obj : BeartypeableT
+        Beartypeable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this beartypeable.
+    '''
+
+    # Return either...
+    return (
+        # If this beartypeable is a class, a label describing this class;
+        f'{label_type(cls=obj, is_color=is_color)} '
+        if isinstance(obj, type) else
+        # Else, this beartypeable is a callable. In this case, a label
+        # describing this callable.
+        f'{label_callable(func=obj, is_color=is_color)} '  # type: ignore[arg-type]
+    )
+
+
+def prefix_beartypeable_pith(
+    # Mandatory parameters.
+    func: Callable,
+    pith_name: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing either the parameter with the passed name
+    *or* return value if this name is ``"return"`` of the passed **beartypeable
+    callable** (i.e., callable wrapped by the :func:`beartype.beartype`
+    decorator with a wrapper function type-checking that callable) suffixed by
+    delimiting whitespace.
+
+    Parameters
+    ----------
+    func : Callable
+        Decorated callable to be labelled.
+    pith_name : str
+        Name of the parameter or return value of this callable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing either the name of this parameter *or*
+        this return value.
+    '''
+    assert isinstance(pith_name, str), f'{repr(pith_name)} not string.'
+
+    # Return a human-readable label describing either...
+    return (
+        # If this name is "return", the return value of this callable.
+        prefix_callable_return(func=func, is_color=is_color)
+        if pith_name == ARG_NAME_RETURN else
+        # Else, the parameter with this name of this callable.
+        prefix_callable_arg_name(
+            func=func, arg_name=pith_name, is_color=is_color)
+    )
+
+# ....................{ PREFIXERS : callable : name        }....................
+def prefix_callable_arg_name(
+    # Mandatory parameters.
+    func: Callable,
+    arg_name: str,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the parameter with the passed name of the
+    passed **decorated callable** (i.e., callable wrapped by the
+    :func:`beartype.beartype` decorator with a wrapper function type-checking
+    that callable) suffixed by delimiting whitespace.
+
+    Parameters
+    ----------
+    func : Callable
+        Decorated callable to be labelled.
+    arg_name : str
+        Name of the parameter of this callable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this parameter's name.
+    '''
+    assert isinstance(arg_name, str), f'{repr(arg_name)} not string.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextansi import color_arg_name
+
+    # Double-quote this argument name.
+    arg_name = f'"{arg_name}"'
+
+    # Create and return this label.
+    return (
+        f'{prefix_beartypeable(obj=func, is_color=is_color)}'
+        f'parameter {color_arg_name(text=arg_name, is_color=is_color)} '
+    )
+
+
+def prefix_callable_return(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the return of the passed **decorated
+    callable** (i.e., callable wrapped by the :func:`beartype.beartype`
+    decorator with a wrapper function type-checking that callable) suffixed by
+    delimiting whitespace.
+
+    Parameters
+    ----------
+    func : Callable
+        Decorated callable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this return.
+    '''
+
+    # Create and return this label.
+    return f'{prefix_beartypeable(obj=func, is_color=is_color)}return '
+
+# ....................{ PREFIXERS : callable : value       }....................
+def prefix_callable_arg_value(
+    # Mandatory parameters.
+    func: Callable,
+    arg_name: str,
+    arg_value: object,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the parameter with the passed name and
+    trimmed value of the passed **decorated callable** (i.e., callable wrapped
+    by the :func:`beartype.beartype` decorator with a wrapper function
+    type-checking that callable) suffixed by delimiting whitespace.
+
+    Parameters
+    ----------
+    func : Callable
+        Decorated callable to be labelled.
+    arg_name : str
+        Name of the parameter of this callable to be labelled.
+    arg_value : object
+        Value of the parameter of this callable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this parameter's name and value.
+    '''
+    assert isinstance(arg_name, str), f'{repr(arg_name)} not string.'
+
+    # Avoid circular import dependencies.
+    #
+    # Note that this function differs enough from the comparable
+    # prefix_callable_arg_name() function to warrant a distinct implementation.
+    from beartype._util.text.utiltextansi import color_arg_name
+
+    # Create and return this label.
+    return (
+        f'{prefix_beartypeable(obj=func, is_color=is_color)}'
+        f'parameter {color_arg_name(text=arg_name, is_color=is_color)}='
+        f'{prefix_pith_value(pith=arg_value, is_color=is_color)}'
+    )
+
+
+def prefix_callable_return_value(
+    # Mandatory parameters.
+    func: Callable,
+    return_value: object,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the passed trimmed return value of the
+    passed **decorated callable** (i.e., callable wrapped by the
+    :func:`beartype.beartype` decorator with a wrapper function type-checking
+    that callable) suffixed by delimiting whitespace.
+
+    Parameters
+    ----------
+    func : Callable
+        Decorated callable to be labelled.
+    return_value : object
+        Value returned by this callable to be labelled.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this return value.
+    '''
+
+    # Create and return this label.
+    return (
+        f'{prefix_callable_return(func=func, is_color=is_color)}'
+        f'{prefix_pith_value(pith=return_value, is_color=is_color)}'
+    )
+
+# ....................{ PREFIXERS ~ pith                   }....................
+def prefix_pith_type(
+    # Mandatory parameters.
+    pith: object,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the passed type of the **current pith**
+    (i.e., arbitrary object violating the current type check) suffixed by
+    delimiting whitespace.
+
+    Parameters
+    ----------
+    pith : object
+        Arbitrary object violating the current type check.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this pith type.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextansi import color_type
+    from beartype._util.text.utiltextlabel import label_object_type
+
+    # To boldly go where no one-liner has gone before.
+    return color_type(text=f'{label_object_type(pith)} ', is_color=is_color)
+
+
+def prefix_pith_value(
+    # Mandatory parameters.
+    pith: object,
+
+    # Optional parameters.
+    is_color: BoolTristate = False,
+) -> str:
+    '''
+    Human-readable label describing the passed value of the **current pith**
+    (i.e., arbitrary object violating the current type check) suffixed by
+    delimiting whitespace.
+
+    Parameters
+    ----------
+    pith : object
+        Arbitrary object violating the current type check.
+    is_color : BoolTristate
+        Tri-state colouring boolean governing ANSI usage. See the
+        :attr:`beartype.BeartypeConf.is_color` attribute for further details.
+        Defaults to :data:`False`.
+
+    Returns
+    -------
+    str
+        Human-readable label describing this pith value.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextlabel import label_pith_value
+
+    # Create and return this label.
+    return f'{label_pith_value(pith=pith, is_color=is_color)} '
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextrepr.py
@@ -0,0 +1,295 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+"""
+Project-wide **string munging** (i.e., generic low-level operations
+transforming strings into new derivative strings) utilities.
+
+This private submodule is *not* intended for importation by downstream callers.
+"""
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarwarn import _BeartypeUtilCallableWarning
+# from beartype.typing import Dict
+from beartype._cave._cavefast import NumberType
+from beartype._data.hint.datahinttyping import TypeWarning
+from beartype._data.kind.datakindtext import CHARS_PUNCTUATION
+from beartype._util.utilobject import get_object_basename_scoped_or_none
+from collections.abc import Callable
+
+# ....................{ REPRESENTERS                       }....................
+def represent_object(
+    # Mandatory parameters.
+    obj: object,
+
+    # Optional parameters.
+    max_len: int = 96,
+) -> str:
+    '''
+    Pretty-printed quasi-human-readable variant of the string returned by the
+    non-pretty-printed machine-readable :meth:`obj.__repr__` dunder method of
+    the passed object, truncated to the passed maximum string length.
+
+    Specifically, this function (in order):
+
+    #. Obtains this object's representation by calling ``repr(object)``.
+    #. If this representation is neither suffixed by a punctuation character
+       (i.e., character in the standard :attr:`string.punctuation` set) *nor*
+       representing a byte-string whose representations are prefixed by ``b'``
+       and suffixed by ``'`` (e.g., ``b'Check, mate.'``), double-quotes this
+       representation for disambiguity with preceding characters -- notably,
+       sequence indices. Since strings returned by this function commonly
+       follow sequence indices in error messages, failing to disambiguate the
+       two produces non-human-readable output:
+
+           >>> def wat(mate: typing.List[str]) -> int: return len(mate)
+           >>> get_func_pith_violation(
+           ...     func=muh_func, pith_name='mate', pith_value=[7,])
+           beartype.roar.BeartypeCallHintParamViolation: @beartyped wat()
+           parameter mate=[7] violates PEP type hint typing.List[str], as list
+           item 0 value 7 not a str.
+
+       Note the substring "item 0 value 7", which misreads like a blatant bug.
+       Double-quoting the "7" suffices to demarcate values from indices.
+    #. If this representation exceeds the passed maximum length, replaces the
+       suffix of this representation exceeding this length with an ellipses
+       (i.e., ``"..."`` substring).
+
+    Caveats
+    -------
+    **This function is unavoidably slow and should thus not be called from
+    optimized performance-critical code.** This function internally performs
+    mildly expensive operations, including iterating-based string munging.
+    Ideally, this function should *only* be called to create user-oriented
+    exception messages where performance is a negligible concern.
+
+    **This function preserves all quote-protected newline characters** (i.e.,
+    ``"\\n"``) **in this representation.** Since the :meth:`str.__repr__`
+    dunder method implicitly quote-protects all newlines in the original
+    string, this function effectively preserves all newlines in strings.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be represented.
+    max_len: int, optional
+        Maximum length of the string to be returned. Defaults to a standard
+        line length of 100 characters minus output indentation of 4 characters.
+
+    Returns
+    -------
+    str
+        Pretty-printed quasi-human-readable variant of this object's
+        non-pretty-printed machine-readable representation.
+    '''
+    assert isinstance(max_len, int), f'{repr(max_len)} not integer.'
+
+    #FIXME: Render this safe against infinitely recursive data structures.
+    #Unfortunately, we *CANNOT* call the standard pprint.saferepr() function to
+    #do so, as that function is *OUTRAGEOUSLY* slow on worst-case edge cases.
+    #Instead, we'll need to implement our own performant saferepr()
+    #alternative. Fortunately, note that someone's already done so: the popular
+    #BSD-licensed Celerity project, whose celerity.utils.saferepr.saferepr()
+    #function claims to actually be faster than the repr() builtin under
+    #certain circumstances. While impressive, repurposing Celerity's saferepr()
+    #implementation for @beartype will be non-trivial; that function internally
+    #leverages a number of non-trivial internal functions, including a
+    #streaming iterator that appears to be performing some sort of ad-hoc
+    #tokenization (!) on the input object's string representation. Although
+    #that submodule is less than 300 lines, that's 300 *INTENSE* lines.
+    #Nonetheless, we'll need to do this sooner or later. Currently, later. By
+    #the time you read this next, probably sooner. Until someone pounds their
+    #fists on our issue tracker, let's pretend this isn't a compelling concern.
+    #See also:
+    #   https://github.com/celery/celery/blob/master/celery/utils/saferepr.py
+    #FIXME: Actually, a trivial way to do this without going full-Celery would
+    #be to just leverage the EAFP principle: e.g.,
+    #    try:
+    #        obj_repr = repr(obj)
+    #    except RecursionError:
+    #        from pprint import saferepr
+    #        obj_repr = saferepr(obj)
+    #
+    #Clearly, that will still be slightly less efficient than the
+    #Celery-oriented approach -- but also considerably easier. *sigh*
+
+    # String describing this object. Note that:
+    # * This representation quote-protects all newlines in this representation.
+    #   Ergo, "\n" *MUST* be matched as r"\n" instead below.
+    # * For debuggability, the verbose (albeit less readable) output of repr()
+    #   is preferred to the terse (albeit more readable) output of str().
+    # * For safety, the pprint.saferepr() function explicitly protected against
+    #   recursive data structures *WOULD* typically be preferred to the unsafe
+    #   repr() builtin *NOT* protected against such recursion. Sadly,
+    #   pprint.saferepr() is extremely unoptimized and thus susceptible to
+    #   extreme performance regressions when passed a worst-case object (e.g.,
+    #   deeply nested container).
+    obj_repr = repr(obj)
+
+    #FIXME: Uncomment to exhibit a performance regression.
+    # from pprint import saferepr
+    # obj_repr = saferepr(obj)
+
+    # If this representation is empty, return empty double-quotes. Although
+    # most objects (including outlier singletons like "None" and the empty
+    # string) have non-empty representations, caller-defined classes may
+    # maliciously override the __repr__() dunder method to return an empty
+    # string rather than the representation of an empty string (i.e., '""').
+    if not obj_repr:
+        return '""'
+    # Else, this representation is non-empty.
+    #
+    # If this representation is neither...
+    elif not (
+        # Prefixed by punctuation *NOR*...
+        obj_repr[0] in CHARS_PUNCTUATION or
+        # An instance of a class whose representations do *NOT* benefit from
+        # explicit quoting...
+        isinstance(obj, _TYPES_UNQUOTABLE)
+    ):
+    # Then this representation is *NOT* demarcated from preceding characters in
+    # the parent string embedding this representation. In this case,
+    # double-quote this representation for disambiguity with preceding
+    # characters (e.g., sequence indices).
+        obj_repr = f'"{obj_repr}"'
+
+    # If this representation exceeds this maximum length...
+    if len(obj_repr) > max_len:
+        # Avoid circular import dependencies.
+        from beartype._util.text.utiltextmunge import truncate_str
+
+        # Truncate this representation to this maximum length.
+        obj_repr = truncate_str(text=obj_repr, max_len=max_len)
+        # print(f'obj repr truncated: {obj_repr}')
+
+    # Return this representation.
+    return obj_repr
+
+# ....................{ REPRESENTER ~ callable             }....................
+def represent_func(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    warning_cls: TypeWarning = _BeartypeUtilCallableWarning,
+) -> str:
+    '''
+    Machine-readable representation of the passed callable.
+
+    Caveats
+    -------
+    **This function is unavoidably slow and should thus not be called from
+    optimized performance-critical code.** This function internally performs
+    extremely expensive operations, including abstract syntax tree (AST)-based
+    parsing of Python scripts and modules deserialized from disk. Ideally, this
+    function should *only* be called to create user-oriented exception messages
+    where performance is a negligible concern.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be represented.
+    warning_cls : TypeWarning, optional
+        Type of warning to be emitted in the event of a non-fatal error.
+        Defaults to :class:`_BeartypeUtilCallableWarning`.
+
+    Warns
+    -----
+    :class:`warning_cls`
+        If this callable is a pure-Python lambda function whose definition is
+        *not* parsable from the script or module defining that lambda.
+
+    Returns
+    -------
+    str
+        Machine-readable representation of that callable.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+
+    # Avoid circular import dependencies.
+    from beartype._util.func.utilfunccode import get_func_code_or_none
+    from beartype._util.func.utilfunctest import is_func_lambda
+
+    # If that callable is a pure-Python lambda function, return either:
+    # * If this lambda is defined by an on-disk script or module source file,
+    #   the exact substring of that file defining this lambda.
+    # * Else (e.g., if this lambda is dynamically defined in-memory), a
+    #   placeholder string.
+    if is_func_lambda(func):
+        return (
+            get_func_code_or_none(func=func, warning_cls=warning_cls) or
+            '<lambda>'
+        )
+    # Else, that callable is *NOT* a pure-Python lambda function.
+
+    #FIXME: Actually, we should be calling a new get_object_name_or_none()
+    #function instead -- but that function currently doesn't exist and we're
+    #lazy. The issue with get_object_basename_scoped_or_none() is that this
+    #getter fails to return the module name of this function. *shrug*
+    func_basename_scoped = get_object_basename_scoped_or_none(func)
+
+    # If that callable is named, return this name.
+    if func_basename_scoped:
+        return func_basename_scoped
+    # Else, that callable is unnamed due to failing to define both the
+    # "__qualname__" and "__name__" dunder attributes and thus have *NO* names.
+    # Although most callables are named, some are not. This includes:
+    # * Callable "functools.partial" objects.
+
+    # Return the machine-readable representation of that callable as a fallback.
+    return repr(func)
+
+# ....................{ REPRESENTERS ~ pith                }....................
+def represent_pith(
+    # Mandatory parameters.
+    pith: object,
+
+    # Optional parameters.
+    is_color: bool = True,
+) -> str:
+    '''
+    Human-readable description of the passed **pith** (i.e., arbitrary object
+    violating the current type check) intended to be embedded in an exception
+    message explaining this violation.
+
+    Parameters
+    ----------
+    pith : object
+        Arbitrary object violating the current type check.
+    is_color : bool, optional
+        :data:`True` only if embellishing this label with colour. Defaults to
+        :data:`True` for convenience.
+
+    Returns
+    -------
+    str
+        Human-readable description of this object.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.text.utiltextlabel import label_pith_value
+    from beartype._util.text.utiltextprefix import prefix_pith_type
+
+    # Create and return this representation.
+    return (
+        f'{prefix_pith_type(pith=pith, is_color=is_color)}'
+        f'{label_pith_value(pith=pith, is_color=is_color)}'
+    )
+
+# ....................{ PRIVATE ~ globals                  }....................
+_TYPES_UNQUOTABLE = (
+    # Byte strings, whose representations are already quoted as "b'...'".
+    bytes,
+    # Numbers, whose representations are guaranteed to both contain *NO*
+    # whitespace and be sufficiently terse as to benefit from *NO* quoting.
+    NumberType,
+)
+'''
+**Unquotable tuple union** (i.e., isinstancable tuple of all classes such that
+the :func:`represent_object` function intentionally avoids double-quoting the
+machine-readable representations all instances of these classes, typically due
+to these representations either being effectively quoted already *or*
+sufficiently terse as to not benefit from being quoted).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltexttest.py
@@ -0,0 +1,46 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype string testing utilities** (i.e., callables testing whether passed
+strings satisfy various conditions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+
+# ....................{ TESTERS                            }....................
+def is_str_float_or_int(text: str) -> bool:
+    '''
+    ``True`` only if the passed string is a valid machine-readable
+    representation of either an integer or finite floating-point number.
+
+    Caveats
+    ----------
+    This tester intentionally returns ``False`` for non-standard floating-point
+    pseudo-numbers that have no finite value, including:
+
+    * Not-a-numbers (i.e., ``float('NaN')`` values).
+    * Negative infinity (i.e., ``float('-inf')`` values).
+    * Positive infinity (i.e., ``float('inf')`` values).
+
+    Parameters
+    ----------
+    text : str
+        String to be inspected.
+
+    Returns
+    ----------
+    bool
+        ``True`` only if this string is a valid machine-readable representation
+        of either an integer or finite floating-point number.
+    '''
+    assert isinstance(text, str), f'{repr(text)} not string.'
+
+    # Return true only if this text represents a finite number. See also:
+    #     s.lstrip('-').replace('.','',1).replace('e-','',1).replace('e','',1).isdigit()
+    return text.lstrip(
+        '-').replace('.','',1).replace('e-','',1).replace('e','',1).isdigit()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/text/utiltextversion.py
@@ -0,0 +1,137 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **version string utilities** (i.e., low-level callables handling
+human-readable ``.``-delimited version strings).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilTextVersionException
+from beartype.typing import Tuple
+from re import compile as re_compile
+
+# ....................{ CONVERTERS                         }....................
+def convert_str_version_to_tuple(version: str) -> Tuple[int, ...]:
+    '''
+    Convert the passed human-readable ``.``-delimited version string into a
+    machine-readable version tuple of corresponding integers, suitable for
+    efficient comparison against other such version tuples via standard rich
+    comparison operators (e.g., ``<``, ``==``).
+
+    Caveats
+    ----------
+    **This converter strictly requires each ``.``-delimited substring of this
+    string to be a non-negative integer.** The exception is the last
+    ``.``-prefixed substring of this string, which this converter permits to
+    *not* be a non-negative integer. Specifically, that last substring:
+
+    * *Must* be prefixed by a non-negative integer.
+    * *May* be followed by any other arbitrary characters, which this converter
+      silently ignores as supplementary software-specific version metadata
+      (e.g., release candidates, alpha releases, beta releases). Since that
+      metadata does *not* cleanly generalize to all possible use cases, that
+      metadata *cannot* be safely converted into a non-negative integer.
+
+    For example, this converter:
+
+    * Converts the valid version string ``"1.26.0"`` to ``(1, 26, 0)``.
+    * Converts the valid version string ``"1.26.0rc1"`` to ``(1, 26, 0)`` by
+      simply ignoring the non-numeric suffix ``"rc1"``.
+    * Raises an exception for the invalid version string ``"1.26.rc1"``.
+
+    Parameters
+    ----------
+    text : str
+        Version string to be converted.
+
+    Returns
+    ----------
+    Tuple[int, ...]
+        Machine-readable version tuple of corresponding integers.
+
+    Raises
+    ----------
+    _BeartypeUtilTextVersionException
+        If this string is syntactically invalid as a version.
+    '''
+    assert isinstance(version, str), f'{repr(version)} not version string.'
+
+    # List of either:
+    # * If this version contains one or more "." delimiters, all "."-delimited
+    #   version components split from this version.
+    # * If this version contains *NO* "." delimiters, the 1-list "[version,]".
+    version_substrs = version.split('.')
+
+    # 0-based index of the last version component in this list.
+    version_substr_index_last = len(version_substrs) - 1
+
+    # List of all version components to be returned as a tuple.
+    version_list = []
+
+    # For the 0-based index of each "."-delimited version component of this
+    # version string and that component...
+    for version_substr_index, version_substr in enumerate(version_substrs):
+        # Attempt to...
+        try:
+            # Coerce this version component into an integer.
+            version_part = int(version_substr)
+
+            # If this component is negative, raise an exception.
+            if version_part < 0:
+                raise _BeartypeUtilTextVersionException(
+                    f'Version {repr(version)} syntactically invalid '
+                    f'(i.e., version component {repr(version_substr)} negative).'
+                )
+            # Else, this component is non-negative.
+        # If doing so raises a "ValueError", this version component is *NOT*
+        # syntactically valid as an integer. In this case...
+        except ValueError as exception:
+            # If the 0-based index of this version component is that of the last
+            # version component in this list, this is *NOT* the last version
+            # component. In this case, this component is syntactically invalid.
+            # Raise an exception.
+            if version_substr_index != version_substr_index_last:
+                raise _BeartypeUtilTextVersionException(
+                    f'Version {repr(version)} syntactically invalid '
+                    f'(i.e., version component {repr(version_substr)} '
+                    f'not an integer).'
+                ) from exception
+            # Else, this is the last version component. In this case, reduce
+            # this component to its non-negative integer prefix.
+
+            # Match result if this component is prefixed by a non-negative
+            # integer *OR* "None" otherwise (i.e., if this component is
+            # syntactically invalid).
+            version_substr_match = _VERSION_SUBSTR_LAST_REGEX.match(
+                version_substr)
+
+            # If this component is syntactically invalid, raise an exception.
+            if version_substr_match is None:
+                raise _BeartypeUtilTextVersionException(
+                    f'Version {repr(version)} syntactically invalid '
+                    f'(i.e., version component {repr(version_substr)} '
+                    f'not an integer).'
+                ) from exception
+            # Else, this component is syntactically valid.
+
+            # Non-negative integer prefixing this component.
+            version_part = int(version_substr_match.group(1))
+
+        # Append this version component to this list.
+        version_list.append(version_part)
+
+    # Return this list coerced into a tuple.
+    return tuple(version_list)
+
+# ....................{ PRIVATE ~ constants                }....................
+_VERSION_SUBSTR_LAST_REGEX = re_compile(r'([0-9]+).+')
+'''
+Compiled regular expression matching the non-negative integer prefixing the last
+``.``-delimited version component in a version string (e.g., ``"5"`` in the
+version string ``"5rc27"``).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/_util/utilobject.py
@@ -0,0 +1,463 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Project-wide **object utilities** (i.e., low-level callables handling arbitrary
+objects in a general-purpose manner).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeUtilObjectNameException
+from beartype.typing import (
+    Any,
+    Optional,
+)
+from beartype._data.cls.datacls import TYPES_CONTEXTMANAGER_FAKE
+from contextlib import AbstractContextManager
+
+# ....................{ CLASSES                            }....................
+class Iota(object):
+    '''
+    **Iota** (i.e., object minimizing space consumption by guaranteeably
+    containing *no* attributes).
+    '''
+
+    __slots__ = ()
+
+# ....................{ CONSTANTS                          }....................
+SENTINEL = Iota()
+'''
+Sentinel object of arbitrary value.
+
+This object is internally leveraged by various utility functions to identify
+erroneous and edge-case input (e.g., iterables of insufficient length).
+'''
+
+# ....................{ TESTERS                            }....................
+def is_object_context_manager(obj: object) -> bool:
+    '''
+    :data:`True` only if the passed object is a **context manager** (i.e.,
+    object defining both the ``__exit__`` and ``__enter__`` dunder methods
+    required to satisfy the context manager protocol).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is a context manager.
+    '''
+
+    # Return true only if...
+    return (
+        # This object satisfies the context manager protocol (i.e., defines both
+        # the __enter__() and __exit__() dunder methods) *AND*...
+        isinstance(obj, AbstractContextManager) and
+        # This object is *NOT* a "fake" context manager (i.e., defines erroneous
+        # __enter__() and __exit__() dunder methods trivially reducing to noops
+        # and also emitting non-fatal deprecation warnings).
+        not isinstance(obj, TYPES_CONTEXTMANAGER_FAKE)
+    )
+
+
+# Note that this tester function *CANNOT* be memoized by the @callable_cached
+# decorator, which requires all passed parameters to already be hashable.
+def is_object_hashable(obj: object) -> bool:
+    '''
+    :data:`True` only if the passed object is **hashable** (i.e., passable to
+    the builtin :func:`hash` function *without* raising an exception and thus
+    usable in hash-based containers like dictionaries and sets).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object is hashable.
+    '''
+
+    # Attempt to hash this object. If doing so raises *any* exception
+    # whatsoever, this object is by definition unhashable.
+    #
+    # Note that there also exists a "collections.abc.Hashable" superclass.
+    # Sadly, this superclass is mostly useless for all practical purposes. Why?
+    # Because user-defined classes are free to subclass that superclass
+    # despite overriding the __hash__() dunder method implicitly called by the
+    # builtin hash() function to raise exceptions: e.g.,
+    #
+    #     from collections.abc import Hashable
+    #     class HashUmUp(Hashable):
+    #         def __hash__(self):
+    #             raise ValueError('uhoh')
+    #
+    # Note also that we catch all possible exceptions rather than merely the
+    # standard "TypeError" exception raised by unhashable builtin types (e.g.,
+    # dictionaries, lists, sets). Why? For the same exact reason as above.
+    try:
+        hash(obj)
+    # If this object is unhashable, return false.
+    except:
+        return False
+
+    # Else, this object is hashable. Return true.
+    return True
+
+# ....................{ GETTERS ~ name                     }....................
+def get_object_name(obj: Any) -> str:
+    '''
+    **Fully-qualified name** (i.e., ``.``-delimited string unambiguously
+    identifying) of the passed object if this object defines either the
+    ``__qualname__`` or ``__name__`` dunder attributes *or* raise an exception
+    otherwise (i.e., if this object defines *no* such attributes).
+
+    Specifically, this name comprises (in order):
+
+    #. If this object is transitively declared by a module, the absolute name
+       of that module.
+    #. If this object is transitively declared by another object (e.g., class,
+       callable) and thus nested in that object, the unqualified basenames of
+       all parent objects transitively declaring this object in that module.
+    #. Unqualified basename of this object.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    str
+        Fully-qualified name of this object.
+
+    Raises
+    ------
+    _BeartypeUtilObjectNameException
+        If this object defines neither ``__qualname__`` *nor* ``__name__``
+        dunder attributes.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._cave._cavefast import CallableOrClassTypes
+    from beartype._util.module.utilmodget import (
+        get_object_module_name_or_none,
+        get_object_type_module_name_or_none,
+    )
+
+    # Lexically scoped name of this object excluding this module name if this
+    # object is named *OR* raise an exception otherwise.
+    object_scopes_name = get_object_basename_scoped(obj)
+
+    # Fully-qualified name of the module declaring this object if this object
+    # is declared by a module *OR* "None" otherwise, specifically defined as:
+    # * If this object is either a callable or class, the fully-qualified name
+    #   of the module declaring this object.
+    # * Else, the fully-qualified name of the module declaring the class of
+    #   this object.
+    object_module_name = (
+        get_object_module_name_or_none(obj)
+        if isinstance(object, CallableOrClassTypes) else
+        get_object_type_module_name_or_none(obj)
+    )
+
+    # Return either...
+    return (
+        # If this module name exists, "."-delimited concatenation of this
+        # module and object name;
+        f'{object_module_name}.{object_scopes_name}'
+        if object_module_name is not None else
+        # Else, this object name as is.
+        object_scopes_name
+    )
+
+# ....................{ GETTERS ~ basename                 }....................
+def get_object_basename_scoped(obj: Any) -> str:
+    '''
+    **Lexically scoped name** (i.e., ``.``-delimited string unambiguously
+    identifying all lexical scopes encapsulating) the passed object if this
+    object defines either the ``__qualname__`` or ``__name__`` dunder attributes
+    *or* raise an exception otherwise (i.e., if this object defines *no* such
+    attributes).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    str
+        Lexically scoped name of this object.
+
+    Raises
+    ------
+    _BeartypeUtilObjectNameException
+        If this object defines neither ``__qualname__`` *nor* ``__name__``
+        dunder attributes.
+
+    See Also
+    --------
+    :func:`.get_object_basename_scoped_or_none`
+        Further details.
+    '''
+
+    # Fully-qualified name of this object excluding its module name.
+    object_scoped_name = get_object_basename_scoped_or_none(obj)
+
+    # If this object is unnamed, raise a human-readable exception. The default
+    # "AttributeError" exception raised by attempting to directly access either
+    # the "obj.__name__" or "obj.__qualname__" attributes is sufficiently
+    # non-explanatory to warrant replacement by our explanatory exception.
+    if object_scoped_name is None:
+        raise _BeartypeUtilObjectNameException(
+            f'{repr(obj)} unnamed '
+            f'(i.e., declares neither "__name__" nor "__qualname__" '
+            f'dunder attributes).'
+        )
+    # Else, this object is named.
+
+    # Remove all "<locals>" placeholder substrings as discussed above.
+    return object_scoped_name.replace('<locals>.', '')
+
+
+#FIXME: Unit test us up, please.
+def get_object_basename_scoped_or_none(obj: Any) -> Optional[str]:
+    '''
+    **Lexically scoped name** (i.e., ``.``-delimited string unambiguously
+    identifying all lexical scopes encapsulating) the passed object if this
+    object defines either the ``__qualname__`` or ``__name__`` dunder attributes
+    *or* :data:`None` otherwise (i.e., if this object defines *no* such
+    attributes).
+
+    Specifically, this name comprises (in order):
+
+    #. If this object is transitively declared by another object (e.g., class,
+       callable) and thus nested in that object, the unqualified basenames of
+       all parent objects transitively declaring this object in that module.
+       For usability, these basenames intentionally omit the meaningless
+       placeholder ``"<locals>"`` substrings artificially injected by Python
+       itself into the original ``__qualname__`` instance variable underlying
+       this getter: e.g.,
+
+       .. code-block:: python
+
+          >>> from beartype._util.utilobject import get_object_basename_scoped
+          >>> def muh_func():
+          ...     def muh_closure(): pass
+          ...     return muh_closure()
+          >>> muh_func().__qualname__
+          'muh_func.<locals>.muh_closure'  # <-- bad Python
+          >>> get_object_basename_scoped(muh_func)
+          'muh_func.muh_closure'  # <-- good @beartype
+
+    #. Unqualified basename of this object.
+
+    Caveats
+    -------
+    **The higher-level** :func:`get_object_name` **getter should typically be
+    called instead of this lower-level getter.** This getter unsafely:
+
+    * Requires the passed object to declare dunder attributes *not* generally
+      declared by arbitrary instances of user-defined classes.
+    * Omits the fully-qualified name of the module transitively declaring this
+      object and thus fails to return fully-qualified names.
+
+    **This high-level getter should always be called in lieu of directly
+    accessing the low-level** ``__qualname__`` **dunder attribute on objects.**
+    That attribute contains one meaningless ``"<locals>"`` placeholder
+    substring conveying *no* meaningful semantics for each parent callable
+    lexically nesting this object.
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If this object defines at least one of the ``__qualname__`` or
+          ``__name__`` dunder attributes, the lexically scoped name of this
+          object.
+        * Else, :data:`None`.
+
+    Raises
+    ------
+    _BeartypeUtilObjectNameException
+        If this object defines neither ``__qualname__`` *nor* ``__name__``
+        dunder attributes.
+    '''
+
+    # Fully-qualified name of this object excluding its module name as follows:
+    # * If this object defines the "__qualname__" dunder attribute whose value
+    #   is the "."-delimited concatenation of the unqualified basenames of all
+    #   parent objects transitively declaring this object, that value with all
+    #   meaningless "<locals>" placeholder substrings removed. If this object
+    #   is a nested non-method callable (i.e., pure-Python function nested in
+    #   one or more parent pure-Python callables), that value contains one such
+    #   placeholder for each parent callable containing this callable. Since
+    #   placeholders convey no meaningful semantics, placeholders are removed.
+    # * Else if this object defines the "__name__" dunder attribute whose value
+    #   is the unqualified basename of this object, that value.
+    # * Else, "None".
+    object_scoped_name = getattr(
+        obj, '__qualname__', getattr(
+            obj, '__name__', None))
+
+    # Return either...
+    return (
+        # If this name exists, all "<locals>" placeholder substrings globally
+        # removed from this name as discussed above;
+        object_scoped_name.replace('<locals>.', '')
+        if object_scoped_name else
+        # Else, either "None" or the empty string.
+        object_scoped_name
+    )
+
+# ....................{ GETTERS ~ filename                 }....................
+def get_object_filename_or_none(obj: object) -> Optional[str]:
+    '''
+    Filename of the module or script physically declaring the passed object if
+    this object is either a callable or class physically declared on-disk *or*
+    :data:`None` otherwise (i.e., if this object is neither a callable nor
+    class *or* is either a callable or class dynamically declared in-memory).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    Optional[str]
+        Either:
+
+        * If this object is either a callable or class physically declared
+          on-disk, the filename of the module or script physically declaring
+          this object.
+        * Else, :data:`None`.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.cls.utilclsget import get_type_filename_or_none
+    from beartype._util.func.utilfuncfile import get_func_filename_or_none
+    from beartype._util.func.utilfunctest import is_func_python
+
+    # Return either...
+    return (
+        # If this object is a pure-Python class, the absolute filename of the
+        # source module file defining that class if that class was defined
+        # on-disk *OR* "None" otherwise (i.e., if that class was defined
+        # in-memory);
+        get_type_filename_or_none(obj)
+        if isinstance(obj, type) else
+        # If this object is a pure-Python callable, the absolute filename of the
+        # absolute filename of the source module file defining that callable if
+        # that callable was defined on-disk *OR* "None" otherwise (i.e., if that
+        # callable was defined in-memory);
+        get_func_filename_or_none(obj)
+        if is_func_python(obj) else
+        # Else, "None".
+        None
+    )
+
+# ....................{ GETTERS ~ type                     }....................
+def get_object_type_unless_type(obj: object) -> type:
+    '''
+    Either the passed object if this object is a class *or* the class of this
+    object otherwise (i.e., if this object is *not* a class).
+
+    Note that this function *never* raises exceptions on arbitrary objects, as
+    the :obj:`type` builtin wisely returns itself when passed itself: e.g.,
+
+    .. code-block:: python
+
+        >>> type(type(type)) is type
+        True
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    type
+        Type of this object.
+    '''
+
+    return obj if isinstance(obj, type) else type(obj)
+
+# ....................{ GETTERS ~ type : name              }....................
+def get_object_type_basename(obj: object) -> str:
+    '''
+    **Unqualified name** (i.e., non-``.``-delimited basename) of either the
+    passed object if this object is a class *or* the class of this object
+    otherwise (i.e., if this object is *not* a class).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    str
+        Unqualified name of this class.
+    '''
+
+    # Elegant simplicity diminishes aggressive tendencies.
+    return get_object_type_unless_type(obj).__name__
+
+
+def get_object_type_name(obj: object) -> str:
+    '''
+    **Fully-qualified name** (i.e., ``.``-delimited name prefixed by the
+    declaring module) of either passed object if this object is a class *or*
+    the class of this object otherwise (i.e., if this object is *not* a class).
+
+    Parameters
+    ----------
+    obj : object
+        Object to be inspected.
+
+    Returns
+    -------
+    str
+        Fully-qualified name of the type of this object.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype._util.module.utilmodget import (
+        get_object_type_module_name_or_none)
+
+    # Type of this object.
+    cls = get_object_type_unless_type(obj)
+
+    # Unqualified name of this type.
+    cls_basename = get_object_type_basename(cls)
+
+    # Fully-qualified name of the module defining this class if this class is
+    # defined by a module *OR* "None" otherwise.
+    cls_module_name = get_object_type_module_name_or_none(cls)
+
+    # Return either...
+    return (
+        # The "."-delimited concatenation of this class basename and module
+        # name if this module name exists.
+        f'{cls_module_name}.{cls_basename}'
+        if cls_module_name is not None else
+        # This class basename as is otherwise.
+        cls_basename
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/cave/__init__.py
@@ -0,0 +1,220 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype cave.**
+
+This submodule collects common types (e.g., :class:`NoneType`, the type of the
+``None`` singleton) and tuples of common types (e.g., :data:`CallableTypes`, a
+tuple of the types of all callable objects).
+
+PEP 484
+----------
+This module is intentionally *not* compliant with the :pep:`484` standard
+implemented by the stdlib :mod:`typing` module, which formalizes type hinting
+annotations with a catalogue of generic classes and metaclasses applicable to
+common use cases. :mod:`typing` enables end users to enforce contractual
+guarantees over the contents of arbitrarily complex data structures with the
+assistance of third-party static type checkers (e.g., :mod:`mypy`,
+:mod:`pyre`), runtime type checkers (e.g., :mod:`beartype`, :mod:`typeguard`),
+and integrated development environments (e.g., PyCharm).
+
+Genericity comes at a cost, though. Deeply type checking a container containing
+``n`` items, for example, requires type checking both that container itself
+non-recursively *and* each item in that container recursively. Doing so has
+time complexity ``O(N)`` for ``N >= n`` the total number of items transitively
+contained in this container (i.e., items directly contained in this container
+*and* items directly contained in containers contained in this container).
+While the cost of this operation can be paid either statically *or* amortized
+at runtime over all calls to annotated callables accepting that container, the
+underlying cost itself remains the same.
+
+By compare, this module only contains standard Python classes and tuples of
+such classes intended to be passed as is to the C-based :func:`isinstance`
+builtin and APIs expressed in terms of that builtin (e.g., :mod:`beartype`).
+This module only enables end users to enforce contractual guarantees over the
+types but *not* contents of arbitrarily complex data structures. This
+intentional tradeoff maximizes runtime performance at a cost of ignoring the
+types of items contained in containers.
+
+In summary:
+
+=====================  ====================  ====================================
+feature set            :mod:`beartype.cave`  :mod:`typing`
+=====================  ====================  ====================================
+type checking          **shallow**           **deep**
+type check items?      **no**                **yes**
+:pep:`484`-compliant?  **no**                **yes**
+time complexity        ``O(1)``              ``O(N)``
+performance            stupid fast           *much* less stupid fast
+implementation         C-based builtin call  pure-Python (meta)class method calls
+low-level primitive    :func:`isinstance`    :mod:`typing.TypingMeta`
+=====================  ====================  ====================================
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: *NEVER IMPORT FROM THIS SUBPACKAGE FROM WITHIN BEARTYPE ITSELF.*
+# This subpackage currently imports from expensive third-party packages on
+# importation (e.g., NumPy) despite beartype itself *NEVER* requiring those
+# imports. Until resolved, this subpackage is considered tainted.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To prevent "mypy --no-implicit-reexport" from raising literally
+# hundreds of errors at static analysis time, *ALL* public attributes *MUST* be
+# explicitly reimported under the same names with "{exception_name} as
+# {exception_name}" syntax rather than merely "{exception_name}". Yes, this is
+# ludicrous. Yes, this is mypy. For posterity, these failures resemble:
+#     beartype/_cave/_cavefast.py:47: error: Module "beartype.roar" does not
+#     explicitly export attribute "BeartypeCallUnavailableTypeException";
+#     implicit reexport disabled  [attr-defined]
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+from beartype.cave._cavelib import (
+    # Types.
+    ArgParserType as ArgParserType,
+    ArgSubparsersType as ArgSubparsersType,
+    WeakRefCType as WeakRefCType,
+
+    # Type tuples.
+    WeakRefProxyCTypes as WeakRefProxyCTypes,
+)
+from beartype._cave._caveabc import (
+    BoolType as BoolType,
+)
+from beartype._cave._cavefast import (
+    # Types.
+    AnyType as AnyType,
+    AsyncCoroutineCType as AsyncCoroutineCType,
+    AsyncGeneratorCType as AsyncGeneratorCType,
+    CallableCodeObjectType as CallableCodeObjectType,
+    ClassDictType as ClassDictType,
+    CallableFrameType as CallableFrameType,
+    CallableFunctoolsPartialType as CallableFunctoolsPartialType,
+    ClassType as ClassType,
+    ClosureVarCellType as ClosureVarCellType,
+    CollectionType as CollectionType,
+    ContainerType as ContainerType,
+    EllipsisType as EllipsisType,
+    EnumType as EnumType,
+    EnumMemberType as EnumMemberType,
+    ExceptionTracebackType as ExceptionTracebackType,
+    FileType as FileType,
+    FunctionType as FunctionType,
+    FunctionOrMethodCType as FunctionOrMethodCType,
+    GeneratorCType as GeneratorCType,
+    GeneratorType as GeneratorType,
+    HashableType as HashableType,
+    HintGenericSubscriptedType as HintGenericSubscriptedType,
+    IntOrFloatType as IntOrFloatType,
+    IntType as IntType,
+    IterableType as IterableType,
+    IteratorType as IteratorType,
+    MappingMutableType as MappingMutableType,
+    MappingType as MappingType,
+    MethodBoundInstanceDunderCType as MethodBoundInstanceDunderCType,
+    MethodBoundInstanceOrClassType as MethodBoundInstanceOrClassType,
+    MethodDecoratorClassType as MethodDecoratorClassType,
+    MethodDecoratorPropertyType as MethodDecoratorPropertyType,
+    MethodDecoratorStaticType as MethodDecoratorStaticType,
+    MethodUnboundClassCType as MethodUnboundClassCType,
+    MethodUnboundInstanceDunderCType as MethodUnboundInstanceDunderCType,
+    MethodUnboundInstanceNondunderCType as MethodUnboundInstanceNondunderCType,
+    MethodUnboundPropertyNontrivialCExtensionType as
+        MethodUnboundPropertyNontrivialCExtensionType,
+    MethodUnboundPropertyTrivialCExtensionType as
+        MethodUnboundPropertyTrivialCExtensionType,
+    ModuleType as ModuleType,
+    NoneType as NoneType,
+    NotImplementedType as NotImplementedType,
+    NumberRealType as NumberRealType,
+    NumberType as NumberType,
+    SizedType as SizedType,
+    QueueType as QueueType,
+    RegexCompiledType as RegexCompiledType,
+    RegexMatchType as RegexMatchType,
+    SetType as SetType,
+    SequenceMutableType as SequenceMutableType,
+    SequenceType as SequenceType,
+    StrType as StrType,
+    UnavailableType as UnavailableType,
+
+    # Type tuples.
+    AsyncCTypes as AsyncCTypes,
+    BoolOrNumberTypes as BoolOrNumberTypes,
+    CallableCTypes as CallableCTypes,
+    CallableOrClassTypes as CallableOrClassTypes,
+    CallableOrStrTypes as CallableOrStrTypes,
+    CallableTypes as CallableTypes,
+    DecoratorTypes as DecoratorTypes,
+    FunctionTypes as FunctionTypes,
+    ModuleOrStrTypes as ModuleOrStrTypes,
+    MethodBoundTypes as MethodBoundTypes,
+    MethodDecoratorBuiltinTypes as MethodDecoratorBuiltinTypes,
+    MethodUnboundTypes as MethodUnboundTypes,
+    MethodTypes as MethodTypes,
+    MappingOrSequenceTypes as MappingOrSequenceTypes,
+    ModuleOrSequenceTypes as ModuleOrSequenceTypes,
+    NumberOrIterableTypes as NumberOrIterableTypes,
+    NumberOrSequenceTypes as NumberOrSequenceTypes,
+    RegexTypes as RegexTypes,
+    ScalarTypes as ScalarTypes,
+    TestableTypes as TestableTypes,
+    UnavailableTypes as UnavailableTypes,
+)
+from beartype._cave._cavemap import (
+    NoneTypeOr as NoneTypeOr,
+)
+
+# ....................{ DEPRECATIONS                       }....................
+def __getattr__(attr_deprecated_name: str) -> object:
+    '''
+    Dynamically retrieve a deprecated attribute with the passed unqualified
+    name from this submodule and emit a non-fatal deprecation warning on each
+    such retrieval if this submodule defines this attribute *or* raise an
+    exception otherwise.
+
+    The Python interpreter implicitly calls this :pep:`562`-compliant module
+    dunder function under Python >= 3.7 *after* failing to directly retrieve an
+    explicit attribute with this name from this submodule. Since this dunder
+    function is only called in the event of an error, neither space nor time
+    efficiency are a concern here.
+
+    Parameters
+    ----------
+    attr_deprecated_name : str
+        Unqualified name of the deprecated attribute to be retrieved.
+
+    Returns
+    ----------
+    object
+        Value of this deprecated attribute.
+
+    Warns
+    ----------
+    :class:`DeprecationWarning`
+        If this attribute is deprecated.
+
+    Raises
+    ----------
+    :exc:`AttributeError`
+        If this attribute is unrecognized and thus erroneous.
+    '''
+
+    # Isolate imports to avoid polluting the module namespace.
+    from beartype._util.module.utilmoddeprecate import deprecate_module_attr
+
+    # Return the value of this deprecated attribute and emit a warning.
+    return deprecate_module_attr(
+        attr_deprecated_name=attr_deprecated_name,
+        attr_deprecated_name_to_nondeprecated_name={
+            'HintPep585Type': 'HintGenericSubscriptedType',
+        },
+        attr_nondeprecated_name_to_value=globals(),
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/cave/_cavelib.py
@@ -0,0 +1,76 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype slow cave** (i.e., private subset of the public :mod:`beartype.cave`
+subpackage profiled to *not* be efficiently importable at :mod:`beartype`
+startup and thus *not* safely importable throughout the internal
+:mod:`beartype` codebase).
+
+This submodule currently imports from expensive third-party packages on
+importation (e.g., :mod:`numpy`) despite :mod:`beartype` itself *never*
+requiring those imports. Until resolved, that subpackage is considered tainted.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Excise this submodule away, please. This submodule was a horrendous idea
+#and has plagued the entire "beartype.cave" subpackage with unnecessary slowdown
+#at import time. It's simply time for this to go, please.
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+from argparse import (
+    ArgumentParser,
+    _SubParsersAction,
+)
+from weakref import (
+    ProxyTypes,
+    ref,
+)
+
+# ....................{ TYPES ~ lib                        }....................
+# Types conditionally dependent upon the importability of third-party
+# dependencies. These types are subsequently redefined by try-except blocks
+# below and initially default to "UnavailableType" for simple types.
+
+# ....................{ TYPES ~ stdlib : argparse          }....................
+ArgParserType = ArgumentParser
+'''
+Type of argument parsers parsing all command-line arguments for either
+top-level commands *or* subcommands of those commands.
+'''
+
+
+ArgSubparsersType = _SubParsersAction
+'''
+Type of argument subparser containers parsing subcommands for parent argument
+parsers parsing either top-level commands *or* subcommands of those commands.
+'''
+
+# ....................{ TYPES ~ stdlib : weakref           }....................
+WeakRefCType = ref
+'''
+Type of all **unproxied weak references** (i.e., callable objects yielding
+strong references to their referred objects when called).
+
+This type matches both the C-based :class:`weakref.ref` class *and* the
+pure-Python :class:`weakref.WeakMethod` class, which subclasses the former.
+'''
+# ....................{ TUPLES ~ stdlib : weakref          }....................
+WeakRefProxyCTypes = ProxyTypes
+'''
+Tuple of all **C-based weak reference proxy classes** (i.e., classes
+implemented in low-level C whose instances are weak references to other
+instances masquerading as those instances).
+
+This tuple contains classes matching both callable and uncallable weak
+reference proxies.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/__init__.py
@@ -0,0 +1,38 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype import hook API.**
+
+This subpackage publishes :pep:`302`- and :pep:`451`-compliant import hooks
+enabling external callers to automatically decorate well-typed third-party
+packages and modules with runtime type-checking dynamically generated by the
+:func:`beartype.beartype` decorator in a single line of code.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Technically, we're not quite done here. The "beartype.claw" API
+#currently silently ignores attempts to subject the "beartype" package itself to
+#@beartyping. Ideally, that API should instead raise human-readable exceptions
+#when users explicitly attempt to do so when calling either the
+#beartype_package() or beartype_packages() functions. After implementing that
+#functionality, assert that in our test suite, please.
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.claw._clawmain import (
+    beartype_all as beartype_all,
+    beartype_package as beartype_package,
+    beartype_packages as beartype_packages,
+    beartype_this_package as beartype_this_package,
+)
+from beartype.claw._pkg.clawpkgcontext import (
+    beartyping as beartyping,
+)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_ast/__init__.py
@@ -0,0 +1,57 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) functionality** (i.e., low-level callables
+and classes instrumenting well-typed third-party modules with runtime
+type-checking dynamically generated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: [PEP 675] *OMG.* See also the third-party "executing" Python package:
+#    https://github.com/alexmojaki/executing
+#
+#IPython itself internally leverages "executing" via "stack_data" (i.e., a
+#slightly higher-level third-party Python package that internally leverages
+#"executing") to syntax-highlight the currently executing AST node. Indeed,
+#"executing" sports an intense test suite (much like ours) effectively
+#guaranteeing a one-to-one mapping between stack frames and AST nodes.
+#
+#So, what's the Big Idea here? The Big Idea here is that @beartype can
+#internally (...possibly only optionally, but possibly mandatorily) leverage
+#"executing" to begin performing full-blown static type-checking at runtime --
+#especially of mission critical type hints like "typing.LiteralString" which can
+#*ONLY* be type-checked via static analysis. :o
+#
+#So, what's the Little Idea here? The Little Idea here is that @beartype can
+#generate type-checking wrappers that type-check parameters or returns annotated
+#by "typing.LiteralString" by calling an internal private utility function --
+#say, "_die_unless_literalstring(func: Callable, arg_name: str) -> None" -- with
+#"func" as the current type-checking wrapper and "arg_name" as either the name
+#of that parameter or "return". The _die_unless_literalstring() raiser then:
+#* Dynamically searches up the call stack for the stack frame encapsulating an
+#  external call to the passed "func" callable.
+#* Passes that stack frame to the "executing" package.
+#* "executing" then returns the AST node corresponding to that stack frame.
+#* Introspects that node for the passed parameter whose name is "arg_name".
+#* Raises an exception unless the value of that parameter is an AST node
+#  corresponding to a string literal.
+#
+#Of course, that won't necessarily be fast -- but it will be accurate. Since
+#security trumps speed, speed is significantly less of a concern insofar as
+#"typing.LiteralString" is concerned. Of course, we should also employ
+#significant caching... if we even can.
+#FIXME: Actually, while demonstrably awesome, even the above fails to suffice to
+#to statically type-check "typing.LiteralString". We failed to fully read PEP
+#675, which contains a section on inference. In the worst case, nothing less
+#than a complete graph of the entire app and all transitive dependencies thereof
+#suffices to decide whether a parameter satisfies "typing.LiteralString".
+#
+#Thankfully, the above idea generalizes from "typing.LiteralString" to other
+#fascinating topics as well. Indeed, given sufficient caching, one could begin
+#to internally generate and cache a mypy-like graph network whose nodes are
+#typed attributes and whose edges are relations between those typed attributes.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_ast/_clawaststar.py
@@ -0,0 +1,89 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) star imports** (i.e., set of all
+``import`` statements importing attributes required by beartype-specific code
+dynamically injected into otherwise beartype-agnostic user code by the
+:class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass).
+
+This private submodule is a "clearing house" of beartype AST imports, intended
+to be dynamically injected as a single **star-import statement** (e.g., of the
+syntactic form ``from beartype.claw._ast._clawaststar import *``) injected into
+the module scope of otherwise beartype-agnostic user code by the
+:class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass. Doing
+so enables all *other* such beartype-specific code to conveniently reference the
+attributes explicitly imported and implicitly exported by this submodule.
+
+This private submodule is *not* intended for importation by downstream callers.
+
+Caveats
+-------
+This private submodule intentionally imports the original attributes into the
+currently visited submodule under obfuscated beartype-specific names suffixed by
+the arbitrary substring ``"_beartype__"``, significantly reducing the likelihood
+of a namespace collision with existing attributes of the same name in that
+submodule. Since all visited submodules are user-defined and thus outside
+beartype control, some level of obfuscation is effectively mandatory.
+'''
+
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: *ALL* imports performed below *MUST* be explicitly listed in the
+# "__all__" dunder global declared before to actually have an effect.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+# ....................{ IMPORTS                            }....................
+# Imports required by PEP-agnostic nodes injected into the current AST by the
+# "beartype.claw._ast..clawastmain.BeartypeNodeTransformer" superclass.
+
+# Import our beartype decorator to be applied by our AST transformer to all
+# applicable callables and classes in third-party modules.
+from beartype._decor.decorcache import beartype as __beartype__
+
+# Import our beartype import hook state (i.e., non-thread-safe singleton
+# centralizing *all* global state maintained by beartype import hooks).
+from beartype.claw._clawstate import claw_state as __claw_state_beartype__
+
+# ....................{ IMPORTS ~ pep : 526                }....................
+# Imports required by PEP 526-compliant nodes injected into the current AST by
+# "beartype.claw._ast.pep.clawastpep526.BeartypeNodeTransformerPep526Mixin".
+
+# Import our beartype exception-raiser (i.e., beartype-specific function raising
+# exceptions on runtime type-checking violations, applied by our AST transformer
+# to all applicable PEP 526-compliant annotated variable assignments).
+#
+# Note that we intentionally import this exception-raiser from our private
+# "beartype.door._doorcheck" submodule rather than our public "beartype.door"
+# subpackage. Why? Because the former consumes marginally less space and time to
+# import than the latter. Whereas the latter imports the full "TypeHint" type
+# hierarchy, the former only imports low-level utility functions.
+from beartype.door._doorcheck import (
+    die_if_unbearable as __die_if_unbearable_beartype__)
+
+# ....................{ IMPORTS ~ pep : 695                }....................
+# Imports required by PEP 695-compliant nodes injected into the current AST by
+# "beartype.claw._ast.pep.clawastpep695.BeartypeNodeTransformerPep695Mixin".
+
+# Import our PEP 695-compliant type alias forward reference proxy factory
+# iterator (i.e., generator iteratively creating and yielding one forward
+# reference proxy for each unqualified relative forward reference in the passed
+# PEP 695-compliant type alias).
+from beartype._util.hint.pep.proposal.utilpep695 import (
+    iter_hint_pep695_forwardrefs as __iter_hint_pep695_forwardref_beartype__)
+
+# ....................{ GLOBALS                            }....................
+__all__ = [
+    '__beartype__',
+    '__claw_state_beartype__',
+    '__die_if_unbearable_beartype__',
+    '__iter_hint_pep695_forwardref_beartype__',
+]
+'''
+Special list global of the unqualified names of all public submodule attributes
+explicitly exported by and thus safely importable from this submodule.
+
+Note that this global *must* be defined. If this global is *not* defined, then
+importing star imports from this submodule silently reduces to a noop.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_ast/_clawastutil.py
@@ -0,0 +1,262 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) mungers** (i.e., low-level callables
+modifying various properties of various nodes in the currently visited AST).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    AST,
+    Attribute,
+    Call,
+    ClassDef,
+    Index,
+    Name,
+    Subscript,
+    expr,
+    keyword,
+)
+from beartype.claw._clawmagic import (
+    NODE_CONTEXT_LOAD,
+    BEARTYPE_CLAW_STATE_CONF_CACHE_VAR_NAME,
+    BEARTYPE_CLAW_STATE_OBJ_NAME,
+    BEARTYPE_DECORATOR_FUNC_NAME,
+)
+from beartype._data.hint.datahinttyping import (
+    NodeDecoratable,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._util.ast.utilastmake import (
+    make_node_kwarg,
+    make_node_name_load,
+    make_node_object_attr_load,
+    make_node_str,
+)
+from beartype._util.ast.utilastmunge import copy_node_metadata
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+
+# ....................{ SUBCLASSES                         }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To improve forward compatibility with the superclass API over which
+# we have *NO* control, avoid accidental conflicts by suffixing *ALL* private
+# and public attributes of this subclass by "_beartype".
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+class BeartypeNodeTransformerUtilityMixin(object):
+    '''
+    **Beartype abstract syntax tree (AST) node utility transformer** (i.e.,
+    low-level mixin of the high-level
+    :class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass
+    supplementing that subclass with various low-level methods creating,
+    modifying, and introspecting common node types and subclass properties).
+    '''
+
+    # ....................{ PRIVATE ~ decorators           }....................
+    #FIXME: Unit test us up, please.
+    def _decorate_node_beartype(
+        self, node: NodeDecoratable, conf: BeartypeConf) -> None:
+        '''
+        Add a new **child beartype decoration node** (i.e., abstract syntax tree
+        (AST) node applying the :func:`beartype.beartype` decorator configured
+        by the passed beartype configuration) to the passed **parent decoratable
+        node** (i.e., AST node encapsulating the definition of a pure-Python
+        object supporting decoration by one or more ``"@"``-prefixed
+        decorations, including both pure-Python classes *and* callables).
+
+        Note that this function **prepends** rather than appends this child
+        decoration node to the beginning of the list of all child decoration
+        nodes for this parent decoratable node. Since that list is "stored
+        outermost first (i.e. the first in the list will be applied last)",
+        prepending guarantees that the beartype decorator will be applied last
+        (i.e., *after* all other decorators). This ensures that explicitly
+        configured beartype decorations applied to this decoratable by the end
+        user (e.g., ``@beartype(conf=BeartypeConf(...))``) assume precedence
+        over implicitly configured beartype decorations applied by this
+        function.
+
+        Parameters
+        ----------
+        node : AST
+            Decoratable node to add a new child beartype decoration node to.
+        conf : BeartypeConf
+            **Beartype configuration** (i.e., dataclass configuring the
+            :mod:`beartype.beartype` decorator for some decoratable object(s)
+            decorated by a parent node passing this dataclass to that
+            decorator).
+        '''
+        assert isinstance(node, AST), f'{repr(node)} not AST node.'
+        assert isinstance(conf, BeartypeConf), (
+            f'{repr(conf)} not configuration.')
+
+        # Child decoration node decorating that callable by our beartype
+        # decorator.
+        beartype_decorator: expr = Name(
+            id=BEARTYPE_DECORATOR_FUNC_NAME, ctx=NODE_CONTEXT_LOAD)
+
+        # Copy all source code metadata from this parent callable node onto this
+        # child decoration node.
+        copy_node_metadata(node_src=node, node_trg=beartype_decorator)
+
+        # If the current beartype configuration is *NOT* the default beartype
+        # configuration, this configuration is a user-defined beartype
+        # configuration which *MUST* be passed to a call to the beartype
+        # decorator. Merely referencing this decorator does *NOT* suffice. In
+        # this case...
+        if conf != BEARTYPE_CONF_DEFAULT:
+            # Replace the reference to this decorator defined above with a
+            # call to this decorator passed this configuration.
+            beartype_decorator = Call(
+                func=beartype_decorator,
+                args=[],
+                # Node encapsulating the passing of this configuration as
+                # the "conf" keyword argument to this call.
+                keywords=[
+                    self._make_node_keyword_conf_beartype(node_sibling=node)],
+            )
+
+            # Copy all source code metadata from this parent callable node onto
+            # this child call node.
+            copy_node_metadata(node_src=node, node_trg=beartype_decorator)
+        # Else, this configuration is simply the default beartype configuration.
+        # In this case, avoid passing that configuration to the beartype
+        # decorator for both efficiency and simplicity.
+
+        # Prepend this child decoration node to the beginning of the list of all
+        # child decoration nodes for this parent callable node. Since this list
+        # is "stored outermost first (i.e. the first in the list will be applied
+        # last)", prepending guarantees that our decorator will be applied last
+        # (i.e., *AFTER* all subsequent decorators). This ensures that
+        # explicitly configured @beartype decorations (e.g.,
+        # "beartype(conf=BeartypeConf(...))") assume precedence over implicitly
+        # configured @beartype decorations inserted by this hook.
+        node.decorator_list.insert(0, beartype_decorator)
+
+    # ....................{ PRIVATE ~ factories            }....................
+    #FIXME: Unit test us up, please.
+    def _make_node_keyword_conf_beartype(self, node_sibling: AST) -> keyword:
+        '''
+        Create and return a new **beartype configuration keyword argument node**
+        (i.e., abstract syntax tree (AST) node passing the beartype
+        configuration associated with the currently visited module as a ``conf``
+        keyword to a :func:`beartype.beartype` decorator orchestrated by the
+        caller).
+
+        Parameters
+        ----------
+        node_sibling : AST
+            Sibling node to copy source code metadata from.
+
+        Returns
+        -------
+        keyword
+            Keyword node passing this configuration to an arbitrary function.
+        '''
+
+        # Node encapsulating the fully-qualified name of the current module.
+        node_module_name = make_node_str(
+            text=self._module_name_beartype, node_sibling=node_sibling)  # type: ignore[attr-defined]
+
+        # Node encapsulating a reference to the beartype configuration object
+        # cache (i.e., dictionary mapping from fully-qualified module names to
+        # the beartype configurations associated with those modules).
+        node_module_name_to_conf = make_node_object_attr_load(
+            obj_name=BEARTYPE_CLAW_STATE_OBJ_NAME,
+            attr_name='module_name_to_beartype_conf',
+            node_sibling=node_sibling,
+        )
+
+        # Node encapsulating the indexation of a dictionary by the
+        # fully-qualified name of the current module.
+        node_module_name_index: AST = None  # type: ignore[assignment]
+
+        # If the active Python interpreter targets Python >= 3.9...
+        if IS_PYTHON_AT_LEAST_3_9:
+            # Reuse this node in a manner specific to Python >= 3.9, which
+            # fundamentally broke backward compatibility with Python 3.8 with
+            # respect to dictionary subscription.
+            node_module_name_index = node_module_name
+        # Else, the active Python interpreter targets Python 3.8. In this case..
+        else:
+            # Create this node in a manner specific to Python 3.8, which
+            # requires an additional intermediary node *NOT* required under
+            # Python >= 3.9.
+            node_module_name_index = Index(value=node_module_name)
+
+            # Copy all source code metadata (e.g., line numbers) from this
+            # sibling node onto this new node.
+            copy_node_metadata(
+                node_src=node_sibling, node_trg=node_module_name_index)
+
+        # Node encapsulating a reference to this beartype configuration,
+        # indirectly (and efficiently) accessed via a dictionary lookup into
+        # this object cache. While cumbersome, this indirection is effectively
+        # "glue" integrating this AST node generation algorithm with the
+        # corresponding Python code subsequently interpreted by Python at
+        # runtime during module importation.
+        node_conf = Subscript(
+            value=node_module_name_to_conf,
+            slice=node_module_name_index,
+            ctx=NODE_CONTEXT_LOAD,
+        )
+
+        # Node encapsulating the passing of this beartype configuration as the
+        # "conf" keyword argument to an arbitrary function call of some suitable
+        # "beartype" function orchestrated by the caller.
+        node_keyword_conf = make_node_kwarg(
+            kwarg_name='conf', kwarg_value=node_conf, node_sibling=node_sibling)
+
+        # Copy all source code metadata (e.g., line numbers) from this sibling
+        # node onto these new nodes.
+        copy_node_metadata(node_src=node_sibling, node_trg=node_conf)
+
+        # Return this "conf" keyword node.
+        return node_keyword_conf
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    def _is_scope_module_beartype(self) -> bool:
+        '''
+        :data:`True` only if the lexical scope of the currently visited node is
+        the **module scope** (i.e., this node is declared directly in the body
+        of the current user-defined module, implying this node to be a global).
+
+        Returns
+        -------
+        bool
+            :data:`True` only if the current lexical scope is a module scope.
+        '''
+
+        # Return true only if the stack of all lexical nodes is currently empty,
+        # implying the current node resides directly in the body of a module.
+        return not self._scope_stack_beartype  # type: ignore[attr-defined]
+
+
+    @property
+    def _is_scope_class_beartype(self) -> bool:
+        '''
+        :data:`True` only if the lexical scope of the currently visited node is
+        a **class scope** (i.e., this node resides directly in the body of a
+        user-defined class).
+
+        Returns
+        -------
+        bool
+            :data:`True` only if the current lexical scope is a class scope.
+        '''
+
+        # Return true only if...
+        return (
+            # The stack of all lexical scope is currently non-empty *AND*...
+            bool(self._scope_stack_beartype) and  # type: ignore[attr-defined]
+            # The current node resides directly in the body of a class.
+            self._scope_stack_beartype[-1] is ClassDef  # type: ignore[attr-defined]
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_ast/clawastmain.py
@@ -0,0 +1,550 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **abstract syntax tree (AST) transformers** (i.e., low-level classes
+instrumenting well-typed third-party modules with runtime type-checking
+dynamically generated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: [PEP 484] Additionally define:
+#* Generator transformers. The idea here is that @beartype *CAN* actually
+#  automatically type-check generator yields, sends, and returns at runtime.
+#  How? By automatically injecting appropriate die_if_unbearable() calls
+#  type-checking the values to be yielded, sent, and returned against the
+#  appropriate type hints of the current generator factory *BEFORE* yielding,
+#  sending, and returning those values. Shockingly, typeguard already does this
+#  -- which is all manner of impressive. See the
+#  TypeguardTransformer._use_memo() context manager for working code. Wow!
+#
+#See also:
+#    https://github.com/agronholm/typeguard/blob/master/src/typeguard/_transformer.py
+
+#FIXME: [SPEED] Consider generalizing the BeartypeNodeTransformer.__new__()
+#class method to internally cache and return "BeartypeNodeTransformer" instances
+#depending on the passed "conf_beartype" parameter. In general, most codebases
+#will only leverage a single @beartype configuration (if any @beartype
+#configuration at all); ergo, caching improves everything by enabling us to
+#reuse the same "BeartypeNodeTransformer" instance for every hooked module.
+#Score @beartype!
+#
+#See the BeartypeConf.__new__() method for relevant logic. \o/
+#FIXME: Oh, wait. We probably do *NOT* want to cache -- at least, not without
+#defining a comparable reinit() method as we do for "BeartypeCall". After
+#retrieving a cached "BeartypeNodeTransformer" instance, we'll need to
+#immediately call BeartypeNodeTransformer.reinit() to reinitialize that
+#instance.
+#
+#This is all feasible, of course -- but let's just roll with the naive
+#implementation for now, please.
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    AST,
+    ClassDef,
+    Constant,
+    Expr,
+    ImportFrom,
+    Module,
+    NodeTransformer,
+)
+from beartype.claw._ast.pep.clawastpep526 import (
+    BeartypeNodeTransformerPep526Mixin)
+from beartype.claw._ast.pep.clawastpep695 import (
+    BeartypeNodeTransformerPep695Mixin)
+from beartype.claw._ast._clawastutil import BeartypeNodeTransformerUtilityMixin
+from beartype._data.hint.datahinttyping import (
+    NodeCallable,
+    NodeT,
+)
+from beartype.typing import (
+    List,
+    Optional,
+    Type,
+)
+from beartype._data.ast.dataast import TYPES_NODE_LEXICAL_SCOPE
+from beartype._conf.confcls import BeartypeConf
+# from beartype._util.ast.utilastget import get_node_repr_indented
+from beartype._util.ast.utilastmake import make_node_importfrom
+from beartype._util.ast.utilasttest import is_node_callable_typed
+
+# ....................{ SUBCLASSES                         }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To improve forward compatibility with the superclass API over which
+# we have *NO* control, avoid accidental conflicts by suffixing *ALL* private
+# and public attributes of this subclass by "_beartype".
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+#FIXME: Unit test us up, please.
+class BeartypeNodeTransformer(
+    # PEP-agnostic superclass defining "core" AST node transformation logic.
+    NodeTransformer,
+
+    # PEP-agnostic mixins defining supplementary AST node functionality in a
+    # PEP-agnostic manner.
+    BeartypeNodeTransformerUtilityMixin,
+
+    # PEP-specific mixins defining additional AST node transformations in a
+    # PEP-specific manner.
+    BeartypeNodeTransformerPep526Mixin,
+    BeartypeNodeTransformerPep695Mixin,
+):
+    '''
+    **Beartype abstract syntax tree (AST) node transformer** (i.e., visitor
+    pattern recursively transforming the AST tree passed to the :meth:`visit`
+    method by decorating all typed callables and classes by the
+    :func:`beartype.beartype` decorator).
+
+    Design
+    ------
+    This class was largely designed by reverse-engineering the standard
+    :mod:`ast` module using the following code snippet. When run as the body of
+    a script from the command line (e.g., ``python3 {muh_script}.py``), this
+    snippet pretty-prints the desired target AST subtree implementing the
+    desired source code (specified in this snippet via the ``CODE`` global). In
+    short, this snippet trivializes the definition of arbitrarily complex
+    AST-based code from arbitrarily complex Python code:
+
+    .. code-block:: python
+
+       import ast
+
+       # Arbitrary desired code to pretty-print the AST representation of.
+       CODE = """
+       from beartype import beartype
+       from beartype._conf.confcache import beartype_conf_id_to_conf
+
+       @beartype(conf=beartype_conf_id_to_conf[139870142111616])
+       def muh_func(): pass
+       """
+
+       # Dismantled, this is:
+       # * "indent=...", producing pretty-printed (i.e., indented) output.
+       # * "include_attributes=True", enabling pseudo-nodes (i.e., nodes lacking
+       #   associated code metadata) to be distinguished from standard nodes
+       #   (i.e., nodes having such metadata).
+       print(ast.dump(ast.parse(CODE), indent=4, include_attributes=True))
+
+    Attributes
+    ----------
+    _conf_beartype : BeartypeConf
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by this node transformer).
+    _module_name_beartype : str
+        Fully-qualified name of the current module being transformed.
+    _scope_name_beartype : str
+        Fully-qualified name of the current lexical scope (i.e., ``.``-delimited
+        absolute name of the module containing this scope followed by the
+        relative basenames of zero or more classes and/or callables). This name
+        is guaranteed to be prefixed by :attr:`._module_name_beartype`.
+    _scope_stack_beartype : list[type[AST]]
+        **Current lexical scope stack** (i.e., list of the zero or more types of
+        parent nodes of the node being recursively visited by this node
+        transformer such that each of those parent nodes declares a new lexical
+        scope). Specifically:
+
+        * If this stack is empty, the current node directly resides in the body
+          of a module (i.e., is a global attribute).
+        * If this stack is non-empty, the current node does *not* directly
+          reside in the body of a module. Instead, if the last item of this
+          stack is:
+
+          * The :class:`ClassDef` node type, the current node directly resides
+            in the body of a class (i.e., is a class attribute or method).
+          * The :class:`FunctionDef` node type, the current node directly
+            resides in the body of a callable (i.e., is a local attribute).
+
+    See Also
+    --------
+    https://github.com/agronholm/typeguard/blob/fe5b578595e00d5e45c3795d451dcd7935743809/src/typeguard/importhook.py
+        Last commit of the third-party Python package whose
+        ``@typeguard.importhook.TypeguardTransformer`` class implements import
+        hooks performing runtime type-checking in a similar manner, strongly
+        inspiring this implementation.
+
+        Note that all subsequent commits to that package generalize those import
+        hooks into something else entirely, which increasingly resembles a
+        static type-checker run at runtime; while fascinating and almost
+        certainly ingenious, those commits are sufficiently inscrutable,
+        undocumented, and unintelligible to warrant caution. Nonetheless, thanks
+        so much to @agronholm (Alex Grönholm) for his pulse-pounding innovations
+        in this burgeoning field! Our AST transformer is for you, @agronholm.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats the purpose.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Slot all instance variables defined on this object to reduce the costs of
+    # both reading and writing these variables by approximately ~10%.
+    __slots__ = (
+        '_conf_beartype',
+        '_module_name_beartype',
+        '_scope_name_beartype',
+        '_scope_stack_beartype',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+
+        # Mandatory keyword-only parameters.
+        *,
+        module_name_beartype : str,
+        conf_beartype: BeartypeConf,
+    ) -> None:
+        '''
+        Initialize this node transformer.
+
+        Parameters
+        ----------
+        module_name_beartype : str
+            Fully-qualified name of the external third-party module being
+            transformed by this node transformer.
+        conf_beartype : BeartypeConf
+            **Beartype configuration** (i.e., dataclass configuring the
+            :mod:`beartype.beartype` decorator for *all* decoratable objects
+            recursively decorated by this node transformer).
+        '''
+        assert isinstance(module_name_beartype, str), (
+            f'{repr(module_name_beartype)} not string.')
+        assert isinstance(conf_beartype, BeartypeConf), (
+            f'{repr(conf_beartype)} not beartype configuration.')
+
+        # Initialize our superclass.
+        super().__init__()
+
+        # Classify all passed parameters.
+        self._conf_beartype = conf_beartype
+        self._module_name_beartype = self._scope_name_beartype = (
+            module_name_beartype)
+
+        # Nullify all remaining instance variables for safety.
+        self._scope_stack_beartype: List[Type[AST]] = []
+
+    # ..................{ SUPERCLASS                         }..................
+    # Overridden methods first defined by the "NodeTransformer" superclass.
+
+    def generic_visit(self, node: NodeT) -> NodeT:
+        '''
+        Recursively visit and possibly transform *all* child nodes of the passed
+        parent node in-place (i.e., preserving this parent node as is).
+
+        Parameters
+        ----------
+        node : NodeT
+            Parent node to transform *all* child nodes of.
+
+        Returns
+        -------
+        NodeT
+            Parent node returned and thus preserved as is.
+        '''
+
+        # Type of this parent node.
+        node_type = type(node)
+
+        # If this parent node declares a new lexical scope (i.e., by defining a
+        # new class or callable)...
+        if node_type in TYPES_NODE_LEXICAL_SCOPE:
+            # Fully-qualified name of the current lexical scope *BEFORE*
+            # visiting this new lexical scope.
+            scope_name_old = self._scope_name_beartype
+
+            # Append to this fully-qualified name the unqualified basename of
+            # this new class or callable declaring this new lexical scope.
+            #
+            # Note that both the "ast.ClassDef" *AND* "ast.FunctionDef" node
+            # types define the "name" instance variable accessed here.
+            self._scope_name_beartype += f'.{node.name}'  # type: ignore[attr-defined]
+
+            # Add the type of this parent node to the top of the stack of all
+            # current lexical scopes *BEFORE* visiting any child nodes of this
+            # parent node.
+            self._scope_stack_beartype.append(node_type)
+
+            # Recursively visit *ALL* child nodes of this parent node.
+            super().generic_visit(node)
+
+            # Restore the fully-qualified name of the prior lexical scope.
+            self._scope_name_beartype = scope_name_old
+
+            # Remove the type of this parent node from the top of the stack of
+            # all current lexical scopes *AFTER* visiting all child nodes of
+            # this parent node.
+            self._scope_stack_beartype.pop()
+        # Else, this parent node does *NOT* declare a new lexical scope. In this
+        # case...
+        else:
+            # Recursively visit all child nodes of this parent node *WITHOUT*.
+            # modifying the stack of all current lexical scopes.
+            super().generic_visit(node)
+
+        # Return this parent node as is.
+        return node
+
+    # ..................{ VISITORS ~ module                  }..................
+    def visit_Module(self, node: Module) -> Module:
+        '''
+        Add a new abstract syntax tree (AST) child node to the passed
+        **module node** (i.e., node encapsulating the module currently being
+        loaded by the
+        :class:`beartype.claw._importlib._clawimpload.BeartypeSourceFileLoader`)
+        importing various attributes required by lower-level child nodes added
+        by subsequent visitor methods defined by this transformer.
+
+        Parameters
+        ----------
+        node : Module
+            Module node to be transformed.
+
+        Returns
+        -------
+        Module
+            That same module node.
+        '''
+
+        # 0-based index of an early child node of this parent module node
+        # immediately *BEFORE* which to insert one or more statements importing
+        # beartype-specific attributes, defaulting to the first child node of
+        # this parent module. Specifically, if this module begins with:
+        # * Neither a module docstring *NOR* any "from __future__" imports, this
+        #   index is guaranteed to be 0.
+        # * Only a module docstring but *NO* "from __future__" imports, this
+        #   index is guaranteed to be 1.
+        # * A module docstring and one or more "from __future__" imports, this
+        #   index is guaranteed to be one more than the number of such imports.
+        node_index_import_beartype_attrs = 0
+
+        # 0-based index of the last child node of this parent module node.
+        node_index_last = len(node.body)
+
+        # Child node of this parent module node immediately preceding the output
+        # import child node to be added below, defaulting to this parent module
+        # node to ensure that the copy_node_metadata() function below *ALWAYS*
+        # copies from a valid node (for simplicity).
+        node_prev: AST = node
+
+        # For the 0-based index and value of each direct child node of this
+        # parent module node...
+        #
+        # This iteration efficiently finds "node_index_import_beartype_attrs"
+        # (i.e., the 0-based index of the first safe position in the list of all
+        # child nodes of this parent module node to insert an import statement
+        # importing our beartype decorator). Despite superficially appearing to
+        # perform a linear search of all n child nodes of this module parent
+        # node and thus exhibit worst-case O(n) time complexity, this iteration
+        # is guaranteed to exhibit worst-case O(1) time complexity. \o/
+        #
+        # Note that the "node.body" instance variable for module nodes is a list
+        # of *ALL* child nodes of this parent module node.
+        for node_prev in node.body:
+            # print(f'node_index_import_beartype_attrs [IN]: {node_index_import_beartype_attrs}')
+
+            # If it is *NOT* the case that this child node signifies either...
+            if not (
+                # A module docstring...
+                #
+                # If that module defines a docstring, that docstring *MUST* be
+                # the first expression of that module. That docstring *MUST* be
+                # explicitly found and iterated past to ensure that the import
+                # statement added below appears *AFTER* rather than *BEFORE* any
+                # docstring. (The latter would destroy the semantics of that
+                # docstring by reducing that docstring to an ignorable string.)
+                (
+                    isinstance(node_prev, Expr) and
+                    isinstance(node_prev.value, Constant)
+                ) or
+                # A future import (i.e., import of the form "from __future__
+                # ...") *OR*...
+                #
+                # If that module performs one or more future imports, these
+                # imports *MUST* necessarily be the first non-docstring
+                # statement of that module and thus appear *BEFORE* all import
+                # statements that are actually imports -- including the import
+                # statement added below.
+                (
+                    isinstance(node_prev, ImportFrom) and
+                    node_prev.module == '__future__'
+                )
+            # Then immediately halt iteration, guaranteeing O(1) runtime.
+            ):
+                break
+            # Else, this child node signifies either a module docstring of
+            # future import. In this case, implicitly skip past this child node
+            # to the next child node.
+
+            # Insert beartype-specific attributes immediately *AFTER* this node.
+            node_index_import_beartype_attrs += 1
+        # "node_index_import_beartype_attrs" is now the index of the first safe
+        # position in this list to insert output child import nodes below.
+        # print(f'node_index_import_beartype_attrs [AFTER]: {node_index_import_beartype_attrs}')
+        # print(f'len(node.body): {len(node.body)}')
+
+        # If the 0-based index of an early child node of this parent module node
+        # immediately *BEFORE* which to insert one or more statements importing
+        # beartype-specific attributes is *NOT* that of the last child node of
+        # this parent module node, this module contains one or more semantically
+        # meaningful child nodes and is thus non-empty. In this case...
+        if node_index_import_beartype_attrs != node_index_last:
+            # print('Injecting beartype imports...')
+
+            # Module-scoped import nodes (i.e., child nodes to be inserted under
+            # the parent node encapsulating the currently visited submodule in
+            # the AST for that module).
+            #
+            # Note that:
+            # * The original attributes are imported into the currently visited
+            #   submodule under obfuscated beartype-specific names,
+            #   significantly reducing the likelihood of a namespace collision
+            #   with existing attributes of the same name in that submodule.
+            # * These nodes are intentionally *NOT* generalized into global
+            #   constants. In theory, doing so would reduce space and time
+            #   complexity by enabling efficient reuse here. In practice, doing
+            #   so would also be fundamentally wrong; these nodes are
+            #   subsequently modified to respect the source code metadata (e.g.,
+            #   line numbers) of this AST module parent node, which prevents
+            #   such trivial reuse. Although we could further attempt to
+            #   circumvent that by shallowly or deeply copying from global
+            #   constants, both the copy() and deepcopy() functions defined by
+            #   the standard "copy" module are pure-Python and thus shockingly
+            #   slow -- which defeats the purpose.
+
+            # Node importing all beartype-specific attributes explicitly
+            # imported and implicitly exported by our private
+            # "beartype.claw._ast.clawaststar" submodule, comprising the set of
+            # all attributes required by code dynamically injected into this AST
+            # by this AST transformer.
+            node_import_all = make_node_importfrom(
+                module_name='beartype.claw._ast._clawaststar',
+                source_attr_name='*',
+                node_sibling=node_prev,
+            )
+
+            # Insert these output child import nodes at this safe position of
+            # the list of all child nodes of this parent module node.
+            #
+            # Note that this syntax efficiently (albeit unreadably) inserts
+            # these output child import nodes at the desired index (in this
+            # arbitrary order) of this parent module node.
+            node.body[node_index_import_beartype_attrs:0] = (node_import_all,)
+        # Else, the 0-based index of an early child node of this parent module
+        # node immediately *BEFORE* which to insert one or more statements
+        # importing beartype-specific attributes is that of the last child node
+        # of this parent module node. In this case, this module contains *NO*
+        # semantically meaningful child nodes and is thus effectively empty.
+        # In this case, silently reduce to a noop. This edge case is *EXTREMELY*
+        # uncommon and thus *NOT* optimized for (either here or elsewhere).
+        #
+        # Note that this edge cases cleanly matches:
+        # * Syntactically empty modules containing only zero or more whitespace
+        #   characters and zero or more inline comments.
+        # * Syntactically non-empty modules containing only a prefacing module
+        #   docstring and/or one or more "from __future__" import statements.
+        #   Semantically, these sorts of modules are effectively empty as well.
+
+        # Recursively transform *ALL* child nodes of this parent module node.
+        node = self.generic_visit(node)
+
+        # #FIXME: Conditionally perform this logic if "conf.is_debug", please.
+        # print(
+        #     f'Module abstract syntax tree (AST) transformed by @beartype to:\n\n'
+        #     f'{get_node_repr_indented(node)}'
+        # )
+
+        # Return this transformed module node.
+        return node
+
+    # ..................{ VISITORS ~ class                   }..................
+    #FIXME: Implement us up, please.
+    def visit_ClassDef(self, node: ClassDef) -> Optional[ClassDef]:
+        '''
+        Add a new child node to the passed **class node** (i.e., node
+        encapsulating the definition of a pure-Python class) unconditionally
+        decorating that class by our private
+        :func:`beartype._decor.decorcore.beartype_object_nonfatal` decorator.
+
+        Parameters
+        ----------
+        node : ClassDef
+            Class node to be transformed.
+
+        Returns
+        -------
+        Optional[ClassDef]
+            This same class node.
+        '''
+
+        # Add a new child decoration node to this parent class node decorating
+        # this class by @beartype under this configuration.
+        self._decorate_node_beartype(node=node, conf=self._conf_beartype)
+
+        # Recursively transform *ALL* child nodes of this parent class node.
+        # Note that doing so implicitly calls the visit_FunctionDef() method
+        # (defined below), each of which then effectively reduces to a noop.
+        return self.generic_visit(node)
+
+    # ..................{ VISITORS ~ callable                }..................
+    def visit_FunctionDef(self, node: NodeCallable) -> Optional[NodeCallable]:
+        '''
+        Add a new child node to the passed **callable node** (i.e., node
+        encapsulating the definition of a pure-Python function or method)
+        decorating that callable by our private
+        :func:`beartype._decor.decorcore.beartype_object_nonfatal` decorator if
+        and only if that callable is **typed** (i.e., annotated by a return type
+        hint and/or one or more parameter type hints).
+
+        Parameters
+        ----------
+        node : NodeCallable
+            Callable node to be transformed.
+
+        Returns
+        -------
+        Optional[NodeCallable]
+            This same callable node.
+        '''
+
+        # If...
+        if (
+            # * This callable node has one or more parent nodes previously
+            #   visited by this node transformer *AND* the immediate parent node
+            #   of this callable node is a class node, then this callable node
+            #   encapsulates a method rather than a function. In this case, the
+            #   visit_ClassDef() method defined above has already explicitly
+            #   decorated the class defining this method by the @beartype
+            #   decorator, which then implicitly decorates both this and all
+            #   other methods of that class by that decorator. For safety and
+            #   efficiency, avoid needlessly re-decorating this method by the
+            #   same decorator by preserving and returning this node as is.
+            # * That is *NOT* the case, then this callable node is either the
+            #   root node of the current AST *OR* has a parent node that is not
+            #   a class node. In either case, this callable node necessarily
+            #   encapsulates a function (rather than a method), which yet to be
+            #   decorated. Do so now! So say we all.
+            #
+            # This logic corresponds to the above "That is *NOT* the case" case
+            # (i.e., this callable node necessarily encapsulates a function).
+            # Look. Just accept that we have a tenuous grasp on reality at best.
+            not self._is_scope_class_beartype and
+            # ...and the currently visited callable is annotated by one or more
+            # type hints and thus *NOT* ignorable with respect to beartype
+            # decoration...
+            is_node_callable_typed(node)
+        ):
+            # Add a new child decoration node to this parent callable node
+            # decorating this callable by @beartype under this configuration.
+            self._decorate_node_beartype(node=node, conf=self._conf_beartype)
+        # Else, that callable is ignorable. In this case, avoid needlessly
+        # decorating that callable by @beartype for efficiency.
+
+        # Recursively transform *ALL* child nodes of this parent callable node.
+        return self.generic_visit(node)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_ast/pep/clawastpep526.py
@@ -0,0 +1,373 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype :pep:`526`-compliant **abstract syntax tree (AST) transformers** (i.e.,
+low-level classes instrumenting :pep:`526`-compliant annotated variable
+assignments in well-typed third-party modules with runtime type-checking
+dynamically generated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    AST,
+    AnnAssign,
+    Attribute,
+    Name,
+)
+from beartype.claw._clawmagic import BEARTYPE_RAISER_FUNC_NAME
+from beartype._data.hint.datahinttyping import NodeVisitResult
+from beartype._conf.confcls import BEARTYPE_CONF_DEFAULT
+from beartype._util.ast.utilastmake import (
+    make_node_call_expr,
+    make_node_kwarg,
+    make_node_name_load,
+    make_node_object_attr_load,
+    make_node_str,
+)
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+from beartype._util.text.utiltextansi import color_attr_name
+
+# ....................{ SUBCLASSES                         }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To improve forward compatibility with the superclass API over which
+# we have *NO* control, avoid accidental conflicts by suffixing *ALL* private
+# and public attributes of this subclass by "_beartype".
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+class BeartypeNodeTransformerPep526Mixin(object):
+    '''
+    Beartype :pep:`526`-compliant **abstract syntax tree (AST) node
+    transformer** (i.e., visitor pattern recursively transforming *all*
+    :pep:`526`-compliant annotated variable assignments in the AST tree passed
+    to the :meth:`visit` method of the
+    :class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass
+    also subclassing this mixin).
+    '''
+
+    # ..................{ VISITORS ~ pep : 526               }..................
+    def visit_AnnAssign(self, node: AnnAssign) -> NodeVisitResult:
+        '''
+        Add a new child node to the passed **annotated assignment node** (i.e.,
+        node signifying the assignment of an attribute annotated by a
+        :pep:`526`-compliant type hint) inserting a subsequent statement
+        following that annotated assignment type-checking that attribute against
+        that type hint by passing both to our :func:`beartype.door.is_bearable`
+        tester.
+
+        Note that the :class:`.AnnAssign` subclass defines these instance
+        variables:
+
+        * ``node.annotation``, a child node describing the PEP-compliant type
+          hint annotating this assignment, typically an instance of either:
+
+          * :class:`ast.Name`.
+          * :class:`ast.Constant`.
+
+          Note that this node is *not* itself a valid PEP-compliant type hint
+          and should *not* be treated as such here or elsewhere.
+        * ``node.target``, a child node describing the target attribute assigned
+          to by this assignment, guaranteed to be an instance of either:
+
+          * :class:`ast.Name`, in which case this is a **simple assignment**
+            (i.e., to a local or global variable). This is the common case in
+            which the attribute being assigned to is *NOT* embedded in
+            parentheses and thus denotes a simple attribute name rather than a
+            full-blown Python expression.
+          * :class:`ast.Attribute`, in which case this is an **object
+            assignment** (i.e., to an instance or class variable of an object).
+          * :class:`ast.Subscript`, in which case this assignment is to the item
+            subscripted by an index of a container rather than to that container
+            itself.
+
+        * ``node.simple``, an integer :superscript:`sigh` that is either:
+
+          * If ``node.target`` is an :class:`ast.Name` node, 1.
+          * Else, 0.
+
+        * ``node.value``, an optional child node defined as either:
+
+          * If this attribute is actually assigned to, a node encapsulating
+            the new value assigned to this target attribute.
+          * Else, :data:`None`.
+
+          You may now be thinking to yourself as you wear a bear hat while
+          rummaging through this filthy code: "What do you mean, 'if this
+          attribute is actually assigned to'? Isn't this attribute necessarily
+          assigned to? Isn't that what the 'AnnAssign' subclass means? I mean,
+          it's right there in the bloody subclass name: 'AnnAssign', right?
+          Clearly, *SOMETHING* is bloody well being assigned to. Right?"
+          Wrong. The name of the :class:`.AnnAssign` subclass was poorly chosen.
+          That subclass ambiguously encapsulates both:
+
+          * Annotated variable assignments (e.g., ``muh_attr: int = 42``).
+          * Annotated variables *without* assignments (e.g., ``muh_attr: int``).
+
+        Parameters
+        ----------
+        node : AnnAssign
+            Annotated assignment node to be transformed.
+
+        Returns
+        -------
+        NodeVisitResult
+            Either:
+
+            * If this annotated assignment node is *not* **simple** (i.e., the
+              attribute being assigned to is embedded in parentheses and thus
+              denotes a full-blown Python expression rather than a simple
+              attribute name), that same parent node unmodified.
+            * If this annotated assignment node is *not* **assigned** (i.e., the
+              attribute in question is simply annotated with a type hint rather
+              than both annotated with a type hint *and* assigned to), that same
+              parent node unmodified.
+            * Else, a 2-list comprising both that node and a new adjacent
+              :class:`Call` node performing this type-check.
+
+        See Also
+        --------
+        https://github.com/awf/awfutils
+            Third-party Python package whose ``@awfutils.typecheck`` decorator
+            implements statement-level :func:`isinstance`-based type-checking in
+            a similar manner, strongly inspiring this implementation. Thanks so
+            much to Cambridge researcher @awf (Andrew Fitzgibbon) for the
+            phenomenal inspiration!
+        '''
+
+        # Recursively transform *ALL* child nodes of this parent callable node.
+        self.generic_visit(node)  # type: ignore[attr-defined]
+
+        # If either...
+        if (
+            # It is *NOT* the case that...
+            not (
+                # This beartype configuration enables type-checking of PEP
+                # 526-compliant annotated variable assignments *AND*...
+                self._conf_beartype.claw_is_pep526 and  # type: ignore[attr-defined]
+                # This statement is an assignment (e.g., "muh_var: int = 2")
+                # rather than just an unassigned annotation of an attribute
+                # (e.g., "muh_var: int").
+                node.value
+            # Then either this beartype configuration disables type-checking of
+            # PEP 526-compliant annotated variable assignments *OR* this
+            # statement is just an unassigned annotation of an attribute *OR*...
+            ) or
+            # This assignment node has one or more parent nodes previously
+            # visited by this node transformer *AND* the immediate parent node
+            # of this assignment node is a class node, then this assignment node
+            # encapsulates a PEP 681-compliant annotated field declaration
+            # rather than an PEP 526-compliant annotated variable assignment. In
+            # this case, the visit_ClassDef() method defined above has already
+            # explicitly decorated the class declaring this annotated field by
+            # the @beartype decorator, which then implicitly decorates both this
+            # and all other fields of that class by that decorator. For safety
+            # and efficiency, avoid needlessly re-decorating this field by the
+            # same decorator by simply preserving and returning this node as is.
+            #
+            # Note, however, that this is *NOT* simply an efficiency concern.
+            # This is a significant semantic concern. While a subset of PEP
+            # 681-compliant annotated field declarations *ARE* amenable to
+            # type-checking by our die_if_unbearable(), still others are
+            # absolutely *NOT* amenable to such type-checking. Indeed, in both
+            # the average and the worst case, PEP 681-compliant annotated field
+            # declarations both supersede and violate PEP 484 typing semantics.
+            # Since PEP 681 assumes supremacy over PEP 484 here, @beartype has
+            # little to say and much to ignore: e.g.,
+            #
+            #     from dataclasses import dataclass, field
+            #
+            #     @dataclass
+            #     class MuhDataclass(object):
+            #         # This annotated field declaration is safely
+            #         # type-checkable by die_if_unbearable(), clearly.
+            #         muh_safe_field: int = 0xBABECAFE
+            #
+            #         # This annotated field declaration is *NOT* safely
+            #         # type-checkable by die_if_unbearable(). Clearly, a
+            #         # dataclass "field" instance is *NOT* a valid integer and
+            #         # thus violates the type hint annotating this field. Since
+            #         # PEP 681 standardizes declarations like this as
+            #         # semantically valid, @beartype has *NO* alternative but
+            #         # to quietly turn a blind eye to what otherwise might be
+            #         # considered a type violation.
+            #         muh_unsafe_field: int = field(default=0xCAFEBABE)
+            self._is_scope_class_beartype  # type: ignore[attr-defined]
+        ):
+            # Then simply preserve and return this node as is.
+            return node
+        # Else:
+        # * This beartype configuration enables type-checking of PEP
+        #   526-compliant annotated variable assignments.
+        # * This assignment is simple and assigning to an attribute name.
+
+        # Human-readable label prefixing the exception message raised by our
+        # die_if_unbearable() type-checker called below when the value assigned
+        # to this variable violates the type hint annotating this variable. For
+        # efficiency, we precompute this label at import hook time.
+        exception_prefix: str = None  # type: ignore[assignment]
+
+        # Unqualified basename of this variable in the current lexical scope.
+        var_basename: str = None  # type: ignore[assignment]
+
+        # Child node passing the value newly assigned to this attribute by this
+        # assignment as the first parameter to die_if_unbearable().
+        node_func_arg_pith: AST = None  # type: ignore[assignment]
+
+        # Child node referencing the target variable being assigned to,
+        # localized purely as a negligible optimization.
+        node_target = node.target
+
+        # If this target variable is a simple local or global variable...
+        if isinstance(node_target, Name):
+            # Unqualified basename of this variable in this lexical scope.
+            var_basename = node_target.id
+
+            # Child node accessing this local or global variable.
+            node_func_arg_pith = make_node_name_load(
+                name=var_basename, node_sibling=node)
+        # Else, this target variable is *NOT* a simple local or global variable.
+        #
+        # If this target variable is an instance or class variable...
+        elif isinstance(node_target, Attribute):
+            #FIXME: Insufficient. Attributes can contain arbitrary nested child
+            #nodes, including other attributes and/or names. Thankfully, the
+            #only reason to even bother attempting to do this is to rigorously
+            #sanitize line and column numbers -- which doesn't appear to be
+            #particularly necessary or even desirable for dynamically generated
+            #code. For now, we simply shallowly reuse the existing "value" node.
+            # # Child node referencing the object containing this instance or
+            # # class variable (e.g., the "self" in "self.attr: str = 'Attr!'").
+            # node_func_arg_pith_obj = Name(
+            #     node_target.value.id, ctx=NODE_CONTEXT_LOAD)
+            # copy_node_metadata(node_src=node, node_trg=node_func_arg_pith_obj)
+
+            # Child node referencing this instance or class variable.
+            node_func_arg_pith = make_node_object_attr_load(
+                node_obj=node_target.value,
+                attr_name=node_target.attr,
+                node_sibling=node,
+            )
+
+            # If the Python interpreter targets Python >= 3.9, the standard
+            # "ast" module provides the unparse() function "unparsing" (i.e.,
+            # obtaining the machine-readable representations of) arbitrary
+            # nodes. In this case...
+            if IS_PYTHON_AT_LEAST_3_9:
+                # Defer version-specific imports.
+                from ast import unparse  # type: ignore[attr-defined]
+
+                # Unqualified basename of this variable in this lexical scope,
+                # defined by "unparsing" this child node.
+                #
+                # Note that the parent object of this attribute is described by
+                # the external node "node_target.value", encapsulating an
+                # arbitrarily complex Python expression. "Unparsing" this
+                # expression manually is *ABSOLUTELY* infeasible.
+                var_basename = unparse(node_target.value)
+            # Else, the Python interpreter targets Python 3.8. In this case,
+            # "ast" fails to provides the unparse() function. Therefore...
+            else:
+                # Unqualified basename of this variable in this lexical scope,
+                # defined by trivially ignoring the arbitrarily complex Python
+                # expression providing the parent object of this attribute.
+                var_basename = node_target.attr
+        # Else, this target variable is *NOT* an instance or class variable. In
+        # this case, this target variable is currently unsupported by this node
+        # transformer for automated type-checking. Simply preserve and return
+        # this node as is.
+        #
+        # Examples include:
+        # * "ast.Subscripted", in which case this target variable is an item of
+        #   a container. It is unclear whether PEP 526 even supports annotated
+        #   variable assignments of container items *OR* whether any @beartype
+        #   users even annotate variable assignments of container items. Ergo,
+        #   this node transformer currently ignores this odd edge case.
+        else:
+            return node
+
+        # List of all nodes encapsulating keyword arguments passed to
+        # die_if_unbearable(), defaulting to the empty list and thus *NO* such
+        # keyword arguments.
+        node_func_kwargs = []
+
+        # If the current beartype configuration is *NOT* the default beartype
+        # configuration, this configuration is a user-defined beartype
+        # configuration which *MUST* be passed as well. In this case...
+        if self._conf_beartype != BEARTYPE_CONF_DEFAULT:  # type: ignore[attr-defined]
+            # Child node encapsulating the passing of this configuration as the
+            # "conf" keyword argument to die_if_unbearable().
+            node_func_kwarg_conf = self._make_node_keyword_conf_beartype(  # type: ignore[attr-defined]
+                node_sibling=node)
+
+            # Append this node to the list of all keyword arguments passed to
+            # die_if_unbearable().
+            node_func_kwargs.append(node_func_kwarg_conf)
+        # Else, this configuration is simply the default beartype configuration.
+        # In this case, avoid passing that configuration to the beartype
+        # decorator for both efficiency and simplicity.
+
+        # If the lexical scope of this parent node is module scope, this node
+        # encapsulates a global variable assignment. In this case...
+        if self._is_scope_module_beartype:  # type: ignore[attr-defined]
+            # Fully-qualified name of this global variable.
+            var_name = f'{self._module_name_beartype}.{var_basename}'  # type: ignore[attr-defined]
+
+            # Human-readable label prefixing this exception message.
+            exception_prefix = f'Global variable "{color_attr_name(var_name)}" '
+        # Else, the lexical scope of this parent node is *NOT* module scope.
+        # However, by above, this scope is also *NOT* class scope. By
+        # elimination, this scope *MUST* thus be a callable scope. In this
+        # case...
+        else:
+            # Fully-qualified name of the callable defining this local variable.
+            callable_name = f'{self._scope_name_beartype}()'  # type: ignore[attr-defined]
+
+            # Human-readable label prefixing this exception message.
+            exception_prefix = (
+                f'Callable {color_attr_name(callable_name)} '
+                f'local variable "{color_attr_name(var_basename)}" '
+            )
+        # print(f'PEP 526 exception_prefix: {exception_prefix}')
+
+        # Child node encapsulating this label as a string literal.
+        node_exception_prefix = make_node_str(
+            text=exception_prefix, node_sibling=node)
+
+        # Child node encapsulating the passing of this exception prefix as the
+        # "exception_prefix" keyword argument to die_if_unbearable().
+        node_func_kwarg_exception_prefix = make_node_kwarg(
+            kwarg_name='exception_prefix',
+            kwarg_value=node_exception_prefix,
+            node_sibling=node,
+        )
+
+        # Append this node to the list of all keyword arguments passed to
+        # die_if_unbearable().
+        node_func_kwargs.append(node_func_kwarg_exception_prefix)
+
+        # Child node type-checking this newly assigned attribute against the
+        # type hint annotating this assignment via our die_if_unbearable()
+        # type-checker.
+        node_func = make_node_call_expr(
+            func_name=BEARTYPE_RAISER_FUNC_NAME,
+            nodes_args=[
+                # Child node passing the value newly assigned to this
+                # attribute by this assignment as the first parameter.
+                node_func_arg_pith,
+                # Child node passing the type hint annotating this assignment as
+                # the second parameter.
+                node.annotation,
+            ],
+            nodes_kwargs=node_func_kwargs,
+            node_sibling=node,
+        )
+
+        # Return a list comprising these two adjacent nodes.
+        #
+        # Note that order is *EXTREMELY* significant. This order ensures that
+        # this attribute is type-checked after being assigned to, as expected.
+        return [node, node_func]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_ast/pep/clawastpep695.py
@@ -0,0 +1,324 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype :pep:`695`-compliant **abstract syntax tree (AST) transformers** (i.e.,
+low-level classes instrumenting :pep:`695`-compliant ``type`` alias statements
+in well-typed third-party modules with runtime type-checking dynamically
+generated by the :func:`beartype.beartype` decorator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: CPython's current implementation of PEP 695 type aliases is
+#fundamentally broken with respect to unquoted relative forward references.
+#Please submit an upstream issue describing this patent failure. On doing so,
+#please also publicly declare that PEP 695 appears to have been poorly tested.
+#As evidence, note that PEP 695 itself advises use of the following idiom:
+#    # A type alias that includes a forward reference
+#    type AnimalOrVegetable = Animal | "Vegetable"
+#
+#*THAT DOES NOT ACTUALLY WORK AT RUNTIME.* Nobody tested that. This is why I
+#facepalm. Notably, PEP 604-compliant new-style unions prohibit strings. They
+#probably shouldn't, but they've *ALWAYS* behaved that way, and nobody's updated
+#them to behave more intelligently -- probably because doing so would require
+#updating the isinstance() builtin (which also accepts PEP 604-compliant
+#new-style unions) to behave more intelligently and ain't nobody goin' there:
+#    $ python3.12
+#    >>> type AnimalOrVegetable = "Animal" | "Vegetable"
+#    >>> AnimalOrVegetable.__value__
+#    Traceback (most recent call last):
+#      Cell In[3], line 1
+#        AnimalOrVegetable.__value__
+#      Cell In[2], line 1 in AnimalOrVegetable
+#        type AnimalOrVegetable = "Animal" | "Vegetable"
+#    TypeError: unsupported operand type(s) for |: 'str' and 'str'
+#
+#However, even ignoring that obvious syntactic issue, PEP 695 still fails to
+#actually support forward references -- because exceptions are *NOT* forward
+#references. Forward references are proxy objects that refer to other objects
+#that have yet to be defined at runtime. Notably:
+#    $ python3.12
+#    # This is a forward reference.
+#    >>> type VegetableRef = 'Vegetable'
+#    >>> VegetableRef.__value__
+#    'Vegetable'
+#
+#    # So is this.
+#    >>> from typing import ForwardRef
+#    >>> type FruityRef = ForwardRef('Fruit')
+#    >>> FruityRef.__value__
+#    ForwardRef('Fruit')
+#
+#    # This is *NOT* a forward reference.
+#    >>> type AnimalOrAnimals = Animal
+#    >>> AnimalOrAnimals.__value__
+#    Traceback (most recent call last):
+#      Cell In[2], line 1
+#        AnimalRef.__value__
+#      Cell In[1], line 1 in AnimalRef
+#        type AnimalRef = Animal
+#    NameError: name 'Animal' is not defined
+#
+#*FACEPALM*
+#FIXME: *BIG YIKES.* CPython's low-level C-based implementation of PEP
+#695-compliant type aliases currently fails to properly resolve unquoted
+#relative forward references defined in a local rather than global scope. I
+#tried literally everything to get this to work via AST transformations -- but
+#whatever arcane type alias machinery it is that they've implemented simply does
+#*NOT* behave as expected at local scope. That said, we've verified this
+#*SHOULD* work via this simple snippet:
+#    def foo():
+#        type bar = wut
+#        globals()['wut'] = str
+#        print(bar.__value__)
+#    foo()
+#
+#That behaves as expected -- until you actually then define the expected class
+#at local scope:
+#    def foo():
+#        type bar = wut
+#        globals()['wut'] = str
+#        print(bar.__value__)
+#        class wut(object): pass  # <-- this causes madness; WTF!?!?!?
+#
+#The above print() statement now raises non-human readable exceptions
+#resembling:
+#    NameError: cannot access free variable 'wut' where it is not associated
+#    with a value in enclosing scope
+#
+#Clearly, this is madness. At the point at which the print() statement is run,
+#the "wut" class has yet to be redefined as a class. This constitutes a profound
+#CPython bug. Please submit us up the F-F-F-bomb.
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    AST,
+    Assign,
+    # Constant,
+    For,
+    # JoinedStr,
+    Subscript,
+)
+from beartype.claw._clawmagic import (
+    BEARTYPE_HINT_PEP695_FORWARDREF_ITER_FUNC_NAME)
+from beartype._data.hint.datahinttyping import NodeVisitResult
+from beartype._data.ast.dataast import NODE_CONTEXT_STORE
+from beartype._util.ast.utilastmunge import copy_node_metadata
+from beartype._util.ast.utilastmake import (
+    make_node_object_attr_load,
+    make_node_call,
+    # make_node_call_expr,
+    # make_node_fstr_field,
+    make_node_name_load,
+    make_node_name_store,
+)
+
+# ....................{ SUBCLASSES                         }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To improve forward compatibility with the superclass API over which
+# we have *NO* control, avoid accidental conflicts by suffixing *ALL* private
+# and public attributes of this subclass by "_beartype".
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+class BeartypeNodeTransformerPep695Mixin(object):
+    '''
+    Beartype :pep:`695`-compliant **abstract syntax tree (AST) node
+    transformer** (i.e., visitor pattern recursively transforming *all*
+    :pep:`695`-compliant ``type`` alias statements in the AST tree passed to the
+    :meth:`visit` method of the
+    :class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass
+    also subclassing this mixin).
+    '''
+
+    # ..................{ VISITORS ~ pep : 695               }..................
+    def visit_TypeAlias(self, node: 'ast.TypeAlias') -> NodeVisitResult:  # type: ignore[name-defined]
+        '''
+        Add new sibling nodes following the passed **type alias statement**
+        (i.e., node signifying the definition of a :pep:`695`-compliant ``type``
+        alias) iteratively defining one **forward reference proxy** (i.e.,
+        :class:`beartype._check.forward.reference.fwdrefabc.BeartypeForwardRefABC`
+        subclass) for each unquoted relative forward reference in this
+        statement.
+
+        Doing so is required, as :pep:`695` fails to actually support unquoted
+        relative forward references despite publicly claiming to do so. Notably,
+        :pep:`695`-compliant type aliases raise non-human-readable
+        :exc:`NameError` and :exc:`UnboundLocalError` exceptions when attempting
+        to resolve type aliases containing one or more unquoted relative forward
+        references. Clearly, exceptions are *not* valid forward references.
+        Forward references are proxy objects that refer to other objects that
+        have yet to be defined at runtime. Notably, this is very awful:
+
+        .. code-block:: pycon
+
+        >>> type AnimalOrAnimals = Animal | list[Animal]
+        >>> AnimalOrAnimals.__value__
+        Traceback (most recent call last):
+          Cell In[2], line 1
+            AnimalOrAnimals.__value__
+          Cell In[1], line 1 in AnimalOrAnimals
+            type AnimalOrAnimals = Animal | list[Animal]
+        NameError: name 'Animal' is not defined
+
+        Circumventing this patent oversight on the part of both Guido and PEP
+        695 authors requires transforming this AST to inject new sibling nodes
+        encapsulating each unquoted relative forward reference in this alias
+        with a new forward reference proxy and then redefining this alias to
+        forcefully uncache this alias.
+
+        Parameters
+        ----------
+        node : TypeAlias
+            Type alias to be transformed.
+
+        Returns
+        -------
+        NodeVisitResult
+            A list comprising (in order):
+
+            #. This type alias node as is.
+            #. New sibling nodes encapsulating each unquoted relative forward
+               reference in this alias with a new forward reference proxy.
+            #. This type alias node recapitulated to undo any prior caching of
+               this type alias.
+        '''
+
+        # Recursively transform *ALL* child nodes of this type alias node.
+        self.generic_visit(node)  # type: ignore[attr-defined]
+
+        # If this type alias is declared at module scope, generate efficient
+        # code permissible *ONLY* at module scope for optimally iteratively
+        # defining one forward reference proxy for each unquoted relative
+        # forward reference in this type alias. Notably, generate this:
+        #     for _ in __iter_hint_pep695_forwardref_beartype__({alias_name}):
+        #         globals()[_.__name_beartype__] = _
+        #
+        # Else, this type alias is *NOT* declared at module scope and is thus
+        # declared at a lower scope (e.g., class, callable). In this case,
+        # fallback to generating inefficient code globally permissible at all
+        # possible scopes. Notably, generate this:
+        #     for _ in __iter_hint_pep695_forwardref_beartype__({alias_name}):
+        #         exec(f'{_.__name_beartype__} = _')
+
+        # Child nodes both accessing and assigning this type alias as a global
+        # or local variable.
+        node_alias_var_name_load = make_node_name_load(
+            name=node.name.id, node_sibling=node)
+        # node_alias_var_name_store = make_node_name_store(
+        #     name=node.name.id, node_sibling=node)
+
+        # Child nodes both accessing and assigning the standard "_" scratch
+        # (i.e., placeholder) local variable.
+        node_scratch_var_name_load = make_node_name_load(
+            name='_', node_sibling=node)
+        node_scratch_var_name_store = make_node_name_store(
+            name='_', node_sibling=node)
+
+        # Child node accessing the unqualified basename of the current forward
+        # reference proxy to be defined in the current lexical scope via the
+        # "BeartypeForwardRefABC.__name_beartype__" class variable of this
+        # proxy, which is currently stored in the "_" scratch local variable.
+        # Notably, "_" is a subclass of the "BeartypeForwardRefABC" superclass.
+        node_forwardref_name_load = make_node_object_attr_load(
+            node_obj=node_scratch_var_name_load,
+            attr_name='__name_beartype__',
+            node_sibling=node,
+        )
+
+        # Child node passing this iterator this type alias, which then returns a
+        # C-based generator object via the standard Python idiom for
+        # "yield"-specific generators.
+        node_forwardref_iter_call = make_node_call(
+            func_name=BEARTYPE_HINT_PEP695_FORWARDREF_ITER_FUNC_NAME,
+            nodes_args=[node_alias_var_name_load],
+            node_sibling=node,
+        )
+
+        # Child node defining a new global or local variable whose:
+        # * Name is the unqualified basename of the undefined attribute referred
+        #   to by the currently iterated forward reference proxy.
+        # * Value is that proxy.
+        node_forwardref_define: AST = None  # type: ignore[assignment]
+
+        # Child node subscripting the...
+        node_forwardref_global_store = Subscript(
+            # Dictionary of all currently defined global variables returned by a
+            # call to the builtin globals() function. Thankfully, this
+            # dictionary is efficiently modifiable and behaves in the typical
+            # way when directly modified.
+            #
+            # Note that the same *CANNOT* be said for the builtin locals()
+            # function, whose behaviour is effectively non-deterministic. Ergo,
+            # the inefficient fallback approach adopted below.
+            value=make_node_call(func_name='globals', node_sibling=node),
+            # Assign the key of the returned dictionary whose name is given by
+            # the "BeartypeForwardRefABC.__name_beartype__" class variable of
+            # this proxy, stored in the scratch variable.
+            slice=node_forwardref_name_load,
+            ctx=NODE_CONTEXT_STORE,
+        )
+
+        # Child node efficiently defining this proxy as a new global,
+        # implemented as an assignment to...
+        node_forwardref_define = Assign(
+            # The global variable whose name is the unqualified basename of the
+            # undefined attribute referred to by the currently iterated forward
+            # reference proxy.
+            targets=[node_forwardref_global_store],
+            # Assigned the value of the scratch variable, which is a subclass of
+            # the "BeartypeForwardRefABC" superclass.
+            value=node_scratch_var_name_load,
+        )
+
+        # Child node iterating over all forward reference proxies generated by
+        # this iterator and, for each such proxy:
+        # * Locally assigning that proxy to the standard "_" scratch (i.e.,
+        #   placeholder) local variable.
+        # * Defining a new global or local variable whose:
+        #   * Name is the unqualified basename of the undefined attribute
+        #     referred to by that proxy.
+        #   * Value is that proxy.
+        node_forwardrefs_define = For(
+            target=node_scratch_var_name_store,
+            iter=node_forwardref_iter_call,
+            body=[node_forwardref_define],
+        )
+
+        # Copy all source code metadata from this type alias node onto *ALL*
+        # sibling nodes created above.
+        copy_node_metadata(node_src=node, node_trg=(
+            node_forwardref_global_store,
+            node_forwardref_define,
+            node_forwardrefs_define,
+        ))
+
+        # Return a list comprising these adjacent nodes.
+        #
+        # Note that order is *EXTREMELY* significant.
+        return [
+            # Initial definition of this type alias preserved as is.
+            node,
+            # For loop iteratively defining one forward reference proxy global
+            # or local variable for each undefined attribute in this type alias.
+            node_forwardrefs_define,
+            # Intentionally redefine this alias. Although this appears to be an
+            # inefficient noop, this is in fact an essential operation. Why?
+            # Because the prior successful access of the "__value__" dunder
+            # variable of this type alias in the iter_hint_pep695_forwardrefs()
+            # iterator called above silently cached and thus froze the value of
+            # this alias. However, alias values are *NOT* necessarily safely
+            # freezable at alias definition time. A canonical example of alias
+            # values that are *NOT* safely freezable at alias definition time
+            # is mutually recursive aliases (i.e., aliases whose values
+            # circularly refer to one another): e.g.,
+            #     type a = b
+            #     type b = a
+            #
+            # PEP 695 provides no explicit means of uncaching alias values. Our
+            # only recourse is to repetitiously redefine this alias. It sucks.
+            node,
+        ]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_clawmagic.py
@@ -0,0 +1,117 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **magic** (i.e., global constants widely leveraged throughout
+submodules of the :mod:`beartype.claw` subpackage).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import (
+    Load,
+    Store,
+)
+from beartype.meta import (
+    NAME,
+    VERSION,
+)
+
+# ....................{ AST                                }....................
+NODE_CONTEXT_LOAD = Load()
+'''
+**Node context load singleton** (i.e., object suitable for passing as the
+``ctx`` keyword parameter accepted by the ``__init__()`` method of various
+abstract syntax tree (AST) node classes).
+'''
+
+
+NODE_CONTEXT_STORE = Store()
+'''
+**Node context store singleton** (i.e., object suitable for passing as the
+``ctx`` keyword parameter accepted by the ``__init__()`` method of various
+abstract syntax tree (AST) node classes).
+'''
+
+# ....................{ STRINGS                            }....................
+BEARTYPE_OPTIMIZATION_MARKER = f'{NAME}{VERSION.replace(".", "v")}'
+'''
+**Beartype optimization marker** (i.e., placeholder substring suffixing the
+``optimization`` parameter passed to the magical hidden
+:func:`importlib._bootstrap_external.cache_from_source` function with metadata
+unique to the currently installed package name and version of :mod:`beartype`).
+
+This marker uniquifies the filename of bytecode files compiled under beartype
+import hooks to the abstract syntax tree (AST) transformation applied by this
+version of :mod:`beartype`. Why? Because external callers can trivially enable
+and disable that transformation for any module by either calling or not calling
+beartype import hooks that accept package name arguments (e.g.,
+:func:`beartype.claw.beartype_package`) with the name of a package transitively
+containing that module. Compiling a beartyped variant of that module to the same
+bytecode file as the non-beartyped variant of that module would erroneously
+persist beartyping to that module -- even *after* removing the relevant call to
+the :func:`beartype.claw.beartype_package` function! Clearly, that's awful.
+Enter @agronholm's phenomenal patch, stage left.
+
+Caveats
+-------
+**Python requires all optimization markers to be alphanumeric strings.** If this
+or *any* other optimization marker contains a non-alphanumeric character, Python
+raises a fatal exception resembling:
+
+    ValueError: '-beartype-0.14.2' is not alphanumeric
+
+Ergo, this string globally replaces *all* non-alphanumeric characters that are
+otherwise commonly present in the version specifier for this version of
+:mod:`beartype` by the arbitrary character ``"v`"" (which is *not* present in
+the name of this package and thus suitable as a machine-readable delimiter).
+'''
+
+# ....................{ STRINGS ~ names                    }....................
+BEARTYPE_DECORATOR_FUNC_NAME = '__beartype__'
+'''
+Unqualified basename of the beartype decorator as imported into the current
+user-defined module being imported and thus transformed by the
+:class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass.
+'''
+
+BEARTYPE_RAISER_FUNC_NAME = '__die_if_unbearable_beartype__'
+'''
+Unqualified basename of the beartype exception-raiser as imported into the
+current user-defined module being imported and thus transformed by the
+:class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass.
+'''
+
+# ....................{ STRINGS ~ names ~ claw             }....................
+BEARTYPE_CLAW_STATE_OBJ_NAME = '__claw_state_beartype__'
+'''
+Unqualified basename of the beartype import hook state as imported into the
+current user-defined module being imported and thus transformed by the
+:class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass.
+'''
+
+
+BEARTYPE_CLAW_STATE_CONF_CACHE_VAR_NAME = 'module_name_to_beartype_conf'
+'''
+Unqualified basename of the **hooked module beartype configuration cache**
+(i.e., dictionary mapping from the fully-qualified name of each previously
+imported submodule of each package previously registered in our global package
+trie to the beartype configuration configuring type-checking by the
+:func:`beartype.beartype` decorator of that submodule) relative to the
+beartype import hook state, which contains this cache.
+'''
+
+# ....................{ STRINGS ~ names : pep : 695        }....................
+BEARTYPE_HINT_PEP695_FORWARDREF_ITER_FUNC_NAME = (
+    '__iter_hint_pep695_forwardref_beartype__')
+'''
+Unqualified basename of the :pep:`695`-compliant **type alias unqualified
+relative forward reference iterator** (i.e., generator iteratively creating and
+yielding one forward reference proxy for each unqualified relative forward
+reference in the passed :pep:`695`-compliant type alias  as imported into the
+current user-defined module being imported and thus transformed by the
+:class:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer` subclass.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_clawmain.py
@@ -0,0 +1,421 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype import hooks** (i.e., public-facing functions integrating high-level
+:mod:`importlib` machinery required to implement :pep:`302`- and
+:pep:`451`-compliant import hooks with the abstract syntax tree (AST)
+transformations defined by the low-level :mod:`beartype.claw._ast.clawastmain`
+submodule).
+
+This private submodule is the main entry point for this subpackage. Nonetheless,
+this private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Improve the beartype_package() and beartype_packages() functions to emit
+#non-fatal warnings when the passed package or packages have already been
+#imported (i.e., are in the "sys.modules" list).
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeClawHookUnpackagedException
+from beartype.claw._pkg.clawpkgenum import BeartypeClawCoverage
+from beartype.claw._pkg.clawpkghook import hook_packages
+from beartype.typing import Iterable
+from beartype._cave._cavefast import CallableFrameType
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._data.module.datamodpy import SCRIPT_MODULE_NAME
+from beartype._util.func.utilfuncfile import get_func_filename_or_none
+from beartype._util.func.utilfuncframe import (
+    get_frame,
+    get_frame_module_name,
+    get_frame_package_name,
+)
+from pathlib import PurePath
+
+# ....................{ HOOKERS                            }....................
+def beartype_all(
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> None:
+    '''
+    Register a new **universal beartype import path hook** (i.e., callable
+    inserted to the front of the standard :mod:`sys.path_hooks` list recursively
+    decorating *all* annotated callables, classes, and variable assignments
+    across *all* submodules of *all* packages on the first importation of those
+    submodules with the :func:`beartype.beartype` decorator, wrapping those
+    callables and classes with performant runtime type-checking).
+
+    This function is the runtime equivalent of a full-blown static type checker
+    like ``mypy`` or ``pyright``, enabling full-stack runtime type-checking of
+    the current app -- including submodules defined by both:
+
+    * First-party proprietary packages directly authored for this app.
+    * Third-party open-source packages authored and maintained elsewhere.
+
+    This function is thread-safe.
+
+    Usage
+    -----
+    This function is intended to be called from module scope as the first
+    statement of the top-level ``__init__`` submodule of the top-level package
+    of an app to be fully type-checked by :mod:`beartype`. This function then
+    registers an import path hook type-checking *all* annotated callables,
+    classes, and variable assignments across *all* submodules of *all* packages
+    on the first importation of those submodules: e.g.,
+
+    .. code-block:: python
+
+       # At the very top of "muh_package.__init__":
+       from beartype.claw import beartype_all
+       beartype_all()  # <-- beartype all subsequent imports, yo
+
+       # Import submodules *AFTER* calling beartype_all().
+       from muh_package._some_module import muh_function  # <-- @beartype it!
+       from yer_package.other_module import muh_class     # <-- @beartype it!
+
+    Caveats
+    -------
+    **This function is not intended to be called from intermediary APIs,
+    libraries, frameworks, or other middleware.** This function is *only*
+    intended to be called from full stack end-user applications as a convenient
+    alternative to manually passing the names of all packages to be type-checked
+    to the more granular :func:`.beartype_packages` function. This function
+    imposes runtime type-checking on downstream reverse dependencies that may
+    not necessarily want, expect, or tolerate runtime type-checking. This
+    function should typically *only* be called by proprietary packages not
+    expected to be reused by others. Open-source packages are advised to call
+    other functions instead.
+
+    **tl;dr:** *Only call this function in non-reusable end-user apps.*
+
+    Parameters
+    ----------
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by the path hook added by this function).
+        Defaults to ``BeartypeConf()``, the default :math:`O(1)` configuration.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If the passed ``conf`` parameter is *not* a beartype configuration
+        (i.e., :class:`BeartypeConf` instance).
+    '''
+
+    # The advantage of one-liners is the vantage of vanity.
+    hook_packages(claw_coverage=BeartypeClawCoverage.PACKAGES_ALL, conf=conf)
+
+
+def beartype_this_package(
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> None:
+    '''
+    Register a new **current package beartype import path hook** (i.e., callable
+    inserted to the front of the standard :mod:`sys.path_hooks` list recursively
+    applying the :func:`beartype.beartype` decorator to *all*
+    annotated callables, classes, and variable assignments across *all*
+    submodules of the current user-defined package calling this function on the
+    first importation of those submodules).
+
+    This function is thread-safe.
+
+    Usage
+    -----
+    This function is intended to be called from module scope as the first
+    statement of the top-level ``__init__`` submodule of any package to be
+    type-checked by :mod:`beartype`. This function then registers an import path
+    hook type-checking *all* annotated callables, classes, and variable
+    assignments across *all* submodules of that package on the first importation
+    of those submodules: e.g.,
+
+    .. code-block:: python
+
+       # At the very top of "muh_package.__init__":
+       from beartype.claw import beartype_this_package
+       beartype_this_package()  # <-- beartype all subsequent imports, yo
+
+       # Import package submodules *AFTER* calling beartype_this_package().
+       from muh_package._some_module import muh_function  # <-- @beartype it!
+       from muh_package.other_module import muh_class     # <-- @beartype it!
+
+    Parameters
+    ----------
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by the path hook added by this function).
+        Defaults to ``BeartypeConf()``, the default :math:`O(1)` configuration.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If the passed ``conf`` parameter is *not* a beartype configuration
+        (i.e., :class:`.BeartypeConf` instance).
+    BeartypeClawHookUnpackagedException
+        If this function is called from outside any package structure (e.g.,
+        top-level module or executable script).
+    '''
+
+    # Stack frame encapsulating the user-defined lexical scope directly calling
+    # this import hook.
+    #
+    # Note that:
+    # * This call is guaranteed to succeed without error. Why? Because:
+    #   * The current call stack *ALWAYS* contains at least one stack frame.
+    #     Ergo, get_frame(0) *ALWAYS* succeeds without error.
+    #   * The call to this import hook guaranteeably adds yet another stack
+    #     frame to the current call stack. Ergo, get_frame(1) also *ALWAYS*
+    #     succeeds without error in this context.
+    # * This and the following logic *CANNOT* reasonably be isolated to a new
+    #   private helper function. Why? Because this logic itself calls existing
+    #   private helper functions assuming the caller to be at the expected
+    #   position on the current call stack.
+    frame_caller: CallableFrameType = get_frame(1)  # type: ignore[assignment,misc]
+
+    # Fully-qualified name of the parent package of the child module defining
+    # that caller if that module resides in some package *OR* the empty string
+    # otherwise (i.e., if that module is a top-level module or script residing
+    # outside any package structure).
+    frame_package_name = get_frame_package_name(frame_caller)
+    # print(f'beartype_this_package: {frame_caller_package_name}')
+    # print(f'beartype_this_package: {repr(frame_caller)}')
+
+    #FIXME: Is "pragma: no cover" accurate here? Is this condition untestable?
+    # If that module has *NO* parent package, raise an exception. Why? Because
+    # this function uselessly (but silently) reduces to a noop when called from
+    # a top-level module or script residing outside any package. Why? Because
+    # this function installs an import hook applicable only to subsequently
+    # imported submodules of the current package. By definition, a top-level
+    # module or script has *NO* package and thus *NO* sibling submodules and
+    # thus *NO* meaningful imports to be hooked. To avoid unwanted confusion, we
+    # intentionally notify the user with a loud exception.
+    if not frame_package_name:  # pragma: no cover
+        # Exception message to be raised below.
+        exception_message: str = None  # type: ignore[assignment]
+
+        # Fully-qualified name of the module encapsulating the caller.
+        frame_module_name = get_frame_module_name(
+            frame=frame_caller,
+            exception_cls=BeartypeClawHookUnpackagedException,
+        )
+
+        # If the caller is a script rather than a module, this name is the
+        # useless magic string "__main__". In this case...
+        if frame_module_name == SCRIPT_MODULE_NAME:
+            # Absolute filename of this script if this script physically resides
+            # on the local filesystem *OR* "None" otherwise (i.e., if this
+            # script is dynamically defined in-memory).
+            frame_filename = get_func_filename_or_none(frame_caller)
+
+            # If this script physically exists...
+            if frame_filename:
+                # Prefix this message appropriately.
+                exception_message_prefix = (
+                    f'Top-level script "{frame_filename}" ')
+            # Else, this script only exists in memory. In this case...
+            else:
+                # Prefix this message appropriately.
+                exception_message_prefix = 'In-memory script '
+
+                # Fabricate an arbitrary filename. Just do it!
+                frame_filename = 'scripts/main.py'
+
+            # Path object encapsulating this filename.
+            frame_path = PurePath(frame_filename)
+
+            # Basename of the parent directory containing this script, defined
+            # as either...
+            frame_package_basename = (
+                # If this filename contains at least two basenames, then:
+                # * The last basename is that of this script.
+                # * The second-to-last basename is that of the parent directory
+                #   containing this script.
+                frame_path.parts[-2]
+                if len(frame_path.parts) >= 2 else
+                # Else, this filename contains only the basename of this script.
+                # In this case, fabricate an arbitrary basename. Just do it!
+                'scripts'
+            )
+
+            # Exception message to be raised below.
+            exception_message = (
+                f'{exception_message_prefix}resides outside package structure. '
+                f'Consider calling another "beartype.claw" import hook. '
+                f'However, note that only other modules will be type-checked. '
+                f'"{frame_filename}" itself will remain unchecked. '
+                f'All business logic should reside in submodules '
+                f'subsequently imported by "{frame_filename}": e.g.,\n'
+                f'    # Instead of this at the top of "{frame_filename}"...\n'
+                f'    from beartype.claw import beartype_this_package  # <-- you are here\n'
+                f'    beartype_this_package()                          # <-- feels bad\n'
+                f'\n'
+                f'    # ...pass the basename of the "{frame_package_basename}/" subdirectory explicitly.\n'
+                f'    from beartype.claw import beartype_package  # <-- you want to be here\n'
+                f'    beartype_package("{frame_package_basename}")  # <-- feels good\n'
+                f'\n'
+                f'    from {frame_package_basename}.main_submodule import main_func  # <-- still feels good\n'
+                f'    main_func()                   # <-- *GOOD*! "beartype.claw" type-checks this\n'
+                f'    some_global: str = 0xFEEDFACE  # <-- *BAD*! "beartype.claw" ignores this\n'
+                f'This has been a message from your friendly neighbourhood bear.'
+            )
+        # Else, the caller is a module with a useful name. In this case, define
+        # an exception message.
+        #
+        # Note that this edge case implies that this is a top-level module
+        # residing outside a package that was *NOT* run as a script. Since this
+        # should *BASICALLY* never occur, there isn't terribly much we can do.
+        else:
+            exception_message = (
+                f'Top-level module "{frame_module_name}" '
+                f'resides outside package structure but was '
+                f'*NOT* directly run as a script. '
+                f'"beartype.claw" import hooks require that modules either '
+                f'reside inside a package structure or be '
+                f'directly run as scripts. '
+                f'Since neither applies here, you are now off the deep end. '
+                f'@beartype no longer has any idea what is going on, sadly. '
+                f'Consider directly decorating classes and functions by the '
+                f'@beartype.beartype decorator instead: e.g.,\n'
+                f'    # Instead of this at the top of "{frame_module_name}"...\n'
+                f'    from beartype.claw import beartype_this_package  # <-- you are here\n'
+                f'    beartype_this_package()                          # <-- feels bad\n'
+                f'\n'
+                f"    # ...go old-school like it's 2017 and you just don't care.\n"
+                f'    from beartype import beartype  # <-- you want to be here\n'
+                f'    @beartype  # <-- feels good, yet kinda icky at same time\n'
+                f'    def spicy_func() -> str: ...  # <-- *GOOD*! @beartype type-checks this\n'
+                f'    some_global: str = 0xFEEDFACE  # <-- *BAD*! @beartype ignores this, but what can you do\n'
+                f'For your safety, @beartype will now crash and burn.'
+            )
+
+        # Raise an exception.
+        raise BeartypeClawHookUnpackagedException(exception_message)
+    # Else, that module has a parent package.
+
+    # Add a new import path hook beartyping this package.
+    hook_packages(
+        claw_coverage=BeartypeClawCoverage.PACKAGES_ONE,
+        package_name=frame_package_name,
+        conf=conf,
+    )
+
+
+#FIXME: Add a "Usage" docstring section resembling that of the docstring for the
+#beartype_this_package() function.
+def beartype_package(
+    # Mandatory parameters.
+    package_name: str,
+
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> None:
+    '''
+    Register a new **single package beartype import path hook** (i.e., callable
+    inserted to the front of the standard :mod:`sys.path_hooks` list recursively
+    applying the :func:`beartype.beartype` decorator to *all* annotated
+    callables, classes, and variable assignments across *all* submodules of the
+    package with the passed names on the first importation of those submodules).
+
+    This function is thread-safe.
+
+    Parameters
+    ----------
+    package_name : str
+        Fully-qualified name of the package to be type-checked.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by the path hook added by this function).
+        Defaults to ``BeartypeConf()``, the default :math:`O(1)` configuration.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If either:
+
+        * The passed ``conf`` parameter is *not* a beartype configuration (i.e.,
+          :class:`BeartypeConf` instance).
+        * The passed ``package_name`` parameter is either:
+
+          * *Not* a string.
+          * The empty string.
+          * A non-empty string that is *not* a valid **package name** (i.e.,
+            ``"."``-delimited concatenation of valid Python identifiers).
+    '''
+
+    # Add a new import path hook beartyping this package.
+    hook_packages(
+        claw_coverage=BeartypeClawCoverage.PACKAGES_ONE,
+        package_name=package_name,
+        conf=conf,
+    )
+
+
+#FIXME: Add a "Usage" docstring section resembling that of the docstring for the
+#beartype_this_package() function.
+def beartype_packages(
+    # Mandatory parameters.
+    package_names: Iterable[str],
+
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> None:
+    '''
+    Register a new **multiple package beartype import path hook** (i.e.,
+    callable inserted to the front of the standard :mod:`sys.path_hooks` list
+    recursively applying the :func:`beartype.beartype` decorator to *all*
+    annotated callables, classes, and variable assignments across *all*
+    submodules of all packages with the passed names on the first importation of
+    those submodules).
+
+    This function is thread-safe.
+
+    Parameters
+    ----------
+    package_names : Iterable[str]
+        Iterable of the fully-qualified names of one or more packages to be
+        type-checked.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by the path hook added by this function).
+        Defaults to ``BeartypeConf()``, the default :math:`O(1)` configuration.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If either:
+
+        * The passed ``conf`` parameter is *not* a beartype configuration (i.e.,
+          :class:`BeartypeConf` instance).
+        * The passed ``package_names`` parameter is either:
+
+          * Non-iterable (i.e., fails to satisfy the
+            :class:`collections.abc.Iterable` protocol).
+          * An empty iterable.
+          * A non-empty iterable containing at least one item that is either:
+
+            * *Not* a string.
+            * The empty string.
+            * A non-empty string that is *not* a valid **package name** (i.e.,
+              ``"."``-delimited concatenation of valid Python identifiers).
+    '''
+
+    # Add a new import path hook beartyping these packages.
+    hook_packages(
+        claw_coverage=BeartypeClawCoverage.PACKAGES_MANY,
+        package_names=package_names,
+        conf=conf,
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_clawstate.py
@@ -0,0 +1,155 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **import hook state** (i.e., data class singletons safely centralizing
+*all* global state maintained by beartype import hooks, enabling each external
+unit test in our test suite to trivially reset that state after completion of
+that test).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._importlib.clawimpcache import ModuleNameToBeartypeConf
+from beartype.claw._pkg.clawpkgtrie import PackagesTrie
+from beartype.typing import Optional
+from beartype._data.hint.datahinttyping import ImportPathHook
+from threading import RLock
+
+# ....................{ CLASSES                            }....................
+class BeartypeClawState(object):
+    '''
+    **Beartype import hook state** (i.e., non-thread-safe singleton safely
+    centralizing global state maintained by beartype import hooks, enabling each
+    external unit test in our test suite to trivially reset that state after
+    completion of that test).
+
+    Attributes
+    ----------
+    beartype_pathhook : Optional[ImportPathHook]
+        Either:
+
+        * If the
+          :func:`beartype.claw._importlib.clawimppath.add_beartype_pathhook`
+          function has been previously called at least once under the active
+          Python interpreter and the
+          :func:`beartype.claw._importlib.clawimppath.add_beartype_pathhook`
+          function has not been called more recently, the **Beartype import path
+          hook singleton** (i.e., factory closure creating and returning a new
+          :class:`importlib.machinery.FileFinder` instance itself creating and
+          leveraging a new :class:`.BeartypeSourceFileLoader` instance).
+        * Else, :data:`None` otherwise.
+
+        Initialized to :data:`None`.
+    module_name_to_beartype_conf : ModuleNameToBeartypeConf
+        **Hooked module beartype configuration cache** (i.e., non-thread-safe
+        dictionary mapping from the fully-qualified name of each previously
+        imported submodule of each package previously registered in our global
+        package trie to the beartype configuration configuring type-checking by
+        the :func:`beartype.beartype` decorator of that submodule).
+    packages_trie : PackagesTrie
+        **Package configuration trie** (i.e., non-thread-safe recursively nested
+        dictionary implementing a prefix tree such that each key-value pair maps
+        from the unqualified basename of each subpackage to be type-checked on
+        the first importation of that subpackage to another instance of the
+        :class:`.PackagesTrie` class similarly describing the sub-subpackages of
+        that subpackage).
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats our purposes.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        'beartype_pathhook',
+        'module_name_to_beartype_conf',
+        'packages_trie',
+    )
+
+    # ....................{ INITIALIZERS                   }....................
+    def __init__(self) -> None:
+
+        # Nullify the proper subset of instance variables requiring
+        # nullification *BEFORE* reinitializing this singleton.
+        self.beartype_pathhook: Optional[ImportPathHook] = None
+
+        # Reinitialize this singleton safely.
+        self._reinit_safe()
+
+
+    def _reinit_safe(self) -> None:
+        '''
+        Reinitialize *all* beartype import hook state encapsulated by this data
+        class back to their initial defaults, trivially clearing *all* metadata
+        pertaining to previously hooked packages and configurations installed by
+        previously called beartype import hooks.
+
+        This method performs the subset of reinitialization that is safe to be
+        called from the :meth:`__init__` method.
+        '''
+
+        # One one-liner to reinitialize them all.
+        self.module_name_to_beartype_conf = ModuleNameToBeartypeConf()
+        self.packages_trie = PackagesTrie(package_basename=None)
+
+
+    def reinit(self) -> None:
+        '''
+        Reinitialize *all* beartype import hook state encapsulated by this data
+        class back to their initial defaults, trivially clearing *all* metadata
+        pertaining to previously hooked packages and configurations installed by
+        previously called beartype import hooks.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype.claw._importlib.clawimppath import (
+            remove_beartype_pathhook)
+
+        # Perform the subset of reinitialization that is safe to be called from
+        # the __init__() method.
+        self._reinit_safe()
+
+        # Perform the remainder of reinitialization that is unsafe to be called
+        # from the __init__() method.
+        #
+        # Remove our beartype import path hook if this path hook has already
+        # been added (e.g., by a prior call to an import hook) *OR* silently
+        # reduce to a noop otherwise.
+        remove_beartype_pathhook()
+
+    # ..................{ DUNDERS                            }..................
+    def __repr__(self) -> str:
+
+        return '\n'.join((
+            f'{self.__class__.__name__}(\n',
+            f'    beartype_pathhook={repr(self.beartype_pathhook)},\n',
+            f'    module_name_to_beartype_conf={repr(self.module_name_to_beartype_conf)},\n',
+            f'    packages_trie={repr(self.packages_trie)},\n',
+            f')',
+        ))
+
+# ....................{ GLOBALS                            }....................
+claw_lock = RLock()
+'''
+Reentrant reusable thread-safe context manager gating access to the otherwise
+non-thread-safe :data:`.claw_state` global.
+'''
+
+
+claw_state = BeartypeClawState()
+'''
+**Beartype import hook state** (i.e., non-thread-safe singleton safely
+centralizing *all* global state maintained by beartype import hooks, enabling
+each external unit test in our test suite to trivially reset that state after
+completion of that test).
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_importlib/_clawimpload.py
@@ -0,0 +1,508 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **import hook module loaders** (i.e., :mod:`importlib`-compliant
+classes dynamically decorating all typed callables and classes of all submodules
+of all packages previously registered in our global package trie by the
+:func:`beartype.beartype` decorator via abstract syntax tree (AST) transformers
+defined by the :mod:`beartype.claw._ast.clawastmain` submodule).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from ast import PyCF_ONLY_AST
+from beartype.claw._ast.clawastmain import BeartypeNodeTransformer
+from beartype.claw._importlib.clawimpcache import (  # type: ignore[attr-defined]
+    cache_from_source_beartype,
+    cache_from_source_original,
+)
+from beartype.roar import BeartypeClawImportAstException
+from beartype.typing import Optional
+from beartype._conf.confcls import BeartypeConf
+from beartype._util.ast.utilastget import get_node_repr_indented
+from beartype._util.text.utiltextlabel import label_exception
+from importlib import (  # type: ignore[attr-defined]
+    _bootstrap_external,  # pyright: ignore
+)
+from importlib.machinery import SourceFileLoader
+from importlib.util import decode_source
+from types import CodeType
+
+# ....................{ CLASSES                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To improve forward compatibility with the superclass API over which
+# we have *NO* control, avoid accidental conflicts by suffixing *ALL* private
+# and public attributes of this subclass by "_beartype".
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+#FIXME: Unit test us up, please.
+class BeartypeSourceFileLoader(SourceFileLoader):
+    '''
+    **Beartype source file loader** implementing :mod:`importlib` machinery
+    loading a **sourceful Python package or module** (i.e., package or module
+    backed by a ``.py``-suffixed source file) into a **module spec** (i.e.,
+    in-memory :class:`importlib._bootstrap.ModuleSpec` instance describing the
+    importation of that package or module, complete with a reference back to
+    this originating loader).
+
+    The :func:`beartype_package` function injects a low-level **import path
+    hook** (i.e., factory closure instantiating this class as an item of the
+    standard :mod:`sys.path_hooks` list) to the front of that list. When called
+    by a higher-level parent **import metapath hook** (i.e., object suitable for
+    use as an item of the standard :mod:`sys.meta_path` list), that closure:
+
+    #. Instantiates one instance of the standard
+       :class:`importlib._bootstrap_external.FileFinder` class for each
+       **imported Python package** (i.e., package on the :mod:`sys.path` list).
+       The :meth:``importlib._bootstrap_external.FileFinder.find_spec` method of
+       that instance then returns this :class:`BeartypeSourceFileLoader` class
+       uninstantiated for each **imported Python package submodule** (i.e.,
+       submodule directly contained in that package).
+    #. Adds a new key-value pair to the standard :mod:`sys.path_importer_cache`
+       dictionary, whose:
+
+       * Key is the package of that module.
+       * Value is that instance of this class.
+
+    Motivation
+    ----------
+    This loader was intentionally implemented so as to exclusively leverage the
+    lower-level :attr:`sys.path_hooks` mechanism for declaring import hooks
+    rather than both that *and* the higher-level :attr:`sys.meta_path`
+    mechanism. All prior efforts in the Python ecosystem to transform the
+    abstract syntax trees (ASTs) of modules at importation time via import hooks
+    leverage both mechanisms. This includes:
+
+    * :mod:`pytest`, which rewrites test assertion statements via import hooks
+      leveraging both mechanisms.
+    * :mod:`typeguard`, which implicitly applies the runtime type-checking
+      :func:`typguard.typechecked` decorator via import hooks leveraging both
+      mechanisms.
+    * :mod:`ideas`, which applies arbitrary caller-defined AST transformations
+      via (...wait for it) import hooks leveraging both mechanisms.
+
+    Beartype subverts this long-storied tradition by *only* leveraging the
+    lower-level :attr:`sys.path_hooks` mechanism. Doing so reduces maintenance
+    burden, code complexity, and inter-package conflicts. The latter is
+    particularly salient. AST transformations applied by both :mod:`typeguard`
+    and :mod:`ideas` accidentally conflict with those applied by :mod:`pytest`.
+    Why? Because (in order):
+
+    #. When run as a test suite runner, :mod:`pytest` necessarily runs first and
+       thus prepends its import hook as the new first item of the
+       :attr:`sys.meta_path` list.
+    #. When imported during subsequent unit and/or integration testing under
+       that test suite runner, :mod:`typeguard` and :mod:`ideas` then install
+       their own import hooks as the new first item of the :attr:`sys.meta_path`
+       list. The import hook previously prepended by :mod:`pytest` then becomes
+       the second item  of the :attr:`sys.meta_path` list. Python consults both
+       the :attr:`sys.meta_path` and :attr:`sys.path_hooks` lists in a
+       first-come-first-served manner. The first hook on each list satisfying a
+       request to find and import a module being imported terminates that
+       request; no subsequent hooks are consulted. Both :mod:`typeguard` and
+       :mod:`ideas` fail to iteratively consult subsequent hooks (e.g., with a
+       piggybacking scheme of some sort). Both squelch the hook previously
+       installed by :mod:`pytest` that rewrote assertions. That is bad.
+
+    Attributes
+    ----------
+    _module_conf_beartype : Optional[BeartypeConf]
+        Either:
+
+        * If the most recent call to the :meth:`get_code` method (which loads a
+          module by creating and return the code object underlying that module)
+          was passed the fully-qualified name of a module with a transitive
+          parent package previously registered by a call to a public
+          :mod:`beartype.claw` import hook factory (e.g.,
+          :func:`beartype.claw.beartype_package`), the beartype configuration
+          with which to type-check that module.
+        * Else, :data:`None`.
+
+        This instance variable enables our override of the parent
+        :meth:`.get_code` method to communicate this configuration to the child
+        :meth:`.source_to_code` method, which fails to accept and thus has *no*
+        access to this module name. The superclass implementation of the
+        :meth:`.get_code` method then internally calls our override of the
+        :meth:`.source_to_code` method, which accesses this instance variable to
+        decide whether and how to type-check that module.
+
+        Ordinarily, this approach would be fraught with fragility. For example,
+        what if something *other* than the :meth:`get_code` method called the
+        :meth:`.source_to_code` method? Thankfully, that is *not* a concern here.
+        :meth:`.source_to_code` is only called by :meth:`get_code` in the
+        :mod:`importlib` codebase. Ergo, :meth:`source_to_code` should ideally
+        have been privatized (e.g., as ``_source_to_code()``).
+    _module_name_beartype : str
+        Fully-qualified name of the module currently being imported by the
+        :meth:`.get_code` method for subsequent reference in the lower-level
+        :meth:`.source_to_code` method transitively called by the former.
+
+    See Also
+    --------
+    * The `comparable "typeguard.importhook" submodule <typeguard import
+      hook_>`__ implemented by the incomparable `@agronholm (Alex Grönholm)
+      <agronholm_>`__, whose intrepid solutions strongly inspired this
+      subpackage. `Typeguard's import hook infrastructure <typeguard import
+      hook_>`__ is a significant improvement over the prior state of the art in
+      Python and a genuine marvel of concise, elegant, and portable abstract
+      syntax tree (AST) transformation.
+
+    .. _agronholm:
+       https://github.com/agronholm
+    .. _typeguard import hook:
+       https://github.com/agronholm/typeguard/blob/master/src/typeguard/importhook.py
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, *args, **kwargs) -> None:
+        '''
+        Initialize this beartype source file loader.
+
+        All passed parameters are passed as is to the superclass method, which
+        then calls our lower-level :meth:`source_to_code` subclass method
+        overridden below.
+        '''
+
+        # Initialize our superclass with all passed parameters.
+        super().__init__(*args, **kwargs)
+
+        # Nullify all subclass-specific instance variables for safety.
+        self._module_conf_beartype: Optional[BeartypeConf] = None
+        self._module_name_beartype: str = None  # type: ignore[assignment]
+
+    # ..................{ LOADER API                         }..................
+    # The importlib._bootstrap_external.*Loader API declares the low-level
+    # exec_module() method, which accepts an "importlib._bootstrap.ModuleSpec"
+    # instance created and returned by a prior call to the higher-level
+    # find_spec() method documented above; the exec_module() method then uses
+    # that module spec to create and return a fully imported module object
+    # (i.e., "types.ModuleType" instance). To do so:
+    # * The default exec_module() implementation internally calls the
+    #   lower-level get_code() method returning an in-memory Python code object
+    #   deserialized from the on-disk or in-memory bytes underlying that module.
+    # * The default get_code() implementation internally calls the
+    #   lower-level source_to_code() method returning an in-memory Python code
+    #   object dynamically compiled from the passed in-memory bytes.
+
+    def get_code(self, fullname: str) -> Optional[CodeType]:
+        '''
+        Create and return the code object underlying the module with the passed
+        name.
+
+        This override of the superclass :meth:`SourceLoader.get_code` method
+        internally follows one of two distinct code paths, conditionally
+        depending on whether a parent package transitively containing that
+        module has been previously registered with the
+        :mod:`beartype.claw._pkg.clawpkghook` submodule (e.g., by a call to the
+        :func:`beartype.claw.beartype_package` function). Specifically:
+
+        * If *no* parent package transitively containing that module has been
+          registered, this method fully defers to the superclass
+          :meth:`SourceLoader.get_code` method.
+        * Else, one or more parent packages transitively containing that module
+          have been registered. In this case, this method (in order):
+
+          #. Temporarily monkey-patches (i.e., replaces) the
+             private :func:`importlib._bootstrap_external.cache_from_source`
+             function with our beartype-specific
+             :func:`_cache_from_source_beartype` variant.
+          #. Calls the superclass :meth:`SourceLoader.get_code` method, which:
+
+             #. Calls our override of the lower-level superclass
+                :meth:`SourceLoader.source_to_code` method.
+
+          #. Restores the
+             :func:`importlib._bootstrap_external.cache_from_source` function to
+             its original implementation.
+
+        Motivation
+        ----------
+        The temporary monkey-patch applied by this method is strongly inspired
+        by a suspiciously similar temporary monkey-patch applied by the external
+        :meth:`typeguard._importhook.TypeguardLoader.exec_module` method
+        authored by the incomparable @agronholm (Alex Grönholm), who writes:
+
+            Use a custom optimization marker – the import lock should make
+            this monkey patch safe
+
+        The aforementioned "custom optimization marker" is, in fact, a
+        beartype-specific constant embedded in the filename of the cached Python
+        bytecode file to which that module is byte-compiled. This filename
+        typically resembles
+        ``__pycache__/{module_basename}.{optimization_markers}.pyc``, where:
+
+        * ``{module_basename}`` is the unqualified basename of that module.
+        * ``{optimization_markers}`` is a ``"-"``-delimited string of
+          **optimization markers** (i.e., arbitrary alphanumeric labels
+          uniquifying this bytecode file to various bytecode-specific metadata,
+          including the name and version of the active Python interpreter).
+
+        This monkey-patch suffixes ``{optimization_markers}`` by
+        :data:`.BEARTYPE_OPTIMIZATION_MARKER`, which additionally uniquifies the
+        filename of this bytecode file to the abstract syntax tree (AST)
+        transformation applied by this version of :mod:`beartype`. Why? Because
+        external callers can trivially enable and disable that transformation
+        for any module by either calling or not calling the
+        :func:`beartype.claw.beartype_package` function with the name of a
+        package transitively containing that module. Compiling a beartyped
+        variant of that module to the same bytecode file as the non-beartyped
+        variant of that module would erroneously persist beartyping to that
+        module -- even *after* removing the relevant call to the
+        :func:`beartype.claw.beartype_package` function! Clearly, that's awful.
+        Enter @agronholm's phenomenal patch, stage left.
+
+        We implicitly trust @agronholm to get that right in a popular project
+        stress-tested across hundreds of open-source projects over the past
+        several decades. So, we avoid explicit thread-safe locking here.
+
+        Lastly, note there appears to be *no* other means of safely implementing
+        this behaviour *without* violating Don't Repeat Yourself (DRY).
+        Specifically, doing so would require duplicating most of the entirety of
+        the *extremely* non-trivial nearly 100 line-long
+        :meth:`importlib._bootstrap_external.SourceLoader.get_code` method.
+        Since duplicating non-trivial and fragile code inherently tied to a
+        specific CPython version is considerably worse than applying a trivial
+        one-line monkey-patch, first typeguard and now @beartype strongly prefer
+        this monkey-patch. Did we mention that @agronholm is amazing? Because
+        that really bears repeating. May the name of Alex Grönholm live eternal!
+
+        Caveats
+        -------
+        This getter intentionally avoids all dangerous attempts to recursively
+        type-check the :mod:`beartype` package by the :func:`beartype.beartype`
+        decorator. Doing so would be:
+
+        * **Fundamentally unnecessary.** The entirety of the :mod:`beartype`
+          package already religiously guards against type violations with a
+          laborious slew of type checks littered throughout the codebase --
+          including assertions of the form ``"assert isinstance({arg}, {type}),
+          ..."``. Further decorating *all* :mod:`beartype` callables with
+          automated type-checking only needlessly reduces the runtime efficiency
+          of the :mod:`beartype` package.
+        * **Fundamentally dangerous**, which is the greater concern. For
+          example, the
+          :meth:`beartype.claw._ast.clawastmain.BeartypeNodeTransformer.visit_Module`
+          method dynamically inserts a module-scoped import of the
+          :func:`beartype._decor.decorcore.beartype_object_nonfatal` decorator
+          at the head of the module currently being imported. But if the
+          :mod:`beartype._decor.decorcore` submodule itself is being imported,
+          then that importation would destructively induce an infinite circular
+          import! Could that ever happen? **YES.** Conceivably, an external
+          caller could force reimportation of all modules by emptying the
+          :mod:`sys.modules` cache.
+
+        Note this edge case is surprisingly common. The public
+        :func:`beartype.claw.beartype_all` function implicitly registers *all*
+        packages (including :mod:`beartype` itself by default) for decoration by
+        the :func:`beartype.beartype` decorator.
+
+        Parameters
+        ----------
+        fullname : str
+            Fully-qualified name of the module currently being imported.
+
+        Returns
+        -------
+        Optional[CodeType]
+            Code object underlying that module.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype.claw._clawstate import claw_state
+        from beartype.claw._pkg.clawpkgtrie import get_package_conf_or_none
+
+        # Beartype configuration with which to type-check that module if that
+        # module is hooked *OR* "None" otherwise (i.e., if that module is
+        # unhooked), defined as either...
+        conf = (
+            # If that module is either the top-level "beartype" package *OR* a
+            # subpackage or submodule of that package, "None". This effectively
+            # silently ignores this dangerous attempt to recursively type-check
+            # the "beartype" package by the @beartype.beartype decorator. See
+            # the method docstring for further commentary.
+            None
+            if (
+                fullname == 'beartype' or
+                fullname.startswith('beartype.')
+            ) else
+            # Else, that module is neither our top-level "beartype" package
+            # *NOR* a subpackage or submodule of that package. In this case, the
+            # beartype configuration with which to type-check that module if
+            # that module is hooked under its fully-qualified name *OR*
+            # "None" otherwise (i.e., if that module is unhooked).
+            get_package_conf_or_none(fullname)
+        )
+        # print(f'Imported module "{fullname}" package "{package_name}" conf: {repr(self._module_conf_beartype)}')
+
+        # If that module is unhooked, preserve that module as is by simply
+        # deferring to the superclass method *WITHOUT* monkey-patching
+        # cache_from_source(). This isn't only an optimization, though it is
+        # that as well. This is critical. Why? Because modules *NOT* being
+        # beartyped should remain compiled under their standard non-beartyped
+        # bytecode filenames.
+        if conf is None:
+            # print(f'Importing module "{fullname}" without beartyping...')
+            return super().get_code(fullname)
+        # Else, that module has been hooked. In this case...
+        #
+        # Note that the logic below requires inefficient exception handling (as
+        # well as a potentially risky monkey-patch) and is thus performed *ONLY*
+        # when absolutely necessary.
+
+        # Classify local attributes as instance variables for subsequent
+        # reference in the lower-level source_to_code() method transitively
+        # called by this higher-level method.
+        self._module_conf_beartype = conf
+        self._module_name_beartype = fullname
+
+        # Expose this configuration to the "beartype.claw._ast" subpackage.
+        claw_state.module_name_to_beartype_conf[fullname] = conf
+
+        # Temporarily monkey-patch away the cache_from_source() function.
+        #
+        # Note that @agronholm (Alex Grönholm) claims that "the import lock
+        # should make this monkey patch safe." We're trusting you here, man!
+        _bootstrap_external.cache_from_source = cache_from_source_beartype
+
+        # Attempt to defer to the superclass method.
+        try:
+            return super().get_code(fullname)
+        # After doing so (and regardless of whether doing so raises an
+        # exception), restore the original cache_from_source() function.
+        finally:
+            _bootstrap_external.cache_from_source = (
+                cache_from_source_original)
+
+
+    # Note that we explicitly ignore mypy override complaints here. For unknown
+    # reasons, mypy believes that "importlib.machinery.SourceFileLoader"
+    # subclasses comply with the "importlib.abc.InspectLoader" abstract base
+    # class (ABC). Naturally, that is *NOT* the case. Ergo, we entirely ignore
+    # mypy complaints here with respect to signature matching.
+    def source_to_code(  # type: ignore[override]
+        self,
+
+        # Mandatory parameters.
+        data: bytes,
+        path: str,
+
+        # Optional keyword-only parameters.
+        *,
+        _optimize: int =-1,
+    ) -> CodeType:
+        '''
+        Code object dynamically compiled from the **sourceful Python package or
+        module** (i.e., package or module backed by a ``.py``-suffixed source
+        file) with the passed undecoded contents and filename, efficiently
+        transformed in-place by our abstract syntax tree (AST) transformation
+        automatically applying the :func:`beartype.beartype` decorator to all
+        applicable objects of that package or module.
+
+        The higher-level :meth:`get_code` superclass method internally calls
+        this lower-level subclass method.
+
+        Parameters
+        ----------
+        data : bytes
+            **Byte array** (i.e., undecoded list of bytes) of the Python package
+            or module to be decoded and dynamically compiled into a code object.
+        path : str
+            Absolute or relative filename of that Python package or module.
+        _optimize : int, optional
+            **Optimization level** (i.e., numeric integer signifying increasing
+            levels of optimization under which to compile that Python package or
+            module). Defaults to -1, implying the current interpreter-wide
+            optimization level with which the active Python process was
+            initially invoked (e.g., via the ``-o`` command-line option).
+
+        Returns
+        -------
+        CodeType
+            Code object dynamically compiled from that Python package or module.
+
+        Raises
+        ------
+        BeartypeClawImportAstException
+            If our **beartype node transformer** (i.e.,
+            :class:`.BeartypeNodeTransformer` instance) dynamically transforms
+            the original valid abstract syntax tree (AST) governing that Python
+            package or module into a new invalid AST.
+        '''
+
+        # If that module has *NOT* been registered for type-checking, preserve
+        # that module as is by simply deferring to the superclass method.
+        if self._module_conf_beartype is None:
+            return super().source_to_code(  # type: ignore[call-arg]
+                data=data, path=path, _optimize=_optimize)  # pyright: ignore
+        # Else, that module has been registered for type-checking.
+
+        # Plaintext decoded contents of that module.
+        module_source = decode_source(data)
+
+        # Abstract syntax tree (AST) parsed from these contents.
+        module_ast = compile(
+            module_source,
+            path,
+            'exec',
+            PyCF_ONLY_AST,
+            # Prevent these contents from inheriting the effects of any
+            # "from __future__ import" statements in effect in beartype itself.
+            dont_inherit=True,
+            optimize=_optimize,
+        )
+
+        # AST transformer decorating typed callables and classes by @beartype.
+        ast_beartyper = BeartypeNodeTransformer(
+            module_name_beartype=self._module_name_beartype,
+            conf_beartype=self._module_conf_beartype,
+        )
+
+        # Abstract syntax tree (AST) modified by this transformer.
+        module_ast_beartyped = ast_beartyper.visit(module_ast)
+
+        #FIXME: Conditionally perform this logic if "conf.is_debug", please.
+        #Note that printing to "stderr" is pivotal. For some reason, Python
+        #fails to forward printing to "stdout" across subprocesses even when we
+        #explicitly tell it to. Look. I don't even know. Just roll with it!
+        # from sys import stderr
+        # print(
+        #     (
+        #         f'Module "{self._module_name_beartype}" abstract syntax tree (AST) '
+        #         f'transformed by @beartype to:\n\n'
+        #         f'{get_node_repr_indented(module_ast_beartyped)}'
+        #     ),
+        #     file=stderr,
+        # )
+
+        # Attempt to...
+        try:
+            # Code object compiled from this transformed AST.
+            module_codeobj = compile(
+                module_ast_beartyped,
+                path,
+                'exec',
+                # Prevent these contents from inheriting the effects of any
+                # "from __future__ import" statements in effect in the beartype
+                # codebase itself.
+                dont_inherit=True,
+                optimize=_optimize,
+            )
+        # If doing so raises *ANY* exception whatsoever, wrap that low-level
+        # exception with a higher-level exception exhibiting the exact issue.
+        # Doing so enables users to submit meaningful issues to our tracker.
+        except Exception as exception:
+            raise BeartypeClawImportAstException(
+                f'Module "{self._module_name_beartype}" unimportable, as '
+                f'@beartype generated invalid '
+                f'abstract syntax tree (AST):\n\n'
+                f'{get_node_repr_indented(module_ast_beartyped)}\n\n'
+                f'ast.compile() exception (when passed the above AST):\n\t'
+                f'{label_exception(exception)}'
+            ) from exception
+
+        # Return this code object.
+        return module_codeobj
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_importlib/clawimpcache.py
@@ -0,0 +1,229 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **import hook module caches** (i.e., private dictionary singletons
+enabling relevant metadata including beartype configurations associated with
+submodules of all packages previously registered in our global package trie to
+be efficiently stored and retrieved based on various criteria).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._clawmagic import BEARTYPE_OPTIMIZATION_MARKER
+from beartype.roar import BeartypeClawImportConfException
+from beartype.typing import Dict
+from beartype._conf.confcls import BeartypeConf
+from pprint import pformat
+
+# Original cache_from_source() function defined by the private (*gulp*)
+# "importlib._bootstrap_external" submodule, preserved *BEFORE* temporarily
+# replacing that function with our beartype-specific variant in the
+# "beartype.claw._importlib._clawimpload" submodule.
+from importlib.util import cache_from_source as cache_from_source_original
+
+# ....................{ CLASSES                            }....................
+class ModuleNameToBeartypeConf(Dict[str, 'BeartypeConf']):
+    '''
+    Non-thread-safe **hooked module beartype configuration cache** (i.e.,
+    dictionary mapping from the fully-qualified name of each previously imported
+    submodule of each package previously registered in our global package trie
+    to the beartype configuration configuring type-checking by the
+    :func:`beartype.beartype` decorator of that submodule).
+
+    This dictionary subclass improves the human readability of exceptions raised
+    by dunder methods of the :class:`dict` superclass (e.g., the
+    :meth:`dict.__getitem__` dunder method), whose C-based implementations
+    raise non-human-readable exceptions in common use cases encountered by end
+    users leveraging beartype import hooks: e.g.,
+
+    .. code-block:: python
+
+        # Otherwise syntactically and semantically correct PEP 526-compliant
+        # annotated assignment expressions like this previously raised spurious
+        # non-human-readable exceptions from this dictionary resembling:
+        #     KeyError: 'muh_module'  # <-- what does this even mean!?!?
+        loves_philosophy: float = len('The fountains mingle with the river')
+
+    Motivation
+    ----------
+    This cache provides an efficient ``O(1)`` alternative to the comparatively
+    less efficient
+    :func:`beartype.claw._pkg.clawpkgtrie.get_package_conf_or_none` function,
+    which exhibits worst-case runtime complexity of ``O(k)`` for ``k`` the
+    maximum depth of our global package trie. Doing so enables the
+    :mod:`beartype.claw._ast.clawastmain` submodule implementing our abstract
+    syntax tree (AST) node transformer to trivially inject efficient code
+    looking up the current beartype configuration associated with the currently
+    transformed module into the body of that module, which would otherwise be
+    quite non-trivial.
+
+    Caveats
+    ----------
+    **This cache is non-thread-safe.** The caller is responsible for
+    guaranteeing thread-safety on writes to this cache. However, Note that reads
+    of this cache are implicitly thread-safe. The :meth:`BeartypeConf.__new__`
+    instantiator thread-safely stores strong references to the currently
+    instantiated beartype configuration in both this and other caches. Since
+    these caches and thus *all* configurations persist for the lifetime of the
+    active Python interpreter, reads are effectively thread-safe.
+    '''
+
+    # ....................{ DUNDERS                        }....................
+    def __getitem__(self, module_name: str) -> 'BeartypeConf':
+        '''
+        Return the previously instantiated beartype configuration associated
+        with the module with the passed name.
+
+        Parameters
+        ----------
+        module_name : str
+            Fully-qualified name of the module associated with the beartype
+            configuration to be returned.
+
+        Returns
+        ----------
+        beartype.BeartypeConf
+            Beartype configuration associated with this module.
+
+        Raises
+        ----------
+        BeartypeClawImportConfException
+            If no beartype configuration with this module has been previously
+            instantiated.
+        '''
+
+        # Attempt to defer to the superclass implementation.
+        try:
+            return super().__getitem__(module_name)
+        # If doing so fails with a low-level non-human-readable exception...
+        except KeyError as exception:  # pragma: no cover
+            #FIXME: Also, consider dropping the parallel
+            #"BeartypeSourceFileLoader._main_module_name_beartype" attribute.
+            #Does this nonsense supercede that nonsense? Probably. Which leads
+            #us directly to...
+
+            # If the module to be inspected is the "__main__" pseudo-module
+            # signifying the main entry-point into the active Python process...
+            if module_name == '__main__':
+                # from sys import argv
+                # print(f'Python arguments: "{repr(argv)}"')
+                # print(f'Main module spec: "{__main__.__spec__}"')
+
+                # Import this pseudo-module.
+                #
+                # Note that:
+                # * Note that Python guarantees this pseudo-module to *ALWAYS*
+                #   be safely importable, regardless of whether a main module
+                #   actually was imported as an entry-point or not.
+                # * This import *MUST* be delayed as long as feasible. In fact,
+                #   this need to delay this import as long as feasible is why
+                #   this import is performed here; this block is actually the
+                #   last possible code path that this import can be delayed to.
+                #
+                # Ideally, this import would be performed earlier (e.g., in the
+                # BeartypeSourceFileLoader.__init__() method defined in the
+                # "beartype.claw._importlib._clawimpload" submodule) for
+                # debuggability, efficiency, and idempotency; for this reason, a
+                # prior implementation of the aforementioned method performed
+                # this import.
+                #
+                # Pragmatically, doing so:
+                # * Succeeded in some common edge cases, including execution of
+                #   a third-party "muh_package" package invoked at the command
+                #   line as "python -m muh_package", containing:
+                #   * A "muh_package.__init__" submodule calling our
+                #     beartype.claw.beartype_this_package() import hook.
+                #   * A "muh_package.__main__" submodule.
+                # * Failed in other common edge cases, including execution of a
+                #   third-party "muh_package.muh_submodule" submodule invoked at
+                #   the command line as "python -m muh_package.muh_submodule",
+                #   containing:
+                #   * A "muh_package.__init__" submodule calling our
+                #     beartype.claw.beartype_this_package() import hook.
+                #   * *NO* "muh_package.__main__" submodule.
+                #
+                # Why the discrepancy? Because CPython itself (specifically,
+                # CPython's "runpy" architecture responsible for bootstrapping
+                # CPython at process startup) is buggy. Due to non-trivial
+                # "runpy" implementation details that are ultimately irrelevant
+                # to @beartype, CPython inconsistently alters the values of
+                # various critical system globals necessarily introspected by
+                # the "beartype.claw" API, including erroneously reporting that:
+                # * In the aforementioned "muh_package.__init__" submodule:
+                #   * The "sys.argv" global is just "[-m]", thus truncating the
+                #     trailing module name.
+                #   * The "__main__" pseudo-module is empty and thus effectively
+                #     unimportable for all intents and purposes.
+                # * In the aforementioned "muh_package.__main__" and
+                #   "muh_package.muh_submodule" submodules:
+                #   * The "sys.argv" global is just "['muh_package']" and
+                #     "['muh_package.muh_submodule']" (respectively), thus
+                #     truncating the leading argument "-m".
+                #   * The "__main__" pseudo-module is non-empty and thus
+                #     importable for all intents and purposes.
+                #
+                # CPython blatantly lies about both the "sys.argv" global *AND*
+                # "__main__" pseudo-module in top-level "muh_package.__init__"
+                # submodules when CPython is passed the "-m" command-line
+                # option. Ergo, beartype has *NO* means of introspecting either
+                # object from any call in the call stack called by a top-level
+                # "muh_package.__init__" submodule -- including any call to any
+                # "beartype.claw" import hook. Instead, beartype *MUST* defer
+                # that introspection to the last possible time... here.
+                #
+                # See also this relevant StackOverflow question on the topic,
+                # which is nearly a decade-old as of this commit (2023 Q3) but
+                # remains unresolved in even the live git version of CPython:
+                #     https://stackoverflow.com/questions/42076706/sys-argv-behavior-with-python-m
+                import __main__
+
+                # Return the fully-qualified name of the actual user-defined
+                # module encapsulated by the "__main__" pseudo-module.
+                #
+                # Note that the value of the "__main__.__name__" dunder
+                # attribute is *ALWAYS* "__main__", yet another blatant lie that
+                # only obfuscates the truth. Thankfully, the low-level
+                # "importlib"-specific spec object publishes the fully-qualified
+                # name of this actual user-defined module. I sleep now. *zzzzzz*
+                return super().__getitem__(__main__.__spec__.name)
+
+            # Raise a high-level human-readable exception instead.
+            raise BeartypeClawImportConfException(
+                f'Beartype configuration associated with '
+                f'module "{module_name}" hooked by '
+                f'"beartype.claw" not found. '
+                f'Existing beartype configurations associated with '
+                f'hooked modules include:\n\t{pformat(self)}'
+            ) from exception
+
+# ....................{ CACHERS                            }....................
+#FIXME: Unit test us up, please.
+def cache_from_source_beartype(*args, **kwargs) -> str:
+    '''
+    Beartype-specific variant of the
+    :func:`importlib._bootstrap_external.cache_from_source` function applying a
+    beartype-specific optimization marker to that function.
+
+    This, in turn, ensures that submodules residing in packages registered by a
+    prior call to the :func:`beartype_package` function are
+    compiled to files with the filetype
+    ``".pyc{optimization}_{BEARTYPE_OPTIMIZATION_MARKER}"``, where
+    ``{optimization}`` is the original ``optimization`` parameter passed to this
+    function call.
+    '''
+
+    # Original optimization parameter passed to this function call if any *OR*
+    # the empty string otherwise.
+    NONBEARTYPE_OPTIMIZATION_MARKER = kwargs.get('optimization', '')
+
+    # New optimization parameter applied by this monkey-patch of that function,
+    # uniquifying that parameter with a beartype-specific suffix.
+    kwargs['optimization'] = (
+        f'{NONBEARTYPE_OPTIMIZATION_MARKER}{BEARTYPE_OPTIMIZATION_MARKER}')
+
+    # Defer to the implementation of the original cache_from_source() function.
+    return cache_from_source_original(*args, **kwargs)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_importlib/clawimppath.py
@@ -0,0 +1,209 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype all-at-once low-level package name cache.**
+
+This private submodule caches package names on behalf of the higher-level
+:func:`beartype.claw.beartype_package` function. Beartype import
+path hooks internally created by that function subsequently lookup these package
+names from this cache when deciding whether or not (and how) to decorate a
+submodule being imported with :func:`beartype.beartype`.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._importlib._clawimpload import BeartypeSourceFileLoader
+from importlib import invalidate_caches
+from importlib.machinery import (
+    BYTECODE_SUFFIXES,
+    SOURCE_SUFFIXES,
+    FileFinder,
+    ExtensionFileLoader,
+    SourcelessFileLoader,
+)
+from sys import (
+    path_hooks,
+    path_importer_cache,
+)
+
+# Intentionally violate privacy encapsulate in the standard Python library,
+# because there is *NO* valid alternative. This low-level private getter
+# function returns a tuple of the filetypes of *ALL* C extensions supported by
+# the current platform (e.g., as shared libraries).
+from _imp import extension_suffixes
+
+# ....................{ ADDERS                             }....................
+#FIXME: Unit test us up, please.
+def add_beartype_pathhook() -> None:
+    '''
+    Add our **beartype import path hook singleton** (i.e., single callable
+    guaranteed to be inserted at most once to the front of the standard
+    :mod:`sys.path_hooks` list recursively applying the
+    :func:`beartype.beartype` decorator to all well-typed callables and classes
+    defined by all submodules of all packages previously registered by a call to
+    a public :func:`beartype.claw` function) if this path hook has yet to be
+    added *or* silently reduce to a noop otherwise (i.e., if this path hook has
+    already been added).
+
+    Caveats
+    ----------
+    **This function is non-thread-safe.** For both simplicity and efficiency,
+    the caller is expected to provide thread-safety through a higher-level
+    locking primitive managed by the caller.
+
+    See Also
+    ----------
+    https://stackoverflow.com/a/43573798/2809027
+        StackOverflow answer strongly inspiring the low-level implementation of
+        this function with respect to inscrutable :mod:`importlib` machinery.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import claw_state
+
+    # If this function has already been called under the active Python
+    # interpreter, silently reduce to a noop.
+    if claw_state.beartype_pathhook is not None:
+        return
+    # Else, this function has *NOT* yet been called under this interpreter.
+
+    # Closure instantiating a new "FileFinder" instance invoking this loader.
+    #
+    # Note that we intentionally ignore mypy complaints here. Why? Because mypy
+    # erroneously believes this method accepts 2-tuples whose first items are
+    # loader *INSTANCES* (e.g., "Tuple[Loader, List[str]]"). In fact, this
+    # method accepts 2-tuples whose first items are loader *TYPES* (e.g.,
+    # "Tuple[Type[Loader], List[str]]"). This is why we can't have nice things.
+    loader_factory = FileFinder.path_hook(*_LOADERS_DETAILS)  # type: ignore[arg-type]
+
+    # Prepend a new path hook (i.e., factory closure encapsulating this loader)
+    # *BEFORE* all other path hooks.
+    path_hooks.insert(0, loader_factory)
+    # path_hooks.append(loader_factory)
+
+    #FIXME: Uncomment as needed to debug the contents of the "path_hooks" list.
+    # print(f'path_hooks: {path_hooks}')
+    # for path_hook in path_hooks:
+    #     try:
+    #         file_finder = path_hook('/usr/lib/python3.11')
+    #         print(f'file_finder: {file_finder} [{file_finder._loaders}]')
+    #     except:
+    #         pass
+
+    # Prevent subsequent calls to this function from erroneously re-adding
+    # duplicate copies of this path hook immediately *AFTER* successfully adding
+    # the first such path hook.
+    #
+    # Note that we intentionally avoid globalizing this path hook until *AFTER*
+    # successfully having done so. Why? Negligible safety. The companion
+    # remove_beartype_pathhook() function raises a non-human-readable exception
+    # if this global is non-"None" but *NOT* in the "path_hooks" list.
+    claw_state.beartype_pathhook = loader_factory
+
+    # Lastly, clear *ALL* import path hook caches for safety.
+    _clear_importlib_caches()
+
+# ....................{ REMOVERS                           }....................
+#FIXME: Unit test us up, please.
+def remove_beartype_pathhook() -> None:
+    '''
+    Remove our **beartype import path hook singleton** (i.e., single callable
+    guaranteed to be inserted at most once to the front of the standard
+    :mod:`sys.path_hooks` list recursively applying the
+    :func:`beartype.beartype` decorator to all well-typed callables and classes
+    defined by all submodules of all packages previously registered by a call to
+    a public :func:`beartype.claw` function) if this path hook has already been
+    added *or* silently reduce to a noop otherwise (i.e., if this path hook has
+    yet to be added).
+
+    Caveats
+    ----------
+    **This function is non-thread-safe.** For both simplicity and efficiency,
+    the caller is expected to provide thread-safety through a higher-level
+    locking primitive managed by the caller.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import claw_state
+
+    # If the add_beartype_pathhook() function has *NOT* yet been called under
+    # the active Python interpreter, silently reduce to a noop.
+    if claw_state.beartype_pathhook is None:
+        return
+    # Else, that function has already been called under this interpreter.
+
+    # Remove the prior path hook added by that function *OR* raise a
+    # non-human-readable "ValueError" exception if this global is non-"None" but
+    # *NOT* in the "path_hooks" list (which should *NEVER* happen, but it will).
+    path_hooks.remove(claw_state.beartype_pathhook)
+
+    # Allow subsequent calls to the add_beartype_pathhook() to re-add a new
+    # instance of this path hook immediately *AFTER* successfully removing the
+    # first such path hook.
+    claw_state.beartype_pathhook = None
+
+    # Lastly, clear *ALL* import path hook caches for safety.
+    _clear_importlib_caches()
+
+# ....................{ PRIVATE ~ globals                  }....................
+_LOADERS_DETAILS = (
+    # Beartype-agnostic C extension loader details. Since C extensions *CANNOT*
+    # (by definition) be decompiled into an abstract syntax tree (AST), beartype
+    # has *NO* means of decorating C extensions. Ergo, we necessarily defer to
+    # Python's default C extension loader.
+    (ExtensionFileLoader, extension_suffixes()),
+
+    # Beartype-specific **source module loader** (i.e., file loader loading
+    # uncompiled pure-Python modules of the filetype ".py").
+    (BeartypeSourceFileLoader, SOURCE_SUFFIXES),
+
+    #FIXME: Generalize this into a beartype-specific bytecode module loader.
+    #How? By leveraging the third-party "astor" package, which provides a
+    #code_to_ast() function decompiling arbitrary code objects into ASTs. See
+    #also this relevant StackOverflow answer by myself:
+    #    https://stackoverflow.com/a/76641537/2809027
+
+    # Beartype-agnostic **bytecode module loader** (i.e., file loader loading
+    # precompiled pure-Python modules from bytecode files compiled in
+    # "__pycache__/" subdirectories that lack corresponding uncompiled
+    # pure-Python modules of the filetype ".py").
+    (SourcelessFileLoader, BYTECODE_SUFFIXES),
+)
+'''
+Tuple of all **file-based module loader details** (i.e., 2-tuple ``(file_loader,
+filetypes)`` of the undocumented format expected by the
+:meth:`FileFinder.path_hook` class method called by the
+:func:`beartype.claw._importlib.clawimppath.add_beartype_pathhook` function,
+associating each file-based module loader with the platform-specific filetypes
+of all modules loaded by that module).
+
+We didn't do it. Don't blame the bear.
+
+See Also
+----------
+:func:`importlib.machinery._get_supported_file_loaders`
+    Low-level private getter function strongly inspiring the definition of this
+    global, which implements nearly identical functionality (albeit in a
+    :mod:`beartype`-specific manner).
+'''
+
+# ....................{ PRIVATE ~ cachers                  }....................
+#FIXME: Unit test us up, please.
+def _clear_importlib_caches() -> None:
+    '''
+    Clear *all* :mod:`sys`- and :mod:`importlib`-specific caches pertaining to
+    **import path hooks** (i.e., the standard :mod:`sys.path_hooks` list).
+
+    This function is typically called immediately *after* our beartype import
+    path hook singleton is either added to or removed from the path hooks list.
+    '''
+
+    # Uncache *ALL* competing loaders cached by prior importations. Just do it!
+    path_importer_cache.clear()
+
+    # Clear *ALL* "importlib" caches as well for safety.
+    invalidate_caches()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_pkg/_clawpkgmake.py
@@ -0,0 +1,218 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **import hook factories** (i.e., low-level utility functions creating
+and returning objects of interest to higher-level import hook functions).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._pkg.clawpkgenum import BeartypeClawCoverage
+from beartype.roar import (
+    BeartypeClawDecorWarning,
+    BeartypeClawHookException,
+)
+from beartype.typing import (
+    Iterable,
+    Optional,
+)
+from beartype._conf.confcls import BeartypeConf
+from beartype._util.text.utiltextidentifier import die_unless_identifier
+from collections.abc import Iterable as IterableABC
+
+# ....................{ PRIVATE ~ factories                }....................
+#FIXME: Unit test us up, please.
+def make_conf_hookable(conf: BeartypeConf) -> BeartypeConf:
+    '''
+    New **hookable beartype configuration** (i.e., beartype configuration
+    suitable for use in import hooks, sanitized from the passed beartype
+    configuration which is typically unsuitable for use in import hooks).
+
+    This getter creates and returns a new configuration permuted from the passed
+    configuration, forcefully enabling these parameters required by import
+    hooks:
+
+    * :attr:`beartype.BeartypeConf.warning_cls_on_decorator_exception`
+      to the :class:`beartype.roar.BeartypeClawDecorWarning` warning category.
+      Doing so instructs the :func:`beartype.beartype` decorator to emit
+      non-fatal warnings rather than raise fatal exceptions at decoration time
+      when implicitly decorating callables and classes defined by modules hooked
+      by our import hooks, substantially improving the robustness and usability
+      of those hooks.
+
+    Returns
+    ----------
+    Optional[Iterable[str]]
+        Iterable of the fully-qualified names of one or more packages to be
+        either hooked or unhooked by the parent call.
+
+    Raises
+    ----------
+    BeartypeClawHookException
+        If the passed ``conf`` parameter is *not* a beartype configuration
+        (i.e., :class:`BeartypeConf` instance).
+
+    See Also
+    ----------
+    :func:`.hook_packages`
+        Further details.
+    '''
+
+    # If the "conf" parameter is *NOT* a configuration, raise an exception.
+    if not isinstance(conf, BeartypeConf):
+        raise BeartypeClawHookException(
+            f'Beartype configuration {repr(conf)} invalid (i.e., not '
+            f'"beartype.BeartypeConf" instance).'
+        )
+    # Else, the "conf" parameter is a configuration.
+
+    # If the caller did *NOT* explicitly set the
+    # "warning_cls_on_decorator_exception" configuration parameter governing the
+    # reduction of fatal exceptions to non-fatal warnings at @beartype
+    # decoration-time...
+    if not conf._is_warning_cls_on_decorator_exception_set:
+        # Keyword dictionary with which to instantiate a new configuration
+        # reducing fatal exceptions to non-fatal warnings of a warning category
+        # specific to beartype import hooks.
+        conf_kwargs = conf.kwargs.copy()
+        conf_kwargs['warning_cls_on_decorator_exception'] = (
+            BeartypeClawDecorWarning)
+
+        # Replace this configuration with this new configuration.
+        conf = BeartypeConf(**conf_kwargs)  # type: ignore[arg-type]
+    # Else, this caller already explicitly set the
+    # "warning_cls_on_decorator_exception" configuration parameter governing the
+    # reduction of fatal exceptions to non-fatal warnings at @beartype
+    # decoration-time. In this case, preserve this user-defined reduction as is.
+
+    # Return this possibly new configuration.
+    return conf
+
+
+#FIXME: Unit test us up, please.
+def make_package_names_from_args(
+    # Keyword-only arguments.
+    *,
+
+    # Mandatory keyword-only arguments.
+    claw_coverage: BeartypeClawCoverage,
+    conf: BeartypeConf,
+
+    # Optional keyword-only arguments.
+    package_name: Optional[str] = None,
+    package_names: Optional[Iterable[str]] = None,
+) -> Optional[Iterable[str]]:
+    '''
+    Validate all parameters passed by the caller to the parent
+    :func:`.hook_packages` or :func:`.unhook_packages` function.
+
+    Returns
+    ----------
+    Optional[Iterable[str]]
+        Iterable of the fully-qualified names of one or more packages to be
+        either hooked or unhooked by the parent call.
+
+    Raises
+    ----------
+    BeartypeClawHookException
+        If the passed ``package_names`` parameter is either:
+
+        * Neither a string nor an iterable (i.e., fails to satisfy the
+          :class:`collections.abc.Iterable` protocol).
+        * An empty string or iterable.
+        * A non-empty string that is *not* a valid **package name** (i.e.,
+          ``"."``-delimited concatenation of valid Python identifiers).
+        * A non-empty iterable containing at least one item that is either:
+
+          * *Not* a string.
+          * The empty string.
+          * A non-empty string that is *not* a valid **package name** (i.e.,
+            ``"."``-delimited concatenation of valid Python identifiers).
+
+    See Also
+    ----------
+    :func:`.hook_packages`
+        Further details.
+    '''
+    assert isinstance(conf, BeartypeConf), f'{repr(conf)} not configuration.'
+    assert isinstance(claw_coverage, BeartypeClawCoverage), (
+        f'{repr(claw_coverage)} not beartype claw coverage.')
+
+    # If the caller requested all-packages coverage...
+    if claw_coverage is BeartypeClawCoverage.PACKAGES_ALL:
+        # If the caller improperly passed a package name despite requesting
+        # all-packages coverage, raise an exception.
+        if package_name is not None:
+            raise BeartypeClawHookException(
+                f'Coverage {repr(BeartypeClawCoverage.PACKAGES_ALL)} '
+                f'but package name {repr(package_name)} passed.'
+            )
+        # Else, the caller properly passed *NO* package name.
+        #
+        # If the caller improperly passed multiple package names despite
+        # requesting all-packages coverage, raise an exception.
+        elif package_names is not None:
+            raise BeartypeClawHookException(
+                f'Coverage {repr(BeartypeClawCoverage.PACKAGES_ALL)} '
+                f'but package names {repr(package_names)} passed.'
+            )
+        # Else, the caller properly passed *NO* package names.
+    # Else, the caller did *NOT* request all-packages coverage. In this case,
+    # the caller requested coverage over only a subset of packages.
+    else:
+        # If the caller requested mono-package coverage...
+        if claw_coverage is BeartypeClawCoverage.PACKAGES_ONE:
+            # If the caller improperly passed *NO* package name despite
+            # requesting mono-package coverage, raise an exception.
+            if package_name is None:
+                raise BeartypeClawHookException(
+                    f'beartype_package() '
+                    f'package name {repr(package_name)} invalid.'
+                )
+            # Else, the caller properly passed a package name.
+
+            # Wrap this package name in a 1-tuple containing only this name.
+            # Doing so unifies logic below.
+            package_names = (package_name,)
+        # Else, the caller requested multi-package coverage.
+        # elif coverage is BeartypeClawCoverage.PACKAGES_MANY:
+
+        # If this package names is *NOT* iterable, raise an exception.
+        if not isinstance(package_names, IterableABC):
+            raise BeartypeClawHookException(
+                f'beartype_packages() '
+                f'package names {repr(package_name)} not iterable.'
+            )
+        # Else, this package names is iterable.
+        #
+        # If *NO* package names were passed, raise an exception.
+        elif not package_names:
+            raise BeartypeClawHookException(
+                'beartype_packages() package names empty.')
+        # Else, one or more package names were passed.
+
+        # For each such package name...
+        for package_name in package_names:
+            # If this package name is *NOT* a string, raise an exception.
+            if not isinstance(package_name, str):
+                raise BeartypeClawHookException(
+                    f'Package name {repr(package_name)} not string.')
+            # Else, this package name is a string.
+            #
+            # If this package name is *NOT* a valid Python identifier, raise an
+            # exception.
+            else:
+                die_unless_identifier(
+                    text=package_name,
+                    exception_cls=BeartypeClawHookException,
+                    exception_prefix='Package name ',
+                )
+            # Else, this package name is a valid Python identifier.
+
+    # Return the iterable of the fully-qualified names of one or more packages
+    # to be either hooked or unhooked by the parent call.
+    return package_names
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_pkg/clawpkgcontext.py
@@ -0,0 +1,172 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **import path hook context managers** (i.e., data structure caching
+package names on behalf of the higher-level :func:`beartype.claw._clawmain`
+submodule, which beartype import path hooks internally created by that submodule
+subsequently lookup when deciding whether or not (and how) to decorate by
+:func:`beartype.beartype` the currently imported user-specific submodule).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._clawstate import (
+    claw_lock,
+    claw_state,
+)
+from beartype.claw._pkg.clawpkgtrie import (
+    die_if_packages_trie,
+    remove_beartype_pathhook_unless_packages_trie,
+)
+from beartype.typing import (
+    Iterator,
+    Optional,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from contextlib import contextmanager
+
+# ....................{ CONTEXTS                           }....................
+#FIXME: Unit test us up, please.
+@contextmanager
+def beartyping(
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> Iterator[None]:
+    '''
+    Context manager temporarily registering a new **universal beartype import
+    path hook** (i.e., callable inserted to the front of the standard
+    :mod:`sys.path_hooks` list recursively decorating *all* typed callables and
+    classes of *all* submodules of *all* packages on the first importation of
+    those submodules with the :func:`beartype.beartype` decorator, wrapping
+    those callables and classes with performant runtime type-checking).
+
+    Specifically, this context manager (in order):
+
+    #. Temporarily registers this hook by calling the public
+       :func:`beartype.claw.beartype_all` function.
+    #. Runs the body of the caller-defined ``with beartyping(...):`` block.
+    #. Unregisters the hook registered by the prior call to that function.
+
+    This context manager is thread-safe.
+
+    Parameters
+    ----------
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by the path hook added by this function).
+        Defaults to ``BeartypeConf()``, the default :math:`O(1)` configuration.
+
+    Yields
+    ------
+    None
+        This context manager yields *no* objects.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If the passed ``conf`` parameter is *not* a beartype configuration
+        (i.e., :class:`.BeartypeConf` instance).
+
+    See Also
+    --------
+    :func:`beartype.claw.beartype_all`
+        Arguably unsafer alternative to this function globalizing the effect of
+        this function to *all* imports performed anywhere.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw import beartype_all
+
+    # Prior global beartype configuration registered by a prior call to the
+    # beartype_all() function if any *OR* "None" otherwise.
+    packages_trie_conf_if_hooked_old: Optional[BeartypeConf] = None
+
+    # Attempt to...
+    try:
+        # With a "beartype.claw"-specific thread-safe reentrant lock...
+        with claw_lock:
+            # Store the prior global beartype configuration if any.
+            packages_trie_conf_if_hooked_old = (
+                claw_state.packages_trie.conf_if_hooked)
+
+            # Prevent the beartype_all() function from raising an exception on
+            # conflicting registrations of beartype configurations.
+            claw_state.packages_trie.conf_if_hooked = None
+
+        # Globalize the passed beartype configuration.
+        beartype_all(conf=conf)
+
+        # Defer to the caller body of the parent "with beartyping(...):" block.
+        yield
+    # After doing so (regardless of whether doing so raised an exception)...
+    finally:
+        # With a "beartype.claw"-specific thread-safe reentrant lock...
+        with claw_lock:
+            # If the current global beartype configuration is still the passed
+            # beartype configuration, then the caller's body of the parent "with
+            # beartyping(...):" block has *NOT* itself called the beartype_all()
+            # function with a conflicting beartype configuration. In this
+            # case...
+            if claw_state.packages_trie.conf_if_hooked == conf:
+                # Restore the prior global beartype configuration if any.
+                claw_state.packages_trie.conf_if_hooked = (
+                    packages_trie_conf_if_hooked_old)
+
+                # Possibly remove our beartype import path hook added by the
+                # above call to beartype_all() if *NO* packages are registered.
+                remove_beartype_pathhook_unless_packages_trie()
+            # Else, the caller's body of the parent "with beartyping(...):"
+            # block has itself called the beartype_all() function with a
+            # conflicting beartype configuration. In this case, preserve that
+            # configuration as is.
+
+
+#FIXME: Unit test us up, please.
+@contextmanager
+def packages_trie_cleared() -> Iterator[None]:
+    '''
+    Test-specific context manager reverting (i.e., clearing, resetting) the
+    :data:`beartype.claw._pkg.clawpkgtrie.packages_trie` global back to its
+    initial state *after* running the body of the caller-defined ``with
+    beartyping(...):`` block.
+
+    This context manager is thread-safe.
+
+    Caveats
+    -------
+    **This context manager is intentionally hidden from users as a private
+    attribute of this submodule** rather than publicly exported. Why? Because
+    this context manager is *only* intended to be invoked by unit and
+    integration tests in our test suite.
+
+    Yields
+    ------
+    None
+        This context manager yields *no* objects.
+    '''
+
+    # If one or more packages are still registered by a prior call to a beartype
+    # import hook, raise an exception.
+    die_if_packages_trie()
+    # Else, *NO* packages are still registered.
+
+    # Perform the caller-defined body of the parent "with" statement.
+    try:
+        yield
+    # After doing so, regardless of whether doing so raised an exception...
+    finally:
+        # print(f'claw_state [after test]: {repr(claw_state)}')
+
+        # With a submodule-specific thread-safe reentrant lock, reset our import
+        # hook state back to its initial defaults.
+        with claw_lock:
+            claw_state.reinit()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_pkg/clawpkgenum.py
@@ -0,0 +1,50 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype import hook enumerations** (i.e., :class:`enum.Enum` subclasses
+enumerating various kinds of divergent strategies and processes specific to
+import hooks defined by the :mod:`beartype.claw` subpackage).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+# from beartype.typing import Literal
+from enum import (
+    Enum,
+    auto as next_enum_member_value,
+    unique as die_unless_enum_member_values_unique,
+)
+
+# ....................{ ENUMS                              }....................
+@die_unless_enum_member_values_unique
+class BeartypeClawCoverage(Enum):
+    '''
+    Enumeration of all kinds of **import hook coverage** (i.e., competing
+    package scopes over which to apply import hooks defined by the
+    :mod:`beartype.claw` subpackage, each with concomitant tradeoffs with
+    respect to runtime complexity and quality assurance).
+
+    Attributes
+    ----------
+    PACKAGES_ALL : EnumMemberType
+        **All-packages coverage** (i.e, hooking imports into *all* packages,
+        including both third-party packages *and* standard packages bundled with
+        Python in the standard library). This coverage is typically applied by a
+        caller calling the :func:`beartype.claw.beartype_all` import hook.
+    PACKAGES_MANY : EnumMemberType
+        **Many-packages coverage** (i.e, hooking imports into two or more
+        explicitly specified packages). This coverage is typically applied by a
+        caller calling the :func:`beartype.claw.beartype_packages` import hook.
+    PACKAGES_ONE : EnumMemberType
+        **One-package coverage** (i.e, hooking imports into only one explicitly
+        specified package). This coverage is typically applied by a caller
+        calling the :func:`beartype.claw.beartype_package` import hook.
+    '''
+
+    PACKAGES_ALL = next_enum_member_value()
+    PACKAGES_MANY = next_enum_member_value()
+    PACKAGES_ONE = next_enum_member_value()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_pkg/clawpkghook.py
@@ -0,0 +1,385 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **import hook managers** (i.e., lower-level private-facing functions
+internally driving the higher-level public facing import hooks exported by the
+:mod:`beartype.claw._clawmain` submodule).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._pkg.clawpkgenum import BeartypeClawCoverage
+from beartype.claw._pkg.clawpkgtrie import (
+    PackagesTrie,
+    iter_packages_trie,
+    remove_beartype_pathhook_unless_packages_trie,
+)
+from beartype.claw._pkg._clawpkgmake import (
+    make_conf_hookable,
+    make_package_names_from_args,
+)
+from beartype.claw._importlib.clawimppath import (
+    add_beartype_pathhook,
+    # remove_beartype_pathhook,
+)
+from beartype.roar import (
+    BeartypeClawHookException,
+)
+from beartype.typing import (
+    Iterable,
+    Optional,
+)
+from beartype._conf.confcls import BeartypeConf
+
+# ....................{ (UN)HOOKERS                        }....................
+#FIXME: Unit test us up, please.
+def hook_packages(
+    # Keyword-only arguments.
+    *,
+
+    # Mandatory keyword-only arguments.
+    claw_coverage: BeartypeClawCoverage,
+    conf: BeartypeConf,
+
+    # Optional keyword-only arguments.
+    package_name: Optional[str] = None,
+    package_names: Optional[Iterable[str]] = None,
+) -> None:
+    '''
+    Register a new **beartype package import path hook** (i.e., callable
+    inserted to the front of the standard :mod:`sys.path_hooks` list recursively
+    applying the :func:`beartype.beartype` decorator to all typed callables and
+    classes of all submodules of all packages with the passed names on the first
+    importation of those submodules).
+
+    Parameters
+    ----------
+    claw_coverage : BeartypeClawCoverage
+        **Import hook coverage** (i.e., competing package scope over which to
+        apply the path hook added by this function, each with concomitant
+        tradeoffs with respect to runtime complexity and quality assurance).
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., dataclass configuring the
+        :mod:`beartype.beartype` decorator for *all* decoratable objects
+        recursively decorated by the path hook added by this function).
+    package_name : Optional[str]
+        Either:
+
+        * If ``coverage`` is :attr:`BeartypeClawCoverage.PACKAGES_ONE`, the
+          fully-qualified name of the package to be type-checked.
+        * Else, ignored.
+
+        Defaults to :data:`None`.
+    package_names : Optional[Iterable[str]]]
+        Either:
+
+        * If ``coverage`` is :attr:`BeartypeClawCoverage.PACKAGES_MANY`, an
+          iterable of the fully-qualified names of one or more packages to be
+          type-checked.
+        * Else, ignored.
+
+        Defaults to :data:`None`.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If either:
+
+        * The passed ``package_names`` parameter is either:
+
+          * Neither a string nor an iterable (i.e., fails to satisfy the
+            :class:`collections.abc.Iterable` protocol).
+          * An empty string or iterable.
+          * A non-empty string that is *not* a valid **package name** (i.e.,
+            ``"."``-delimited concatenation of valid Python identifiers).
+          * A non-empty iterable containing at least one item that is either:
+
+            * *Not* a string.
+            * The empty string.
+            * A non-empty string that is *not* a valid **package name** (i.e.,
+              ``"."``-delimited concatenation of valid Python identifiers).
+
+        * The passed ``conf`` parameter is *not* a beartype configuration (i.e.,
+          :class:`BeartypeConf` instance).
+
+    See Also
+    --------
+    https://stackoverflow.com/a/43573798/2809027
+        StackOverflow answer strongly inspiring the low-level implementation of
+        this function with respect to inscrutable :mod:`importlib` machinery.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import (
+        claw_lock,
+        claw_state,
+    )
+
+    # Replace this beartype configuration (which is typically unsuitable for
+    # usage in import hooks) with a new beartype configuration suitable for
+    # usage in import hooks.
+    conf = make_conf_hookable(conf)
+
+    # Iterable of the passed fully-qualified names of all packages to be hooked.
+    package_names = make_package_names_from_args(
+        claw_coverage=claw_coverage,
+        conf=conf,
+        package_name=package_name,
+        package_names=package_names,
+    )
+
+    # With a submodule-specific thread-safe reentrant lock...
+    with claw_lock:
+        # If the caller requested all-packages coverage...
+        if claw_coverage is BeartypeClawCoverage.PACKAGES_ALL:
+            # Beartype configuration currently associated with *ALL* packages by
+            # a prior call to this function if any *OR* "None" (i.e., if this
+            # function has yet to be called under this Python interpreter).
+            conf_curr = claw_state.packages_trie.conf_if_hooked
+
+            # If the higher-level beartype_all() function (calling this
+            # lower-level adder) has yet to be called under this interpreter,
+            # associate this configuration with *ALL* packages.
+            if conf_curr is None:
+                claw_state.packages_trie.conf_if_hooked = conf
+            # Else, beartype_all() was already called under this interpreter.
+            #
+            # If the caller passed a different configuration to that prior call
+            # than that passed to this current call, raise an exception.
+            elif conf_curr != conf:
+                raise BeartypeClawHookException(
+                    f'beartype_all() previously passed '
+                    f'conflicting beartype configuration:\n'
+                    f'\t----------( OLD "conf" PARAMETER )----------\n'
+                    f'\t{repr(conf_curr)}\n'
+                    f'\t----------( NEW "conf" PARAMETER )----------\n'
+                    f'\t{repr(conf)}\n'
+                )
+            # Else, the caller passed the same configuration to that prior call
+            # than that passed to the current call.
+        # Else, the caller requested coverage over a subset of packages. In this
+        # case...
+        else:
+            # For the fully-qualified name of each package to be registered...
+            for package_name in package_names:  # type: ignore[union-attr]
+                # List of each unqualified basename comprising this name, split
+                # from this fully-qualified name on "." delimiters. Note that
+                # the "str.split('.')" and "str.rsplit('.')" calls produce the
+                # exact same lists under all possible edge cases. We arbitrarily
+                # call the former rather than the latter for simplicity.
+                package_basenames = package_name.split('.')
+
+                # Current subtrie of the global package trie describing the
+                # currently iterated basename of this package, initialized to
+                # the global trie configuring all top-level packages.
+                subpackages_trie = claw_state.packages_trie
+
+                # For each unqualified basename comprising the directed path from
+                # the root parent package of that package to that package...
+                for package_basename in package_basenames:
+                    # Current subtrie of that trie describing that parent package if
+                    # that parent package was registered by a prior call to the
+                    # hook_packages() function *OR* "None" (i.e., if that parent
+                    # package has yet to be registered).
+                    subpackages_subtrie = subpackages_trie.get(package_basename)
+
+                    # If this is the first registration of that parent package,
+                    # register a new subtrie describing that parent package.
+                    #
+                    # Note that this test could be obviated away by refactoring our
+                    # "PackagesTrie" subclass from the "collections.defaultdict"
+                    # superclass rather than the standard "dict" class. Since doing
+                    # so would obscure erroneous attempts to access non-existing
+                    # keys, however, this test is preferable to inviting even *MORE*
+                    # bugs into this bug-riddled codebase. Just kidding! There are
+                    # absolutely no bugs in this codebase. *wink*
+                    if subpackages_subtrie is None:
+                        subpackages_subtrie = \
+                            subpackages_trie[package_basename] = \
+                            PackagesTrie(package_basename=package_basename)
+                    # Else, that parent package was already registered by a prior
+                    # call to this function.
+
+                    # Iterate the current subtrie one subpackage deeper.
+                    subpackages_trie = subpackages_subtrie
+                # Since the "package_basenames" list contains at least one basename,
+                # the above iteration set the currently examined subdictionary
+                # "subpackages_trie" to at least one subtrie of the global package
+                # trie. Moreover, that subtrie is guaranteed to describe the current
+                # (sub)package being registered.
+                # print(f'Hooked package "{package_name}" subpackage trie {repr(subpackages_trie)}...')
+
+                # Beartype configuration currently associated with that package by a
+                # prior call to this function if any *OR* "None" (i.e., if that
+                # package has yet to be registered by a prior call to this
+                # function).
+                conf_curr = subpackages_trie.conf_if_hooked
+
+                # If that package has yet to be registered, associate this
+                # configuration with that package.
+                if conf_curr is None:
+                    subpackages_trie.conf_if_hooked = conf
+                # Else, that package was already registered by a previous call to
+                # this function.
+                #
+                # If the caller passed a different configuration to that prior call
+                # than that passed to this current call, raise an exception.
+                elif conf_curr != conf:
+                    raise BeartypeClawHookException(
+                        f'Beartype import hook '
+                        f'(e.g., beartype.claw.beartype_*() function) '
+                        f'previously passed '
+                        f'conflicting beartype configuration for '
+                        f'package name "{package_name}":\n'
+                        f'\t----------( OLD "conf" PARAMETER )----------\n'
+                        f'\t{repr(conf_curr)}\n'
+                        f'\t----------( NEW "conf" PARAMETER )----------\n'
+                        f'\t{repr(conf)}\n'
+                    )
+                # Else, the caller passed the same configuration to that prior call
+                # than that passed to the current call. In this case, silently
+                # ignore this redundant request to reregister that package.
+
+        # Lastly, if our beartype import path hook singleton has *NOT* already
+        # been added to the standard "sys.path_hooks" list, do so now.
+        #
+        # Note that we intentionally:
+        # * Do so in a thread-safe manner *INSIDE* this lock.
+        # * Defer doing so until *AFTER* the above iteration has successfully
+        #   registered the desired packages with our global trie. Why? This path
+        #   hook subsequently calls the companion get_package_conf_or_none()
+        #   function, which accesses this trie.
+        add_beartype_pathhook()
+
+
+#FIXME: Unit test us up, please.
+def unhook_packages(
+    # Keyword-only arguments.
+    *,
+
+    # Mandatory keyword-only arguments.
+    claw_coverage: BeartypeClawCoverage,
+    conf: BeartypeConf,
+
+    # Optional keyword-only arguments.
+    package_name: Optional[str] = None,
+    package_names: Optional[Iterable[str]] = None,
+) -> None:
+    '''
+    Unregister a previously registered **beartype package import path hook**
+    (i.e., callable inserted to the front of the standard :mod:`sys.path_hooks`
+    list recursively applying the :func:`beartype.beartype` decorator to all
+    typed callables and classes of all submodules of all packages with the
+    passed names on the first importation of those submodules).
+
+    See Also
+    --------
+    :func:`.hook_packages`
+        Further details.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import (
+        claw_lock,
+        claw_state,
+    )
+
+    # Replace this beartype configuration (which is typically unsuitable for
+    # usage in import hooks) with a new beartype configuration suitable for
+    # usage in import hooks.
+    conf = make_conf_hookable(conf)
+
+    # Iterable of the passed fully-qualified names of all packages to be
+    # unhooked.
+    package_names = make_package_names_from_args(
+        claw_coverage=claw_coverage,
+        conf=conf,
+        package_name=package_name,
+        package_names=package_names,
+    )
+
+    # With a submodule-specific thread-safe reentrant lock...
+    with claw_lock:
+        # If the caller requested all-packages coverage...
+        if claw_coverage is BeartypeClawCoverage.PACKAGES_ALL:
+            # Unhook the beartype configuration previously associated with *ALL*
+            # packages by a prior call to the beartype_all() function.
+            claw_state.packages_trie.conf_if_hooked = None
+        # Else, the caller requested coverage over a subset of packages. In this
+        # case...
+        else:
+            # For the fully-qualified names of each package to be
+            # unregistered...
+            for package_name in package_names:  # type: ignore[union-attr]
+                # List of all subpackages tries describing each parent package
+                # transitively containing the passed package (as well as that of
+                # that package itself).
+                subpackages_tries = list(iter_packages_trie(package_name))
+
+                # Reverse this list in-place, such that:
+                # * The first item of this list is the subpackages trie
+                #   describing that package itself.
+                # * The last item of this list is the subpackages trie
+                #   describing the root package of that package.
+                subpackages_tries.reverse()
+
+                # Unhook the beartype configuration previously associated with
+                # that package by a prior call to the hook_packages() function.
+                subpackages_tries[0].conf_if_hooked = None
+
+                # Child sub-subpackages trie of the currently iterated
+                # subpackages trie, describing the child subpackage of the
+                # current parent package transitively containing that package.
+                subsubpackages_trie = None
+
+                # For each subpackages trie describing a parent package
+                # transitively containing that package...
+                for subpackages_trie in subpackages_tries:
+                    # If this is *NOT* the first iteration of this loop (in
+                    # which case this subpackages trie is a parent package
+                    # rather than that package itself) *AND*...
+                    if subsubpackages_trie is not None:
+                        # If this child sub-subpackages trie describing this
+                        # child sub-subpackage has one or more children, then
+                        # this child sub-subpackages trie still stores
+                        # meaningful metadata and is thus *NOT* safely
+                        # deletable. Moreover, this implies that:
+                        # * *ALL* parent subpackages tries of this child
+                        #   sub-subpackages trie also still store meaningful
+                        #   metadata and are thus also *NOT* safely deletable.
+                        # * There exists no more meaningful work to be performed
+                        #   by this iteration. Ergo, we immediately halt this
+                        #   iteration now.
+                        if subsubpackages_trie:
+                            break
+                        # Else, this child sub-subpackages trie describing this
+                        # child sub-subpackage has *NO* children, implying this
+                        # child sub-subpackages trie no longer stores any
+                        # meaningful metadata and is thus safely deletable.
+
+                        # Unqualified basename of this child sub-subpackage.
+                        subsubpackage_basename = (
+                            subsubpackages_trie.package_basename)
+
+                        # Delete this child sub-subpackages trie from this
+                        # parent subpackages trie.
+                        del subpackages_trie[subsubpackage_basename]  # pyright: ignore
+                    # Else, this is the first iteration of this loop.
+
+                    # Treat this parent subpackages trie as the child
+                    # sub-subpackages trie in the next iteration of this loop.
+                    subsubpackages_trie = subpackages_trie
+
+        # Lastly, if *ALL* meaningful metadata has now been removed from our
+        # global trie, remove our beartype import path hook singleton from the
+        # standard "sys.path_hooks" list.
+        #
+        # Note that we intentionally:
+        # * Do so in a thread-safe manner *INSIDE* this lock.
+        # * Defer doing so until *AFTER* the above iteration has successfully
+        #   unregistered the desired packages with our global trie.
+        remove_beartype_pathhook_unless_packages_trie()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/claw/_pkg/clawpkgtrie.py
@@ -0,0 +1,401 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype import path hook trie** (i.e., data structure caching package names
+on behalf of the higher-level :func:`beartype.claw._clawmain` submodule, which
+beartype import path hooks internally created by that submodule subsequently
+lookup when deciding whether or not (and how) to decorate by
+:func:`beartype.beartype` the currently imported user-specific submodule).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.claw._importlib.clawimppath import remove_beartype_pathhook
+from beartype.roar import BeartypeClawHookException
+from beartype.typing import (
+    Dict,
+    Iterable,
+    # Iterator,
+    Optional,
+)
+from beartype._cave._cavemap import NoneTypeOr
+from beartype._conf.confcls import BeartypeConf
+# from pprint import pformat
+
+# ....................{ CLASSES                            }....................
+#FIXME: Unit test us up, please.
+class PackagesTrie(
+    #FIXME: Use "beartype.typing.Self" here instead once we backport that.
+    Dict[str, Optional['PackagesTrie']]):
+    '''
+    **(Sub)package configuration (sub)trie** (i.e., recursively nested
+    dictionary mapping from the unqualified basename of each subpackage of the
+    current package to be runtime type-checked on the first importation of that
+    subpackage to another instance of this class similarly describing the
+    sub-subpackages of that subpackage).
+
+    This (sub)cache is suitable for caching as the values of:
+
+    * The :data:`.packages_trie` global dictionary.
+    * Each (sub)value mapped to by that global dictionary.
+
+    Motivation
+    ----------
+    This dictionary is intentionally implemented as a nested trie data structure
+    rather than a trivial non-nested flat dictionary. Why? Efficiency. Consider
+    this flattened set of package names:
+
+        .. code-block:: python
+
+           package_names = {'a.b', 'a.c', 'd'}
+
+    Deciding whether an arbitrary package name is in this set requires
+    worst-case ``O(n)`` iteration across the set of ``n`` package names.
+
+    Consider instead this nested dictionary whose keys are package names split
+    on ``"."`` delimiters and whose values are either recursively nested
+    dictionaries of the same format *or* the :data:`None` singleton (terminating
+    the current package name):
+
+        .. code-block:: python
+
+           package_names_trie = {'a': {'b': None, 'c': None}, 'd': None}
+
+    Deciding whether an arbitrary package name is in this dictionary only
+    requires worst-case ``O(h)`` iteration across the height ``h`` of this
+    dictionary (equivalent to the largest number of ``"."`` delimiters for any
+    fully-qualified package name encapsulated by this dictionary). ``h <<<< n``,
+    so this dictionary offers *much* faster worst-case lookup than that set.
+
+    Moreover, in the worst case:
+
+    * That set requires one inefficient string prefix test for each item.
+    * This dictionary requires *only* one efficient string equality test for
+      each nested key-value pair while descending towards the target package
+      name.
+
+    Let's do this, fam.
+
+    Caveats
+    -------
+    **This dictionary is only safely accessible in a thread-safe manner from
+    within a** ``with claw_lock:`` **context manager.** Equivalently, this
+    dictionary is *not* safely accessible outside that manager.
+
+    Examples
+    --------
+    An example instance of this dictionary hooked on submodules of the root
+    ``package_z`` package, the child ``package_a.subpackage_k`` submodule, and
+    the ``package_a.subpackage_b.subpackage_c`` and
+    ``package_a.subpackage_b.subpackage_d`` submodules:
+
+        >>> packages_trie = PackagesTrie({
+        ...     'package_a': PackagesTrie({
+        ...         'subpackage_b': PackagesTrie({
+        ...             'subpackage_c': None,
+        ...             'subpackage_d': None,
+        ...         }),
+        ...         'subpackage_k': None,
+        ...     }),
+        ...     'package_z': None,
+        ... })
+
+    Attributes
+    ----------
+    conf_if_hooked : Optional[BeartypeConf]
+        Either:
+
+        * If this (sub)package has been explicitly registered by a prior call to
+          the :func:`add_package_names` function, the **beartype
+          configuration** (i.e., dataclass encapsulating all settings
+          configuring type-checking for this (sub)package).
+        * Else, :data:`None`.
+    package_basename : Optional[str]
+        Either:
+
+        * If this (sub)trie is the global trie :data:`.packages_trie`,
+          :data:`None`.
+        * Else, the unqualified basename of the (sub)package configured by this
+          (sub)trie.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats our purposes.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        'package_basename',
+        'conf_if_hooked',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+        package_basename : Optional[str],
+        *args, **kwargs
+    ) -> None:
+        '''
+        Initialize this package name (sub)cache.
+
+        Parameters
+        ----------
+        basename : Optional[str]
+            Either:
+
+            * If this (sub)trie is the global trie :data:`.packages_trie`,
+              :data:`None`.
+            * Else, the unqualified basename of the (sub)package configured by
+              this (sub)trie.
+
+        All remaining passed parameters are passed as is to the superclass
+        :meth:`dict.__init__` method.
+        '''
+        assert isinstance(package_basename, NoneTypeOr[str]), (
+            f'{repr(package_basename)} neither string nor "None".')
+
+        # Initialize our superclass with all passed parameters.
+        super().__init__(*args, **kwargs)
+
+        # Classify all remaining passed parameters.
+        self.package_basename = package_basename
+
+        # Nullify all subclass-specific parameters for safety.
+        self.conf_if_hooked: Optional[BeartypeConf] = None
+
+    # ..................{ DUNDERS                            }..................
+    def __repr__(self) -> str:
+
+        return '\n'.join((
+            f'{self.__class__.__name__}(',
+            f'    package_basename={repr(self.package_basename)},',
+            f'    conf_if_hooked={repr(self.conf_if_hooked)},',
+            f'    dict={super().__repr__()},',
+            f')',
+        ))
+
+# ....................{ RAISERS                            }....................
+def die_if_packages_trie() -> None:
+    '''
+    Raise an exception if one or more packages have been registered by a prior
+    call to the :func:`beartype.claw._pkg.clawpkghook.hook_packages` function.
+
+    Raises
+    ------
+    BeartypeClawHookException
+        If one or more packages have been registered by a prior call to the
+        :func:`beartype.claw._pkg.clawpkghook.hook_packages` function.
+    '''
+
+    # If one or more packages have been registered...
+    if is_packages_trie():
+        # Avoid circular import dependencies.
+        from beartype.claw._clawstate import claw_state
+
+        # If a global configuration has been added by a prior call to the public
+        # beartype.claw.beartype_all() function, raise an exception.
+        if claw_state.packages_trie.conf_if_hooked is not None:
+            raise BeartypeClawHookException(
+                f'Prior call to package-agnostic import hook '
+                f'beartype.claw.beartype_all() already registered all packages '
+                f'for type-checking under global beartype configuration '
+                f'{repr(claw_state.packages_trie.conf_if_hooked)}.'
+            )
+        # Else, or more package-specific configurations have been added by prior
+        # calls to public beartype.claw.beartype_*() functions. In this case,
+        # raise another exception.
+        else:
+            raise BeartypeClawHookException(
+                f'Prior call to package-specific import hook '
+                f'beartype.claw.beartype_*() already registered some packages '
+                f'for type-checking under beartype configurations:\n\t'
+                f'{repr(claw_state.packages_trie)}'
+            )
+
+# ....................{ TESTERS                            }....................
+#FIXME: Unit test us up, please.
+def is_packages_trie() -> bool:
+    '''
+    :data:`True` only if one or more packages have been registered by a prior
+    call to the :func:`beartype.claw._pkg.clawpkghook.hook_packages` function.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if one or more packages have been registered.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import claw_state
+
+    # Return true only if either...
+    return (
+        # A global configuration has been added by a prior call to the public
+        # beartype.claw.beartype_all() function *OR*...
+        claw_state.packages_trie.conf_if_hooked is not None or
+        # One or more package-specific configurations have been added by prior
+        # calls to public beartype.claw.beartype_*() functions.
+        bool(claw_state.packages_trie)
+    )
+
+# ....................{ GETTERS                            }....................
+#FIXME: Unit test us up, please.
+def get_package_conf_or_none(package_name: str) -> Optional[BeartypeConf]:
+    '''
+    Beartype configuration with which to type-check the package with the passed
+    name if that package *or* a parent package of that package was registered by
+    a prior call to the :func:`.hook_packages` function *or* :data:`None`
+    otherwise (i.e., if neither that package *nor* a parent package of that
+    package was registered by such a call).
+
+    Parameters
+    ----------
+    package_name : str
+        Fully-qualified name of the package to be inspected.
+
+    Returns
+    -------
+    Optional[BeartypeConf]
+        Either:
+
+        * If that package or a parent package of that package was registered by
+          a prior call to the :func:`.hook_packages` function, the beartype
+          configuration with which to type-check that package.
+        * Else, :data:`None`.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import claw_state
+
+    # Beartype configuration registered for the currently iterated package,
+    # defaulting to the beartype configuration registered for the global trie
+    # applicable to *ALL* packages if an external caller previously called the
+    # public beartype.claw.beartype_all() function *OR* "None" otherwise (i.e.,
+    # if that function has yet to be called).
+    subpackage_conf = claw_state.packages_trie.conf_if_hooked
+
+    # For each subpackages trie describing each parent package transitively
+    # containing this package (as well as that of that package itself)...
+    for subpackages_trie in iter_packages_trie(package_name):
+        # Beartype configuration registered with either...
+        subpackage_conf = (
+            # That parent package if any *OR*...
+            #
+            # Since that parent package is more granular (i.e., unique) than
+            # any transitive parent package of that parent package, the
+            # former takes precedence over the latter when defined.
+            subpackages_trie.conf_if_hooked or
+            # A transitive parent package of that parent package if any.
+            subpackage_conf
+        )
+
+    # Return this beartype configuration if any *OR* "None" otherwise.
+    return subpackage_conf
+
+# ....................{ ITERATORS                          }....................
+#FIXME: Unit test us up, please.
+def iter_packages_trie(package_name: str) -> Iterable[PackagesTrie]:
+    '''
+    Generator iteratively yielding one **(sub)package configuration (sub)trie**
+    (i.e., :class:`PackagesTrie` instance) describing each transitive parent
+    package of the package with the passed name if that package *or* a parent
+    package of that package was registered by a prior call to the
+    :func:`beartype.claw._pkg.clawpkghook..hook_packages` function *or* the
+    empty iterable otherwise otherwise (i.e., if neither that package *nor* a
+    parent package of that package was registered by such a call).
+
+    Specifically, this generator yields (in order):
+
+    #. The subtrie of that trie configuring the root package of the passed
+       (sub)package.
+    #. And so on, until eventually yielding...
+    #. The subsubtrie of that subtrie configuring the passed (sub)package
+       itself.
+
+    This generator intentionally avoids yielding the global trie
+    :data:`.packages_trie`, which is already accessible via that global.
+
+    Parameters
+    ----------
+    package_name : str
+        Fully-qualified name of the package to be inspected.
+
+    Yields
+    ------
+    PackagesTrie
+        (Sub)package configuration (sub)trie describing the currently iterated
+        transitive parent package of the package with this name.
+    '''
+    assert isinstance(package_name, str), f'{repr(package_name)} not string.'
+
+    # Avoid circular import dependencies.
+    from beartype.claw._clawstate import (
+        claw_lock,
+        claw_state,
+    )
+
+    # List of each unqualified basename comprising this name, split from this
+    # fully-qualified name on "." delimiters. Note that the "str.split('.')" and
+    # "str.rsplit('.')" calls produce the exact same lists under all possible
+    # edge cases. We arbitrarily call the former rather than the latter for
+    # simplicity and readability.
+    package_basenames = package_name.split('.')
+
+    # With a submodule-specific thread-safe reentrant lock...
+    with claw_lock:
+        # Current subtrie of the global trie describing the currently iterated
+        # basename of this package, initialized to this global trie itself.
+        subpackages_trie: Optional[PackagesTrie] = claw_state.packages_trie
+
+        # For each unqualified basename of each parent package transitively
+        # containing this package (as well as that of that package itself)...
+        for package_basename in package_basenames:
+            # Current subtrie of that trie describing that parent package if
+            # that parent package was registered by a prior call to the
+            # hook_packages() function *OR* "None" otherwise (i.e., if that
+            # parent package has yet to be registered).
+            subpackages_trie = subpackages_trie.get(package_basename)  # type: ignore[union-attr]
+
+            # If that parent package has yet to be registered, halt iteration.
+            if subpackages_trie is None:
+                break
+            # Else, that parent package was previously registered.
+
+            # Yield the current subtrie describing that parent package.
+            yield subpackages_trie
+
+# ....................{ REMOVERS                           }....................
+#FIXME: Unit test us up, please.
+def remove_beartype_pathhook_unless_packages_trie() -> None:
+    '''
+    Remove our **beartype import path hook singleton** (i.e., single callable
+    guaranteed to be inserted at most once to the front of the standard
+    :mod:`sys.path_hooks` list recursively applying the
+    :func:`beartype.beartype` decorator to all well-typed callables and classes
+    defined by all submodules of all packages previously registered by a call to
+    a public :func:`beartype.claw` function) if this path hook has already been
+    added and all previously registered packages have been unregistered *or*
+    silently reduce to a noop otherwise (i.e., if either this path hook has yet
+    to be added or one or more packages are still registered).
+
+    Caveats
+    -------
+    **This function is non-thread-safe.** For both simplicity and efficiency,
+    the caller is expected to provide thread-safety through a higher-level
+    locking primitive managed by the caller.
+    '''
+
+    # If all previously registered packages have been unregistered, safely
+    # remove our import path hook from the "sys.path_hooks" list.
+    if not is_packages_trie():
+        remove_beartype_pathhook()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/__init__.py
@@ -0,0 +1,62 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype Decidedly Object-Oriented Runtime-checking (DOOR) API.**
+
+This subpackage provides an object-oriented type hint class hierarchy,
+encapsulating the crude non-object-oriented type hint declarative API
+standardized by the :mod:`typing` module.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Create one unique "TypeHint" subclass *FOR EACH UNIQUE KIND OF TYPE
+#HINT.* We're currently simply reusing the same
+#"_TypeHintOriginIsinstanceableArgs*" family of concrete subclasses to
+#transparently handle these unique kinds of type hints. That's fine as an
+#internal implementation convenience. Sadly, that's *NOT* fine for users
+#actually trying to introspect types. That's the great disadvantage of standard
+#"typing" types, after all; they're *NOT* introspectable by type. Ergo, we need
+#to explicitly define subclasses like:
+#* "beartype.door.ListTypeHint".
+#* "beartype.door.MappingTypeHint".
+#* "beartype.door.SequenceTypeHint".
+#
+#And so on. There are a plethora, but ultimately a finite plethora, which is all
+#that matters. Do this for our wonderful userbase, please.
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.door._cls.doorsuper import (
+    TypeHint as TypeHint)
+from beartype.door._doorcheck import (
+    die_if_unbearable as die_if_unbearable,
+    is_bearable as is_bearable,
+    is_subhint as is_subhint,
+)
+from beartype.door._cls.pep.doorpep484604 import (
+    UnionTypeHint as UnionTypeHint)
+from beartype.door._cls.pep.doorpep586 import (
+    LiteralTypeHint as LiteralTypeHint)
+from beartype.door._cls.pep.doorpep593 import (
+    AnnotatedTypeHint as AnnotatedTypeHint)
+from beartype.door._cls.pep.pep484.doorpep484class import (
+    ClassTypeHint as ClassTypeHint)
+from beartype.door._cls.pep.pep484.doorpep484newtype import (
+    NewTypeTypeHint as NewTypeTypeHint)
+from beartype.door._cls.pep.pep484.doorpep484typevar import (
+    TypeVarTypeHint as TypeVarTypeHint)
+from beartype.door._cls.pep.pep484585.doorpep484585callable import (
+    CallableTypeHint as CallableTypeHint)
+
+#FIXME: Actually, let's *NOT* publicly expose this for the moment. Why? Because
+#we still need to split this into fixed and variadic tuple subclasses.
+# from beartype.door._cls.pep.pep484585.doorpep484585tuple import (
+#     _TupleTypeHint as _TupleTypeHint)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/doormeta.py
@@ -0,0 +1,284 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype Decidedly Object-Oriented Runtime-checking (DOOR) metaclass
+hierarchy** (i.e., metaclass hierarchy driving our object-oriented type hint
+class hierarchy, especially with respect to instantiation, mapping, and
+memoization).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from abc import ABCMeta
+from beartype.typing import Any
+from beartype._cave._cavefast import NoneType
+from beartype._util.cache.map.utilmapbig import CacheUnboundedStrong
+from beartype._util.hint.utilhinttest import is_hint_uncached
+from threading import RLock
+
+# ....................{ METACLASSES                        }....................
+#FIXME: Unit test us up, please.
+class _TypeHintMeta(ABCMeta):
+    '''
+    **Singleton abstract base class (ABC) metaclass** (i.e., the standard
+    :class:`abc.ABCMeta` metaclass augmented with caching to implement the
+    singleton design pattern).
+
+    This metaclass is superior to the usual approach of implementing the
+    singleton design pattern: overriding the :meth:`__new__` method of a
+    singleton class to conditionally create a new instance of that class only if
+    an instance has *not* already been created. Why? Because that approach
+    unavoidably re-calls the :meth:`__init__` method of a previously initialized
+    singleton instance on each instantiation of that class. Doing so is
+    generally considered harmful.
+
+    This metaclass instead guarantees that the :meth:`__init__` method of a
+    singleton instance is only called exactly once on the first instantiation of
+    that class.
+
+    Attributes
+    ----------
+    __singleton : Optional[type]
+        Either:
+
+        * If the current singleton abstract base class (ABC) has been
+          initialized (i.e., if the :meth:`__init__` method of this metaclass
+          initializing that class with metaclass-specific logic) but a singleton
+          instance of that class has *not* yet been instantiated (i.e., if the
+          :meth:`__call__` method of this metaclass calling the :meth:`__new__`
+          and :meth:`__init__` methods of that class (in that order) has been
+          called), ``None``.
+        * Else, the current singleton ABC has been initialized and a singleton
+          instance of that class has been instantiated. In this case, that
+          instance.
+
+        For forward compatibility with future :class:`ABCMeta` changes, the name
+        of this instance variable is prefixed by ``"__"`` and thus implicitly
+        obfuscated by Python to be externally inaccessible.
+
+    See Also
+    ----------
+    https://stackoverflow.com/a/8665179/2809027
+        StackOverflow answers strongly inspiring this implementation.
+    '''
+
+    # ..................{ INSTANTIATORS                      }..................
+    def __call__(cls: '_TypeHintMeta', hint: object) -> Any:  # type: ignore[override]
+        '''
+        Factory constructor magically instantiating and returning a singleton
+        instance of the concrete subclass of the :class:`beartype.door.TypeHint`
+        abstract base class (ABC) appropriate for handling the passed low-level
+        type hint.
+
+        Parameters
+        ----------
+        cls : _TypeHintMeta
+            The :class:`beartype.door.TypeHint` ABC.
+        hint : object
+            Low-level type hint to be wrapped by a singleton
+            :class:`beartype.door.TypeHint` instance.
+
+        Raises
+        ----------
+        BeartypeDoorNonpepException
+            If this class does *not* currently support the passed hint.
+        BeartypeDecorHintPepSignException
+            If the passed hint is *not* actually a PEP-compliant type hint.
+        '''
+        # print(f'!!!!!!!!!!!!! [ in _TypeHintMeta.__call__(cls={repr(cls)}, hint={repr(hint)}) ] !!!!!!!!!!!!!!!')
+
+        # ................{ IMPORTS                            }................
+        # Avoid circular import dependencies.
+        from beartype.door._cls.doorsuper import TypeHint
+
+        # ................{ TRIVIALITIES                       }................
+        # If this class is a concrete subclass of the "TypeHint" abstract base
+        # class (ABC) rather than ABC itself, instantiate that subclass in the
+        # standard way.
+        if cls is not TypeHint:
+            # print('!!!!!!!!!!!!! [ _TypeHintMeta.__call__ ] instantiating subclass... !!!!!!!!!!!!!!!')
+            return super().__call__(hint)
+        # Else, this class is that ABC. In this case, instantiate that ABC in a
+        # non-standard way.
+        #
+        # If this low-level type hint is already a high-level type hint wrapper,
+        # return this wrapper as is. This guarantees the following constraint:
+        #     >>> TypeHint(TypeHint(hint)) is TypeHint(hint)
+        #     True
+        elif isinstance(hint, TypeHint):
+            # print('!!!!!!!!!!!!! [ _TypeHintMeta.__call__ ] reducing to noop... !!!!!!!!!!!!!!!')
+            return hint
+        # Else, this hint is *NOT* already a wrapper.
+
+        # ................{ CACHING                            }................
+        # Key uniquely identifying this hint, defined as either...
+        hint_key = (
+            # If this hint is *NOT* self-caching (i.e., *NOT* already internally
+            # cached by its parent class or module), the machine-readable
+            # representation of this hint. Computing this string consumes more
+            # time and space and is thus performed *ONLY* where required, which
+            # is for hints that are *NOT* already reduced to singleton objects.
+            #
+            # Note that this is *NOT* merely an optimization concern. Some
+            # PEP-compliant type hints have arbitrary caller-defined and thus
+            # possibly ambiguous representations. Ergo, the machine-readable
+            # representation of an arbitrary hint does *NOT* uniquely identify
+            # that hint in general and thus *CANNOT* be used to cache that hint.
+            # Class factories producing hints with such names include:
+            # * "typing.ParamSpec".
+            # * "typing.TypeVar".
+            repr(hint)
+            if is_hint_uncached(hint) else
+            # Else, this hint is self-caching and thus already reduced to a
+            # singleton object. In this case, the identifier identifying this
+            # singleton object.
+            id(hint)
+        )
+
+        # Type hint wrapper wrapping this hint, efficiently cached such that
+        # each hint that evaluates to the same key is wrapped by the same
+        # instance of the "TypeHint" class under this Python interpreter.
+        wrapper = (
+            _HINT_KEY_TO_WRAPPER.cache_or_get_cached_func_return_passed_arg(
+                # Cache this wrapper singleton under this key.
+                key=hint_key,
+                # If a wrapper singleton has yet to be instantiated for this
+                # hint, do so by calling this private factory method...
+                value_factory=cls._make_wrapper,
+                # ...with this hint passed as the sole parameter to that method.
+                arg=hint,
+            ))
+
+        # Return this wrapper.
+        return wrapper
+
+    # ..................{ PRIVATE                            }..................
+    def _make_wrapper(cls: '_TypeHintMeta', hint: object) -> object:
+        '''
+        **Type hint wrapper factory** (i.e., low-level private method creating
+        and returning a new :class:`beartype.door.TypeHint` instance wrapping
+        the passed type hint), intended to be called by the
+        :meth:`CacheUnboundedStrong.cache_or_get_cached_func_return_passed_arg`
+        method to create a new type hint wrapper singleton for the passed hint.
+
+        Parameters
+        ----------
+        cls : _TypeHintMeta
+            The :class:`beartype.door.TypeHint` ABC.
+        hint : object
+            Low-level type hint to be wrapped by a singleton
+            :class:`beartype.door.TypeHint` instance.
+
+        Raises
+        ----------
+        BeartypeDoorNonpepException
+            If this class does *not* currently support the passed hint.
+        BeartypeDecorHintPepSignException
+            If the passed hint is *not* actually a PEP-compliant type hint.
+        '''
+
+        # ................{ IMPORTS                            }................
+        # Avoid circular import dependencies.
+        from beartype.door._doordata import get_typehint_subclass
+
+        # ................{ REDUCTION                          }................
+        # Reduce this hint to a more amenable form suitable for mapping to a
+        # concrete "TypeHint" subclass if desired.
+        #
+        # Note that this reduction intentionally ignores the entire
+        # "beartype._check.convert" subpackage. Although submodules of that
+        # subpackage do perform various coercions, reductions, and sanitizations
+        # of low-level PEP-compliant type hints, they do so only for the express
+        # purpose of dynamic code generation. That subpackage is *NOT*
+        # general-purpose and is, in fact, harmful in this context. Why? Because
+        # that subpackage erodes the semantic meaning from numerous type hints
+        # that this subpackage necessarily preserves.
+        #
+        # ................{ REDUCTION ~ pep 484 : none         }................
+        # If this is the PEP 484-compliant "None" singleton, reduce this hint to
+        # the type of that singleton. While *NOT* explicitly defined by the
+        # "typing" module, PEP 484 explicitly supports this singleton:
+        #     When used in a type hint, the expression None is considered
+        #     equivalent to type(None).
+        #
+        # The "None" singleton is used to type callables lacking an explicit
+        # "return" statement and thus absurdly common. Ergo, detect this early.
+        if hint is None:
+            hint = NoneType  # pyright: ignore[reportGeneralTypeIssues]
+        # Else, this is *NOT* the PEP 484-compliant "None" singleton.
+
+        # ................{ INSTANTIATION                      }................
+        # Concrete "TypeHint" subclass handling this hint if this hint is
+        # supported by an existing "TypeHint" subclass *OR* raise an exception
+        # otherwise (i.e., if this hint is currently unsupported).
+        wrapper_subclass = get_typehint_subclass(hint)
+        # print(f'!!!!!!!!!!!!! [ in {repr(cls)}.__new__() ] !!!!!!!!!!!!!!!')
+
+        # Type hint wrapper wrapping this hint as a new singleton instance of
+        # this subclass.
+        wrapper = wrapper_subclass(hint)
+        # wrapper = super(_TypeHintMeta, wrapper_subclass).__call__(hint)
+        # print('!!!!!!!!!!!!! [ _TypeHintMeta.__call__ ] caching and returning singleton... !!!!!!!!!!!!!!!')
+
+        # Return this wrapper.
+        return wrapper
+
+# ....................{ PRIVATE ~ mappings                 }....................
+_HINT_KEY_TO_WRAPPER = CacheUnboundedStrong(
+    # Prefer the slower reentrant lock type for safety. As the subpackage name
+    # implies, the DOOR API is fundamentally recursive and requires reentrancy.
+    lock_type=RLock,
+)
+'''
+**Type hint wrapper cache** (i.e., non-thread-safe cache mapping from the
+machine-readable representations of all type hints to cached singleton instances
+of concrete subclasses of the :class:`beartype.door.TypeHint` abstract base
+class (ABC) wrapping those hints).
+
+Design
+--------------
+**This dictionary is intentionally thread-safe.** Why? Because this dictionary
+is used to ensure that :class:`beartype.door.TypeHint` instances are singletons,
+enabling callers to reliably implement higher-level abstractions memoized (i.e.,
+cached) against these singletons. Those abstractions could be module-scoped and
+thus effectively global. To prevent race conditions between competing threads
+contending over those globals, this dictionary *must* be thread-safe.
+
+**This dictionary is intentionally designed as a naive dictionary rather than a
+robust LRU cache,** for the same reasons that callables accepting hints are
+memoized by the :func:`beartype._util.cache.utilcachecall.callable_cached`
+rather than the :func:`functools.lru_cache` decorator. Why? Because:
+
+* The number of different type hints instantiated across even worst-case
+  codebases is negligible in comparison to the space consumed by those hints.
+* The :attr:`sys.modules` dictionary persists strong references to all
+  callables declared by previously imported modules. In turn, the
+  ``func.__annotations__`` dunder dictionary of each such callable persists
+  strong references to all type hints annotating that callable. In turn, these
+  two statements imply that type hints are *never* garbage collected but
+  instead persisted for the lifetime of the active Python process. Ergo,
+  temporarily caching hints in an LRU cache is pointless, as there are *no*
+  space savings in dropping stale references to unused hints.
+
+**This dictionary intentionally caches machine-readable representation strings
+hashes rather than alternative keys** (e.g., actual hashes). Why? Disambiguity.
+Although comparatively less efficient in both space and time to construct than
+hashes, the :func:`repr` strings produced for two dissimilar type hints *never*
+ambiguously collide unless an external caller maliciously modified one or more
+identifying dunder attributes of those hints (e.g., the ``__module__``,
+``__qualname__``, and/or ``__name__`` dunder attributes). That should *never*
+occur in production code. Meanwhile, the :func:`hash` values produced for two
+dissimilar type hints *commonly* ambiguously collide. This is why hashable
+containers (e.g., :class:`dict`, :class:`set`) explicitly handle hash table
+collisions and why we are *not* going to do so.
+
+Likewise, this dictionary intentionally caches machine-readable representations
+of low-level type hints rather than those hints themselves. Since increasingly
+many hints are no longer self-caching (e.g., PEP 585-compliant type hints like
+"list[str]"), the latter *CANNOT* be guaranteed to be singletons and thus safely
+used as cache keys. Also:
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/doorsub.py
@@ -0,0 +1,168 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **Decidedly Object-Oriented Runtime-checking (DOOR) middle-men
+subclasses** (i.e., abstract subclasses of the object-oriented type hint class
+hierarchy simplifying the definition of concrete subclasses of this hierarchy).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from abc import abstractmethod
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.roar import BeartypeDoorException
+# from beartype.typing import (
+#     Any,
+# )
+# from beartype._util.cache.utilcachecall import property_cached
+# from beartype._util.cls.utilclstest import is_type_subclass
+
+# ....................{ SUBCLASSES                         }....................
+#FIXME: Excise us up, please. Globally replace all instances of
+#"_TypeHintSubscripted" with simply "TypeHint".
+class _TypeHintSubscripted(TypeHint):
+    '''
+    **Subscripted type hint wrapper** (i.e., high-level object encapsulating a
+    low-level parent type hint subscripted (indexed) by one or more equally
+    low-level children type hints).
+    '''
+
+    pass
+
+# ....................{ SUBCLASSES ~ isinstanceable        }....................
+class _TypeHintOriginIsinstanceable(_TypeHintSubscripted):
+    '''
+    **Isinstanceable type hint wrapper** (i.e., high-level object
+    encapsulating a low-level parent type hint subscripted (indexed) by exactly
+    one or more low-level child type hints originating from isinstanceable
+    classes such that *all* objects satisfying those hints are instances of
+    those class).
+    '''
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    @abstractmethod
+    def _args_len_expected(self) -> int:
+        '''
+        Number of child type hints that this instance of a concrete subclass of
+        this abstract base class (ABC) is expected to be subscripted (indexed)
+        by.
+        '''
+
+        pass
+
+    # ..................{ PRIVATE ~ factories                }..................
+    def _make_args(self) -> tuple:
+
+        # Tuple of the zero or more low-level child type hints subscripting
+        # (indexing) the low-level parent type hint wrapped by this wrapper.
+        args = super()._make_args()
+
+        # If this hint was subscripted by an unexpected number of child hints...
+        if len(args) != self._args_len_expected:
+            #FIXME: This seems sensible, but currently provokes test failures.
+            #Let's investigate further at a later time, please.
+            # # If this hint was subscripted by *NO* parameters, comply with PEP
+            # # 484 standards by silently pretending this hint was subscripted by
+            # # the "typing.Any" fallback for all missing parameters.
+            # if len(self._args) == 0:
+            #     return (Any,)*self._args_len_expected
+
+            #FIXME: Consider raising a less ambiguous exception type, yo.
+            #FIXME: Consider actually testing this. This *IS* technically
+            #testable and should thus *NOT* be marked as "pragma: no cover".
+
+            # In most cases it will be hard to reach this exception, since most
+            # of the typing library's subscripted type hints will raise an
+            # exception if constructed improperly.
+            raise BeartypeDoorException(  # pragma: no cover
+                f'{type(self)} type must have {self._args_len_expected} '
+                f'argument(s), but got {len(args)}.'
+            )
+        # Else, this hint was subscripted by the expected number of child hints.
+
+        # Return these child hints.
+        return args
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    # Note that this redefinition of the superclass _is_equal() method is
+    # technically unnecessary, as that method is already sufficiently
+    # general-purpose to suffice for *ALL* possible subclasses (including this
+    # subclass). Nonetheless, we wrote this method first. More importantly, this
+    # method is *SUBSTANTIALLY* faster than the superclass method. Although
+    # efficiency is typically *NOT* a pressing concern for the DOOR API,
+    # discarding faster working code would be senseless.
+    def _is_equal(self, other: TypeHint) -> bool:
+
+        # If *ALL* of the child type hints subscripting both of these parent
+        # type hints are ignorable, return true only if these parent type hints
+        # both originate from the same isinstanceable class.
+        if self._is_args_ignorable and other._is_args_ignorable:
+            return self._origin == other._origin
+        # Else, one or more of the child type hints subscripting either of these
+        # parent type hints are unignorable.
+        #
+        # If either...
+        elif (
+            # These hints have differing signs *OR*...
+            self._hint_sign is not other._hint_sign or
+            # These hints have a differing number of child type hints...
+            len(self._args_wrapped_tuple) != len(other._args_wrapped_tuple)
+        ):
+            # Then these hints are unequal.
+            return False
+        # Else, these hints share the same sign and number of child type hints.
+
+        # Return true only if all child type hints of these hints are equal.
+        return all(
+            this_child == that_child
+            #FIXME: Probably more efficient and maintainable to write this as:
+            #    for this_child in self
+            #    for that_child in other
+            for this_child, that_child in zip(
+                self._args_wrapped_tuple, other._args_wrapped_tuple)
+        )
+
+
+class _TypeHintOriginIsinstanceableArgs1(_TypeHintOriginIsinstanceable):
+    '''
+    **1-argument isinstanceable type hint wrapper** (i.e., high-level object
+    encapsulating a low-level parent type hint subscripted (indexed) by exactly
+    one low-level child type hint originating from an isinstanceable class such
+    that *all* objects satisfying that hint are instances of that class).
+    '''
+
+    @property
+    def _args_len_expected(self) -> int:
+        return 1
+
+
+class _TypeHintOriginIsinstanceableArgs2(_TypeHintOriginIsinstanceable):
+    '''
+    **2-argument isinstanceable type hint wrapper** (i.e., high-level object
+    encapsulating a low-level parent type hint subscripted (indexed) by exactly
+    two low-level child type hints originating from isinstanceable classes such
+    that *all* objects satisfying those hints are instances of those classes).
+    '''
+
+    @property
+    def _args_len_expected(self) -> int:
+        return 2
+
+
+class _TypeHintOriginIsinstanceableArgs3(_TypeHintOriginIsinstanceable):
+    '''
+    **3-argument isinstanceable type hint wrapper** (i.e., high-level object
+    encapsulating a low-level parent type hint subscripted (indexed) by exactly
+    three low-level child type hints originating from isinstanceable classes
+    such that *all* objects satisfying those hints are instances of those
+    classes).
+    '''
+
+    @property
+    def _args_len_expected(self) -> int:
+        return 3
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/doorsuper.py
@@ -0,0 +1,935 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **Decidedly Object-Oriented Runtime-checking (DOOR) superclass**
+(i.e., root of the object-oriented type hint class hierarchy encapsulating the
+non-object-oriented type hint API standardized by the :mod:`typing` module).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Slot "TypeHint" attributes for lookup efficiency, please.
+#FIXME: Privatize most (...or perhaps all) public instance variables, please.
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._doorcheck import (
+    die_if_unbearable,
+    is_bearable,
+)
+from beartype.door._cls.doormeta import _TypeHintMeta
+from beartype.door._doortest import die_unless_typehint
+from beartype.typing import (
+    Any,
+    FrozenSet,
+    Generic,
+    Iterable,
+    Tuple,
+    overload,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._data.hint.datahinttyping import T
+from beartype._util.cache.utilcachecall import (
+    method_cached_arg_by_id,
+    property_cached,
+)
+from beartype._util.hint.pep.utilpepget import (
+    get_hint_pep_args,
+    get_hint_pep_origin_type_or_none,
+    get_hint_pep_sign_or_none,
+)
+from beartype._util.hint.utilhinttest import is_hint_ignorable
+from beartype._util.utilobject import get_object_type_basename
+
+# ....................{ SUPERCLASSES                       }....................
+#FIXME: Subclass all applicable "collections.abc" ABCs for explicitness, please.
+#FIXME: Document all public and private attributes of this class, please.
+class TypeHint(Generic[T], metaclass=_TypeHintMeta):
+    '''
+    Abstract base class (ABC) of all **type hint wrapper** (i.e., high-level
+    object encapsulating a low-level type hint augmented with a magically
+    object-oriented Pythonic API, including equality and rich comparison
+    testing) subclasses.
+
+    Sorting
+    -------
+    **Type hint wrappers are partially ordered** with respect to one another.
+    Type hints wrappers support all binary comparators (i.e., ``==``, ``!=``,
+    ``<``, ``<=``, ``>``, and ``>=``) such that for any three type hint wrappers
+    ``a``, ``b`, and ``c``:
+
+    * ``a ≤ a`` (i.e., **reflexivity**).
+    * If ``a ≤ b`` and ``b ≤ c``, then ``a ≤ c`` (i.e., **transitivity**).
+    * If ``a ≤ b`` and ``b ≤ a``, then ``a == b`` (i.e., **antisymmetry**).
+
+    **Type hint wrappers are not totally ordered,** however. Like unordered
+    sets, type hint wrappers do *not* satisfy **totality** (i.e., either ``a ≤
+    b`` or ``b ≤ a``, which is *not* necessarily the case for incommensurable
+    type hint wrappers that *cannot* reasonably be compared with one another).
+
+    Type hint wrappers are thus usable in algorithms and data structures
+    requiring at most a partial ordering over their input.
+
+    Examples
+    --------
+    .. code-block:: pycon
+
+       >>> from beartype.door import TypeHint
+       >>> hint_a = TypeHint(Callable[[str], list])
+       >>> hint_b = TypeHint(Callable[Union[int, str], Sequence[Any]])
+       >>> hint_a <= hint_b
+       True
+       >>> hint_a > hint_b
+       False
+       >>> hint_a.is_subhint(hint_b)
+       True
+       >>> list(hint_b)
+       [TypeHint(typing.Union[int, str]), TypeHint(typing.Sequence[typing.Any])]
+
+    Attributes
+    ----------
+    _args : Tuple[object, ...]
+        Tuple of the zero or more low-level child type hints subscripting
+        (indexing) the low-level parent type hint wrapped by this wrapper.
+    _hint : T
+        Low-level type hint wrapped by this wrapper.
+    _hint_sign : beartype._data.hint.pep.sign.datapepsigncls.HintSign | None
+        Either:
+
+        * If this hint is PEP-compliant and thus uniquely identified by a
+          :mod:`beartype`-specific sign, that sign.
+        * Else (i.e., if this hint is an isinstanceable class), :data:`None`.
+    _origin: type
+        Either:
+
+        * If this hint originates from an **isinstanceable class** such that all
+          objects satisfying this hint are instances of that class, that class.
+        * Else, the root superclass :class:`object` of *all* classes,
+          guaranteeing sanity when this instance variable is passed as either
+          the first or second parameters to the :func:`issubclass` builtin.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, hint: T) -> None:
+        '''
+        Initialize this type hint wrapper from the passed low-level type hint.
+
+        Parameters
+        ----------
+        hint : object
+            Low-level type hint to be wrapped by this wrapper.
+        '''
+
+        # Classify all passed parameters. Note that this type hint is guaranteed
+        # to be a type hint by validation performed by this metaclass __init__()
+        # method.
+        self._hint = hint
+
+        # Sign uniquely identifying this and that hint if any *OR* "None"
+        self._hint_sign = get_hint_pep_sign_or_none(hint)
+
+        # Isinstance class originating this hint if any *OR* "None" otherwise,
+        # defined as either...
+        self._origin: type = (
+            # If this hint originates from an origin type, that type;
+            get_hint_pep_origin_type_or_none(hint) or
+            # Else, this hint does *NOT* originate from an origin type. In this
+            # case, the root superclass "object" of *ALL* classes, guaranteeing
+            # sanity when this instance variable is passed as either the first
+            # or second parameters to the issubclass() builtin.
+            object
+        )
+
+        # Tuple of all low-level child type hints of this hint.
+        self._args = self._make_args()
+
+    # ..................{ DUNDERS                            }..................
+    def __hash__(self) -> int:
+        '''
+        Hash of the low-level immutable type hint wrapped by this immutable
+        wrapper.
+
+        Defining this method satisfies the :class:`collections.abc.Hashable`
+        abstract base class (ABC), enabling this wrapper to be used as in
+        hashable containers (e.g., dictionaries, sets).
+        '''
+
+        return hash(self._hint)
+
+
+    def __repr__(self) -> str:
+        '''
+        Machine-readable representation of this type hint wrapper.
+        '''
+
+        # Unqualified name of the concrete subclass wrapping this hint.
+        hint_wrapper_basename = get_object_type_basename(self)
+
+        # If this concrete subclass is currently private, deviously hide this
+        # implementation detail by defaulting to the unqualified name of this
+        # public "TypeHint" superclass instead.
+        if hint_wrapper_basename[0] == '_':
+            hint_wrapper_basename = 'TypeHint'
+        # Else, this concrete subclass is public.
+
+        # Return this machine-readable representation.
+        return f'{hint_wrapper_basename}({repr(self._hint)})'
+
+    # ..................{ DUNDERS ~ compare : equals         }..................
+    # Note that we intentionally avoid typing this method as returning
+    # "Union[bool, NotImplementedType]". Why? Because mypy in particular has
+    # epileptic fits about "NotImplementedType". This is *NOT* worth the agony!
+    @method_cached_arg_by_id
+    def __eq__(self, other: object) -> bool:
+        '''
+        ``True`` only if the low-level type hint wrapped by this wrapper is
+        semantically equivalent to the other low-level type hint wrapped by the
+        passed wrapper.
+
+        This tester is memoized for efficiency, as Python implicitly calls this
+        dunder method on hashable-based container lookups (e.g.,
+        :meth:`dict.get`) expected to be ``O(1)`` fast.
+
+        Parameters
+        ----------
+        other : object
+            Other type hint to be tested against this type hint.
+
+        Returns
+        -------
+        bool
+            ``True`` only if this type hint is equal to that other hint.
+        '''
+
+        # If that object is *NOT* a type hint wrapper, defer to either:
+        # * If the class of that object defines a similar __eq__() method
+        #   supporting the "TypeHint" API, that method.
+        # * Else, Python's builtin C-based fallback equality comparator that
+        #   merely compares whether two objects are identical (i.e., share the
+        #   same object ID).
+        if not isinstance(other, TypeHint):
+            return NotImplemented
+        # Else, that object is also a type hint wrapper.
+
+        # Defer to the subclass-specific implementation of this test.
+        return self._is_equal(other)
+
+
+    def __ne__(self, other: object) -> bool:
+        return not (self == other)
+
+    # ..................{ DUNDERS ~ compare : rich           }..................
+    def __le__(self, other: object) -> bool:
+        '''
+        :data:`True` if this hint is a subhint of the passed hint.
+        '''
+
+        if not isinstance(other, TypeHint):
+            return NotImplemented
+
+        return self.is_subhint(other)
+
+
+    def __lt__(self, other: object) -> bool:
+        '''
+        :data:`True` if this hint is a strict subhint of the passed hint.
+        '''
+
+        if not isinstance(other, TypeHint):
+            return NotImplemented
+
+        return self.is_subhint(other) and self != other
+
+
+    def __ge__(self, other: object) -> bool:
+        '''
+        :data:`True` if this hint is a superhint of the passed hint.
+        '''
+
+        if not isinstance(other, TypeHint):
+            return NotImplemented
+
+        return self.is_superhint(other)
+
+
+    def __gt__(self, other: object) -> bool:
+        '''
+        :data:`True` if this hint is a strict superhint of the passed hint.
+        '''
+
+        if not isinstance(other, TypeHint):
+            return NotImplemented
+
+        return self.is_superhint(other) and self != other
+
+    # ..................{ DUNDERS ~ iterable                 }..................
+    def __contains__(self, hint_child: 'TypeHint') -> bool:
+        '''
+        :data:`True` only if the low-level type hint wrapped by the passed
+        **type hint wrapper** (i.e., :class:`TypeHint` instance) is a child type
+        hint originally subscripting the low-level parent type hint wrapped by
+        this :class:`TypeHint` instance.
+        '''
+
+        # Sgt. Pepper's One-liners GitHub Club Band.
+        return hint_child in self._args_wrapped_frozenset
+
+
+    def __iter__(self) -> Iterable['TypeHint']:
+        '''
+        Generator iteratively yielding all **children type hint wrappers**
+        (i.e., :class:`TypeHint` instances wrapping all low-level child type
+        hints originally subscripting the low-level parent type hint wrapped by
+        this :class:`TypeHint` instance).
+
+        Defining this method satisfies the :class:`collections.abc.Iterable`
+        abstract base class (ABC).
+        '''
+
+        # For those who are about to one-liner, we salute you.
+        yield from self._args_wrapped_tuple
+
+    # ..................{ DUNDERS ~ iterable : item          }..................
+    # Inform static type-checkers of the one-to-one correspondence between the
+    # type of the object subscripting an instance of this class with the type of
+    # the object returned by that subscription. Note this constraint is strongly
+    # inspired by this erudite StackOverflow answer:
+    #     https://stackoverflow.com/a/71183076/2809027
+
+    @overload
+    def __getitem__(self, index: int) -> 'TypeHint': ...
+    @overload
+    def __getitem__(self, index: slice) -> Tuple['TypeHint', ...]: ...
+
+    # Note that the actual implementation of this overload is intentionally:
+    # * *NOT* decorated by the standard @overload decorator.
+    # * *NOT* annotated by type hints. By PEP 484, only the signatures of
+    #   @overload-decorated callables are annotated by type hints.
+    def __getitem__(self, index):
+        '''
+        Either:
+
+        * If the passed object is an integer, then this type hint wrapper was
+          subscripted by either a positive 0-based absolute index or a negative
+          -1-based relative index. In either case, this dunder method returns
+          the **child type hint wrapper** (i.e., :class:`TypeHint` instance
+          wrapping a low-level child type hint originally subscripting the
+          low-level parent type hint wrapped by this :class:`TypeHint` instance)
+          with the same index.
+        * If the passed object is a slice, then this type hint wrapper was
+          subscripted by a range of such indices. In this case, this dunder
+          method returns a tuple of the zero or more child type hint wrappers
+          with the same indices.
+
+        Parameters
+        ----------
+        index : Union[int, slice]
+            Either:
+
+            * Positive 0-based absolute index or negative -1-based relative
+              index of the child type hint originally subscripting the parent
+              type hint wrapped by this :class:`TypeHint` instance to be
+              returned wrapped by a new :class:`TypeHint` instance.
+            * Slice of such indices of the zero or more child type hints
+              originally subscripting the parent type hint wrapped by this
+              :class:`TypeHint` instance to be returned in a tuple of these
+              child type hints wrapped by new :class:`TypeHint` instances.
+
+        Returns
+        -------
+        Union['TypeHint', Tuple['TypeHint', ...]]
+            Child type hint wrapper(s) at these ind(ex|ices), as detailed above.
+        '''
+
+        # Defer validation of the correctness of the passed index or slice to
+        # the low-level tuple.__getitem__() dunder method. Though we could (and
+        # possibly should) perform that validation here, doing so is non-trivial
+        # in the case of both a negative relative index *AND* a passed slice.
+        # This trivial approach suffices for now.
+        return self._args_wrapped_tuple[index]
+
+    # ..................{ DUNDERS ~ iterable : sized         }..................
+    #FIXME: Unit test us up, please.
+    def __bool__(self) -> bool:
+        '''
+        :data:`True` only if the low-level parent type hint wrapped by this
+        wrapper was subscripted by at least one child type hint.
+        '''
+
+        # See __len__() for further commentary.
+        return bool(self._args_wrapped_tuple)
+
+
+    #FIXME: Unit test us up, please.
+    def __len__(self) -> int:
+        '''
+        Number of low-level child type hints subscripting the low-level parent
+        type hint wrapped by this wrapper.
+
+        Defining this method satisfies the :class:`collections.abc.Sized`
+        abstract base class (ABC).
+        '''
+
+        # Return the exact length of the same iterable returned by the
+        # __iter__() dunder method rather than the possibly differing length of
+        # the "self._args" tuple, for safety. Theoretically, these two iterables
+        # should exactly coincide in length. Pragmatically, it's best to assume
+        # nothing in the murky waters we swim in.
+        return len(self._args_wrapped_tuple)
+
+    # ..................{ PROPERTIES ~ read-only             }..................
+    # Read-only properties intentionally defining *NO* corresponding setter.
+
+    #FIXME: Unit test us up, please.
+    @property
+    def args(self) -> tuple:
+        '''
+        Tuple of the zero or more low-level child type hints subscripting
+        (indexing) the low-level parent type hint wrapped by this wrapper.
+        '''
+
+        # Who could argue with a working one-liner? Not you. Surely, not you.
+        return self._args
+
+
+    @property
+    def hint(self) -> T:
+        '''
+        **Original type hint** (i.e., low-level PEP-compliant type hint wrapped
+        by this wrapper at :meth:`TypeHint.__init__` instantiation time).
+        '''
+
+        # Q: Can one-liners solve all possible problems? A: Yes.
+        return self._hint
+
+
+    @property
+    def is_ignorable(self) -> bool:
+        '''
+        :data:`True` only if this type hint is **ignorable** (i.e., conveys
+        *no* meaningful semantics despite superficially appearing to do so).
+
+        While one might expect the set of all ignorable type hints to be both
+        finite and small, this set is actually **countably infinite** in size.
+        Countably infinitely many type hints are ignorable. This includes:
+
+        * :attr:`typing.Any`, by design.
+        * :class:`object`, the root superclass of all types. Ergo, parameters
+          and return values annotated as :class:`object` unconditionally match
+          *all* objects under :func:`isinstance`-based type covariance and thus
+          semantically reduce to unannotated parameters and return values.
+        * The unsubscripted :attr:`typing.Optional` singleton, which
+          semantically expands to the implicit ``Optional[Any]`` type hint under
+          :pep:`484`. Since :pep:`484` also stipulates that all ``Optional[t]``
+          type hints semantically expand to ``Union[t, type(None)]`` type hints
+          for arbitrary arguments ``t``, ``Optional[Any]`` semantically expands
+          to merely ``Union[Any, type(None)]``. Since all unions subscripted by
+          :attr:`typing.Any` semantically reduce to merely :attr:`typing.Any`,
+          the unsubscripted :attr:`typing.Optional` singleton also reduces to
+          merely :attr:`typing.Any`. This intentionally excludes the
+          ``Optional[type(None)]`` type hint, which the :mod:`typing` module
+          reduces to merely ``type(None)``.
+        * The unsubscripted :attr:`typing.Union` singleton, which
+          semantically reduces to :attr:`typing.Any` by the same argument.
+        * Any subscription of :attr:`typing.Union` by one or more ignorable type
+          hints. There exists a countably infinite number of such subscriptions,
+          many of which are non-trivial to find by manual inspection. The
+          ignorability of a union is a transitive property propagated "virally"
+          from child to parent type hints. Consider:
+
+          * ``Union[Any, bool, str]``. Since :attr:`typing.Any` is ignorable,
+            this hint is trivially ignorable by manual inspection.
+          * ``Union[str, List[int], NewType('MetaType', Annotated[object,
+            53])]``. Although several child type hints of this union are
+            non-ignorable, the deeply nested :class:`object` child type hint is
+            ignorable by the argument above. It transitively follows that the
+            ``Annotated[object, 53]`` parent type hint subscripted by
+            :class:`object`, the :obj:`typing.NewType` parent type hint aliased
+            to ``Annotated[object, 53]``, *and* the entire union subscripted by
+            that :obj:`typing.NewType` are themselves all ignorable as well.
+
+        * Any subscription of :attr:`typing.Annotated` by one or more ignorable
+          type hints. As with :attr:`typing.Union`, there exists a countably
+          infinite number of such subscriptions. (See the prior item.)
+        * The :class:`typing.Generic` and :class:`typing.Protocol` superclasses,
+          both of which impose no constraints *in and of themselves.* Since all
+          possible objects satisfy both superclasses. Both superclasses are
+          synonymous to the ignorable :class:`object` root superclass: e.g.,
+
+          .. code-block:: pycon
+
+             >>> from typing as Protocol
+             >>> isinstance(object(), Protocol)
+             True
+             >>> isinstance('wtfbro', Protocol)
+             True
+             >>> isinstance(0x696969, Protocol)
+             True
+
+        * Any subscription of either the :class:`typing.Generic` or
+          :class:`typing.Protocol` superclasses, regardless of whether the child
+          type hints subscripting those superclasses are ignorable or not.
+          Subscripting a type that conveys no meaningful semantics continues to
+          convey no meaningful semantics. For example, the type hints
+          ``typing.Generic[typing.Any]`` and ``typing.Generic[str]`` are both
+          equally ignorable – despite the :class:`str` class being otherwise
+          unignorable in most type hinting contexts.
+        * And frankly many more. And... *now we know why this tester exists.*
+
+        This property is memoized for efficiency.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this type hint is ignorable.
+        '''
+
+        # Mechanic: Somebody set up us the bomb.
+        return is_hint_ignorable(self._hint)
+
+    # ..................{ CHECKERS                           }..................
+    def die_if_unbearable(
+        self,
+
+        # Mandatory flexible parameters.
+        obj: object,
+
+        # Optional keyword-only parameters.
+        *,
+        conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+        exception_prefix: str = 'die_if_unbearable() ',
+    ) -> None:
+        '''
+        Raise an exception if the passed arbitrary object violates this type
+        hint under the passed beartype configuration.
+
+        To configure the type of violation exception raised by this method, set
+        the :attr:`.BeartypeConf.violation_door_type` option of the passed
+        ``conf`` parameter accordingly.
+
+        Parameters
+        ----------
+        obj : object
+            Arbitrary object to be tested against this hint.
+        conf : BeartypeConf, optional
+            **Beartype configuration** (i.e., self-caching dataclass
+            encapsulating all settings configuring type-checking for the passed
+            object). Defaults to ``BeartypeConf()``, the default ``O(1)``
+            constant-time configuration.
+        exception_prefix : str, optional
+            Human-readable label prefixing the representation of this object in
+            the exception message. Defaults to a reasonably sensible string.
+
+        Raises
+        ------
+        ``conf.violation_door_type``
+            If this object violates this hint.
+        beartype.roar.BeartypeDecorHintNonpepException
+            If this hint is *not* PEP-compliant (i.e., complies with *no* Python
+            Enhancement Proposals (PEPs) currently supported by
+            :mod:`beartype`).
+        beartype.roar.BeartypeDecorHintPepUnsupportedException
+            If this hint is currently unsupported by :mod:`beartype`.
+
+        Examples
+        --------
+        .. code-block:: pycon
+
+           >>> from beartype.door import TypeHint
+           >>> TypeHint(list[str]).die_if_unbearable(
+           ...     ['And', 'what', 'rough', 'beast,'], )
+           >>> TypeHint(list[str]).die_if_unbearable(
+           ...     ['its', 'hour', 'come', 'round'], list[int])
+           beartype.roar.BeartypeDoorHintViolation: Object ['its', 'hour',
+           'come', 'round'] violates type hint list[int], as list index 0 item
+           'its' not instance of int.
+        '''
+
+        # One-liner, one love, one heart. Let's get together and code alright.
+        die_if_unbearable(
+            obj=obj,
+            hint=self._hint,
+            conf=conf,
+            exception_prefix=exception_prefix,
+        )
+
+
+    def is_bearable(
+        self,
+
+        # Mandatory flexible parameters.
+        obj: object,
+
+        # Optional keyword-only parameters.
+        *, conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+    ) -> bool:
+        '''
+        :data:`True` only if the passed arbitrary object satisfies this type
+        hint under the passed beartype configuration.
+
+        Parameters
+        ----------
+        obj : object
+            Arbitrary object to be tested against this hint.
+        conf : BeartypeConf, optional
+            **Beartype configuration** (i.e., self-caching dataclass
+            encapsulating all settings configuring type-checking for the passed
+            object). Defaults to ``BeartypeConf()``, the default
+            constant-time configuration.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this object satisfies this hint.
+
+        Raises
+        ------
+        beartype.roar.BeartypeDecorHintForwardRefException
+            If this hint contains one or more relative forward references, which
+            this tester explicitly prohibits to improve both the efficiency and
+            portability of calls to this tester.
+
+        Examples
+        --------
+        .. code-block:: python
+
+           >>> from beartype.door import TypeHint
+           >>> TypeHint(list[str]).is_bearable(['Things', 'fall', 'apart;'])
+           True
+           >>> TypeHint(list[int]).is_bearable(
+           ...     ['the', 'centre', 'cannot', 'hold;'])
+           False
+        '''
+
+        # One-liners justify their own existence.
+        return is_bearable(obj=obj, hint=self._hint, conf=conf)
+
+    # ..................{ TESTERS ~ subhint                  }..................
+    # Note that the @method_cached_arg_by_id rather than @callable_cached
+    # decorator is *ABSOLUTELY* required here. Why? Because the @callable_cached
+    # decorator internally caches the passed "other" argument as the key of a
+    # dictionary. Subsequent calls to this method when passed the same argument
+    # lookup that "other" in that dictionary. Since dictionary lookups
+    # implicitly call other.__eq__() to resolve key collisions *AND* since the
+    # TypeHint.__eq__() method calls TypeHint.is_subhint(), infinite recursion!
+    @method_cached_arg_by_id
+    def is_subhint(self, other: 'TypeHint') -> bool:
+        '''
+        :data:`True` only if this type hint is a **subhint** of the passed type
+        hint.
+
+        This tester method is memoized for efficiency.
+
+        Parameters
+        ----------
+        other : TypeHint
+            Other type hint to be tested against this type hint.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this type hint is a subhint of that other hint.
+
+        See Also
+        --------
+        :func:`beartype.door.is_subhint`
+            Further details.
+        '''
+
+        # If the passed object is *NOT* a type hint wrapper, raise an exception.
+        die_unless_typehint(other)
+        # Else, that object is a type hint wrapper.
+
+        # Return true only if either...
+        return (
+            # That other hint is the "typing.Any" catch-all. By definition, that
+            # hint is the superhint of *ALL* hints -- including "typing.Any"
+            # itself. Ergo, this hint is necessarily a subhint of that hint.
+            other._hint is Any or
+            # Else, that other hint is *NOT* the "typing.Any" catch-all. In this
+            # case, defer to the subclass-specific implementation of this test.
+            self._is_subhint(other)
+        )
+
+
+    def is_superhint(self, other: 'TypeHint') -> bool:
+        '''
+        :data:`True` only if this type hint is a **superhint** of the passed
+        type hint.
+
+        This tester method is memoized for efficiency.
+
+        Parameters
+        ----------
+        other : TypeHint
+            Other type hint to be tested against this type hint.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this type hint is a superhint of that other
+            hint.
+
+        See Also
+        --------
+        :func:`beartype.door.is_subhint`
+            Further details.
+        '''
+
+        # If the passed object is *NOT* a type hint wrapper, raise an exception.
+        die_unless_typehint(other)
+        # Else, that object is a type hint wrapper.
+
+        # Return true only if this hint is a superhint of the passed hint.
+        return other.is_subhint(self)
+
+    # ..................{ PRIVATE                            }..................
+    # Subclasses are encouraged to override these concrete methods defaulting to
+    # general-purpose implementations suitable for most subclasses.
+
+    # ..................{ PRIVATE ~ factories                }..................
+    def _make_args(self) -> tuple:
+        '''
+        Tuple of the zero or more low-level child type hints subscripting
+        (indexing) the low-level parent type hint wrapped by this wrapper, which
+        the :meth:`TypeHint.__init__` method assigns to the :attr:`_args`
+        instance variable of this wrapper.
+
+        Subclasses are advised to override this method to set the :attr:`_args`
+        instance variable of this wrapper in a subclass-specific manner.
+        '''
+
+        # We are the one-liner. We are the codebase.
+        return get_hint_pep_args(self._hint)
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    def _is_equal(self, other: 'TypeHint') -> bool:
+        '''
+        :data:`True` only if the low-level type hint wrapped by this wrapper is
+        semantically equivalent to the other low-level type hint wrapped by the
+        passed wrapper.
+
+        Subclasses are advised to override this method to implement the public
+        :meth:`is_subhint` tester method (which internally defers to this
+        private tester method) in a subclass-specific manner. Since the default
+        implementation is guaranteed to suffice for *all* possible use cases,
+        subclasses should override this method only for efficiency reasons; the
+        default implementation calls the :meth:`is_subhint` method twice and is
+        thus *not* necessarily the optimal implementation for subclasses.
+        Notably, the default implementation exploits the well-known syllogism
+        between two partially ordered items ``A`` and ``B``:
+
+        * If ``A <= B`` and ``A >= B``, then ``A == B``.
+
+        This private tester method is *not* memoized for efficiency, as the
+        caller is guaranteed to be the public :meth:`__eq__` tester method,
+        which is already memoized.
+
+        Parameters
+        ----------
+        other : TypeHint
+            Other type hint to be tested against this type hint.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this type hint is equal to that other hint.
+        '''
+
+        # Return true only if both...
+        #
+        # Note that this conditional implements the trivial boolean syllogism
+        # that we all know and adore: "If A <= B and B <= A, then A == B".
+        return (
+            # This union is a subhint of that object.
+            self.is_subhint(other) and
+            # That object is a subhint of this union.
+            other.is_subhint(self)
+        )
+
+    # ..................{ PRIVATE ~ testers : subhint        }..................
+    def _is_subhint(self, other: 'TypeHint') -> bool:
+        '''
+        :data:`True` only if this type hint is a **subhint** of the passed type
+        hint.
+
+        Subclasses are advised to override this method to implement the public
+        :meth:`is_subhint` tester method (which internally defers to this
+        private tester method) in a subclass-specific manner.
+
+        This private tester method is *not* memoized for efficiency, as the
+        caller is guaranteed to be the public :meth:`is_subhint` tester method,
+        which is already memoized.
+
+        Parameters
+        ----------
+        other : TypeHint
+            Other type hint to be tested against this type hint.
+
+        Returns
+        -------
+        bool
+            :data:`True` only if this type hint is a subhint of that other hint.
+
+        See Also
+        --------
+        :func:`beartype.door.is_subhint`
+            Further details.
+        '''
+
+        # Return true only if this hint is a subhint of *ANY* branch of that
+        # other hint.
+        return any(
+            self._is_subhint_branch(other_branch)
+            for other_branch in other._branches
+        )
+
+
+    def _is_subhint_branch(self, branch: 'TypeHint') -> bool:
+        '''
+        :data:`True` only if this type hint is a subhint of the passed branch of
+        another type hint passed to a parent call of the :meth:`is_subhint`
+        method, itself called by the :meth:`__le__` dunder method.
+
+        Parameters
+        ----------
+        branch : TypeHint
+            Conditional branch of another type hint to be tested against.
+
+        See Also
+        --------
+        :meth:`__le__`
+            Further details.
+        '''
+
+        # If that branch is unsubscripted, assume that branch to have been
+        # subscripted by "Any" and simply check for compatible origin types.
+        if branch._is_args_ignorable:
+            # print(f'is_subhint_branch({self}, {branch} [unsubscripted])')
+            return issubclass(self._origin, branch._origin)
+        # Else, that branch is subscripted.
+
+        # Return true only if...
+        return (
+            # That branch is also a type hint wrapper of the same concrete
+            # subclass as this type hint wrapper *AND*...
+            isinstance(branch, type(self)) and
+            # The class originating this hint is a subclass of the class
+            # originating that branch...
+            issubclass(self._origin, branch._origin) and
+            # All child type hints of this parent type hint are subhints of the
+            # corresponding child type hints of that branch.
+            all(
+                self_child <= branch_child
+                for self_child, branch_child in zip(
+                    self._args_wrapped_tuple, branch._args_wrapped_tuple)
+            )
+        )
+
+    # ..................{ PRIVATE ~ properties : read-only   }..................
+    # Read-only properties intentionally defining *NO* corresponding setter.
+
+    @property  # type: ignore
+    @property_cached
+    def _args_wrapped_tuple(self) -> Tuple['TypeHint', ...]:
+        '''
+        Tuple of the zero or more high-level **child type hint wrappers** (i.e.,
+        :class:`TypeHint` instances) wrapping the low-level child type hints
+        subscripting (indexing) the low-level parent type hint wrapped by this
+        wrapper.
+
+        This attribute is intentionally defined as a memoized property to
+        minimize space and time consumption for use cases *not* accessing this
+        attribute.
+        '''
+
+        # One-liner, don't fail us now!
+        return tuple(TypeHint(hint_child) for hint_child in self._args)
+
+
+    @property  # type: ignore
+    @property_cached
+    def _args_wrapped_frozenset(self) -> FrozenSet['TypeHint']:
+        '''
+        Frozen set of the zero or more high-level child **type hint wrappers**
+        (i.e., :class:`TypeHint` instances) wrapping the low-level child type
+        hints subscripting (indexing) the low-level parent type hint wrapped by
+        this wrapper.
+
+        This attribute is intentionally defined as a memoized property to
+        minimize space and time consumption for use cases *not* accessing this
+        attribute.
+        '''
+
+        return frozenset(self._args_wrapped_tuple)
+
+
+    @property  # type: ignore
+    @property_cached
+    def _branches(self) -> Iterable['TypeHint']:
+        '''
+        Immutable iterable of all **branches** (i.e., high-level type hint
+        wrappers encapsulating all low-level child type hints subscripting
+        (indexing) the low-level parent type hint encapsulated by this
+        high-level parent type hint wrappers if this is a union (and thus an
+        instance of the :class:`UnionTypeHint` subclass) *or* the 1-tuple
+        containing only this instance itself otherwise) of this type hint
+        wrapper.
+
+        This property enables the child type hints of both :pep:`484`- and
+        :pep:`604`-compliant unions (e.g., :attr:`typing.Union`,
+        :attr:`typing.Optional`, and ``|``-delimited type objects) to be handled
+        transparently *without* special cases in subclass implementations.
+        '''
+
+        # Default to returning the 1-tuple containing only this instance, as
+        # *ALL* subclasses except "_HintTypeUnion" require this default.
+        return (self,)
+
+
+    @property  # type: ignore
+    @property_cached
+    def _is_args_ignorable(self) -> bool:
+        '''
+        :data:`True` only if this hint is effectively **unsubscripted** (i.e.,
+        either indexed by *no* child type hints or only indexed by ignorable
+        child type hints).
+
+        If :data:`True`, this hint can be trivially and efficiently evaluated
+        by simply inspecting its :attr:`_origin` property. Relevant type hints
+        include:
+
+        * Unsubscripted type hint factories (e.g., ``Tuple``, ``Callable``).
+        * Type hints subscripted only by ignorable child type hints (e.g.,
+          ``Tuple[Any, ...]``, ``Callable[..., Any]``).
+
+        This boolean trivializes comparisons between syntactically unrelated
+        type hints that are nonetheless semantically equivalent: e.g.,
+
+        .. code-block:: pycon
+
+           >>> from beartype.door import TypeHint
+           >>> from typing import Any, Tuple
+
+           # These type hints are all semantically equivalent despite being
+           # mostly syntactically unrelated.
+           >>> TypeHint(tuple) == TypeHint(typing.Tuple) == \
+           ... TypeHint(typing.Tuple[Any, ...])
+           True
+
+        Note that this property is *not* equivalent to the :meth:`is_ignorable`
+        property. Although related, a non-ignorable parent type hint can
+        trivially have ignorable child type hints (e.g., ``list[Any]``).
+        '''
+
+        # Return true only if all child type hints subscripting this parent type
+        # hint are themselves ignorable.
+        # print(f'[_is_args_ignorable] {self}._args_wrapped_tuple: {self._args_wrapped_tuple}')
+        return all(
+            hint_child.is_ignorable for hint_child in self._args_wrapped_tuple)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/doorpep484604.py
@@ -0,0 +1,77 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Decidedly Object-Oriented Runtime-checking (DOOR) union type hint classes**
+(i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`484`-compliant :attr:`typing.Optional` and :attr:`typing.Union` type
+hints and :pep:`604`-compliant ``|``-delimited union type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsub import _TypeHintSubscripted
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.typing import Iterable
+
+# ....................{ SUBCLASSES                         }....................
+class UnionTypeHint(_TypeHintSubscripted):
+    '''
+    **Union type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`484`-compliant :attr:`typing.Optional` or
+    :attr:`typing.Union` type hint *or* :pep:`604`-compliant ``|``-delimited
+    union type hint).
+    '''
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    def _branches(self) -> Iterable[TypeHint]:
+        return self._args_wrapped_tuple
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    def _is_subhint_branch(self, branch: TypeHint) -> bool:
+        raise NotImplementedError('UnionTypeHint._is_subhint_branch() unsupported.')  # pragma: no cover
+
+
+    def _is_subhint(self, other: TypeHint) -> bool:
+
+        # Return true only if *EVERY* child type hint of this union is a subhint
+        # of at least one other child type hint of the passed other union.
+        #
+        # Note that this test has O(n**2) time complexity. Although non-ideal,
+        # this is also unavoidable. Thankfully, since most real-world unions are
+        # subscripted by only a small number of child type hints, this is also
+        # mostly ignorable in practice.
+        return all(
+            # For each child type hint subscripting this union...
+            (
+                # If that other type hint is itself a union, true only if...
+                any(
+                    # For at least one other child type hint subscripting that
+                    # other union, this child type hint is a subhint of that
+                    # other child type hint.
+                    this_branch.is_subhint(that_branch)
+                    for that_branch in other._branches
+                ) if isinstance(other, UnionTypeHint) else
+                # Else, that other type hint is *NOT* a union. In this case,
+                # true only if this child type hint is a subhint of that other
+                # type hint.
+                #
+                # Note that this is a common edge case. Examples include:
+                # * "TypeHint(Union[...]) <= TypeHint(Any)". Although "Any" is
+                #   *NOT* a union, *ALL* unions are subhints of "Any".
+                # * "TypeHint(Union[A, B]) <= TypeHint(Union[A])" where "A" is
+                #   the superclass of "B". Since Python reduces "Union[A]" to
+                #   just "A", this is exactly equivalent to the comparison
+                #   "TypeHint(Union[A, B]) <= TypeHint(A)". Although "A" is
+                #   *NOT* a union, this example clearly demonstrates that a
+                #   union may be a subhint of a non-union that is *NOT* "Any" --
+                #   contrary to intuition. Examples include:
+                #   * "TypeHint(Union[int, bool]) <= TypeHint(Union[int])".
+                this_branch.is_subhint(other)
+            )
+            for this_branch in self._branches
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/doorpep586.py
@@ -0,0 +1,86 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **Decidedly Object-Oriented Runtime-checking (DOOR) literal type hint
+classes** (i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`586`-compliant :attr:`typing.Literal` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsub import _TypeHintSubscripted
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.typing import Tuple
+
+# ....................{ SUBCLASSES                         }....................
+class LiteralTypeHint(_TypeHintSubscripted):
+    '''
+    **Literal type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`586`-compliant :attr:`typing.Literal` type hint).
+    '''
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    def _args_wrapped_tuple(self) -> Tuple[TypeHint, ...]:
+
+        # Return the empty tuple, thus presenting "Literal" type hints as having
+        # *NO* child type hints. Why? Because the arguments subscripting a
+        # Literal type hint are *NOT* generally PEP-compliant type hints and
+        # thus *CANNOT* be safely wrapped by "TypeHint" instances. These
+        # arguments are merely arbitrary values.
+        #
+        # Note that this property getter is intentionally *NOT* memoized with
+        # @property_cached, as Python already efficiently guarantees the empty
+        # tuple to be a singleton.
+        return ()
+
+
+    @property
+    def _is_args_ignorable(self) -> bool:
+        return False
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    def _is_subhint(self, other: TypeHint) -> bool:
+
+        # If the passed hint is also a literal, return true only if the set of
+        # all child hints subscripting this literal is a subset of the set of
+        # all child hints subscripting that literal.
+        if isinstance(other, LiteralTypeHint):
+            return all(self_arg in other._args for self_arg in self._args)
+        # Else, the passed hint is *NOT* also a literal.
+
+        # Return true only if either...
+        return (
+            # The class of each child hint subscripting this literal is a
+            # subhint (e.g., subclass) of the passed hint *OR*...
+            #
+            # Note that, unlike most type hints, each child hints subscripting
+            # this literal is typically *NOT* a valid type hint in and of itself
+            # (e.g., "Literal[True]" is a valid type hint, but "True" is not).
+            # This test *CANNOT* be reduced to the simpler and sensible variant:
+            #     return all(
+            #         hint_child.is_subhint(other)
+            #         for hint_child in self._args_wrapped_tuple
+            #     )
+            all(
+                TypeHint(type(literal_child)).is_subhint(other)
+                for literal_child in self._args
+            ) or
+            # Else, the class of one or more child hints subscripting this
+            # literal is *NOT* a subhint (e.g., subclass) of the passed hint.
+            #
+            # Defer to the superclass implementation of this method. Why?
+            # Because this literal could still be a subhint of passed hint
+            # according to standard typing semantics. Notably, this literal
+            # could be a child type hint and thus a subhint of the passed type
+            # hint - despite failing all of the above literal-specific subhint
+            # tests: e.g.,
+            #     # The call below handles this surprisingly common edge case.
+            #     >>> Literal[True] <= Union[Literal[True], Literal[False]]
+            #     True
+            super()._is_subhint(other)
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/doorpep593.py
@@ -0,0 +1,106 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Decidedly Object-Oriented Runtime-checking (DOOR) annotated type hint
+classes** (i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`593`-compliant :attr:`typing.Annotated` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsuper import TypeHint
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.hint.pep.proposal.utilpep593 import (
+    get_hint_pep593_metadata,
+    get_hint_pep593_metahint,
+)
+from contextlib import suppress
+
+# ....................{ SUBCLASSES                         }....................
+class AnnotatedTypeHint(TypeHint):
+    '''
+    **Annotated type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`593`-compliant :attr:`typing.Annotated` type hint).
+
+    Attributes (Private)
+    --------
+    _metadata : tuple[object]
+        **Metadata** (i.e., tuple of zero or more arbitrary low-level
+        caller-defined objects annotating this :attr:`typing.Annotated` type
+        hint, equivalent to all remaining arguments subscripting this hint).
+    _metahint_wrapper : TypeHint
+        **Metahint wrapper** (i.e., :class:`TypeHint` instance wrapping the
+        child type hint annotated by this parent :attr:`typing.Annotated` type
+        hint, equivalent to the first argument subscripting this hint).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, hint: object) -> None:
+
+        # Initialize our superclass.
+        super().__init__(hint)
+
+        # Tuple of the zero or more arbitrary caller-defined arguments following
+        # the first argument subscripting this hint.
+        self._metadata = get_hint_pep593_metadata(hint)
+
+        # Wrapper wrapping the first argument subscripting this hint.
+        self._metahint_wrapper = TypeHint(get_hint_pep593_metahint(hint))
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    def _is_args_ignorable(self) -> bool:
+        # since Annotated[] must be used with at least two arguments, we are
+        # never just the origin of the metahint
+        return False
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    def _is_equal(self, other: TypeHint) -> bool:
+
+        return (
+            isinstance(other, AnnotatedTypeHint)
+            and self._metahint_wrapper == other._metahint_wrapper
+            and self._metadata == other._metadata
+        )
+
+
+    def _is_subhint_branch(self, branch: TypeHint) -> bool:
+
+        # If the other type is not annotated, we ignore annotations on this
+        # one and just check that the metahint is a subhint of the other.
+        # e.g. Annotated[t.List[int], 'meta'] <= List[int]
+        if not isinstance(branch, AnnotatedTypeHint):
+            return self._metahint_wrapper.is_subhint(branch)
+
+        # Else, that hint is a "typing.Annotated[...]" type hint. If either...
+        if (
+            # The child type hint annotated by this parent hint does not subhint
+            # the child type hint annotated by that parent hint *OR*...
+            self._metahint_wrapper > branch._metahint_wrapper or
+            # These hints are annotated by a differing number of objects...
+            len(self._metadata) != len(branch._metadata)
+        ):
+            # This hint *CANNOT* be a subhint of that hint. Return false.
+            return False
+
+        # Attempt to...
+        #
+        # Note that the following iteration performs equality comparisons on
+        # arbitrary caller-defined objects. Since these comparisons may raise
+        # arbitrary caller-defined exceptions, we silently squelch any such
+        # exceptions that arise by returning false below instead.
+        with suppress(Exception):
+            # Return true only if these hints are annotated by equivalent
+            # objects. We avoid testing for a subhint relation here (e.g., with
+            # the "<=" operator), as arbitrary caller-defined objects are *MUCH*
+            # more likely to define a relevant equality comparison than a
+            # relevant less-than-or-equal-to comparison.
+            return self._metadata == branch._metadata
+
+        # Else, one or more objects annotating these hints are incomparable. So,
+        # this hint *CANNOT* be a subhint of that hint. Return false.
+        return False  # pragma: no cover
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/pep484/doorpep484class.py
@@ -0,0 +1,168 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Decidedly Object-Oriented Runtime-checking (DOOR) class type hint classes**
+(i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`484`-compliant type hints that are, in fact, simple classes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.typing import (
+    TYPE_CHECKING,
+    Any,
+)
+
+# ....................{ SUBCLASSES                         }....................
+class ClassTypeHint(TypeHint):
+    '''
+    **Class type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`484`-compliant type hint that is, in fact, a simple class).
+
+    Caveats
+    ----------
+    This wrapper also intentionally wraps :pep:`484`-compliant :data:``None`
+    type hints as the simple type of the :data:``None` singleton, as :pep:`484`
+    standardized the reduction of the former to the latter:
+
+         When used in a type hint, the expression None is considered equivalent
+         to type(None).
+
+    Although a unique ``NoneTypeHint`` subclass of this class specific to the
+    :data:`None` singleton *could* be declared, doing so is substantially
+    complicated by the fact that numerous PEP-compliant type hints internally
+    elide :data:``None` to the type of that singleton before the `beartype.door`
+    API ever sees a distinction. Notably, this includes :pep:`484`-compliant
+    unions subscripted by that singleton: e.g.,
+
+    .. code-block:: python
+
+       >>> from typing import Union
+       >>> Union[str, None].__args__
+       (str, NoneType)
+    '''
+
+    # ..................{ STATIC                             }..................
+    # Squelch false negatives from static type checkers.
+    if TYPE_CHECKING:
+        _hint: type
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    def _is_args_ignorable(self) -> bool:
+
+        # Unconditionally return true, as simple classes are unsubscripted and
+        # could thus be said to only have ignorable arguments. Look. Semantics.
+        return True
+
+    # ..................{ PRIVATE ~ methods                  }..................
+    def _is_subhint_branch(self, branch: TypeHint) -> bool:
+        # print(f'is_subhint({repr(self)}, {repr(branch)})?')
+        # print(f'{repr(self)}._origin: {self._origin}')
+        # # print(f'{repr(self)}._origin.__args__: {self._origin.__args__}')
+        # print(f'{repr(self)}._origin.__parameters__: {self._origin.__parameters__}')
+        # print(f'{repr(branch)}._origin: {branch._origin}')
+        # # print(f'{repr(branch)}._origin.__args__: {branch._origin.__args__}')
+        # print(f'{repr(branch)}._origin.__parameters__: {branch._origin.__parameters__}')
+        # print(f'{repr(self)}._is_args_ignorable: {self._is_args_ignorable}')
+        # print(f'{repr(branch)}._is_args_ignorable: {branch._is_args_ignorable}')
+
+        #FIXME: *UGH.* This is redundant. Ideally:
+        #* There should exist a concrete TypeHint._is_subhint_branch()
+        #  implementation performing this logic on behalf of *EVERY* subclass.
+        #* TypeHint._is_subhint_branch() should then call a subclass-specific
+        #  abstract TypeHint._is_subhint_branch_override() method.
+        #FIXME: Actually, TypeHint._is_subhint_branch() is only called in
+        #exactly one place: by TypeHint._is_subhint(). So, the simpler solution
+        #would be to simply implement the following tests there, please.
+
+        # Everything is a subclass of "Any".
+        if branch._hint is Any:
+            return True
+
+        #FIXME: *UHM.* Wat? Do we really currently wrap "typing.Any" with an
+        #instance of this class? Why? That makes *NO* sense. "typing.Any" should
+        #be wrapped by its own "TypeHintAny" subclass, please. *sigh*
+        # "Any" is only a subclass of "Any".
+        elif self._hint is Any:
+            return False
+
+        #FIXME: Actually, let's avoid the implicit numeric tower for now.
+        #Explicit is better than implicit and we really strongly disagree with
+        #this subsection of PEP 484, which does more real-world harm than good.
+        # # Numeric tower:
+        # # https://peps.python.org/pep-0484/#the-numeric-tower
+        # if self._origin is float and branch._origin in {float, int}:
+        #     return True
+        # if self._origin is complex and branch._origin in {complex, float, int}:
+        #     return True
+
+        #FIXME: This simplistic logic fails to account for parametrized
+        #generics. To do so, we'll probably want to:
+        #* Define a new "beartype.door._cls._pep.pep484585.doorpep484585generic"
+        #  submodule.
+        #* In that submodule:
+        #  * Define a new "GenericTypeHint" subclass initially simply
+        #    copy-pasted from this subclass.
+        #* Incorporate that subclass into the "beartype.door._doordata"
+        #  submodule.
+        #* Validate that tests still pass.
+        #* Begin implementing custom generic-specific logic in the
+        #  "GenericTypeHint" subclass. Notably, this tester should be refactored
+        #  as follows:
+        #  # If this generic is *NOT* a subclass of that generic, then this generic
+        #  # is *NOT* a subhint of that generic. In this case, return false.
+        #  if not issubclass(self._hint, branch._hint):
+        #      return False
+        #  # Else, this generic is a subclass of that generic. Note, however,
+        #  # that this does *NOT* imply this generic to be a subhint of that
+        #  # generic. The issubclass() builtin ignores parametrizations and thus
+        #  # returns false positives for parametrized generics: e.g.,
+        #  #     >>> from typing import Generic, TypeVar
+        #  #     >>> T = TypeVar('T')
+        #  #     >>> class MuhGeneric(Generic[T]): pass
+        #  #     >>> issubclass(MuhGeneric, MuhGeneric[int])
+        #  #     True
+        #  #
+        #  # Clearly, the unsubscripted generic "MuhGeneric" is a superhint
+        #  # (rather than a subhint) of the subscripted generic
+        #  # "MuhGeneric[int]". Further introspection is needed to decide how
+        #  # exactly these two generics interrelate.
+        #
+        #  #FIXME: Do something intelligent here. In particular, we probably
+        #  #*MUST* expand unsubscripted generics like "MuhGeneric" to their
+        #  #full transitive subscriptions like "MuhGeneric[T]". Of course,
+        #  #"MuhGeneric" has *NO* "__args__" and only an empty "__parameters__";
+        #  #both are useless. Ergo, we have *NO* recourse but to iteratively
+        #  #reconstruct the full transitive subscriptions for unsubscripted
+        #  #generics by iterating with the
+        #  #iter_hint_pep484585_generic_bases_unerased_tree() iterator. The idea
+        #  #here is that we want to iteratively inspect first the "__args__" and
+        #  #then the "__parameters__" of all superclasses of both "self" and
+        #  #"branch" until obtaining two n-tuples (where "n" is the number of
+        #  #type variables with which the root "Generic[...]" superclass was
+        #  #originally subscripted):
+        #  #* "self_args", the n-tuple of all types or type variables
+        #  #   subscripting this generic.
+        #  #* "branch_args", the n-tuple of all types or type variables
+        #  #   subscripting the "branch" generic.
+        #  #
+        #  #Once we have those two n-tuples, we can then decide the is_subhint()
+        #  #relation by simply iteratively subjecting each pair of items from
+        #  #both "self_args" and "branch_args" to is_subhint(). Notably, we
+        #  #return True if and only if is_subhint() returns True for *ALL* pairs
+        #  #of items of these two n-tuples.
+
+        # Return true only if...
+        return (
+            # This class is unsubscripted (and thus *NOT* a subscripted generic)
+            # *AND*...
+            branch._is_args_ignorable and
+            # This class is a subclass of that class.
+            issubclass(self._origin, branch._origin)
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/pep484/doorpep484newtype.py
@@ -0,0 +1,69 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Decidedly Object-Oriented Runtime-checking (DOOR) new-type type hint classes**
+(i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`484`-compliant :attr:`typing.NewType` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.pep.pep484.doorpep484class import ClassTypeHint
+from beartype._util.cls.utilclsmake import make_type
+from beartype._util.hint.pep.proposal.pep484.utilpep484newtype import (
+    get_hint_pep484_newtype_alias)
+
+# ....................{ SUBCLASSES                         }....................
+class NewTypeTypeHint(ClassTypeHint):
+    '''
+    **New-type type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`484`-compliant :attr:`typing.NewType` type hint).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, hint: object) -> None:
+
+        # Initialize the superclass with all passed parameters.
+        super().__init__(hint)
+
+        # Non-new type type hint encapsulated by this new type.
+        hint_embedded = get_hint_pep484_newtype_alias(hint)
+
+        # If this non-new type hint is a class...
+        if isinstance(hint_embedded, type):
+            #FIXME: Define a new get_hint_pep484_newtype_name() getter ala:
+            #    def get_hint_pep484_newtype_name(
+            #        hint: Any, exception_prefix: str = '') -> type:
+            #        #FIXME: Does this suffice? Does "NewType" guarantee the
+            #        #"__name__" instance variable to exist? No idea. *sigh*
+            #        return getattr(hint, '__name__')
+            #Then, call that below in lieu of the "name = getattr(...)" call.
+            # Unqualified basename of the new subclass of this class to be
+            # created below.
+            hint_name = getattr(hint, '__name__', str(hint))
+
+            # Dynamically synthesize a new subclass of this class with the name
+            # of this new type, effectively fabricating a fake origin type
+            # treating this new type as a subclass of this class. For example,
+            # if this new type is "NewType("MyType", str)", then this logic
+            # fabricates a fake origin type resembling:
+            #     class MyString(str): pass
+            #
+            # Note that this would typically be non-ideal due to explosive space
+            # and time consumption. Thankfully, however, "TypeHint" wrappers are
+            # cached; the "_TypeHintMeta" metaclass guarantees this __init__()
+            # method to be called exactly once for each "NewType" type hint.
+            self._origin = make_type(
+                type_name=hint_name,
+                type_bases=(hint_embedded,),  # type: ignore[arg-type]
+            )
+        # Else, this non-new type hint is a non-class (e.g., "Any"). In this
+        # case, preserve this non-class as is.
+        else:
+            #FIXME: This can't be right. Isn't "self._origin" supposed to *ONLY*
+            #be a class? Mypy complaints are probably justified here, frankly.
+            self._origin = hint_embedded  # type: ignore[assignment]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/pep484/doorpep484typevar.py
@@ -0,0 +1,110 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **Decidedly Object-Oriented Runtime-checking (DOOR) type variable
+classes** (i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`484`-compliant :attr:`typing.TypeVar` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.door._cls.pep.doorpep484604 import UnionTypeHint
+# from beartype.roar import BeartypeDoorPepUnsupportedException
+from beartype.typing import (
+    TYPE_CHECKING,
+    Any,
+    Tuple,
+    TypeVar,
+)
+from beartype._util.cache.utilcachecall import property_cached
+
+# ....................{ SUBCLASSES                         }....................
+class TypeVarTypeHint(UnionTypeHint):
+    '''
+    **Type variable wrapper** (i.e., high-level object encapsulating a low-level
+    :pep:`484`-compliant :attr:`typing.TypeVar` type hint).
+    '''
+
+    # ..................{ STATIC                             }..................
+    # Squelch false negatives from static type checkers.
+    if TYPE_CHECKING:
+        _hint: TypeVar
+
+    # ..................{ PROPERTIES                         }..................
+    @property
+    def is_ignorable(self) -> bool:
+
+        # This type variable is ignorable only if this type variable is either:
+        # * Unconstrained by any bounds or constraints (and thus effectively
+        #   bound only by the "typing.Any" catch-all).
+        # * Bound by an ignorable bound: e.g.,
+        #       TypeVar('T', bound=object)
+        # * Constrained by one or more ignorable constraints. Since constraints
+        #   effectively build a union over those constraints, even a single
+        #   ignorable constraint suffices to render the entire type variable
+        #   ignorable: e.g.,
+        #       TypeVar('T', object)
+        return self._is_args_ignorable
+
+    # ..................{ PRIVATE ~ properties               }..................
+    #FIXME: *HMM.* We should arguably just define the _make_args() factory
+    #method instead. That implementation would become quite a bit simpler as
+    #well as generalize to cover more use cases. By defining this method,
+    #"self._args" and "self._args_wrapped_tuple" are now desynchronized. *sigh*
+
+    @property  # type: ignore[misc]
+    @property_cached
+    def _args_wrapped_tuple(self) -> Tuple[TypeHint, ...]:
+
+        #FIXME: Support covariance and contravariance, please. We don't
+        #particularly care about either at the moment. Moreover, runtime type
+        #checkers were *NEVER* expected to support either -- although we
+        #eventually intend to do so. For now, raising a fatal exception here
+        #would seem to be extreme overkill. Doing nothing is (probably) better
+        #than doing something reckless and wild.
+        # # Human-readable string describing the variance of this type variable if
+        # # any *OR* "None" otherwise (i.e., if this type variable is invariant).
+        # variance_str = None
+        # if self._hint.__covariant__:
+        #     variance_str = 'covariant'
+        # elif self._hint.__contravariant__:
+        #     variance_str = 'contravariant'
+        #
+        # # If this type variable is variant, raise an exception.
+        # if variance_str:
+        #     raise BeartypeDoorPepUnsupportedException(
+        #         f'Type hint {repr(self._hint)} '
+        #         f'variance "{variance_str}" currently unsupported.'
+        #     )
+        # # Else, this type variable is invariant.
+
+        # TypeVars may only be bound or constrained, but not both. The
+        # difference between the two has semantic meaning for static type
+        # checkers but relatively little meaning for us. Ultimately, we're only
+        # concerned with the set of compatible types present in either the bound
+        # or the constraints. So, we treat a type variable as a union of its
+        # constraints or bound. See also:
+        #     https://docs.python.org/3/library/typing.html#typing.TypeVar
+
+        # If this type variable is bounded, return the 1-tuple containing only
+        # this wrapped bound.
+        if self._hint.__bound__ is not None:
+            return (TypeHint(self._hint.__bound__),)
+        # Else, this type variable is unbounded.
+        #
+        # If this type variable is constrained, return the n-tuple containing
+        # each of these wrapped constraints.
+        elif self._hint.__constraints__:
+            return tuple(TypeHint(t) for t in self._hint.__constraints__)
+        # Else, this type variable is unconstrained.
+
+        #FIXME: Consider globalizing this as a private constant for efficiency.
+        # Return the 1-tuple containing only the "typing.Any" catch-all. Why?
+        # Because an unconstrained and unbounded type variable is semantically
+        # equivalent to a type variable bounded by "typing.Any".
+        return (TypeHint(Any),)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/pep484585/doorpep484585callable.py
@@ -0,0 +1,297 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **Decidedly Object-Oriented Runtime-checking (DOOR) callable type hint
+classes** (i.e., :class:`beartype.door.TypeHint` subclasses implementing support
+for :pep:`484`- and :pep:`585`-compliant ``Callable[...]`` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsub import _TypeHintSubscripted
+from beartype.door._cls.doorsuper import (
+    TypeHint,
+    # T,
+)
+from beartype.roar import BeartypeDoorPepUnsupportedException
+from beartype.typing import (
+    Any,
+    Tuple,
+)
+from beartype._data.hint.pep.sign.datapepsignset import (
+    HINT_SIGNS_CALLABLE_PARAMS)
+# from beartype._data.kind.datakindsequence import TUPLE_EMPTY
+from beartype._util.cache.utilcachecall import property_cached
+from beartype._util.hint.pep.proposal.pep484585.utilpep484585callable import (
+    get_hint_pep484585_callable_params,
+    get_hint_pep484585_callable_return,
+)
+from beartype._util.hint.pep.utilpepget import get_hint_pep_sign_or_none
+
+# ....................{ SUBCLASSES                         }....................
+class CallableTypeHint(_TypeHintSubscripted):
+    '''
+    **Callable type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`484`- or :pep:`585`-compliant ``Callable[...]`` type hint).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def _make_args(self) -> tuple:
+        # print(f'{self}._origin: {self._origin}')
+
+        # Tuple of all child type hints subscripting this callable type hint,
+        # localized for both readability and negligible efficiency gains.
+        #
+        # Note that this is a flattened tuple of the one or more child type
+        # hints subscripting this callable type hint. Presumably for space
+        # efficiency reasons, both PEP 484- *AND* 585-compliant callable type
+        # hints implicitly flatten the "__args__" dunder tuple from the original
+        # data structure subscripting those hints. CPython produces this
+        # flattened tuple as the concatenation of:
+        #
+        # * Either:
+        #   * If the first child type originally subscripting this hint was a
+        #     list, all items subscripting the nested list of zero or more
+        #     parameter type hints originally subscripting this hint as is:
+        #         >>> Callable[[], bool].__args__
+        #         (bool,)
+        #         >>> Callable[[int, str], bool].__args__
+        #         (int, str, bool)
+        #
+        #     This includes a list containing only the empty tuple signifying a
+        #     callable accepting *NO* parameters, in which case that empty tuple
+        #     is preserved as is:
+        #         >>> Callable[[()], bool].__args__
+        #         ((), bool)
+        #   * Else, the first child type originally subscripting this hint as
+        #     is. In this case, that child type is required to be either:
+        #     * An ellipsis object (i.e., the "Ellipsis" builtin singleton):
+        #         >>> Callable[..., bool].__args__
+        #         (Ellipsis, bool)
+        #     * A PEP 612-compliant parameter specification (i.e.,
+        #       "typing.ParamSpec[...]" type hint):
+        #         >>> Callable[ParamSpec('P'), bool].__args__
+        #         (~P, bool)
+        #     * A PEP 612-compliant parameter concatenation (i.e.,
+        #       "typing.Concatenate[...]" type hint):
+        #         >>> Callable[Concatenate[str, ParamSpec('P')], bool].__args__
+        #         (typing.Concatenate[str, ~P], bool)
+        # * The return type hint originally subscripting this hint.
+        #
+        # Note that both PEP 484- *AND* 585-compliant callable type hints
+        # guarantee this tuple to contain at least one child type hint. Ergo, we
+        # avoid validating that constraint here:
+        #     >>> from typing import Callable
+        #     >>> Callable[()]
+        #     TypeError: Callable must be used as Callable[[arg, ...], result].
+        #     >>> from collections.abc import Callable
+        #     >>> Callable[()]
+        #     TypeError: Callable must be used as Callable[[arg, ...], result].
+        # args = self._args
+        args = super()._make_args()
+
+        # Note that this branch may be literally unreachable, as an
+        # unsubscripted "Callable" should already be implicitly handled by the
+        # "ClassTypeHint" subclass. Nonetheless, this branch exists for safety.
+        if not args:  # pragma: no cover
+            args = (..., Any,)
+        else:
+            # Parameters type hint(s) subscripting this callable type hint.
+            #
+            # Note that this:
+            # * May be a special object (e.g., ellipsis) rather than a tuple of
+            #   zero or more parameter type hints.
+            # * Has the essential side effect of eliminating harmful edge cases
+            #   (e.g., "Callable[[()], Any]", which is semantically but *NOT*
+            #   syntactically equivalent to "Callable[[], Any]").
+            args_params = get_hint_pep484585_callable_params(self._hint)
+
+            # Return type hint subscripting this callable type hint.
+            args_return = get_hint_pep484585_callable_return(self._hint)
+
+            # Sign uniquely identifying this parameter list if any *OR*
+            # "None" otherwise.
+            hint_args_sign = get_hint_pep_sign_or_none(args_params)
+
+            # If this hint was first subscripted by a PEP 612-compliant
+            # parameter type hint, raise an exception. *sigh*
+            if hint_args_sign in HINT_SIGNS_CALLABLE_PARAMS:
+                raise BeartypeDoorPepUnsupportedException(
+                    f'PEP 484 or 585 callable type hint {repr(self._hint)} '
+                    f'PEP 612 child type hint {repr(args_params)} '
+                    f'currently unsupported.'
+                )
+            # Else, this hint was *NOT* first subscripted by a PEP
+            # 612-compliant parameter type hint.
+
+            # Parameters type hint(s) subscripting this callable type hint,
+            # coerced into a 1-tuple if *NOT* already a tuple.
+            args_params_tuple = (
+                args_params
+                if isinstance(args_params, tuple) else
+                (args_params,)
+            )
+
+            # Recreate the tuple of child type hints subscripting this parent
+            # callable type hint from the tuple of argument type hints
+            # introspected above. Why? Because the latter is saner than the
+            # former in edge cases (e.g., ellipsis, empty argument lists).
+            args = args_params_tuple + (args_return,)
+
+        # Return these child hints.
+        return args
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    # @property_cached
+    def _args_wrapped_tuple(self) -> Tuple[TypeHint, ...]:
+
+        # Tuple of all child type hints subscripting this callable type hint.
+        args = self._args
+
+        # Number of child type hints subscripting this callable type hint.
+        args_len = len(args)
+
+        # Tuple of all child type hint wrappers subscripting this callable type
+        # hint wrapper, initialized to the empty tuple for simplicity.
+        args_wrapped_tuple: Tuple[TypeHint, ...] = ()
+
+        # If this type hint is unsubscripted, return the empty tuple.
+        if not args_len:
+            pass
+        # Else, this type hint is subscripted by one or more child type hints.
+        #
+        # If this type hint is subscripted by exactly one child type hint, then
+        # that child type hint signifies this callable's return type hint,
+        # implying this callable accepts *NO* parameters. In this case...
+        elif args_len == 1:
+            # Return a 2-tuple consisting of...
+            args_wrapped_tuple = (
+                # Empty parameter list.
+                TypeHint(Tuple[()]),
+                # Return type hint.
+                TypeHint(args[-1]),
+            )
+        # Else, this type hint is subscripted by two or more child type hints.
+        #
+        # If the first child type hint subscripting this type hint is an
+        # ellipsis (i.e., "..."), this callable accepts *ANY* parameters of
+        # *ANY* arbitrary types. In this case...
+        elif args[0] is ...:
+            # Return a 2-tuple consisting of...
+            args_wrapped_tuple = (
+                # Variadic parameter list.
+                TypeHint(Any),
+                # Return type hint.
+                TypeHint(args[-1]),
+            )
+        # Else, the first child type hint subscripting this type hint is *NOT*
+        # an ellipsis. In this case, defer to the superclass approach.
+        else:
+            args_wrapped_tuple = super()._args_wrapped_tuple
+
+        # Return this tuple.
+        # print(f'Callable: {self._hint}; args: {self._args}; args_wrapped_tuple: {args_wrapped_tuple}')
+        return args_wrapped_tuple
+
+    # ..................{ PROPERTIES ~ hints                 }..................
+    @property  # type: ignore
+    @property_cached
+    def param_hints(self) -> Tuple[TypeHint, ...]:
+        '''
+        Tuple of the one or more parameter type hints subscripting this
+        callable type hint.
+
+        Notably, if this callable accepts:
+
+        * *No* parameters (i.e., was originally subscripted by the empty list as
+          ``Callable[[], ???]``), this is the 1-tuple
+          ``(TypeHint(Tuple[()]),)``.
+        * *Any* parameters of *any* arbitrary types (i.e., was originally
+          subscripted by an ellipsis as ``Callable[..., ???]``), this is the
+          1-tuple ``(TypeHint(Any),)``.
+        '''
+
+        return self._args_wrapped_tuple[:-1]
+
+
+    @property
+    def return_hint(self) -> TypeHint:
+        '''
+        Return type hint subscripting this callable type hint.
+        '''
+
+        return self._args_wrapped_tuple[-1]
+
+    # ..................{ PROPERTIES ~ bools                 }..................
+    # FIXME: Remove this by instead adding support for ignoring ignorable
+    # callable type hints to our core is_hint_ignorable() tester. Specifically:
+    # * Ignore "Callable[..., {hint_ignorable}]" type hints, where "..." is the
+    #  ellipsis singleton and "{hint_ignorable}" is any ignorable type hint.
+    #  This has to be handled in a deep manner by:
+    #  * Defining a new is_hint_pep484585_ignorable_or_none() tester in the
+    #    existing "utilpep484585" submodule, whose initial implementation tests
+    #    for *ONLY* ignorable callable type hints.
+    #  * Import that tester in the "utilpeptest" submodule.
+    #  * Add that tester to the "_IS_HINT_PEP_IGNORABLE_TESTERS" tuple.
+    #  * Add example ignorable callable type hints to our test suite's data.
+    @property
+    def is_ignorable(self) -> bool:
+        # Callable[..., Any] (or just `Callable`)
+        return self.is_params_ignorable and self.is_return_ignorable
+
+
+    @property
+    def is_params_ignorable(self) -> bool:
+        # Callable[..., ???]
+        return self._args[0] is Ellipsis
+
+
+    @property
+    def is_return_ignorable(self) -> bool:
+        # Callable[???, Any]
+        return self.return_hint.is_ignorable
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    #FIXME: Internally comment us up, please.
+    def _is_subhint_branch(self, branch: TypeHint) -> bool:
+
+        # If that branch is unsubscripted, assume it is subscripted as
+        # "typing.Callable[..., Any]" and just test for compatible origins.
+        if branch._is_args_ignorable:
+            return issubclass(self._origin, branch._origin)
+        elif not isinstance(branch, CallableTypeHint):
+            return False
+        elif not issubclass(self._origin, branch._origin):
+            return False
+        elif not branch.is_params_ignorable and (
+            (
+                self.is_params_ignorable or
+                len(self.param_hints) != len(branch.param_hints) or
+                any(
+                    self_arg > branch_arg
+                    for self_arg, branch_arg in zip(
+                        self.param_hints, branch.param_hints)
+                )
+            )
+        ):
+            return False
+
+        # FIXME: Insufficient, sadly. There are *MANY* different type hints that
+        # are ignorable and thus semantically equivalent to "Any". It's likely
+        # we should just reduce this to a one-liner resembling:
+        #    return self.return_hint <= branch.return_hint
+        #
+        # Are we missing something? We're probably missing something. *sigh*
+        elif not branch.is_return_ignorable:
+            return (
+                False
+                if self.is_return_ignorable else
+                self.return_hint <= branch.return_hint
+            )
+
+        return True
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_cls/pep/pep484585/doorpep484585tuple.py
@@ -0,0 +1,138 @@
+#!/usr/bin/env python3
+#--------------------( LICENSE                             )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Decidedly Object-Oriented Runtime-checking (DOOR) callable type hint classes**
+(i.e., :class:`beartype.door.TypeHint` subclasses implementing support for
+:pep:`484`- and :pep:`585`-compliant ``Tuple[...]`` type hints).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsub import _TypeHintSubscripted
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.typing import Any
+
+# ....................{ SUBCLASSES                         }....................
+# FIXME: Document all public and private attributes of this class, please.
+class _TupleTypeHint(_TypeHintSubscripted):
+    '''
+    **Tuple type hint wrapper** (i.e., high-level object encapsulating a
+    low-level :pep:`484`- or :pep:`585`-compliant ``Tuple[...]`` type hint).
+
+    Attributes (Private)
+    --------
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, hint: object) -> None:
+
+        #FIXME: Actually, it might be preferable to define two distinct
+        #subclasses:
+        #* "class _TypeHintTupleVariadic(_TypeHintSequence)", handling variadic
+        #  tuple type hints of the form "Tuple[T, ...]".
+        #* "class _TypeHintTupleFixed(_TypeHintSubscripted)", handling
+        #  fixed-length tuple type hints.
+        #
+        #Why? Because variadic and fixed-length tuple type hints have *NOTHING*
+        #semantically to do with one another. All they share is the common
+        #prefix "Tuple". Aside from that, everything is dissimilar. Indeed,
+        #most of the logic below (especially _is_subhint_branch(), which is kinda
+        #cray-cray) would strongly benefit from separating this class into two
+        #subclasses.
+        #
+        #Note that implementing this division will probably require generalizing
+        #the TypeHint.__new__() method to support this division.
+
+        # Initialize all subclass-specific instance variables for safety.
+        self._is_variable_length: bool = False
+
+        #FIXME: Non-ideal. The superclass __len__() method already returns 0 as
+        #expected for "Tuple[()]" type hints. Excise us up!
+        self._is_empty_tuple: bool = False
+
+        # Initialize the superclass with all passed parameters.
+        super().__init__(hint)
+
+
+    def _make_args(self) -> tuple:
+
+        # Tuple of the zero or more low-level child type hints subscripting
+        # (indexing) the low-level parent type hint wrapped by this wrapper.
+        args = super()._make_args()
+
+        # Validate these child hints. Specifically, remove any
+        # PEP-noncompliant child hints from this tuple and set associated flags.
+        #
+        # e.g. `Tuple` without any arguments
+        # This may be unreachable (since a bare Tuple will go to ClassTypeHint),
+        # but it's here for completeness and safety.
+        if len(args) == 0:  # pragma: no cover
+            args = (Any,)
+            self._is_variable_length = True
+        #FIXME: This is non-portable and thus basically broken. Ideally, empty
+        #tuples should instead be detected by explicitly calling the
+        #is_hint_pep484585_tuple_empty() tester.
+        elif len(args) == 1 and args[0] == ():
+            args = ()
+            self._is_empty_tuple = True
+        elif len(args) == 2 and args[1] is Ellipsis:
+            args = (args[0],)
+            self._is_variable_length = True
+
+        # Return these child hints.
+        return args
+
+    # ..................{ PRIVATE ~ properties               }..................
+    @property
+    def _is_args_ignorable(self) -> bool:
+
+        #FIXME: Actually, pretty sure this only returns true if this hint is
+        #"Tuple[Any, ...]". *shrug*
+        # Return true only if this hint is either "Tuple[Any, ...]" or the
+        # unsubscripted "Tuple" type hint factory.
+        return (
+            self._is_variable_length and
+            bool(self) and
+            self[0].is_ignorable
+        )
+
+    # ..................{ PRIVATE ~ testers                  }..................
+    def _is_subhint_branch(self, branch: TypeHint) -> bool:
+
+        if branch._is_args_ignorable:
+            return issubclass(self._origin, branch._origin)
+        elif not isinstance(branch, _TupleTypeHint):
+            return False
+        elif self._is_args_ignorable:
+            return False
+        elif branch._is_empty_tuple:
+            return self._is_empty_tuple
+        elif branch._is_variable_length:
+            that_hint = branch._args_wrapped_tuple[0]
+
+            if self._is_variable_length:
+                return that_hint.is_subhint(self._args_wrapped_tuple[0])
+
+            return all(
+                this_child.is_subhint(that_hint)
+                for this_child in self._args_wrapped_tuple
+            )
+        elif self._is_variable_length:
+            return (
+                branch._is_variable_length and
+                self._args_wrapped_tuple[0].is_subhint(
+                    branch._args_wrapped_tuple[0])
+            )
+        elif len(self._args) != len(branch._args):
+            return False
+
+        return all(
+            this_child <= that_child
+            for this_child, that_child in zip(
+                self._args_wrapped_tuple, branch._args_wrapped_tuple
+            )
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_doorcheck.py
@@ -0,0 +1,299 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype Decidedly Object-Oriented Runtime-checking (DOOR) procedural
+type-checkers** (i.e., high-level functions type-checking arbitrary objects
+against type hints at *any* time during the lifecycle of the active Python
+process).
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: This submodule intentionally does *not* import the
+# @beartype.beartype decorator. Why? Because that decorator conditionally
+# reduces to a noop under certain contexts (e.g., `python3 -O` optimization),
+# whereas the API defined by this submodule is expected to unconditionally
+# operate as expected regardless of the current context.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.typing import (
+    Any,
+    Type,
+    overload,
+)
+from beartype._check.checkmake import (
+    make_func_raiser,
+    make_func_tester,
+)
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._data.hint.datahintfactory import TypeGuard
+from beartype._data.hint.datahinttyping import T
+
+# ....................{ VALIDATORS                         }....................
+def die_if_unbearable(
+    # Mandatory flexible parameters.
+    obj: object,
+    hint: object,
+
+    # Optional keyword-only parameters.
+    *,
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+    exception_prefix: str = 'die_if_unbearable() ',
+) -> None:
+    '''
+    Raise an exception if the passed arbitrary object violates the passed type
+    hint under the passed beartype configuration.
+
+    To configure the type of violation exception raised by this function, set
+    the :attr:`.BeartypeConf.violation_door_type` option of the passed ``conf``
+    parameter accordingly.
+
+    Parameters
+    ----------
+    obj : object
+        Arbitrary object to be type-checked against this hint.
+    hint : object
+        Type hint to type-check this object against.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object). Defaults
+        to ``BeartypeConf()``, the default :math:`O(1)` constant-time
+        configuration.
+    exception_prefix : str, optional
+        Human-readable label prefixing the representation of this object in the
+        exception message. Defaults to a reasonably sensible string.
+
+    Raises
+    ------
+    ``conf.violation_door_type``
+        If this object violates this hint.
+    beartype.roar.BeartypeDecorHintNonpepException
+        If this hint is *not* PEP-compliant (i.e., complies with *no* Python
+        Enhancement Proposals (PEPs) currently supported by :mod:`beartype`).
+    beartype.roar.BeartypeDecorHintPepUnsupportedException
+        If this hint is currently unsupported by :mod:`beartype`.
+
+    Examples
+    --------
+    .. code-block:: pycon
+
+       >>> from beartype.door import die_if_unbearable
+       >>> die_if_unbearable(['And', 'what', 'rough', 'beast,'], list[str])
+       >>> die_if_unbearable(['its', 'hour', 'come', 'round'], list[int])
+       beartype.roar.BeartypeDoorHintViolation: Object ['its', 'hour', 'come',
+       'round'] violates type hint list[int], as list index 0 item 'its' not
+       instance of int.
+    '''
+    # conf._is_debug = True
+
+    # Memoized low-level type-checking raiser function either raising an
+    # exception or emitting a warning only if the passed object passed violates
+    # the type hint passed to this high-level type-checking raiser function.
+    #
+    # Note that parameters are intentionally passed positionally for efficiency.
+    # Since make_func_raiser() is memoized, passing parameters by keyword would
+    # raise a non-fatal
+    # "_BeartypeUtilCallableCachedKwargsWarning" warning.
+    func_raiser = make_func_raiser(hint, conf, exception_prefix)
+
+    # Either raise an exception or emit a warning only if the passed object
+    # violates this hint.
+    func_raiser(obj)  # pyright: ignore[reportUnboundVariable]
+
+# ....................{ TESTERS                            }....................
+def is_subhint(subhint: object, superhint: object) -> bool:
+    '''
+    :data:`True` only if the first passed hint is a **subhint** of the second
+    passed hint, in which case this second hint is a **superhint** of this first
+    hint.
+
+    Equivalently, this tester returns :data:`True` only if *all* of the
+    following conditions apply:
+
+    * These two hints are **semantically related** (i.e., convey broadly similar
+      semantics enabling these two hints to be reasonably compared). For
+      example:
+
+      * ``callable.abc.Iterable[str]`` and ``callable.abc.Sequence[int]`` are
+        semantically related. These two hints both convey container semantics.
+        Despite their differing child hints, these two hints are broadly similar
+        enough to be reasonably comparable.
+      * ``callable.abc.Iterable[str]`` and ``callable.abc.Callable[[], int]``
+        are *not* semantically related. Whereas the first hints conveys a
+        container semantic, the second hint conveys a callable semantic. Since
+        these two semantics are unrelated, these two hints are dissimilar
+        enough to *not* be reasonably comparable.
+
+    * The first hint is **semantically equivalent** to or **narrower** than the
+      second hint. Equivalently:
+
+      * The first hint matches less than or equal to the total number of all
+        possible objects matched by the second hint.
+      * The size of the countably infinite set of all possible objects matched
+        by the first hint is less than or equal to that of those matched by the
+        second hint.
+
+    * The first hint is **compatible** with the second hint. Since the first
+      hint is semantically narrower than the second, APIs annotated by the first
+      hint may safely replace that hint with the second hint; doing so preserves
+      backward compatibility.
+
+    Parameters
+    ----------
+    subhint : object
+        Type hint or type to be tested as the subhint.
+    superhint : object
+        Type hint or type to be tested as the superhint.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this first hint is a subhint of this second hint.
+
+    Examples
+    --------
+        >>> from beartype.door import is_subhint
+        >>> is_subhint(int, int)
+        True
+        >>> is_subhint(Callable[[], list], Callable[..., Sequence[Any]])
+        True
+        >>> is_subhint(Callable[[], list], Callable[..., Sequence[int]])
+        False
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.door._cls.doorsuper import TypeHint
+
+    # The one-liner is mightier than the... many-liner.
+    return TypeHint(subhint).is_subhint(TypeHint(superhint))
+
+# ....................{ TESTERS ~ is_bearable              }....................
+#FIXME: Document this tester's conditional compliance with PEP 647 (i.e.,
+#"typing.TypeGuard") in our official documentation, please.
+
+# Note that this PEP 484- and 647-compliant API is entirely the brain child of
+# @asford (Alex Ford). If this breaks, redirect all ~~vengeance~~ enquiries to:
+#     https://github.com/asford
+@overload
+def is_bearable(
+    obj: object, hint: Type[T], *, conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> TypeGuard[T]:
+    '''
+    :pep:`647`-compliant type guard conditionally narrowing the passed object to
+    the passed type hint *only* when this hint is actually a valid **type**
+    (i.e., subclass of the builtin :class:`type` superclass).
+    '''
+
+
+@overload
+def is_bearable(
+    obj: T, hint: Any, *, conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+) -> TypeGuard[T]:
+    '''
+    :pep:`647`-compliant fallback preserving (rather than narrowing) the type of
+    the passed object when this hint is *not* a valid type (e.g., the
+    :pep:`586`-compliant ``typing.Literal['totally', 'not', 'a', 'type']``,
+    which is clearly *not* a type).
+    '''
+
+
+# Note that the actual implementation of this overload is intentionally:
+# * *NOT* decorated by the standard @overload decorator.
+# * *NOT* annotated by type hints. By PEP 484, only the signatures of
+#   @overload-decorated callables are annotated by type hints.
+def is_bearable(obj, hint, *, conf = BEARTYPE_CONF_DEFAULT):  # pyright: ignore
+    '''
+    :data:`True` only if the passed arbitrary object satisfies the passed
+    type hint under the passed beartype configuration.
+
+    Note that this tester is a :pep:`647`-compliant **conditional type guard**
+    (i.e., is annotated by the return type hint ``typing.TypeGuard[bool]``).
+    Specifically:
+
+    * If the passed type hint is a valid **type** (i.e., subclass of the builtin
+      :class:`type` superclass), this tester is a general-purpose type guard
+      that performs type narrowing on the passed object: e.g.,
+
+      .. code-block:: python
+
+         from beartype.door import is_bearable
+
+         def narrow_types_like_a_boss_with_beartype(lst: list[int | str]):
+             # If "lst" is a list of integers, instruct static type-checkers
+             # (e.g., mypy, pyright) that the call to munch_list_of_integers()
+             # function expecting a list of integers is valid.
+             #
+             # Note that this works only because the is_bearable() tester
+             # complies with PEP 647. If this were *NOT* the case, then static
+             # type-checkers would raise a type-checking violation here.
+             if is_bearable(lst, list[int]):
+                 munch_list_of_integers(lst)
+             # Else if "lst" is a list of strings, behave similarly as above.
+             elif is_bearable(lst, list[str]):
+                 munch_list_of_strings(lst)
+
+         def munch_list_of_strings(lst: list[str]): ...
+         def munch_list_of_integers(lst: list[int]): ....
+
+    * If the passed type hint is *not* a valid type (e.g., the
+      :pep:`586`-compliant ``typing.Literal['totally', 'not', 'a', 'type']``,
+      which is clearly *not* a type), this tester is *not* a type guard and thus
+      performs *no* type narrowing on the passed object. This is due to
+      inadequacies in :pep:`647` rather than :mod:`beartype`.
+
+    Parameters
+    ----------
+    obj : object
+        Arbitrary object to be tested against this hint.
+    hint : object
+        Type hint to test this object against.
+    conf : BeartypeConf, optional
+        **Beartype configuration** (i.e., self-caching dataclass encapsulating
+        all settings configuring type-checking for the passed object). Defaults
+        to ``BeartypeConf()``, the default constant-time configuration.
+
+    Returns
+    -------
+    bool
+        :data:`True` only if this object satisfies this hint.
+
+    Raises
+    ------
+    beartype.roar.BeartypeConfException
+        If this configuration is *not* a :class:`BeartypeConf` instance.
+    beartype.roar.BeartypeDecorHintForwardRefException
+        If this hint contains one or more relative forward references, which
+        this tester explicitly prohibits to improve both the efficiency and
+        portability of calls to this tester.
+    beartype.roar.BeartypeDecorHintNonpepException
+        If this hint is *not* PEP-compliant (i.e., complies with *no* Python
+        Enhancement Proposals (PEPs) currently supported by :mod:`beartype`).
+    beartype.roar.BeartypeDecorHintPepUnsupportedException
+        If this hint is currently unsupported by :mod:`beartype`.
+
+    Examples
+    --------
+        >>> from beartype.door import is_bearable
+        >>> is_bearable(['Things', 'fall', 'apart;'], list[str])
+        True
+        >>> is_bearable(['the', 'centre', 'cannot', 'hold;'], list[int])
+        False
+    '''
+
+    # Memoized low-level type-checking tester function returning true only if
+    # the object passed to that tester satisfies the type hint passed to this
+    # high-level type-checking tester function.
+    #
+    # Note that parameters are intentionally passed positionally for efficiency.
+    # Since make_func_tester() is memoized, passing parameters by keyword would
+    # raise a non-fatal
+    # "_BeartypeUtilCallableCachedKwargsWarning" warning.
+    func_tester = make_func_tester(hint, conf)
+
+    # Return true only if the passed object satisfies this hint.
+    return func_tester(obj)  # pyright: ignore
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_doordata.py
@@ -0,0 +1,214 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype Decidedly Object-Oriented Runtime-checking (DOOR) data** (i.e.,
+global constants internally required throughout the :mod:`beartype.door`
+subpackage).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.door._cls.doorsub import (
+    _TypeHintOriginIsinstanceableArgs1,
+    _TypeHintOriginIsinstanceableArgs2,
+    _TypeHintOriginIsinstanceableArgs3,
+    _TypeHintSubscripted,
+)
+from beartype.door._cls.doorsuper import TypeHint
+from beartype.door._cls.pep.pep484.doorpep484class import ClassTypeHint
+from beartype.door._cls.pep.doorpep484604 import UnionTypeHint
+from beartype.door._cls.pep.doorpep586 import LiteralTypeHint
+from beartype.door._cls.pep.doorpep593 import AnnotatedTypeHint
+from beartype.door._cls.pep.pep484.doorpep484newtype import NewTypeTypeHint
+from beartype.door._cls.pep.pep484.doorpep484typevar import TypeVarTypeHint
+from beartype.door._cls.pep.pep484585.doorpep484585callable import (
+    CallableTypeHint)
+from beartype.door._cls.pep.pep484585.doorpep484585tuple import _TupleTypeHint
+from beartype.roar import (
+    BeartypeDoorNonpepException,
+    # BeartypeDoorPepUnsupportedException,
+)
+from beartype.typing import (
+    Dict,
+    Type,
+)
+from beartype._data.hint.pep.sign.datapepsigncls import HintSign
+from beartype._data.hint.pep.sign.datapepsigns import (
+    HintSignAnnotated,
+    HintSignCallable,
+    HintSignGeneric,
+    HintSignLiteral,
+    HintSignNewType,
+    HintSignTuple,
+    HintSignTypeVar,
+)
+from beartype._util.hint.pep.utilpepget import (
+    get_hint_pep_args,
+    # get_hint_pep_origin_or_none,
+    get_hint_pep_sign_or_none,
+)
+from beartype._util.hint.pep.utilpeptest import is_hint_pep_typing
+
+# ....................{ GETTERS                            }....................
+def get_typehint_subclass(hint: object) -> Type[TypeHint]:
+    '''
+    Concrete :class:`TypeHint` subclass handling the passed low-level unwrapped
+    PEP-compliant type hint if any *or* raise an exception otherwise.
+
+    Parameters
+    ----------
+    hint : object
+        Low-level type hint to be inspected.
+
+    Returns
+    ----------
+    Type[TypeHint]
+        Concrete subclass of the abstract :mod:`TypeHint` superclass handling
+        this hint.
+
+    Raises
+    ----------
+    beartype.roar.BeartypeDoorNonpepException
+        If this API does *not* currently support the passed hint.
+    beartype.roar.BeartypeDecorHintPepSignException
+        If the passed hint is *not* actually a PEP-compliant type hint.
+    '''
+
+    # ..................{ SUBCLASS                           }..................
+    # Sign uniquely identifying this hint if any *OR* "None" otherwise (i.e., if
+    # this hint is a PEP-noncompliant class).
+    hint_sign = get_hint_pep_sign_or_none(hint)
+
+    # Private concrete subclass of this ABC handling this hint if any *OR*
+    # "None" otherwise (i.e., if no such subclass has been authored yet).
+    wrapper_subclass = _HINT_SIGN_TO_TYPEHINT_CLS.get(hint_sign)  # type: ignore[arg-type]
+
+    # If this hint appears to be currently unsupported...
+    if wrapper_subclass is None:
+        #FIXME: This condition is kinda intense. Should we really be conflating
+        #typing attributes that aren't types with objects that are types? Let's
+        #investigate exactly which kinds of type hints require this and
+        #contemplate something considerably more elegant.
+
+        # If either...
+        if (
+            # This hint is a PEP-noncompliant isinstanceable class *OR*...
+            isinstance(hint, type) or
+            # An unsupported kind of PEP-compliant type hint (e.g.,
+            # "typing.TypedDict" instance)...
+            is_hint_pep_typing(hint)
+        # Return the concrete "TypeHint" subclass handling all such classes.
+        ):
+            wrapper_subclass = ClassTypeHint
+        # Else, raise an exception.
+        else:
+            raise BeartypeDoorNonpepException(
+                f'Type hint {repr(hint)} '
+                f'currently unsupported by "beartype.door.TypeHint".'
+            )
+    # Else, this hint is supported.
+
+    #FIXME: Alternately, it might be preferable to refactor this to resemble:
+    #    if (
+    #       not get_hint_pep_args(hint) and
+    #       get_hint_pep_origin_type_or_none(hint) is not None
+    #    ):
+    #        wrapper_subclass = ClassTypeHint
+    #
+    #That's possibly simpler and cleaner, as it seamlessly conveys the exact
+    #condition we're going for -- assuming it works, of course. *sigh*
+    #FIXME: While sensible, the above approach induces non-trivial test
+    #failures. Let's investigate this further at a later time, please.
+
+    #FIXME: Push the "not" up to the top level of this conditional, please.
+    # If this hint is unsubscripted a subscriptable type has no args, all we care about is the origin.
+    elif (
+        # Unsubscripted (i.e., indexed by *NO* child type hints) *AND*...
+        not get_hint_pep_args(hint) and
+        #FIXME: No idea, bro. This is pretty weird. For one,
+        #"_HINT_SIGNS_ORIGINLESS" doesn't even contain all the signs it should
+        #(e.g., "HintSignLiteral", "HintSignUnion"). For another we should just
+        #be calling this instead:
+        #    get_hint_pep_origin_type_or_none(hint) is not None
+        hint_sign not in _HINT_SIGNS_ORIGINLESS
+    ):
+        wrapper_subclass = ClassTypeHint
+    # In any case, this hint is supported by this concrete subclass.
+
+    # Return this subclass.
+    return wrapper_subclass
+
+# ....................{ PRIVATE ~ globals                  }....................
+# Further initialized below by the _init() function.
+_HINT_SIGN_TO_TYPEHINT_CLS: Dict[HintSign, Type[TypeHint]] = {
+    HintSignAnnotated: AnnotatedTypeHint,
+    HintSignCallable:  CallableTypeHint,
+    HintSignGeneric:   _TypeHintSubscripted,
+    HintSignLiteral:   LiteralTypeHint,
+    HintSignNewType:   NewTypeTypeHint,
+    HintSignTuple:     _TupleTypeHint,
+    HintSignTypeVar:   TypeVarTypeHint,
+}
+'''
+Dictionary mapping from each sign uniquely identifying PEP-compliant type hints
+to the :class:`TypeHint` subclass handling those hints.
+'''
+
+
+#FIXME: Consider shifting into "datapepsignset" if still required.
+_HINT_SIGNS_ORIGINLESS = frozenset((
+    HintSignNewType,
+    HintSignTypeVar,
+))
+'''
+Frozen set of all **origin-less signs.**
+'''
+
+# ....................{ PRIVATE ~ initializers             }....................
+def _init() -> None:
+    '''
+    Initialize this submodule.
+    '''
+
+    # Isolate function-specific imports.
+    from beartype._data.hint.pep.sign.datapepsignset import (
+        HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_1,
+        HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_2,
+        HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_3,
+        HINT_SIGNS_UNION,
+    )
+
+    # Fully initialize the "HINT_SIGN_TO_TYPEHINT" dictionary declared above.
+    for sign in HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_1:
+        _HINT_SIGN_TO_TYPEHINT_CLS[sign] = _TypeHintOriginIsinstanceableArgs1
+    for sign in HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_2:
+        _HINT_SIGN_TO_TYPEHINT_CLS[sign] = _TypeHintOriginIsinstanceableArgs2
+    for sign in HINT_SIGNS_ORIGIN_ISINSTANCEABLE_ARGS_3:
+        _HINT_SIGN_TO_TYPEHINT_CLS[sign] = _TypeHintOriginIsinstanceableArgs3
+    for sign in HINT_SIGNS_UNION:
+        _HINT_SIGN_TO_TYPEHINT_CLS[sign] = UnionTypeHint
+
+    # For each concrete "TypeHint" subclass registered with this dictionary
+    # (*AFTER* initializing this dictionary)...
+    for typehint_cls in _HINT_SIGN_TO_TYPEHINT_CLS.values():
+        # If the unqualified basename of this subclass is prefixed by an
+        # underscore, this subclass is private rather than public. In this case,
+        # silently ignore this private subclass and continue to the next.
+        if typehint_cls.__name__.startswith('_'):
+            continue
+        # Else, this subclass is public.
+
+        # Sanitize the fully-qualified module name of this public subclass from
+        # the private submodule declaring this subclass (e.g.,
+        # "beartype.door._cls.pep.doorpep484604.UnionTypeHint") to the public
+        # "beartype.door" subpackage to both improve the readability of
+        # exceptions and discourage users from violating privacy encapsulation.
+        typehint_cls.__module__ = 'beartype.door'
+
+# ....................{ MAIN                               }....................
+# Initialize this submodule.
+_init()
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/door/_doortest.py
@@ -0,0 +1,42 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype Decidedly Object-Oriented Runtime-checking (DOOR) testers** (i.e.,
+callables testing and validating :class:`beartype.door.TypeHint` instances).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeDoorException
+
+# ....................{ VALIDATORS                         }....................
+def die_unless_typehint(obj: object) -> None:
+    '''
+    Raise an exception unless the passed object is a **type hint wrapper**
+    (i.e., :class:`TypeHint` instance).
+
+    Parameters
+    ----------
+    obj : object
+        Arbitrary object to be validated.
+
+    Raises
+    ----------
+    beartype.roar.BeartypeDoorException
+        If this object is *not* a type hint wrapper.
+    '''
+
+    # Avoid circular import dependencies.
+    from beartype.door._cls.doorsuper import TypeHint
+
+    # If this object is *NOT* a type hint wrapper, raise an exception.
+    if not isinstance(obj, TypeHint):
+        raise BeartypeDoorException(
+            f'{repr(obj)} not type hint wrapper '
+            f'(i.e., "beartype.door.TypeHint" instance).'
+        )
+    # Else, this object is a type hint wrapper.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/meta.py
@@ -0,0 +1,787 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype metadata.**
+
+This submodule exports global constants synopsizing this package -- including
+versioning and dependencies.
+
+Python Version
+--------------
+For uniformity between this codebase and the ``setup.py`` setuptools script
+importing this module, this module also validates the version of the active
+Python 3 interpreter. An exception is raised if this version is insufficient.
+
+As a tradeoff between backward compatibility, security, and maintainability,
+this package strongly attempts to preserve compatibility with the first stable
+release of the oldest version of CPython still under active development. Hence,
+obsolete and insecure versions of CPython that have reached their official End
+of Life (EoL) (e.g., Python 3.5) are explicitly unsupported.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To avoid accidental importation of optional runtime dependencies
+# (e.g., "typing-extensions") at installation time *BEFORE* the current package
+# manager has installed those dependencies, this module may *NOT* import from
+# any submodules of the current package. This includes *ALL* "beartype._util"
+# submodules, most of which import from "beartype.typing", which conditionally
+# imports optional runtime dependencies under certain contexts.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To avoid race conditions during setuptools-based installation, this
+# module may import *ONLY* from modules guaranteed to exist at the start of
+# installation. This includes all standard Python and package modules but
+# *NOT* third-party dependencies, which if currently uninstalled will only be
+# installed at some later time in the installation.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+import sys as _sys
+# from beartype.typing import Tuple as _Tuple
+
+# ....................{ METADATA                           }....................
+NAME = 'beartype'
+'''
+Human-readable package name.
+'''
+
+
+LICENSE = 'MIT'
+'''
+Human-readable name of the license this package is licensed under.
+'''
+
+# ....................{ METADATA ~ package                 }....................
+PACKAGE_NAME = NAME.lower()
+'''
+Fully-qualified name of the top-level Python package containing this submodule.
+'''
+
+
+PACKAGE_TEST_NAME = f'{PACKAGE_NAME}_test'
+'''
+Fully-qualified name of the top-level Python package exercising this project.
+'''
+
+# ....................{ PYTHON ~ version                   }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: Changes to this section *MUST* be synchronized with:
+# * Signs declared by the private
+#   "beartype._data.hint.pep.datapepsign" submodule, which *MUST*
+#   be synchronized against the "__all__" dunder list global of the "typing"
+#   module bundled with the most recent CPython release.
+# * Continuous integration test matrices, including:
+#   * The top-level "tox.ini" file.
+#   * The "jobs/tests/strategy/matrix/{tox-env,include/python-version}"
+#     settings of the GitHub Actions-specific
+#     ".github/workflows/python_test.yml" file.
+# * Front-facing documentation (e.g., "README.rst", "doc/md/INSTALL.md").
+#
+# On bumping the minimum required version of Python, consider also documenting
+# the justification for doing so in the "Python Version" section of this
+# submodule's docstring above.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+PYTHON_VERSION_MIN = '3.8.0'
+'''
+Human-readable minimum version of Python required by this package as a
+``.``-delimited string.
+
+See Also
+--------
+"Python Version" section of this submodule's docstring for a detailed
+justification of this constant's current value.
+'''
+
+
+PYTHON_VERSION_MINOR_MAX = 13
+'''
+Maximum minor stable version of this major version of Python currently released
+(e.g., ``5`` if Python 3.5 is the most recent stable version of Python 3.x).
+'''
+
+
+def _convert_version_str_to_tuple(version_str: str):  # -> _Tuple[int, ...]:
+    '''
+    Convert the passed human-readable ``.``-delimited version string into a
+    machine-readable version tuple of corresponding integers.
+    '''
+    assert isinstance(version_str, str), f'"{version_str}" not version string.'
+
+    return tuple(int(version_part) for version_part in version_str.split('.'))
+
+
+PYTHON_VERSION_MIN_PARTS = _convert_version_str_to_tuple(PYTHON_VERSION_MIN)
+'''
+Machine-readable minimum version of Python required by this package as a
+tuple of integers.
+'''
+
+
+_PYTHON_VERSION_PARTS = _sys.version_info[:3]
+'''
+Machine-readable current version of the active Python interpreter as a
+tuple of integers.
+'''
+
+
+# Validate the version of the active Python interpreter *BEFORE* subsequent
+# code possibly depending on this version. Since this version should be
+# validated both at setuptools-based install time and post-install runtime
+# *AND* since this module is imported sufficiently early by both, stash this
+# validation here to avoid duplication of this logic and hence the hardcoded
+# Python version.
+#
+# The "sys" module exposes three version-related constants for this purpose:
+# * "hexversion", an integer intended to be specified in an obscure (albeit
+#   both efficient and dependable) hexadecimal format: e.g.,
+#    >>> sys.hexversion
+#    33883376
+#    >>> '%x' % sys.hexversion
+#    '20504f0'
+# * "version", a human-readable string: e.g.,
+#    >>> sys.version
+#    2.5.2 (r252:60911, Jul 31 2008, 17:28:52)
+#    [GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)]
+# * "version_info", a tuple of three or more integers *OR* strings: e.g.,
+#    >>> sys.version_info
+#    (2, 5, 2, 'final', 0)
+#
+# For sanity, this package will *NEVER* conditionally depend upon the
+# string-formatted release type of the current Python version exposed via the
+# fourth element of the "version_info" tuple. Since the first three elements of
+# that tuple are guaranteed to be integers *AND* since a comparable 3-tuple of
+# integers is declared above, comparing the former and latter yield the
+# simplest and most reliable Python version test.
+#
+# Note that the nearly decade-old and officially accepted PEP 345 proposed a
+# new field "requires_python" configured via a key-value pair passed to the
+# call to setup() in "setup.py" (e.g., "requires_python = ['>=2.2.1'],"), that
+# field has yet to be integrated into either disutils or setuputils. Hence,
+# that field is validated manually in the typical way.
+if _PYTHON_VERSION_PARTS < PYTHON_VERSION_MIN_PARTS:
+    # Human-readable current version of Python. Ideally, "sys.version" would be
+    # leveraged here instead; sadly, that string embeds significantly more than
+    # merely a version and hence is inapplicable for real-world usage: e.g.,
+    #
+    #     >>> import sys
+    #     >>> sys.version
+    #     '3.6.5 (default, Oct 28 2018, 19:51:39) \n[GCC 7.3.0]'
+    _PYTHON_VERSION = '.'.join(
+        str(version_part) for version_part in _sys.version_info[:3])
+
+    # Die ignominiously.
+    raise RuntimeError(
+        f'{NAME} requires at least Python {PYTHON_VERSION_MIN}, but '
+        f'the active interpreter only targets Python {_PYTHON_VERSION}. '
+        f'We feel unbearable sadness for you.'
+    )
+
+# ....................{ METADATA ~ version                 }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: When modifying the current version of this package below,
+# consider adhering to the Semantic Versioning schema. Specifically, the
+# version should consist of three "."-delimited integers
+# "{major}.{minor}.{patch}", where:
+#
+# * "{major}" specifies the major version, incremented only when either:
+#   * Breaking backward compatibility in this package's public API.
+#   * Implementing headline-worthy functionality (e.g., a GUI). Technically,
+#     this condition breaks the Semantic Versioning schema, which stipulates
+#     that *ONLY* changes breaking backward compatibility warrant major bumps.
+#     But this is the real world. In the real world, significant improvements
+#     are rewarded with significant version changes.
+#   In either case, the minor and patch versions both reset to 0.
+# * "{minor}" specifies the minor version, incremented only when implementing
+#   customary functionality in a manner preserving such compatibility. In this
+#   case, the patch version resets to 0.
+# * "{patch}" specifies the patch version, incremented only when correcting
+#   outstanding issues in a manner preserving such compatibility.
+#
+# When in doubt, increment only the minor version and reset the patch version.
+# For further details, see http://semver.org.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+VERSION = '0.18.5'
+'''
+Human-readable package version as a ``.``-delimited string.
+'''
+
+
+VERSION_PARTS = _convert_version_str_to_tuple(VERSION)
+'''
+Machine-readable package version as a tuple of integers.
+'''
+
+# ....................{ METADATA ~ synopsis                }....................
+SYNOPSIS = 'Unbearably fast runtime type checking in pure Python.'
+'''
+Human-readable single-line synopsis of this package.
+
+By PyPI design, this string must *not* span multiple lines or paragraphs.
+'''
+
+# ....................{ METADATA ~ authors                 }....................
+AUTHOR_EMAIL = 'leycec@gmail.com'
+'''
+Email address of the principal corresponding author (i.e., the principal author
+responding to public correspondence).
+'''
+
+
+AUTHORS = 'Cecil Curry, et al.'
+'''
+Human-readable list of all principal authors of this package as a
+comma-delimited string.
+
+For brevity, this string *only* lists authors explicitly assigned copyrights.
+For the list of all contributors regardless of copyright assignment or
+attribution, see the `contributors graph`_ for this project.
+
+.. _contributors graph:
+   https://github.com/beartype/beartype/graphs/contributors
+'''
+
+
+COPYRIGHT = '2014-2024 Beartype authors'
+'''
+Legally binding copyright line excluding the license-specific prefix (e.g.,
+``"Copyright (c)"``).
+
+For brevity, this string *only* lists authors explicitly assigned copyrights.
+For the list of all contributors regardless of copyright assignment or
+attribution, see the `contributors graph`_ for this project.
+
+.. _contributors graph:
+   https://github.com/beartype/beartype/graphs/contributors
+'''
+
+# ....................{ METADATA ~ urls                    }....................
+URL_CONDA = f'https://anaconda.org/conda-forge/{PACKAGE_NAME}'
+'''
+URL of this project's entry on **Anaconda** (i.e., alternate third-party Python
+package repository utilized by the Anaconda Python distribution).
+'''
+
+
+URL_LIBRARIES = f'https://libraries.io/pypi/{PACKAGE_NAME}'
+'''
+URL of this project's entry on **Libraries.io** (i.e., third-party open-source
+package registrar associated with the Tidelift open-source funding agency).
+'''
+
+
+URL_PYPI = f'https://pypi.org/project/{PACKAGE_NAME}'
+'''
+URL of this project's entry on **PyPI** (i.e., official Python package
+repository, also colloquially known as the "cheeseshop").
+'''
+
+
+URL_RTD = f'https://readthedocs.org/projects/{PACKAGE_NAME}'
+'''
+URL of this project's entry on **ReadTheDocs (RTD)** (i.e., popular Python
+documentation host, shockingly hosting this project's documentation).
+'''
+
+# ....................{ METADATA ~ urls : docs             }....................
+URL_HOMEPAGE = f'https://{PACKAGE_NAME}.readthedocs.io'
+'''
+URL of this project's homepage.
+'''
+
+
+URL_PEP585_DEPRECATIONS = (
+    f'{URL_HOMEPAGE}/en/latest/api_roar/#pep-585-deprecations')
+'''
+URL documenting :pep:`585` deprecations of :pep:`484` type hints.
+'''
+
+# ....................{ METADATA ~ urls : repo             }....................
+URL_REPO_ORG_NAME = PACKAGE_NAME
+'''
+Name of the **organization** (i.e., parent group or user principally responsible
+for maintaining this project, indicated as the second-to-last trailing
+subdirectory component) of the URL of this project's git repository.
+'''
+
+
+URL_REPO_BASENAME = PACKAGE_NAME
+'''
+**Basename** (i.e., trailing subdirectory component) of the URL of this
+project's git repository.
+'''
+
+
+URL_REPO = f'https://github.com/{URL_REPO_ORG_NAME}/{URL_REPO_BASENAME}'
+'''
+URL of this project's git repository.
+'''
+
+
+URL_DOWNLOAD = f'{URL_REPO}/archive/{VERSION}.tar.gz'
+'''
+URL of the source tarball for the current version of this project.
+
+This URL assumes a tag whose name is ``v{VERSION}`` where ``{VERSION}`` is the
+human-readable current version of this project (e.g., ``v0.4.0``) to exist.
+Typically, no such tag exists for live versions of this project -- which
+have yet to be stabilized and hence tagged. Hence, this URL is typically valid
+*only* for previously released (rather than live) versions of this project.
+'''
+
+
+URL_FORUMS = f'{URL_REPO}/discussions'
+'''
+URL of this project's user forums.
+'''
+
+
+URL_ISSUES = f'{URL_REPO}/issues'
+'''
+URL of this project's issue tracker.
+'''
+
+
+URL_RELEASES = f'{URL_REPO}/releases'
+'''
+URL of this project's release list.
+'''
+
+# ....................{ METADATA ~ libs : runtime          }....................
+_LIB_RUNTIME_OPTIONAL_VERSION_MINIMUM_NUMPY = '1.21.0'
+'''
+Minimum optional version of NumPy recommended for use with this project.
+
+NumPy >= 1.21.0 first introduced the third-party PEP-noncompliant
+:attr:`numpy.typing.NDArray` type hint supported by the
+:func:`beartype.beartype` decorator.
+'''
+
+
+_LIB_RUNTIME_OPTIONAL_VERSION_MINIMUM_TYPING_EXTENSIONS = '3.10.0.0'
+'''
+Minimum optional version of the third-party :mod:`typing_extensions` package
+recommended for use with this project.
+
+:mod:`typing_extensions` >= 3.10.0.0 backports all :mod:`typing` attributes
+unavailable under older Python interpreters supported by the
+:func:`beartype.beartype` decorator.
+'''
+
+
+# Note that we intentionally omit NumPy here, because:
+# * If you want it, you're already using it.
+# * If you do *NOT* want it, you're *NOT* already using it.
+LIBS_RUNTIME_OPTIONAL = (
+    (
+        f'typing-extensions >='
+        f'{_LIB_RUNTIME_OPTIONAL_VERSION_MINIMUM_TYPING_EXTENSIONS}'
+    ),
+)
+'''
+Optional runtime package dependencies as a tuple of :mod:`setuptools`-specific
+requirements strings of the format ``{project_name}
+{comparison1}{version1},...,{comparisonN}{versionN}``, where:
+
+* ``{project_name}`` is a :mod:`setuptools`-specific project name (e.g.,
+  ``"numpy"``, ``"scipy"``).
+* ``{comparison1}`` and ``{comparisonN}`` are :mod:`setuptools`-specific
+  version comparison operators. As well as standard mathematical comparison
+  operators (e.g., ``==``, ``>=``, ``<``), :mod:`setuptools` also supports the
+  PEP 440-compliant "compatible release" operator ``~=`` more commonly denoted
+  by ``^`` in modern package managers (e.g., poetry, npm); this operator
+  enables forward compatibility with all future versions of this dependency
+  known *not* to break backward compatibility, but should only be applied to
+  dependencies strictly following the semantic versioning contract.
+* ``{version1}`` and ``{version1}`` are arbitrary version strings (e.g.,
+  ``2020.2.16``, ``0.75a2``).
+'''
+
+# ....................{ METADATA ~ libs : test : optional  }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# CAUTION: Avoid constraining optional test-time dependencies to version
+# ranges, which commonly fail for edge-case test environments -- including:
+# * The oldest Python version still supported by @beartype, which typically is
+#   *NOT* supported by newer versions of these dependencies.
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+LIBS_TESTTIME_OPTIONAL = (
+    # Required by optional Equinox-specific integration tests.
+    'equinox',
+
+    # Require a reasonably recent version of mypy known to behave well. Less
+    # recent versions are significantly deficient with respect to error
+    # reporting and *MUST* thus be blacklisted.
+    #
+    # Note that PyPy currently fails to support mypy. See also this official
+    # documentation discussing this regrettable incompatibility:
+    #     https://mypy.readthedocs.io/en/stable/faq.html#does-it-run-on-pypy
+    'mypy >=0.800; platform_python_implementation != "PyPy"',
+
+    #FIXME: Let's avoid attempting to remotely compile with nuitka under GitHub
+    #Actions-hosted continuous integration (CI) for the moment. Doing so is
+    #non-trivial enough under local testing workflows. *sigh*
+    # Require a reasonably recent version of nuitka if the current platform is a
+    # Linux distribution *AND* the active Python interpreter targets Python >=
+    # 3.8. For questionable reasons best ignored, nuitka fails to compile
+    # beartype under Python <= 3.7.
+    # 'nuitka >=1.2.6; sys_platform == "linux" and python_version >= "3.8.0"',
+
+    #FIXME: Consider dropping the 'and platform_python_implementation != "PyPy"'
+    #clause now that "tox.ini" installs NumPy wheels from a third-party vendor
+    #explicitly supporting PyPy.
+    # Require NumPy. NumPy has become *EXTREMELY* non-trivial to install under
+    # macOS with "pip", due to the conjunction of multiple issues. These
+    # include:
+    # * NumPy > 1.18.0, whose initial importation now implicitly detects
+    #   whether the BLAS implementation NumPy was linked against is sane and
+    #   raises a "RuntimeError" exception if that implementation is insane:
+    #       RuntimeError: Polyfit sanity test emitted a warning, most
+    #       likely due to using a buggy Accelerate backend. If you
+    #       compiled yourself, more information is available at
+    #       https://numpy.org/doc/stable/user/building.html#accelerated-blas-lapack-libraries
+    #       Otherwise report this to the vendor that provided NumPy.
+    #       RankWarning: Polyfit may be poorly conditioned
+    # * Apple's blatantly broken multithreaded implementation of their
+    #   "Accelerate" BLAS replacement, which neither NumPy nor "pip" have *ANY*
+    #   semblance of control over.
+    # * "pip" under PyPy, which for unknown reasons fails to properly install
+    #   NumPy even when the "--force-reinstall" option is explicitly passed to
+    #   "pip". Oddly, passing that option to "pip" under CPython resolves this
+    #   issue -- which is why we only selectively disable NumPy installation
+    #   under macOS + PyPy.
+    #
+    # See also this upstream NumPy issue:
+    #     https://github.com/numpy/numpy/issues/15947
+    (
+        'numpy; '
+        'sys_platform != "darwin" and '
+        'platform_python_implementation != "PyPy"'
+    ),
+
+    # Required by optional Pandera-specific integration tests.
+    'pandera',
+
+    # Required by optional Sphinx-specific integration tests.
+    #
+    # Note that Sphinx currently provokes unrelated test failures under Python
+    # 3.7 with  obscure deprecation warnings. Since *ALL* of this only applies
+    # to Python 3.7, we crudely circumvent this nonsense by simply avoiding
+    # installing Sphinx under Python 3.7. The exception resembles:
+    #     FAILED
+    #     ../../../beartype_test/a00_unit/a20_util/test_utilobject.py::test_is_object_hashable
+    #     - beartype.roar.BeartypeModuleUnimportableWarning: Ignoring module
+    #     "pkg_resources.__init__" importation exception DeprecationWarning:
+    #     Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.
+    'sphinx; python_version >= "3.8.0"',
+
+    #FIXME: Temporarily disabled for sanity.
+    # Required by optional PyTorch-specific integration tests.
+    #
+    # Note that PyTorch has yet to release a Python >= 3.12-compatible version.
+    # 'torch; python_version < "3.12.0"',
+
+    # Required to exercise third-party backports of type hint factories
+    # published by the standard "typing" module under newer versions of Python.
+    (
+        f'typing-extensions >='
+        f'{_LIB_RUNTIME_OPTIONAL_VERSION_MINIMUM_TYPING_EXTENSIONS}'
+    ),
+)
+'''
+**Optional developer test-time package dependencies** (i.e., dependencies
+recommended to test this package with :mod:`tox` as a developer at the command
+line) as a tuple of :mod:`setuptools`-specific requirements strings of the
+format ``{project_name} {comparison1}{version1},...,{comparisonN}{versionN}``.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
+
+# ....................{ METADATA ~ libs : test : mandatory }....................
+LIBS_TESTTIME_MANDATORY_COVERAGE = (
+    'coverage >=5.5',
+)
+'''
+**Mandatory test-time coverage package dependencies** (i.e., dependencies
+required to measure test coverage for this package) as a tuple of
+:mod:`setuptools`-specific requirements strings of the format ``{project_name}
+{comparison1}{version1},...,{comparisonN}{versionN}``.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
+
+
+# For completeness, install *ALL* optional test-time dependencies into *ALL*
+# isolated virtual environments managed by "tox". Failure to list *ALL*
+# optional test-time dependencies here commonly results in errors from mypy,
+# which raises false positives on parsing "import" statements for currently
+# uninstalled third-party packages (e.g., "import numpy as np").
+LIBS_TESTTIME_MANDATORY_TOX = LIBS_TESTTIME_OPTIONAL + (
+    'pytest >=4.0.0',
+)
+'''
+**Mandatory tox test-time package dependencies** (i.e., dependencies required
+to test this package under :mod:`tox`) as a tuple of :mod:`setuptools`-specific
+requirements strings of the format ``{project_name}
+{comparison1}{version1},...,{comparisonN}{versionN}``.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
+
+
+LIBS_TESTTIME_MANDATORY = (
+    LIBS_TESTTIME_MANDATORY_COVERAGE +
+    LIBS_TESTTIME_MANDATORY_TOX + (
+        # A relatively modern version of tox is required.
+        'tox >=3.20.1',
+    )
+)
+'''
+**Mandatory developer test-time package dependencies** (i.e., dependencies
+required to test this package with :mod:`tox` as a developer at the command
+line) as a tuple of :mod:`setuptools`-specific requirements strings of the
+format ``{project_name} {comparison1}{version1},...,{comparisonN}{versionN}``.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
+
+# ....................{ METADATA ~ libs : doc : sphinx     }....................
+_SPHINX_VERSION_MINIMUM = '4.2.0'
+'''
+Machine-readable minimum (inclusive) version as a ``.``-delimited string of
+:mod:`sphinx` required to build package documentation.
+
+Specifically, this project requires:
+
+* :mod:sphinx` >= 4.2.0, which resolved a `severe compatibility issue`_ with
+  Python >= 3.10.
+
+.. _severe compatibility issue:
+   https://github.com/sphinx-doc/sphinx/issues/9816
+'''
+
+
+#FIXME: Once "pydata-sphinx-theme" 0.13.0 is released:
+#* Relax this restriction (e.g., by simply commenting this global out both here
+#  and below).
+#* Bump "_SPHINX_THEME_VERSION_MAXIMUM >= '0.13.0'" below.
+_SPHINX_VERSION_MAXIMUM_EXCLUSIVE = '6.0.0'
+'''
+Machine-readable maximum (exclusive) version as a ``.``-delimited string of
+:mod:`sphinx` required to build package documentation.
+
+Specifically, this project requires:
+
+* :mod:sphinx` < 6.0.0, as more recent versions `currently conflict with our
+  Sphinx theme <theme conflict_>`__.
+
+.. _theme conflict:
+   https://github.com/sphinx-doc/sphinx/issues/9816
+'''
+
+# ....................{ METADATA ~ libs : doc : theme      }....................
+#FIXME: Switch! So, "pydata-sphinx-theme" is ostensibly *MOSTLY* great. However,
+#there are numerous obvious eccentricities in "pydata-sphinx-theme" that we
+#strongly disagree with -- especially that theme's oddball division in TOC
+#heading levels between the top and left sidebars.
+#
+#Enter "sphinx-book-theme", stage left. "sphinx-book-theme" is based on
+#"pydata-sphinx-theme", but entirely dispenses with all of the obvious
+#eccentricities that hamper usage of "pydata-sphinx-theme". We no longer have
+#adequate time to maintain custom documentation CSS against the moving target
+#that is "pydata-sphinx-theme". Ergo, we should instead let "sphinx-book-theme"
+#do all of that heavy lifting for us. Doing so will enable us to:
+#* Lift the horrifying constraint above on a maximum Sphinx version. *gulp*
+#* Substantially simplify our Sphinx configuration. Notably, the entire fragile
+#  "doc/src/_templates/" subdirectory should be *ENTIRELY* excised away.
+#
+#Please transition to "sphinx-book-theme" as time permits.
+SPHINX_THEME_NAME = 'pydata-sphinx-theme'
+'''
+Name of the third-party Sphinx extension providing the custom HTML theme
+preferred by this documentation.
+
+Note that we selected this theme according to mostly objective (albeit
+ultimately subjective) heuristic criteria. In descending order of importance, we
+selected the theme with:
+
+#. The most frequent git commit history.
+#. The open issues and pull requests (PRs).
+#. The most GitHub stars as a crude proxy for aggregate rating.
+#. **IS NOT STRONGLY OPINIONATED** (i.e., is configurable with standard Sphinx
+   settings and directives).
+
+Furo
+----------
+Furo_ handily bested all other themes across the first three criteria. Furo is
+very well-maintained, frequently closes out open issues and merges open PRs, and
+sports the highest quantity of GitHub stars by an overwhelming margin. Sadly,
+Furo handily loses against literally unmaintained themes across the final
+criteria. Furo is absurdly strongly opinionated to an authoritarian degree we
+rarely find in open-source software. Why? Because it's principal maintainer is.
+Like maintainer, like software. Furo routinely ignores standard Sphinx settings
+and directives due to subjective opinions held by its maintainer, including:
+
+* Most user-defined ``:toctree:`` settings used to configure both global and
+  local tables of contents (TOCs) and thus the leftmost navigation sidebar,
+  effectively preventing users from using that sidebar to navigate to anything.
+  We are *not* kidding. ``:toctree:`` settings ignored by Furo include:
+
+  * ``:maxdepth:``. Internally, Furo forces the ``:titlesonly:`` setting by
+    passing ``titles_only=True`` to Sphinx's ``toctree()`` function at runtime.
+    Doing so effectively coerces ``:maxdepth: 1``, thus intentionally hiding
+    *all* document structure from the navigation sidebar -- where (usually)
+    *all* document structure is displayed. Users thus have no means of directly
+    jumping from the root landing page to child leaf documents, significantly
+    obstructing user experience (UX) and usability. See also this `feature
+    request <Furo discussion_>`__ to relax these constraints, to which the Furo
+    maintainer caustically replies:
+
+        No, there isn't any (supported) way to do this.
+
+        Separating the page content hierarchy and site structure was an explicit
+        design goal.
+
+We fundamentally disagree with those goals and have thus permanently switched
+away from Furo. Unjustified opinions are the little death of sanity.
+
+PyData
+======
+Furo and PyData are neck-and-neck with respect to git commit history; both are
+extremely well-maintained. Furo leaps ahead with respect to both issue and PR
+resolution, however; PyData has an extreme number of open issues and PRs, where
+Furo enjoys none. Moreover, Furo also enjoys dramatically more GitHub stars.
+
+Nonetheless, PyData is *not* strongly opinionated; Furo is. PyData does *not*
+silently ignore standard Sphinx settings and directives for largely indefensible
+reasons. Consequently, PyData wins by default. In fact, *any* other theme
+(including even unmaintained dead themes) wins by default; *no* other theme (to
+my limited knowledge) forcefully ignores standard Sphinx settings and directives
+to the extent that Furo does.
+
+PyData wins by *literally* doing nothing. Laziness prevails. All hail La-Z-Boy.
+
+.. _Furo:
+   https://github.com/pradyunsg/furo
+.. _Furo discussion:
+   https://github.com/pradyunsg/furo/discussions/146
+'''
+
+
+_SPHINX_THEME_VERSION_MAXIMUM = '0.7.2'
+# _SPHINX_THEME_VERSION_MAXIMUM = '0.12.0'
+'''
+Machine-readable maximum (inclusive) version as a ``.``-delimited string of the
+above Sphinx theme optionally leveraged when building package documentation.
+
+This theme is a rapidly moving target that frequently breaks backward
+compatibility. Although understandable, the fragility of this theme leaves us
+little alternatives but to pin to a **maximum** rather than **minimum** version
+of this theme. Specifically, this project requires:
+
+* :mod:pydata_sphinx_theme` <= 0.7.2, as our circumvention of both
+  pydata/pydata-sphinx-theme#90 and pydata/pydata-sphinx-theme#221 assumes a
+  reasonably older version of this theme. See also this currently `open issue`_.
+
+.. _open issue:
+   https://github.com/pydata/pydata-sphinx-theme/issues/1181
+'''
+
+# ....................{ METADATA ~ libs : doc              }....................
+LIBS_DOCTIME_MANDATORY = (
+    # Sphinx itself.
+    (
+        f'sphinx '
+        f'>={_SPHINX_VERSION_MINIMUM}, '
+        f'<{_SPHINX_VERSION_MAXIMUM_EXCLUSIVE}'
+    ),
+
+    # Third-party Sphinx theme.
+    f'{SPHINX_THEME_NAME} <={_SPHINX_THEME_VERSION_MAXIMUM}',
+
+    # Third-party Sphinx extensions.
+    'autoapi >=0.9.0',
+    'sphinxext-opengraph >= 0.7.5',
+)
+'''
+**Mandatory developer documentation build-time package dependencies** (i.e.,
+dependencies required to manually build documentation for this package as a
+developer at the command line) as a tuple of :mod:`setuptools`-specific
+requirements strings of the format ``{project_name}
+{comparison1}{version1},...,{comparisonN}{versionN}``.
+
+For flexibility, these dependencies are loosely relaxed to enable developers to
+build with *any* versions satisfying at least the bare minimum. For the same
+reason, optional documentation build-time package dependencies are omitted.
+Since our documentation build system emits a non-fatal warning for each missing
+optional dependency, omitting these optional dependencies here imposes no undue
+hardships while improving usability.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
+
+
+#FIXME: For future use, we still preserve an RTD-specific list of requirements.
+#It's unclear whether we actually require this, however. Consider excising. The
+#prior approach of pinning exact Sphinx versions failed painfully by
+#accidentally constraining us to obsolete Sphinx versions known to be broken.
+LIBS_DOCTIME_MANDATORY_RTD = LIBS_DOCTIME_MANDATORY
+# LIBS_DOCTIME_MANDATORY_RTD = (
+#     f'sphinx =={_SPHINX_VERSION_MINIMUM}',
+#     f'{SPHINX_THEME_NAME} =={_SPHINX_THEME_VERSION_MAXIMUM}',
+# )
+'''
+**Mandatory Read The Docs (RTD) documentation build-time package dependencies**
+(i.e., dependencies required to automatically build documentation for this
+package from the third-party RTD hosting service) as a tuple of
+:mod:`setuptools`-specific requirements strings of the format ``{project_name}
+{comparison1}{version1},...,{comparisonN}{versionN}``.
+
+For consistency, these dependencies are strictly constrained to force RTD to
+build against a single well-tested configuration known to work reliably.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
+
+# ....................{ METADATA ~ libs : dev              }....................
+LIBS_DEVELOPER_MANDATORY = LIBS_TESTTIME_MANDATORY + LIBS_DOCTIME_MANDATORY
+'''
+**Mandatory developer package dependencies** (i.e., dependencies required to
+develop and meaningfully contribute pull requests for this package) as a tuple
+of :mod:`setuptools`-specific requirements strings of the format
+``{project_name} {comparison1}{version1},...,{comparisonN}{versionN}``.
+
+This tuple includes all mandatory test- and documentation build-time package
+dependencies and is thus a convenient shorthand for those lower-level tuples.
+
+See Also
+----------
+:data:`LIBS_RUNTIME_OPTIONAL`
+    Further details.
+'''
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/peps/__init__.py
@@ -0,0 +1,28 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype Python Enhancement Proposal (PEP) API.**
+
+This subpackage provides a medley of miscellaneous low-level utility functions
+implementing unofficial (albeit well-tested) runtime support for PEPs lacking
+official runtime support in CPython's standard library. This subpackage is
+intended to be used both by downstream third-party packages and the
+:mod:`beartype` codebase itself. Supported PEPs include:
+
+* :pep:`563` (i.e., "Postponed Evaluation of Annotations") via the
+  :func:`resolve_pep563` function.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.peps._pep563 import (
+    resolve_pep563 as resolve_pep563,
+)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/peps/_pep563.py
@@ -0,0 +1,418 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype :pep:`563` **resolvers** (i.e., public high-level callables resolving
+stringified :pep:`563`-compliant type hints implicitly postponed by the active
+Python interpreter via a ``from __future__ import annotations`` statement at the
+head of the external user-defined module currently being introspected).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: [DOCOS] Officially document both this and the public "beartype.peps"
+#submodule, please.
+
+#FIXME: Conditionally emit a non-fatal PEP 563-specific warning when the active
+#Python interpreter targets Python >= 3.10 *AND* the passed callable is nested.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypePep563Exception
+from beartype._check.checkcall import make_beartype_call
+from beartype._check.forward.fwdmain import resolve_hint
+from beartype._conf.confcls import (
+    BEARTYPE_CONF_DEFAULT,
+    BeartypeConf,
+)
+from beartype._data.hint.datahinttyping import TypeStack
+from beartype._util.cache.pool.utilcachepoolobjecttyped import (
+    release_object_typed)
+from beartype._util.func.utilfuncget import get_func_annotations
+from collections.abc import Callable
+
+# ....................{ RESOLVERS                          }....................
+def resolve_pep563(
+    # Mandatory parameters.
+    func: Callable,
+
+    # Optional parameters.
+    conf: BeartypeConf = BEARTYPE_CONF_DEFAULT,
+    cls_stack: TypeStack = None,
+) -> None:
+    '''
+    Resolve all :pep:`563`-based **postponed annotations** (i.e., strings that
+    when dynamically evaluated as Python expressions yield actual annotations)
+    on the passed callable to their **referents** (i.e., the actual annotations
+    to which those postponed annotations evaluate) if `PEP 563`_ is active for
+    that callable *or* silently reduce to a noop otherwise (i.e., if :pep:`563`
+    is *not* active for that callable).
+
+    :pep:`563` is active for that callable if the module declaring that callable
+    explicitly enabled :pep:`563` support with a leading dunder importation of
+    the form ``from __future__ import annotations``. If :pep:`563` is active for
+    that callable, then for each type-hint annotating that callable:
+
+    * If that hint is a string and thus postponed, this function:
+
+      #. Dynamically evaluates that string within that callable's globals
+         context (i.e., set of all global variables defined by the module
+         declaring that callable).
+      #. Replaces that hint's string value with the expression produced by this
+         dynamic evaluation.
+
+    * Else, this function preserves that hint as is (e.g., due to that hint
+      that was previously postponed having already been evaluated by a prior
+      decorator).
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to resolve postponed annotations on.
+    conf : BeartypeConf, optional
+        Beartype configuration configuring :func:`beartype.beartype` uniquely
+        specific to this callable. Defaults to :data`.BEARTYPE_CONF_DEFAULT`,
+        the default beartype configuration.
+    cls_stack : TypeStack
+        Either:
+
+        * If that callable is a method of a class, the **type stack** (i.e.,
+          tuple of one or more lexically nested classes in descending order of
+          top- to bottom-most lexically nested) such that:
+
+          * The first item of this tuple is expected to be the **root class**
+            (i.e., top-most class whose lexical scope encloses that callable,
+            typically declared at module scope and thus global).
+          * The last item of this tuple is expected to be the **current class**
+            (i.e., possibly nested class directly containing that method).
+
+        * Else, that callable is *not* a method of a class. In this case,
+          :data:`None`.
+
+        Defaults to :data:`None`.
+
+        Note that this function requires *both* the root and current class to
+        correctly resolve edge cases under :pep:`563`: e.g.,
+
+        .. code-block:: python
+
+           from __future__ import annotations
+           from beartype import beartype
+
+           @beartype
+           class Outer(object):
+               class Inner(object):
+                   # At this time, the "Outer" class has been fully defined but
+                   # is *NOT* yet accessible as a module-scoped attribute. Ergo,
+                   # the *ONLY* means of exposing the "Outer" class to the
+                   # recursive decoration of this get_outer() method is to
+                   # explicitly pass the "Outer" class as the "cls_root"
+                   # parameter to all decoration calls.
+                   def get_outer(self) -> Outer:
+                       return Outer()
+
+        Note also that nested classes have *no* implicit access to either their
+        parent classes *or* to class variables declared by those parent classes.
+        Nested classes *only* have explicit access to module-scoped classes --
+        exactly like any other arbitrary objects: e.g.,
+
+        .. code-block:: python
+
+           class Outer(object):
+               my_str = str
+
+               class Inner(object):
+                   # This induces a fatal compile-time exception resembling:
+                   #     NameError: name 'my_str' is not defined
+                   def get_str(self) -> my_str:
+                       return 'Oh, Gods.'
+
+        Nonetheless, this tuple *must* contain all of those nested classes
+        lexically containing the passed method. Why? Because this function
+        resolves local attributes defined in the body of the callable on the
+        current call stack lexically containing those nested classes (if any) by
+        treating the length of this tuple as the total number of classes
+        lexically nesting the current class. In short, just pass everything.
+
+    Raises
+    ----------
+    BeartypePep563Exception
+        If either:
+
+        * That callable is *not* a pure-Python callable (e.g., is C-based).
+        * Evaluating a postponed annotation on that callable raises an exception
+          (e.g., due to that annotation referring to local state inaccessible in
+          this deferred context).
+    '''
+
+    # ..................{ NOOP                               }..................
+    # Dictionary to be returned, mapping from the name of each annotated
+    # parameter and return of the passed callable to the non-string type hint
+    # resolved from the string type hint annotating that parameter or return --
+    # raising an exception if that callable is *NOT* a pure-Python callable.
+    #
+    # Note that the "func.__annotations__" dictionary *CANNOT* be safely
+    # directly assigned to below, as the loop performing that assignment below
+    # necessarily iterates over that dictionary. As with most languages, Python
+    # containers cannot be safely mutated while being iterated.
+    arg_name_to_hint = get_func_annotations(
+        func=func,
+        exception_cls=BeartypePep563Exception,
+        exception_prefix='Callable ',
+    )
+
+    # If that callable is unannotated, silently reduce to a noop.
+    if not arg_name_to_hint:
+        return
+    # Else, that callable is annotated by one or more type hints.
+
+    # If that callable was *NOT* subject to PEP 563-compliant postponement of
+    # type hints under the standard "from __future__ import annotations" import,
+    # silently reduce to a noop.
+    #
+    # Note that there exist numerous means of detecting PEP 563. This approach:
+    # * Is the least efficient, requiring O(n) iteration for n the number of
+    #   type hints annotating that callable.
+    # * Is the most reliable, detecting PEP 563 regardless of whether:
+    #   * That callable was dynamically synthesized in-memory *OR* physically
+    #     defined in an on-disk source module. In the latter case, this
+    #     detection heuristic could statically analyze the on-disk source code
+    #     underlying that callable for an import of the form:
+    #         from __future__ import annotations
+    #     In the former case, however, that analysis is infeasible.
+    #   * The "__future__.annotations" singleton object is a global attribute of
+    #     the module defining that callable. This simplistic test fails under
+    #     numerous edge cases, including if:
+    #     * That callable was dynamically synthesized in-memory, in which case
+    #       that callable may have *NO* such module.
+    #     * That callable was physically defined in an on-disk source module
+    #       that enabled PEP 563 but which then maliciously deleted the
+    #       "__future__.annotations" singleton object from module scope: e.g.,
+    #           from __future__ import annotations
+    #           del annotations
+    #       Yes, that is valid Python. Yes, Python continues to enable PEP 563
+    #       for that module despite that module deleting the "annotations"
+    #       attribute from module scope. Yes, we're facepalming ourselves.
+    #
+    # Since reliability is *FAR* more important than efficiency, this function
+    # adopts the detection heuristic that is the most inefficient and reliable.
+    #
+    # For the name of each annotated parameter and return of the passed callable
+    # and the type hint annotating that parameter or return...
+    for arg_name, hint in arg_name_to_hint.items():
+        # If this hint is *NOT* stringified, this hint was either:
+        # * Never postponed under PEP 563 (i.e., the module defining that
+        #   callable did *NOT* import "from __future__ import annotations").
+        # * Previously postponed under PEP 563 (i.e., the module defining that
+        #   callable imported "from __future__ import annotations") but has
+        #   since been resolved into a non-string type hint by a competing
+        #   runtime type-introspector, possibly including @beartype itself.
+        #
+        # In either case, PEP 563 is now disabled for this hint. But PEP 563 is
+        # a module-scoped effect that universally applies to *ALL* type hints
+        # annotating *ALL* callables of a module. If PEP 563 is disabled for one
+        # hint of a callable, then PEP 563 must necessarily be disabled for all
+        # hints of that same callable. In this case, reduce to a noop.
+        if not isinstance(hint, str):
+            return
+        # Else, this hint is stringified. In this case, this hint was either:
+        # * Postponed under PEP 563 (i.e., the module defining that callable
+        #   imported "from __future__ import annotations").
+        # * Never postponed under PEP 563 (i.e., the module defining that
+        #   callable did *NOT* import "from __future__ import annotations") but
+        #   was instead simply a PEP 484-compliant forward reference (e.g.,
+        #   "def muh_func(muh_arg: 'MuhClass'): ...").
+        #
+        # Differentiating these two cases is infeasible! Python's standard
+        # library failed to ship solutions to this or any other outstanding
+        # runtime issues with PEP 563. Instead, we pretend everything will be
+        # okay by silently ignoring the latter case. Doing so largely suffices
+        # but can technically yield a false positive. This is why PEP 563 should
+        # have failed Python's peer review process. Of course, it passed
+        # instead. In short: "Trust me, bro."
+    # All type hints annotating the passed callable are now guaranteed to have
+    # been stringified. For simplicity, we assume these hints were stringified
+    # automatically by PEP 563 rather than manually by user typing.
+
+    # ..................{ LOCALS                             }..................
+    # Beartype call metadata describing the passed callable.
+    bear_call = make_beartype_call(
+        func=func,
+        conf=conf,
+        cls_stack=cls_stack,
+    )
+
+    # Make a shallow copy of the dictionary to be returned. Why? Because the
+    # "func.__annotations__" dictionary *CANNOT* be safely directly assigned to
+    # below, as the loop performing that assignment below necessarily iterates
+    # over that dictionary. As with most languages, Python containers cannot be
+    # safely mutated while being iterated.
+    arg_name_to_hint = arg_name_to_hint.copy()
+
+    # ..................{ RESOLUTION                         }..................
+    # For the name of each annotated parameter and return of the passed callable
+    # and the stringified type hint annotating that parameter or return...
+    #
+    # Note that refactoring this iteration into a dictionary comprehension would
+    # be both:
+    # * Largely infeasible (e.g., due to the need to raise human-readable
+    #   exceptions on evaluating invalid type hints).
+    # * largely pointless (e.g., due to dictionary comprehensions being either
+    #   no faster or even slower than explicit iteration for small dictionary
+    #   sizes, as "func.__annotations__" usually is).
+    for arg_name, hint in arg_name_to_hint.items():
+        # If this hint is stringified, resolve this stringified type hint to the
+        # non-string type hint to which this string refers.
+        #
+        # Note that this test could technically yield a false positive in the
+        # unlikely edge case that this hint was previously postponed but has
+        # since been replaced in-place by its referent that is itself a PEP
+        # 484-compliant forward reference matching the PEP 563 format without
+        # actually being a PEP 563-postponed type hint. Since PEP 563 failed to
+        # provide solutions to this or any other outstanding runtime issues with
+        # PEP 563, there is *NOTHING* we can differentiate these two edge cases.
+        # Instead, we pretend everything will be okay. "Trust me, bro!"
+        if isinstance(hint, str):
+            arg_name_to_hint[arg_name] = resolve_hint(
+                hint=hint,
+                bear_call=bear_call,
+                exception_cls=BeartypePep563Exception,
+            )
+        # Else, this hint is *NOT* stringified. In this case, preserve this hint
+        # as is.
+
+    # ..................{ RETURN                             }..................
+    # Release this beartype call metadata back to its object pool.
+    release_object_typed(bear_call)
+
+    # Attempt to...
+    try:
+        # Atomically (i.e., all-at-once) replace that callable's postponed
+        # annotations with these resolved annotations for safety and efficiency.
+        #
+        # While the @beartype decorator goes to great lengths to preserve the
+        # originating "__annotations__" dictionary as is, PEP 563 is
+        # sufficiently expensive, non-trivial, and general-purpose to implement
+        # that generally resolving postponed annotations for downstream
+        # third-party callers is justified. Everyone benefits from replacing
+        # useless postponed annotations with useful real annotations; so, do so.
+        func.__annotations__ = arg_name_to_hint
+    # If doing so fails with an exception resembling the following, then that
+    # callable is *NOT* a pure-Python callable but rather a C-based decorator
+    # object of some sort (e.g., class, property, or static method descriptor):
+    #     AttributeError: 'method' object has no attribute '__annotations__'
+    #
+    # C-based decorator objects define a read-only "__annotations__" dunder
+    # attribute that proxies an original writeable "__annotations__" dunder
+    # attribute of the pure-Python callables they originally decorated. Ergo,
+    # detecting this edge case is non-trivial and most most easily deferred to
+    # this late time. While non-ideal, simplicity >>>> idealism in this case.
+    except AttributeError:
+        # For the name of each annotated parameter and return of that callable
+        # and the destringified type hint annotating this parameter or return,
+        # overwrite the stringified type hint originally annotating this
+        # parameter or return with this destringified type hint.
+        #
+        # Note that:
+        # * The above assignment is an efficient O(1) operation and thus
+        #   intentionally performed first.
+        # * This iteration-based assignment is an inefficient O(n) operation
+        #   (where "n" is the number of annotated parameters and returns of that
+        #   callable) and thus intentionally performed last here.
+        for arg_name, arg_hint in arg_name_to_hint.items():
+            func.__annotations__[arg_name] = arg_hint
+
+    # print(
+    #     f'{func.__name__}() PEP 563-postponed annotations resolved:'
+    #     f'\n\t------[ POSTPONED ]------\n\t{func_hints_postponed}'
+    #     f'\n\t------[ RESOLVED  ]------\n\t{func_hints_resolved}'
+    # )
+
+# ....................{ PRIVATE ~ resolvers                }....................
+#FIXME: We currently no longer require this. See above for further commentary.
+# from beartype.roar import BeartypeDecorHintPepException
+# from beartype._util.cache.pool.utilcachepoollistfixed import FIXED_LIST_SIZE_MEDIUM
+#
+# def _die_if_hint_repr_exceeds_child_limit(
+#     hint_repr: str, pith_label: str) -> None:
+#     '''
+#     Raise an exception if the passed machine-readable representation of an
+#     arbitrary annotation internally exceeds the **child limit** (i.e., maximum
+#     number of nested child type hints listed as subscripted arguments of
+#     PEP-compliant type hints) permitted by the :func:`beartype.beartype`
+#     decorator.
+#
+#     The :mod:`beartype` decorator internally traverses over these nested child
+#     types of the parent PEP-compliant type hint produced by evaluating this
+#     string representation to its referent with a breadth-first search (BFS).
+#     For efficiency, this search is iteratively implemented with a cached
+#     **fixed list** (i.e.,
+#     :class:`beartype._util.cache.pool.utilcachepoollistfixed.FixedList`
+#     instance) rather than recursively implemented with traditional recursion.
+#     Since the size of this list is sufficiently large to handle all uncommon
+#     *and* uncommon edge cases, this list suffices for *all* PEP-compliant type
+#     hints of real-world interest.
+#
+#     Nonetheless, safety demands that we guarantee this by explicitly raising an
+#     exception when the internal structure of this string suggests that the
+#     resulting PEP-compliant type hint will subsequently violate this limit.
+#     This has the convenient side effect of optimizing that BFS, which may now
+#     unconditionally insert child hints into arbitrary indices of that cached
+#     fixed list without having to explicitly test whether each index exceeds the
+#     fixed length of that list.
+#
+#     Caveats
+#     ----------
+#     **This function is currently irrelevant.** Why? Because all existing
+#     implementations of the :mod:`typing` module are sufficiently
+#     space-consumptive that they already implicitly prohibit deep nesting of
+#     PEP-compliant type hints. See commentary in the
+#     :mod:`beartype_test.a00_unit.data.pep.pep563.data_pep563_poem` submodule for appalling details.
+#     Ergo, this validator could technically be disabled. Indeed, if this
+#     validator actually incurred any measurable costs, it *would* be disabled.
+#     Since it doesn't, this validator has preserved purely for forward
+#     compatibility with some future revision of the :mod:`typing` module that
+#     hopefully improves that module's horrid space consumption.
+#
+#     Parameters
+#     ----------
+#     hint_repr : str
+#         Machine-readable representation of this annotation, typically but *not*
+#         necessarily as a :pep:`563`-formatted postponed string.
+#     pith_label : str
+#         Human-readable label describing the callable parameter or return value
+#         annotated by this string.
+#
+#     Raises
+#     ----------
+#     BeartypeDecorHintPepException
+#         If this representation internally exceeds this limit.
+#     '''
+#     assert isinstance(hint_repr, str), f'{repr(hint_repr)} not string.'
+#
+#     # Total number of hints transitively encapsulated in this hint (i.e., the
+#     # total number of all child hints of this hint as well as this hint
+#     # itself), defined as the summation of...
+#     hints_num = (
+#         # Number of parent PEP-compliant type hints nested in this hint,
+#         # including this hint itself *AND*...
+#         hint_repr.count('[') +
+#         # Number of child type hints (both PEP-compliant type hints and
+#         # non-"typing" types) nested in this hint, excluding the last child
+#         # hint subscripting each parent PEP-compliant type hint *AND*...
+#         hint_repr.count(',') +
+#         # Number of last child hints subscripting all parent PEP-compliant type
+#         # hints.
+#         hint_repr.count(']')
+#     )
+#
+#     # If this number exceeds the fixed length of the cached fixed list with
+#     # which the @beartype decorator traverses this hint, raise an exception.
+#     if hints_num >= FIXED_LIST_SIZE_MEDIUM:
+#         raise BeartypeDecorHintPepException(
+#             f'{pith_label} hint representation "{hint_repr}" '
+#             f'contains {hints_num} subscripted arguments '
+#             f'exceeding maximum limit {FIXED_LIST_SIZE_MEDIUM-1}.'
+#         )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/plug/__init__.py
@@ -0,0 +1,22 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype plugin API.**
+
+This submodule publishes a medley of attributes enabling users to extend
+:mod:`beartype` with user-defined runtime behaviours.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.plug._plughintable import (
+    BeartypeHintable as BeartypeHintable,
+)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/plug/_plughintable.py
@@ -0,0 +1,271 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype plugin mixin hierarchy** (i.e., public classes intended to be
+subclassed as mixins by users extending :mod:`beartype` with third-party runtime
+behaviours).
+
+Most of the public attributes defined by this private submodule are explicitly
+exported to external users in our top-level :mod:`beartype.plug.__init__`
+submodule. This private submodule is *not* intended for direct importation by
+downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Optional,
+    Tuple,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+
+# ....................{ MIXINS                             }....................
+class BeartypeHintable(object):
+    '''
+    **Beartype hintable mixin** (i.e., class intended to be subclassed as a
+    mixin by user-defined classes extending :mod:`beartype` with class-specific
+    runtime type-checking via the :mod:`beartype`-specific
+    :meth:`__beartype_hint__` method).
+
+    Usage
+    ----------
+    **You are encouraged but not required to subclass this mixin.** Doing so
+    publicly declares your intention to implement this abstract method and then
+    raises a :exc:`NotImplementedError` exception when you fail to do so,
+    improving the quality of your codebase with a simple contractual guarantee.
+    This mixin does *not* require a custom metaclass and is thus safely
+    subclassable by everything -- including your own classes.
+
+    **Beartype internally ignores this mixin.** This mixin exists *only* to
+    improve the quality of your codebase. Instead, beartype detects type hints
+    defining :meth:`__beartype_hint__` methods via the :func:`getattr` builtin
+    and then replaces those hints with the new type hints returned by those
+    methods. In pseudo-code, this logic crudely resembles: e.g.,
+
+    .. code-block:: python
+
+       # "__beartype_hint__" attribute of this type hint if any *OR* "None".
+       beartype_hinter = getattr(hint, '__beartype_hint__')
+
+       # If this hint defines this method, replace this hint with the new type
+       # hint created and returned by this method.
+       if callable(beartype_hinter):
+           hint = beartype_hinter()
+
+    You care about this, because this means that:
+
+    * You can trivially monkey-patch third-party classes *not* under your direct
+      control with :meth:`__beartype_hint__` methods, constraining those classes
+      with runtime type-checking implemented by you!
+    * :mod:`beartype` accepts *any* arbitrary objects defining
+      :meth:`__beartype_hint__` methods as valid type hints -- including objects
+      that are neither classes nor PEP-compliant! Of course, doing so would
+      render your code incompatible with static type-checkers and thus IDEs.
+      That's a bad thing. Nonetheless, this API enables you to do bad things.
+      With great plugin power comes great user responsibility.
+    '''
+
+    # ....................{ METHODS                        }....................
+    @classmethod
+    def __beartype_hint__(cls) -> object:
+        '''
+        **Beartype type hint transform** (i.e., :mod:`beartype`-specific dunder
+        class method returning a new type hint, which typically constrains this
+        class with additional runtime type-checking).
+        '''
+
+        raise NotImplementedError(  # pragma: no cover
+            'Abstract base class method '
+            'BeartypeHintable.__beartype_hint__() undefined.'
+        )
+
+# ....................{ TESTERS                            }....................
+#FIXME: Document us up, please.
+#FIXME: Unit test us up, please.
+#FIXME: Call us elsewhere, please.
+@callable_cached
+def is_hint_beartypehintable(hint: object) -> bool:
+
+    # Return true only if this hint defines the "__beartype_hint__" attribute.
+    return hasattr(hint, '__beartype_hint__')
+
+# ....................{ TRANSFORMERS ~ more than meets the }....................
+# ....................{                                eye }....................
+#FIXME: Document us up, please.
+#FIXME: Unit test us up, please.
+#FIXME: Significant complications exist suggesting that we should immediately
+#release beartype 0.12.0 and contemplate implementing this later:
+#* The "beartype._check.error" subpackage will need to implement a comparable
+#  mechanism as the "beartype._check.code" subpackage for detecting and avoiding
+#  recursion in this reduction. Curiously, "beartype._check.error" only ever
+#  calls the sanify_hint_child() sanifier in a single place. That simplifies
+#  things a bit. Still, we'll need to add a similar "set" somewhere in that
+#  subpackage tracking which "BeartypeHintable" objects have already been
+#  reduced.
+#* Even ignoring that, detecting and avoiding recursion in
+#  "beartype._check.code" alone will be non-trivial. We can't pass the original
+#  presanified type hint to the make_check_expr() factory, because that hint has
+#  *NOT* been coerced into a memoizable singleton (e.g., think PEP 585). That
+#  means the caller needs to pass either:
+#  * A boolean "is_hint_beartypehintable" parameter that is true only if the
+#    presanified root type hint was a "BeartypeHintable".
+#  * A "beartypehintables: Optional[set]" parameter that is a non-empty set
+#    containing the presanified root type hint if that hint was a
+#    "BeartypeHintable" *OR* "None" otherwise.
+#  The caller can trivially detect "BeartypeHintable" hints by calling the
+#  is_hint_beartypehintable() tester defined above. That's *NOT* the issue,
+#  thankfully. The issue is that we call sanify_*_root() functions in exactly
+#  three different places. We'll now need to duplicate this detection of
+#  "BeartypeHintable" hints across those three different places. Is this
+#  something we *REALLY* want to do? Is there truly no better way?
+#
+#Examining the code calling sanify_*_root() functions, it superficially looks
+#like we might want to consider *NO LONGER DEFINING OR CALLING* sanify_*_root()
+#functions. Like, seriously. The logic performed by those functions has become
+#trivial. They're practically one-liners. That said, sanify_hint_child() is
+#still extremely useful and should be preserved exactly as is. Consider:
+#* High-level functions calling sanify_*_root() functions should instead just
+#  call either coerce_func_hint_root() or coerce_hint_root() based on context.
+#  Those functions should *NOT* call reduce_hint() anymore.
+#* Excise up all sanify_*_root() functions.
+#* The make_check_expr() function should now call:
+#  * On the passed root type hint:
+#       if is_hint_beartypehintable(hint_root):
+#           hint_parent_beartypehintables = {hint_root,}
+#           hint_root = transform_hint_beartypehintable(hint_root)
+#
+#       hint_root = reduce_hint(hint_root)
+#  * On each child type hint:
+#       # This exact logic is likely to be duplicated into
+#       # "beartype._check.error". That's not particularly a problem -- just
+#       # something worth noting. One approach to preserving DRY here would be
+#       # to shift this "if" statement into sanify_hint_child(). Of course,
+#       # everything then becomes non-trivial, because we would then need to
+#       # both pass *AND* return "hint_parent_beartypehintables" sets to and
+#       # from the sanify_hint_child() function. *sigh*
+#       if (
+#           is_hint_beartypehintable(hint_child) and
+#           hint_child not in hint_parent_beartypehintables
+#       ):
+#           if hint_parent_beartypehintables is None:
+#               hint_parent_beartypehintables  = {hint_child,}
+#           else:
+#               hint_parent_beartypehintables |= {hint_child,}
+#
+#           hint_child = transform_hint_beartypehintable(hint_child)
+#
+#       hint_child = sanify_hint_child(hint_root)
+#FIXME: Wow. What a fascinatingly non-trivial issue. The above doesn't work,
+#either. Why? Two reasons:
+#* sanify_*_root() functions *MUST* continue to perform reduction -- including
+#  calling both reduce_hint() and transform_hint_beartypehintable(). Why? Because
+#  reduction *MUST* be performed before deciding "is_hint_ignorable", which
+#  *MUST* be decided before generating code. This is non-optional.
+#* transform_hint_beartypehintable() *CANNOT* be performed in either:
+#  * reduce_hint(), because reduce_hint() is memoized but
+#    transform_hint_beartypehintable() is non-memoizable by definition.
+#  * coerce_*_hint(), because coerce_*_hint() is permanently applied to
+#    "__annotations__" but transform_hint_beartypehintable() should *NEVER* be.
+#
+#Altogether, this suggests that:
+#* All sanify_*() functions *MUST* call transform_hint_beartypehintable()
+#  directly, outside of calls to either reduce_hint() and coerce_*_hint().
+#* Frozensets should be used. Doing so enables memoization, if we wanted.
+#* Call transform_hint_beartypehintable() from sanify_hint_child(), whose
+#  signature *MUST* be augmented accordingly (i.e., to both accept and return
+#  "hints_parent_beartypehintable: Optional[frozenset]").
+#* Call transform_hint_beartypehintable() from sanify_*hint_root(), whose
+#  signatures *MUST* be augmented accordingly (i.e., to additionally return
+#  "Optional[frozenset]").
+#* Augment make_check_expr() to:
+#  * Accept an additional
+#    "hints_parent_beartypehintable: Optional[frozenset]," parameter.
+#  * Add yet another new entry to each "hint_meta" FixedList as follows:
+#    * Define a new "HINT_META_INDEX_HINTS_PARENT_BEARTYPEHINTABLE" constant.
+#    * For the root "hint_meta", initialize the value of:
+#          hint_root_meta[HINT_META_INDEX_HINTS_PARENT_BEARTYPEHINTABLE] = (
+#              hints_parent_beartypehintable)
+#* Restore unit testing in "_data_nonpepbeartype", please.
+#
+#That should more or less do it, folks. Phew! It's still sufficiently
+#non-trivial that we want to defer this until *AFTER* beartype 0.12.0, though.
+
+#FIXME: Unit test us up, please.
+#FIXME: Document us up, please.
+@callable_cached
+def transform_hint_beartypehintable(
+    hint: object,
+    hints_parent_beartypehintable: Optional[frozenset],
+) -> Tuple[object, Optional[frozenset]]:
+
+    # ..................{ PLUGIN                             }..................
+    # Beartype plugin API. Respect external user-defined classes satisfying the
+    # beartype plugin API *BEFORE* handling these classes in any way.
+
+    # If this hint has already been transformed by a prior call to this
+    # function, preserve this hint as is. Doing so avoids infinite recursion and
+    # is, indeed, the entire point of the "hints_parent_beartypehintable" set.
+    if (
+        hints_parent_beartypehintable and
+        hint in hints_parent_beartypehintable
+    ):
+        return (hint, hints_parent_beartypehintable)
+    # Else, this hint has *NOT* yet been transformed by such a call.
+
+    # Beartype-specific "__beartype_hint__" attribute defined by this hint if
+    # any *OR* "None" otherwise.
+    #
+    # Note that usage of the low-level getattr() builtin is intentional. *ALL*
+    # alternative higher-level approaches suffer various deficits, including:
+    # * Obstructing monkey-patching. The current approach trivializes
+    #   monkey-patching by third parties, enabling users to readily add
+    #   __beartype_hint__() support to third-party packages *NOT* under their
+    #   direct control. Alternative higher-level approaches obstruct that by
+    #   complicating (or just outright prohibiting) monkey-patching.
+    # * Abstract base classes (ABCs) assume that hints that are classes are
+    #   issubclassable (i.e., safely passable as the first arguments of the
+    #   issubclass() builtin). Sadly, various real-world hints that are classes
+    #   are *NOT* issubclassable. This includes the core
+    #   "typing.NDArray[{dtype}]" type hints, astonishingly. Of course, even
+    #   this edge case could be surmounted by explicitly testing for
+    #   issubclassability (e.g., by calling our existing
+    #   is_type_issubclassable() tester); since that tester internally leverages
+    #   the inefficient Easier to Ask for Forgiveness than Permission (EAFP)
+    #   paradigm, doing so would impose a measurable performance penalty. This
+    #   only compounds the monkey-patching complications that an ABC imposes.
+    # * PEP 544-compliant protocols assume that the active Python interpreter
+    #   supports PEP 544, which Python 3.7 does not. While Python 3.7 has
+    #   probably hit its End of Life (EOL) by the time you are reading this,
+    #   additional issue exist. On the one hand, protocols impose even *MORE* of
+    #   a performance burden than ABCs. On the other hand, protocols ease the
+    #   user-oriented burden of monkey-patching.
+    #
+    # In short, this low-level approach effectively imposes *NO* burdens at all.
+    # There exists *NO* reason to prefer higher-level alternatives.
+    __beartype_hint__ = getattr(hint, '__beartype_hint__', None)
+
+    # If this hint does *NOT* define the "__beartype_hint__" attribute, preserve
+    # this hint as is.
+    if __beartype_hint__ is None:
+        return (hint, hints_parent_beartypehintable)
+    # Else, this hint defines the "__beartype_hint__" attribute.
+
+    #FIXME: Define a new private exception type, please.
+    # # If this attribute is *NOT* callable, raise an exception.
+    # if not callable(beartypehintable_reducer):
+    #     raise SomeExceptiot(...)
+    # # Else, this attribute is callable.
+
+    # Replace this hint with the new type hint returned by this callable.
+    hint = __beartype_hint__()
+
+    if hints_parent_beartypehintable is None:
+        hints_parent_beartypehintable = frozenset((hint,))
+    else:
+        #FIXME: Unsure if this works for frozensets. Probably not. *sigh*
+        hints_parent_beartypehintable |= {hint,}
+
+    # Return this transformed hint.
+    return (hint, hints_parent_beartypehintable)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/roar/__init__.py
@@ -0,0 +1,201 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype exception and warning hierarchies.**
+
+This submodule publishes a hierarchy of:
+
+* :mod:`beartype`-specific exceptions raised both by:
+
+  * The :func:`beartype.beartype` decorator at decoration and call time.
+  * Other public submodules and subpackages at usage time, including
+    user-defined data validators imported from the :mod:`beartype.vale`
+    subpackage.
+
+* :mod:`beartype`-specific warnings emitted at similar times.
+
+Hear :mod:`beartype` roar as it efficiently checks types, validates data, and
+raids native beehives for organic honey.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To prevent "mypy --no-implicit-reexport" from raising literally
+# hundreds of errors at static analysis time, *ALL* public attributes *MUST* be
+# explicitly reimported under the same names with "{exception_name} as
+# {exception_name}" syntax rather than merely "{exception_name}". Yes, this is
+# ludicrous. Yes, this is mypy. For posterity, these failures resemble:
+#     beartype/_cave/_cavefast.py:47: error: Module "beartype.roar" does not
+#     explicitly export attribute "BeartypeCallUnavailableTypeException";
+#     implicit reexport disabled  [attr-defined]
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+# Public exception hierarchy.
+from beartype.roar._roarexc import (
+    # Exceptions.
+    BeartypeException as BeartypeException,
+    BeartypeCaveException as BeartypeCaveException,
+    BeartypeCaveNoneTypeOrException as BeartypeCaveNoneTypeOrException,
+    BeartypeCaveNoneTypeOrKeyException as BeartypeCaveNoneTypeOrKeyException,
+    BeartypeCaveNoneTypeOrMutabilityException as BeartypeCaveNoneTypeOrMutabilityException,
+    BeartypeClawException as BeartypeClawException,
+    BeartypeClawHookException as BeartypeClawHookException,
+    BeartypeClawHookUnpackagedException as BeartypeClawHookUnpackagedException,
+    BeartypeClawImportException as BeartypeClawImportException,
+    BeartypeClawImportAstException as BeartypeClawImportAstException,
+    BeartypeClawImportConfException as BeartypeClawImportConfException,
+    BeartypeConfException as BeartypeConfException,
+    BeartypeConfParamException as BeartypeConfParamException,
+    BeartypeConfShellVarException as BeartypeConfShellVarException,
+    BeartypeDoorException as BeartypeDoorException,
+    BeartypeDoorNonpepException as BeartypeDoorNonpepException,
+    BeartypeDoorPepException as BeartypeDoorPepException,
+    BeartypeDoorPepUnsupportedException as BeartypeDoorPepUnsupportedException,
+    BeartypeDecorException as BeartypeDecorException,
+    BeartypeDecorWrappeeException as BeartypeDecorWrappeeException,
+    BeartypeDecorWrapperException as BeartypeDecorWrapperException,
+    BeartypeDecorHintException as BeartypeDecorHintException,
+    BeartypeDecorHintForwardRefException as BeartypeDecorHintForwardRefException,
+    BeartypeDecorHintNonpepException as BeartypeDecorHintNonpepException,
+    BeartypeDecorHintNonpepNumpyException as BeartypeDecorHintNonpepNumpyException,
+    BeartypeDecorHintNonpepPanderaException as BeartypeDecorHintNonpepPanderaException,
+    BeartypeDecorHintPepException as BeartypeDecorHintPepException,
+    BeartypeDecorHintPepSignException as BeartypeDecorHintPepSignException,
+    BeartypeDecorHintPepUnsupportedException as BeartypeDecorHintPepUnsupportedException,
+    BeartypeDecorHintPep484Exception as BeartypeDecorHintPep484Exception,
+    BeartypeDecorHintPep484585Exception as BeartypeDecorHintPep484585Exception,
+    BeartypeDecorHintPep544Exception as BeartypeDecorHintPep544Exception,
+    BeartypeDecorHintPep557Exception as BeartypeDecorHintPep557Exception,
+    BeartypeDecorHintPep585Exception as BeartypeDecorHintPep585Exception,
+    BeartypeDecorHintPep586Exception as BeartypeDecorHintPep586Exception,
+    BeartypeDecorHintPep591Exception as BeartypeDecorHintPep591Exception,
+    BeartypeDecorHintPep593Exception as BeartypeDecorHintPep593Exception,
+    BeartypeDecorHintPep604Exception as BeartypeDecorHintPep604Exception,
+    BeartypeDecorHintPep647Exception as BeartypeDecorHintPep647Exception,
+    BeartypeDecorHintPep673Exception as BeartypeDecorHintPep673Exception,
+    BeartypeDecorHintPep695Exception as BeartypeDecorHintPep695Exception,
+    BeartypeDecorHintPep3119Exception as BeartypeDecorHintPep3119Exception,
+    BeartypeDecorHintTypeException as BeartypeDecorHintTypeException,
+    BeartypeDecorParamException as BeartypeDecorParamException,
+    BeartypeDecorParamNameException as BeartypeDecorParamNameException,
+    BeartypeCallException as BeartypeCallException,
+    BeartypeCallUnavailableTypeException as BeartypeCallUnavailableTypeException,
+    BeartypeCallHintException as BeartypeCallHintException,
+    BeartypeCallHintForwardRefException as BeartypeCallHintForwardRefException,
+    BeartypeKindException as BeartypeKindException,
+    BeartypeKindFrozenDictException as BeartypeKindFrozenDictException,
+    BeartypeHintOverridesException as BeartypeHintOverridesException,
+    BeartypePepException as BeartypePepException,
+    BeartypePep563Exception as BeartypePep563Exception,
+    BeartypePlugException as BeartypePlugException,
+    BeartypePlugInstancecheckStrException as BeartypePlugInstancecheckStrException,
+    BeartypeValeException as BeartypeValeException,
+    BeartypeValeSubscriptionException as BeartypeValeSubscriptionException,
+    BeartypeValeValidationException as BeartypeValeValidationException,
+
+    # Violations (i.e., exceptions raised during runtime type-checking).
+    BeartypeCallHintViolation as BeartypeCallHintViolation,
+    BeartypeCallHintParamViolation as BeartypeCallHintParamViolation,
+    BeartypeCallHintReturnViolation as BeartypeCallHintReturnViolation,
+    BeartypeDecorHintParamDefaultViolation as BeartypeDecorHintParamDefaultViolation,
+    BeartypeDoorHintViolation as BeartypeDoorHintViolation,
+)
+
+# Public warning hierarchy.
+from beartype.roar._roarwarn import (
+    BeartypeWarning as BeartypeWarning,
+    BeartypeClawWarning as BeartypeClawWarning,
+    BeartypeClawDecorWarning as BeartypeClawDecorWarning,
+    BeartypeConfWarning as BeartypeConfWarning,
+    BeartypeConfShellVarWarning as BeartypeConfShellVarWarning,
+    BeartypeDecorHintWarning as BeartypeDecorHintWarning,
+    BeartypeDecorHintParamDefaultForwardRefWarning as BeartypeDecorHintParamDefaultForwardRefWarning,
+    BeartypeDecorHintPepWarning as BeartypeDecorHintPepWarning,
+    BeartypeDecorHintPepDeprecationWarning as BeartypeDecorHintPepDeprecationWarning,
+    BeartypeDecorHintPep585DeprecationWarning as BeartypeDecorHintPep585DeprecationWarning,
+    BeartypeDecorHintPep613DeprecationWarning as BeartypeDecorHintPep613DeprecationWarning,
+    BeartypeDecorHintNonpepWarning as BeartypeDecorHintNonpepWarning,
+    BeartypeDecorHintNonpepNumpyWarning as BeartypeDecorHintNonpepNumpyWarning,
+    BeartypeModuleWarning as BeartypeModuleWarning,
+    BeartypeModuleNotFoundWarning as BeartypeModuleNotFoundWarning,
+    BeartypeModuleAttributeNotFoundWarning as BeartypeModuleAttributeNotFoundWarning,
+    BeartypeModuleUnimportableWarning as BeartypeModuleUnimportableWarning,
+    BeartypeValeWarning as BeartypeValeWarning,
+    BeartypeValeLambdaWarning as BeartypeValeLambdaWarning,
+)
+
+# ....................{ DEPRECATIONS                       }....................
+def __getattr__(attr_deprecated_name: str) -> object:
+    '''
+    Dynamically retrieve a deprecated attribute with the passed unqualified
+    name from this submodule and emit a non-fatal deprecation warning on each
+    such retrieval if this submodule defines this attribute *or* raise an
+    exception otherwise.
+
+    The Python interpreter implicitly calls this :pep:`562`-compliant module
+    dunder function under Python >= 3.7 *after* failing to directly retrieve an
+    explicit attribute with this name from this submodule. Since this dunder
+    function is only called in the event of an error, neither space nor time
+    efficiency are a concern here.
+
+    Parameters
+    ----------
+    attr_deprecated_name : str
+        Unqualified name of the deprecated attribute to be retrieved.
+
+    Returns
+    ----------
+    object
+        Value of this deprecated attribute.
+
+    Warns
+    ----------
+    :class:`DeprecationWarning`
+        If this attribute is deprecated.
+
+    Raises
+    ----------
+    :exc:`AttributeError`
+        If this attribute is unrecognized and thus erroneous.
+    '''
+
+    # Isolate imports to avoid polluting the module namespace.
+    from beartype._util.module.utilmoddeprecate import deprecate_module_attr
+
+    # Return the value of this deprecated attribute and emit a warning.
+    return deprecate_module_attr(
+        attr_deprecated_name=attr_deprecated_name,
+        attr_deprecated_name_to_nondeprecated_name={
+            'BeartypeAbbyException': (
+                'BeartypeDoorException'),
+            'BeartypeAbbyHintViolation': (
+                'BeartypeDoorHintViolation'),
+            'BeartypeAbbyTesterException': (
+                'BeartypeDoorException'),
+            'BeartypeCallHintPepException': (
+                'BeartypeCallHintViolation'),
+            'BeartypeCallHintPepParamException': (
+                'BeartypeCallHintParamViolation'),
+            'BeartypeCallHintPepReturnException': (
+                'BeartypeCallHintReturnViolation'),
+            'BeartypeDecorHintNonPepException': (
+                'BeartypeDecorHintNonpepException'),
+            'BeartypeDecorHintNonPepNumPyException': (
+                'BeartypeDecorHintNonpepNumpyException'),
+            'BeartypeDecorHintPep563Exception': (
+                'BeartypePep563Exception'),
+            'BeartypeDecorHintPepDeprecatedWarning': (
+                'BeartypeDecorHintPepDeprecationWarning'),
+            'BeartypeDecorPepException': (
+                'BeartypePepException'),
+        },
+        attr_nondeprecated_name_to_value=globals(),
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/roar/_roarexc.py
@@ -0,0 +1,1544 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **exception hierarchy** (i.e., public and private exception subclasses
+raised at decoration, call, and usage time by :mod:`beartype`).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from abc import ABCMeta as _ABCMeta
+
+# ....................{ PRIVATE ~ mixins                   }....................
+class _BeartypeHintForwardRefExceptionMixin(Exception, metaclass=_ABCMeta):
+    '''
+    Mixin of all **beartype forward reference exceptions** (i.e., exceptions
+    concerning parent type hints containing one or more forward references to
+    child type hints that have yet to be declared).
+
+    This mixin enables internal logic throughout the :mod:`beartype` codebase to
+    conveniently, efficiently, and transparently handle *all* forward reference
+    exceptions -- including:
+
+    * :exc:`.BeartypeCallHintForwardRefException`.
+    * :exc:`.BeartypeDecorHintForwardRefException`.
+    '''
+
+    pass
+
+# ....................{ SUPERCLASS                         }....................
+class BeartypeException(Exception, metaclass=_ABCMeta):
+    '''
+    Abstract base class of all **beartype exceptions.**
+
+    Instances of subclasses of this exception are raised either:
+
+    * At decoration time from the :func:`beartype.beartype` decorator.
+    * At call time from the new callable generated by the
+      :func:`beartype.beartype` decorator to wrap the original callable.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, message: str) -> None:
+        '''
+        Initialize this exception.
+
+        This constructor (in order):
+
+        #. Passes all passed arguments as is to the superclass constructor.
+        #. Sanitizes the fully-qualified module name of this
+           exception from the private ``"beartype.roar._roarexc"`` submodule to
+           the public ``"beartype.roar"`` subpackage to both improve the
+           readability of exception messages and discourage end users from
+           accessing this private submodule. By default, Python emits less
+           readable and dangerous exception messages resembling:
+
+               beartype.roar._roarexc.BeartypeCallHintParamViolation:
+               @beartyped quote_wiggum_safer() parameter lines=[] violates type
+               hint typing.Annotated[list[str], Is[lambda lst: bool(lst)]], as
+               value [] violates validator Is[lambda lst: bool(lst)].
+        '''
+        assert isinstance(message, str), (
+            f'{repr(message)} not exception message.')
+
+        # If...
+        #
+        # Note that this logic unavoidably duplicates the body of the existing
+        # beartype._util.text.utiltextmunge.uppercase_str_char_first() function
+        # for safety. Attempting to call *ANY* beartype-specific callable
+        # (including that function) from within an exception initializer would
+        # invite a shocking calamity that would surely shatter the whole world.
+        if (
+            # This message contains at least two characters *AND*...
+            len(message) >= 2 and
+            # The first character of this message is lowercase...
+            message[0].islower()
+        ):
+            # Then uppercase only this character for readability.
+            message = f'{message[0].upper()}{message[1:]}'
+
+        # Defer to the superclass constructor.
+        super().__init__(message)
+
+        # Sanitize the fully-qualified module name of the class of this
+        # exception. See the docstring for justification.
+        self.__class__.__module__ = 'beartype.roar'
+        # print(f'{self.__class__.__name__}: {message}')
+
+# ....................{ DECORATOR                          }....................
+class BeartypeDecorException(BeartypeException):
+    '''
+    Abstract base class of all **beartype decorator exceptions.**
+
+    Instances of subclasses of this exception are raised at decoration time
+    from the :func:`beartype.beartype` decorator.
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ wrapp[ee|er]           }....................
+class BeartypeDecorWrappeeException(BeartypeDecorException):
+    '''
+    **Beartype decorator wrappee exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator when passed a **wrappee** (i.e., object
+    to be decorated by this decorator) of invalid type.
+    '''
+
+    pass
+
+
+class BeartypeDecorWrapperException(BeartypeDecorException):
+    '''
+    **Beartype decorator parse exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on accidentally generating an **invalid
+    wrapper** (i.e., syntactically invalid new callable to wrap the original
+    callable).
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint                   }....................
+class BeartypeDecorHintException(BeartypeDecorException):
+    '''
+    Abstract base class of all **beartype decorator type hint exceptions.**
+
+    Instances of subclasses of this exception are raised at decoration time
+    from the :func:`beartype.beartype` decorator on receiving a callable
+    annotated by one or more **invalid type hints** (i.e., annotations that are
+    neither PEP-compliant nor PEP-compliant type hints supported by this
+    decorator).
+    '''
+
+    pass
+
+
+class BeartypeDecorHintForwardRefException(
+    BeartypeDecorHintException, _BeartypeHintForwardRefExceptionMixin):
+    '''
+    **Beartype decorator forward reference type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by an
+    **invalid forward reference type hint** (i.e., string whose value is the
+    name of a user-defined class that has yet to be declared).
+    '''
+
+    pass
+
+
+class BeartypeDecorHintTypeException(BeartypeDecorHintException):
+    '''
+    **Beartype decorator class type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by an
+    **invalid class type hint** (i.e., class invalid for use as a type hint,
+    typically due to failing to support runtime :func:`isinstance` calls).
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint : non-pep         }....................
+class BeartypeDecorHintNonpepException(BeartypeDecorHintException):
+    '''
+    **Beartype decorator PEP-noncompliant type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by an
+    **invalid PEP-noncompliant type hint** (i.e., type hint failing to comply
+    with :mod:`beartype`-specific semantics, including tuple unions and
+    fully-qualified forward references).
+
+    Tuple unions, for example, are required to contain *only* PEP-noncompliant
+    annotations. This exception is thus raised for callables type-hinted with
+    tuples containing one or more PEP-compliant items (e.g., instances or
+    classes declared by the stdlib :mod:`typing` module) *or* arbitrary objects
+    (e.g., dictionaries, lists, numbers, sets).
+    '''
+
+    pass
+
+
+class BeartypeDecorHintNonpepNumpyException(BeartypeDecorHintNonpepException):
+    '''
+    **Beartype decorator PEP-noncompliant NumPy type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by an
+    **invalid NumPy type hint** (e.g., ``numpy.typing.NDArray[...]`` type hint
+    subscripted by an invalid number of arguments).
+    '''
+
+    pass
+
+
+class BeartypeDecorHintNonpepPanderaException(BeartypeDecorHintNonpepException):
+    '''
+    **Beartype decorator PEP-noncompliant Pandera type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by an
+    **invalid Pandera type hint** (e.g., ``pandera.typing.DataFrame[...]`` type
+    hint annotating a parameter or return of a callable *not* decorated by the
+    PEP-noncompliant :func:`pandera.check_types` decorator).
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint : pep             }....................
+class BeartypeDecorHintPepException(BeartypeDecorHintException):
+    '''
+    Abstract base class of all **beartype decorator PEP-compliant type hint
+    value exceptions.**
+
+    Instances of subclasses of this exception are raised at decoration time
+    from the :func:`beartype.beartype` decorator on receiving a callable
+    annotated with one or more PEP-compliant type hints either violating an
+    annotation-centric PEP (e.g., :pep:`484`) *or* this decorator's
+    implementation of such a PEP.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPepSignException(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator PEP-compliant type hint sign exception.**
+
+    Instances of subclasses of this exception are raised at decoration time
+    from the :func:`beartype.beartype` decorator on receiving a callable
+    annotated with one or more PEP-compliant type hints *not* uniquely
+    identifiable by a **sign** (i.e., object uniquely identifying a category
+    of PEP-compliant type hints).
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPepUnsupportedException(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator unsupported PEP-compliant type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints (e.g., instances or classes declared
+    by the stdlib :mod:`typing` module) currently unsupported by this
+    decorator.
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint : pep : proposal  }....................
+class BeartypeDecorHintPep3119Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`3119`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`3119` *or* this
+    decorator's implementation of :pep:`3119`, including:
+
+    * Hints that are **non-isinstanceable classes** (i.e., classes that
+      prohibit being passed as the second parameter to the :func:`isinstance`
+      builtin by leveraging metaclasses overriding the ``__instancecheck__()``
+      dunder method to raise exceptions). Notably, this includes most public
+      classes declared by the standard :mod:`typing` module.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep484Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`484`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`484` *or* this
+    decorator's implementation of :pep:`484`, including:
+
+    * Hints subscripted by the :attr:`typing.NoReturn` type hint (e.g.,
+      ``typing.List[typing.NoReturn]``).
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep484585Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`484`- or :pep:`585`-compliant **dual type hint
+    exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints violating :pep:`484`, :pep:`585`, *or*
+    this decorator's implementation of :pep:`484` or :pep:`585`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep544Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`544`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`544` *or* this
+    decorator's implementation of :pep:`544`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep557Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`557`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`557` *or* this
+    decorator's implementation of :pep:`557`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep585Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`585`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`585` *or* this
+    decorator's implementation of :pep:`585`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep586Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`586`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`586` *or* this
+    decorator's implementation of :pep:`586`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep591Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`591`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`591` *or* this
+    decorator's implementation of :pep:`591`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep593Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`593`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`593` *or* this
+    decorator's implementation of :pep:`593`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep604Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`604`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`604` *or* this
+    decorator's implementation of :pep:`604`.
+    '''
+
+    pass
+
+class BeartypeDecorHintPep647Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`647`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`647` *or* this
+    decorator's implementation of :pep:`647`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep673Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`673`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`673` *or* this
+    decorator's implementation of :pep:`673`.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep695Exception(BeartypeDecorHintPepException):
+    '''
+    **Beartype decorator** :pep:`695`-compliant **type hint exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated with
+    one or more PEP-compliant type hints either violating :pep:`695` *or* this
+    decorator's implementation of :pep:`695`.
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ param                  }....................
+class BeartypeDecorParamException(BeartypeDecorException):
+    '''
+    Abstract base class of all **beartype decorator parameter exceptions.**
+
+    Instances of subclasses of this exception are raised at decoration time
+    from the :func:`beartype.beartype` decorator on receiving a callable
+    declaring invalid parameters.
+    '''
+
+    pass
+
+
+class BeartypeDecorParamNameException(BeartypeDecorParamException):
+    '''
+    **Beartype decorator parameter name exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable declaring
+    parameters with **invalid names** (i.e., prefixed by the
+    :mod:`beartype`-reserved substring ``"__bear"``).
+    '''
+
+    pass
+
+# ....................{ CALL                               }....................
+class BeartypeCallException(BeartypeException):
+    '''
+    Abstract base class of all **beartyped callable exceptions.**
+
+    Instances of subclasses of this exception are raised from wrapper functions
+    generated by the :func:`beartype.beartype` decorator, typically when
+    failing a runtime type-check at call time.
+    '''
+
+    pass
+
+
+class BeartypeCallUnavailableTypeException(BeartypeCallException):
+    '''
+    **Beartyped callable unavailable type exceptions.**
+
+    This exception is raised from the :class:`beartype.cave.UnavailableType`
+    class when passed to either the :func:`isinstance` or :func:`issubclass`
+    builtin functions, typically due to a type defined by the
+    :class:`beartype.cave` submodule being conditionally unavailable under the
+    active Python interpreter.
+    '''
+
+    pass
+
+# ....................{ CALL ~ hint                        }....................
+class BeartypeCallHintException(BeartypeCallException):
+    '''
+    Abstract base class of all **beartype type-checking exceptions.**
+
+    Instances of subclasses of this exception are raised from wrapper functions
+    generated by the :func:`beartype.beartype` decorator when failing a runtime
+    type-check at callable call time, typically due to either being passed a
+    parameter or returning a value violating a type hint annotating that
+    parameter or return.
+    '''
+
+    pass
+
+
+class BeartypeCallHintForwardRefException(
+    BeartypeCallHintException, _BeartypeHintForwardRefExceptionMixin):
+    '''
+    **Beartype type-checking forward reference exception.**
+
+    This exception is raised from wrapper functions generated by the
+    :func:`beartype.beartype` decorator when a **forward reference type hint**
+    (i.e., string whose value is the name of a user-defined class that has yet
+    to be defined) erroneously references a module attribute whose value is
+    *not* actually a class.
+    '''
+
+    pass
+
+# ....................{ CALL ~ hint : violation            }....................
+class BeartypeCallHintViolation(BeartypeCallHintException):
+    '''
+    Abstract base class of all **beartype type-checking violations.**
+
+    Instances of subclasses of this exception are raised by :mod:`beartype` when
+    an object to be type-checked violates the type hint annotating that object.
+    This includes wrapper functions generated by the :func:`beartype.beartype`
+    decorator when either passed a parameter or returning an object violating
+    the type hint annotating that parameter or return.
+
+    Attributes
+    ----------
+    _culprits_weakref_and_repr : Tuple[(object, str), ...]
+        Tuple of 2-tuples (``culprit_weakref``, ``culprit_repr``) weakly
+        referring to all of the culprits previously passed to the
+        :meth:`__init__` method, where:
+
+        * ``culprits_repr`` is the machine-readable string representation of the
+          culprit weakly referred to by the ``culprit_weakref`` reference.
+        * ``culprits_weakref`` is a weak reference to that culprit, defined as
+            either:
+
+            * If that culprit is not ``None`` *and* that culprit can be weakly
+              referenced, a **weak reference** (i.e., :class:`weakref.ref`
+              instance) to that culprit.
+            * If that culprit is ``None``, a singleton non-``None`` placeholder.
+              Since the :class:`weakref.ref` class ambiguously returns ``None``
+              when that culprit has already been garbage-collected, this
+              attribute intentionally substitutes ``None`` for this placeholder.
+            * If that culprit *cannot* be weakly referenced (e.g., due to being
+              an instance of a builtin variable-sized C-based type), ``None``.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, message: str, culprits: tuple) -> None:
+        '''
+        Initialize this type-checking exception.
+
+        Parameters
+        ----------
+        message : str
+            Human-readable message describing this exception.
+        culprits : Tuple[object, ...]
+            Tuple of one or more **culprits** (i.e., user-defined objects
+            directly responsible for this exception, typically due to violating
+            a type hint annotating a parameter passed to *or* object returned
+            from the wrapper function generated by the :func:`beartype.beartype`
+            decorator raising this exception). This exception internally
+            preserves a weak reference to these culprits, which callers may then
+            safely retrieve at any time via the :meth:`culprits` property.
+
+        Raises
+        ------
+        _BeartypeUtilExceptionException
+            If the culprits are either:
+
+            * *Not* a tuple.
+            * The empty tuple.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype._util.py.utilpyweakref import make_obj_weakref_and_repr
+
+        # Initialize the superclass with the passed message.
+        super().__init__(message)
+
+        #FIXME: Unit test us up, please.
+        # If the culprits are *NOT* a tuple, raise an exception.
+        if not isinstance(culprits, tuple):
+            raise _BeartypeUtilExceptionException(
+                f'Culprits {repr(culprits)} not tuple.')
+        # Else, the culprits are a tuple.
+        #
+        # If the culprits are the empty tuple, raise an exception.
+        elif not culprits:
+            raise _BeartypeUtilExceptionException('Culprits tuple empty.')
+        # Else, the culprits are a non-empty tuple.
+
+        # Tuple of 2-tuples ("culprit_weakref", "culprit_repr") weakly referring
+        # to all of the passed culprits.
+        self._culprits_weakref_and_repr = tuple(
+            make_obj_weakref_and_repr(culprit)
+            for culprit in culprits
+        )
+
+    # ..................{ PROPERTIES                         }..................
+    # Read-only properties intentionally providing no corresponding setters.
+
+    @property
+    def culprits(self) -> tuple:
+        '''
+        Tuple of one or more **culprits** (i.e., user-defined objects directly
+        responsible for this exception, typically due to violating a type hint
+        annotating a parameter passed to *or* object returned from the wrapper
+        function generated by the :func:`beartype.beartype` decorator raising
+        this exception).
+
+        Specifically, this property returns either:
+
+        * If a container (e.g., dictionary, list, set, tuple) is responsible for
+          this exception, the 2-tuple ``(culprit_root, culprit_leaf)`` where:
+
+          * ``culprit_root`` is the outermost such container. Typically, this is
+            the passed parameter or returned value indirectly violating this
+            hint.
+          * ``culprit_leaf`` is the innermost item transitively contained in
+            ``culprit_root`` directly violating this hint.
+
+        * If a non-container (e.g., scalar, class instance) is responsible for
+          this exception, the 1-tuple ``(culprit,)`` where ``culprit`` is that
+          non-container.
+
+        Caveats
+        -------
+        **This property is safely accessible from any context.** However, this
+        property is most usefully accessed *only* from the ``except ...:`` block
+        directly catching this exception. To avoid memory leaks, this property
+        only weakly rather than strongly refers to these culprits and is thus
+        best accessed only where these culprits are accessible. Notably, this
+        property is guaranteed to refer to these culprits *only* for the
+        duration of the ``except ...:`` block directly catching this exception.
+        Since these culprits may be garbage-collected at any time thereafter,
+        this property *cannot* be guaranteed to refer to these culprits outside
+        that block. If this property is accessed from *any* other context and
+        ore or more of these culprits have already been garbage-collected, the
+        corresponding item(s) of this property are only the machine-readable
+        representations of those culprits rather than those actual culprits.
+
+        **This property returns the machine-readable representation of instances
+        of builtin variable-sized C-based types** (e.g., :class:`dict`,
+        :class:`int`, :class:`list`, :class:`tuple`) **rather than those
+        instances themselves.** Why? Because CPython limitations prevent those
+        instances from being weakly referred to. Blame Guido and the BDFL!
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype._util.py.utilpyweakref import get_weakref_obj_or_repr
+
+        # Tuple of one or more strong references to the culprits previously
+        # passed to the __init__() method for those culprits that are alive
+        # *OR* their representations otherwise.
+        culprits = tuple(
+            get_weakref_obj_or_repr(
+                obj_weakref=culprit_weakref, obj_repr=culprit_repr)
+            for culprit_weakref, culprit_repr in self._culprits_weakref_and_repr
+        )
+        # print(f'culprits_weakref_and_repr: {self._culprits_weakref_and_repr}')
+
+        # Return these culprits.
+        return culprits
+
+
+class BeartypeCallHintParamViolation(BeartypeCallHintViolation):
+    '''
+    **Beartyped callable parameter type-checking exception.**
+
+    This exception is raised from a call to a wrapper function generated by the
+    :func:`beartype.beartype` decorator type-checking a decorated callable when
+    the caller passes that call a parameter violating the type hint annotating
+    that parameter of that decorated callable.
+    '''
+
+    pass
+
+
+class BeartypeCallHintReturnViolation(BeartypeCallHintViolation):
+    '''
+    **Beartyped callable return type-checking exception.**
+
+    This exception is raised from a call to a wrapper function generated by the
+    :func:`beartype.beartype` decorator type-checking a decorated callable when
+    that call returns an object violating the type hint annotating the return
+    of that decorated callable.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintParamDefaultViolation(BeartypeCallHintViolation):
+    '''
+    **Beartyped decorator optional parameter default value type-checking
+    exception.**
+
+    This exception is raised at decoration time by the :func:`beartype.beartype`
+    decorator when type-checking a decorated callable accepting an optional
+    parameter whose default value violates the type hint annotating that
+    parameter.
+    '''
+
+# ....................{ PEP                                }....................
+class BeartypePepException(BeartypeDecorException):
+    '''
+    Abstract base class of all **beartype Python Enhancement Proposal (PEP)
+    exceptions.**
+
+    Instances of subclasses of this exception are raised at both call time and
+    decoration time on receiving a callable or class violating a specific PEP.
+    '''
+
+    pass
+
+
+class BeartypePep563Exception(BeartypePepException):
+    '''
+    **Beartype** :pep:`563` **exception.**
+
+    This exception is raised at both call time of the
+    :func:`beartype.peps.resolve_pep563` function and decoration time of the
+    :func:`beartype.beartype` decorator on failing to dynamically evaluate a
+    postponed annotation of a callable for which :pep:`563` is active.
+    '''
+
+    pass
+
+# ....................{ API ~ cave                         }....................
+class BeartypeCaveException(BeartypeException):
+    '''
+    Abstract base class of all **beartype cave exceptions.**
+
+    Instances of subclasses of this exception are raised at usage time from
+    various types published by the :func:`beartype.cave` submodule.
+    '''
+
+    pass
+
+# ....................{ API ~ cave : nonetypeor            }....................
+class BeartypeCaveNoneTypeOrException(BeartypeCaveException):
+    '''
+    Abstract base class of all **beartype cave** ``None`` **tuple factory
+    exceptions.**
+
+    Instances of subclasses of this exception are raised at usage time from
+    the :func:`beartype.cave.NoneTypeOr` tuple factory.
+    '''
+
+    pass
+
+
+class BeartypeCaveNoneTypeOrKeyException(BeartypeCaveNoneTypeOrException):
+    '''
+    **Beartype cave** ``None`` **tuple factory key exception.**
+
+    Instances of this exception are raised when indexing the :func:
+    `beartype.cave.NoneTypeOr` dictionary with an invalid key, including:
+
+    * The empty tuple.
+    * Arbitrary objects that are neither:
+
+      * **Types** (i.e., :class:`beartype.cave.ClassType` instances).
+      * **Tuples of types** (i.e., tuples whose items are all
+        :class:`beartype.cave.ClassType` instances).
+    '''
+
+    pass
+
+
+class BeartypeCaveNoneTypeOrMutabilityException(
+    BeartypeCaveNoneTypeOrException):
+    '''
+    **Beartype cave** ``None`` **tuple factory mutability exception.**
+
+    Instances of this exception are raised when attempting to explicitly set a
+    key on the :func:`beartype.cave.NoneTypeOr` dictionary.
+    '''
+
+    pass
+
+# ....................{ API ~ claw                         }....................
+class BeartypeClawException(BeartypeException):
+    '''
+    Abstract base class of all **beartype import hook exceptions.**
+
+    Instances of subclasses of this exception are raised at call time from the
+    callables and classes published by the :mod:`beartype.claw` subpackage.
+    '''
+
+    pass
+
+# ....................{ API ~ claw : hook                  }....................
+class BeartypeClawHookException(BeartypeClawException):
+    '''
+    **Beartype import hook-time exception.**
+
+    This exception is raised at **beartype import hook-time** (i.e., the early
+    time encompassing the call to a public beartype import hook published by the
+    :mod:`beartype.claw` subpackage by a downstream third-party codebase) on
+    various fatal errors (e.g., when that codebase calls that hook with invalid
+    parameters).
+    '''
+
+    pass
+
+
+class BeartypeClawHookUnpackagedException(BeartypeClawHookException):
+    '''
+    **Beartype import hook-time unpackaged exception.**
+
+    This exception is raised at **beartype import hook-time** (i.e., the early
+    time encompassing the call to a public beartype import hook published by the
+    :mod:`beartype.claw` subpackage by a downstream third-party codebase) when
+    the :func:`beartype.claw.beartype_this_package` function is called from
+    outside any package structure (e.g., top-level module or executable script).
+    '''
+
+    pass
+
+# ....................{ API ~ claw : import                }....................
+class BeartypeClawImportException(BeartypeClawException):
+    '''
+    **Beartype import hook import exception.**
+
+    This exception is raised at import time when importing a module erroneously
+    transformed by a beartype import hook previously installed by a prior call
+    to a public function published by the :mod:`beartype.claw` subpackage.
+    '''
+
+    pass
+
+
+class BeartypeClawImportAstException(BeartypeClawImportException):
+    '''
+    **Beartype import hook abstract syntax tree (AST) exception.**
+
+    This exception is raised at import time when a **beartype import hook**
+    (i.e., previously installed by a prior call to a public function published
+    by the :mod:`beartype.claw` subpackage) erroneously transforms a module from
+    its original syntactically valid AST into a new syntactically invalid AST.
+    '''
+
+    pass
+
+
+class BeartypeClawImportConfException(BeartypeClawImportException):
+    '''
+    **Beartype import hook configuration exception.**
+
+    This exception is raised at import time when a **beartype import hook**
+    (i.e., previously installed by a prior call to a public function published
+    by the :mod:`beartype.claw` subpackage) erroneously attempts to access a
+    non-existent beartype configuration.
+    '''
+
+    pass
+
+# ....................{ API ~ conf                         }....................
+class BeartypeConfException(BeartypeException):
+    '''
+    Abstract base class of all **beartype configuration exceptions.**
+
+    Instances of subclasses of this exception are raised by the
+    :class:`beartype.BeartypeConf` class to inform the user of various fatal
+    edge cases concerning beartype configuration.
+    '''
+
+    pass
+
+
+class BeartypeConfParamException(BeartypeConfException):
+    '''
+    **Beartype configuration parameter exception.**
+
+    Instances of this exception are raised at instantiation time of the
+    :class:`beartype.BeartypeConf` class when the caller attempts to erroneously
+    instantiate that class with an invalid parameter.
+    '''
+
+    pass
+
+
+class BeartypeConfShellVarException(BeartypeConfException):
+    '''
+    **Beartype configuration shell environment variable exception.**
+
+    Instances of this exception are raised at instantiation time of the
+    :class:`beartype.BeartypeConf` class when the caller erroneously sets a
+    shell environment variable recognized by that class (e.g.,
+    ``${BEARTYPE_IS_COLOR}``) to an invalid value.
+    '''
+
+    pass
+
+# ....................{ API ~ door                         }....................
+class BeartypeDoorException(BeartypeException):
+    '''
+    Abstract base class of all **Decidedly Object-Oriented Runtime-checking
+    (DOOR) exceptions.**
+
+    Instances of subclasses of this exception are raised at call time from
+    callables and classes published by the :func:`beartype.door` subpackage.
+    '''
+
+    pass
+
+
+class BeartypeDoorHintViolation(BeartypeCallHintViolation):
+    '''
+    **Beartype object-oriented type-checking exception.**
+
+    This exception is raised at call time by both:
+
+    * The :func:`beartype.door.die_if_unbearable` function when passed an
+      object violating the passed type hint.
+    * The :meth:`beartype.door.TypeHint.die_if_unbearable` method when passed an
+      object violating the current type hint.
+    '''
+
+    pass
+
+# ....................{ API ~ door : pep                   }....................
+class BeartypeDoorNonpepException(BeartypeDoorException):
+    '''
+    **Decidedly Object-Oriented Runtime-checking (DOOR) PEP-noncompliant type
+    hint exception.**
+
+    This exception is raised at call time from :func:`beartype.door` callables
+    and classes on receiving an **invalid PEP-noncompliant type hint** (i.e.,
+    type hint failing to comply with PEP standards currently supported by the
+    :mod:`beartype.door` API).
+    '''
+
+    pass
+
+
+class BeartypeDoorPepException(BeartypeDoorException):
+    '''
+    **Decidedly Object-Oriented Runtime-checking (DOOR) PEP-compliant type hint
+    exception.**
+
+    This exception is raised at call time from :func:`beartype.door` callables
+    and classes on receiving an **invalid PEP-compliant type hint** (i.e.,
+    type hint complying with PEP standards currently supported by the
+    :mod:`beartype.door` API but otherwise invalid for various reasons).
+    '''
+
+    pass
+
+
+class BeartypeDoorPepUnsupportedException(BeartypeDoorPepException):
+    '''
+    **Decidedly Object-Oriented Runtime-checking (DOOR) unsupported
+    PEP-compliant type hint exception.**
+
+    This exception is raised at call time from :func:`beartype.door` callables
+    and classes on receiving an **unsupported PEP-compliant type hint** (i.e.,
+    type hint complying with PEP standards *not* currently supported by the
+    :mod:`beartype.door` API).
+    '''
+
+    pass
+
+# ....................{ API ~ kind                         }....................
+class BeartypeKindException(BeartypeException):
+    '''
+    Abstract base class of all **beartype container exceptions.**
+
+    Instances of subclasses of this exception are raised at usage (e.g.,
+    instantiation, callable call) time from various class hierarchies
+    implementing **beartype containers** (i.e., pure-Python data structures
+    defined by :mod:`beartype`).
+    '''
+
+    pass
+
+# ....................{ API ~ kind : dict                  }....................
+class BeartypeKindFrozenDictException(BeartypeException):
+    '''
+    **Beartype frozen dictionary exception.**
+
+    This exception is raised from various methods of the private
+    :class:`beartype._util.kind.map.utilmapfrozen.FrozenDict` class publicly
+    exposed as the :class:`beartype.BeartypeHintOverrides` subclass, typically
+    due to external callers erroneously attempting to modify key-value pairs of
+    instances of this class.
+    '''
+
+    pass
+
+
+class BeartypeHintOverridesException(BeartypeKindFrozenDictException):
+    '''
+    **Beartype hint overrides exception.**
+
+    This exception is raised from various methods of the public
+    :class:`beartype.BeartypeHintOverrides` class, typically due to external
+    callers erroneously attempting to instantiate instances of this class with
+    **recursive hint overrides** (e.g.,
+    ``BeartypeHintOverrides{str: list[str]})``).
+    '''
+
+    pass
+
+# ....................{ API ~ plug                         }....................
+class BeartypePlugException(BeartypeException):
+    '''
+    Abstract base class of all **beartype plugin exceptions.**
+
+    Instances of subclasses of this exception are raised at various times from
+    functionality utilizing :mod:`beartype`-specific plugin APIs standardized by
+    the :mod:`beartype.plug` subpackage, typically on detecting invalid usage of
+    a :mod:`beartype`-specific plugin API within a third-party Python package or
+    module.
+    '''
+
+    pass
+
+
+class BeartypePlugInstancecheckStrException(BeartypePlugException):
+    '''
+    **Beartype** ``__instancecheck_str__()`` **exception.**
+
+    This exception is raised at various times from functionality utilizing the
+    :mod:`beartype`-specific ``__instancecheck_str__()`` plugin API (i.e., a
+    :mod:`beartype`-specific dunder method defined on metaclasses of classes to
+    return human-readable substrings describing the failure of arbitrary objects
+    to satisfy those classes).
+    '''
+
+    pass
+
+# ....................{ API ~ vale                         }....................
+class BeartypeValeException(BeartypeException):
+    '''
+    Abstract base class of all **beartype validator exceptions.**
+
+    Instances of subclasses of this exception are raised at usage (e.g.,
+    instantiation, callable call) time from the class hierarchy published by
+    the :mod:`beartype.vale` subpackage.
+    '''
+
+    pass
+
+
+class BeartypeValeSubscriptionException(BeartypeValeException):
+    '''
+    **Beartype validator subscription exception.**
+
+    This exception is raised at instantiation time when subscripting (indexing)
+    factories published by the :mod:`beartype.vale` subpackage, including
+    attempts to:
+
+    * Instantiate *any* of these factories. Like standard type hints, these
+      factories are *only* intended to be subscripted (indexed).
+    * Apply the ``&`` or ``|`` operators to *any* subscriptions of these
+      factories and *any* other objects (e.g.,
+      ``beartype.vale.Is[lambda obj: True]] & 'If it seems bad, it is.'``).
+    * Subscript the :attr:`beartype.vale.Is` factory by anything other than a
+      **validator** (i.e., tester function satisfying the type hint
+      ``collections.abc.Callable[[typing.Any,], bool]``).
+    '''
+
+    pass
+
+
+class BeartypeValeValidationException(BeartypeValeException):
+    '''
+    **Beartype validator validation exception.**
+
+    This exception is raised at validation time (e.g.,, at call time of a
+    :func:`beartype.beartype`-decorated callable annotated by a beartype
+    validator) when a beartype validator fails to properly validate an object,
+    including attempts to:
+
+    * Subscript the :attr:`beartype.vale.Is` factory by a **non-bool-like
+      validator** (i.e., tester function returning an object that is neither a
+      :class:`bool` *nor* implicitly convertible into a :class:`bool`).
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ door                       }..................
+class _BeartypeDoorTextException(BeartypeDoorException):
+    '''
+    **Decidedly Object-Oriented Runtime-checking (DOOR) text exception.**
+
+    This exception is raised at call time from :func:`beartype.door` callables
+    and classes on detecting invalid strings (e.g., on raising an exception
+    whose message is *not* prefixed by the expected substring).
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ vale                     }....................
+class _BeartypeValeUtilException(BeartypeValeException):
+    '''
+    **Beartype validator utility exception.**
+
+    This exception is raised from various submodules of the private
+    :func:`beartype.vale._util` subpackage.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util                     }....................
+class _BeartypeUtilException(BeartypeException):
+    '''
+    Abstract base class of all **beartype private utility exceptions.**
+
+    Instances of subclasses of this exception are raised by *most* (but *not*
+    all) private submodules of the private :mod:`beartype._util` subpackage.
+    These exceptions denote critical internal issues and should thus *never* be
+    raised, let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilExceptionException(_BeartypeUtilException):
+    '''
+    **Beartype exception utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype.roar._roarexc` subpackage.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : ast                 }..................
+class _BeartypeUtilAstException(_BeartypeUtilException):
+    '''
+    **Beartype abstract syntax tree (AST) utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.ast` subpackage.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : cache               }..................
+class _BeartypeUtilCachedException(_BeartypeUtilException):
+    '''
+    Abstract base class of all **beartype caching utility exceptions.**
+
+    Instances of subclasses of this exception are raised by private submodules
+    of the private :mod:`beartype._util.cache` subpackage. These exceptions
+    denote critical internal issues and should thus *never* be raised -- let
+    alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilCallableCachedException(_BeartypeUtilCachedException):
+    '''
+    **Beartype memoization exception.**
+
+    This exception is raised by the
+    :func:`beartype._util.cache.utilcache.utilcachecall.callable_cached`
+    decorator on various fatal errors (e.g., when the signature of the
+    decorated callable is unsupported).
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilCacheLruException(_BeartypeUtilCachedException):
+    '''
+    **Beartype Least Recently Used (LRU) cache exception.**
+
+    This exception is raised by the
+    :func:`beartype._util.cache.utilcache.utilcachelru.CacheLruStrong` class
+    on various fatal errors (e.g., when the cache capacity is *not* a positive
+    integer).
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : cache : pool        }..................
+class _BeartypeUtilCachedKeyPoolException(_BeartypeUtilException):
+    '''
+    **Beartype key pool exception.**
+
+    This exception is raised by private functions of the private
+    :mod:`beartype._util.cache.pool.utilcachepool` subpackage on various fatal
+    edge cases.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+    pass
+
+
+class _BeartypeUtilCachedFixedListException(_BeartypeUtilCachedException):
+    '''
+    **Beartype decorator fixed list exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator when an internal callable erroneously
+    mutates a **fixed list** (i.e., list constrained to a fixed length defined
+    at instantiation time), usually by attempting to modify the length of that
+    list.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilCachedObjectTypedException(_BeartypeUtilCachedException):
+    '''
+    **Beartype decorator typed object exception.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator when an internal callable erroneously
+    acquires a **pooled typed object** (i.e., object internally cached to a
+    pool of all objects of that type).
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : call                }..................
+class _BeartypeCallHintRaiseException(_BeartypeUtilException):
+    '''
+    Abstract base class of all **beartype human-readable exception raiser
+    exceptions.**
+
+    Instances of subclasses of this exception are raised by private utility
+    **exception raiser functions** (i.e., functions raising human-readable
+    exceptions from wrapper functions when either passed a parameter or
+    returning a value annotated by a type hint fails the runtime type-check
+    required by that hint) when an unexpected failure occurs.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeCallHintPepRaiseException(_BeartypeCallHintRaiseException):
+    '''
+    **Beartype PEP-compliant human-readable exception raiser exception.**
+
+    This exception is raised by the
+    :func:`beartype._check.error.errorget.get_func_pith_violation`
+    exception raiser function when an unexpected failure occurs.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeCallHintPepRaiseDesynchronizationException(
+    _BeartypeCallHintPepRaiseException):
+    '''
+    **Beartype human-readable exception raiser desynchronization exception.**
+
+    This exception is raised by the
+    :func:`beartype._check.error.errorget.get_func_pith_violation` function
+    (which raises human-readable exceptions from wrapper functions when either
+    passed a parameter or returning a value, referred to as the "pith" for
+    brevity, annotated by a PEP-compliant type hint fails the type-check
+    required by that hint) when this pith appears to satisfy this type-check, a
+    runtime paradox implying either:
+
+    * The parent wrapper function generated by the :mod:`beartype.beartype`
+      decorator type-checking this pith triggered a false negative by
+      erroneously misdetecting this pith as failing this type check.
+    * The
+        :func:`beartype._check.error.errorget.get_func_pith_violation`
+      function re-type-checking this pith triggered a false positive by
+      erroneously misdetecting this pith as satisfying this type check when in
+      fact this pith fails to do so.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : kind                }..................
+class _BeartypeUtilCallFrameException(_BeartypeUtilException):
+    '''
+    **Beartype call stack frame utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.utilfunc` subpackage. This exception denotes a critical
+    internal issue and should thus *never* be raised -- let alone allowed to
+    percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilMappingException(_BeartypeUtilException):
+    '''
+    **Beartype mapping utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.kind.map` subpackage. This exception denotes a
+    critical internal issue and should thus *never* be raised -- let alone
+    allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilModuleException(_BeartypeUtilException):
+    '''
+    **Beartype module utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.module.utilmodget` subpackage. Notably, this includes:
+
+    * When dynamically importing an unimportable external user-defined module,
+      typically due to a **PEP-compliant forward reference type hint** (i.e.,
+      string whose value is the name of a user-defined class that has yet to be
+      defined) erroneously referencing a non-existent module or module
+      attribute.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilPathException(_BeartypeUtilException):
+    '''
+    **Beartype path utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.path` subpackage on various fatal edge cases. This
+    exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilTypeException(_BeartypeUtilException):
+    '''
+    **Beartype class utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.cls` subpackage. This exception denotes a critical
+    internal issue and should thus *never* be raised -- let alone allowed to
+    percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : kind : callable     }..................
+class _BeartypeUtilCallableException(_BeartypeUtilException):
+    '''
+    **Beartype callable utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.func` subpackage. This exception denotes a critical
+    internal issue and should thus *never* be raised -- let alone allowed to
+    percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilCallableScopeException(_BeartypeUtilCallableException):
+    '''
+    **Beartype callable scope utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.func.utilfuncscope` submodule. This exception denotes a
+    critical internal issue and should thus *never* be raised -- let alone
+    allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilCallableScopeNotFoundException(
+    _BeartypeUtilCallableException):
+    '''
+    **Beartype callable missing scope utility exception.**
+
+    This exception is raised by the private
+    :mod:`beartype._util.func.utilfuncscope.get_func_locals` getter on failing
+    to find the lexical scope of the parent callable or class declaring the
+    passed nested callable, enabling callers of that getter to identify this
+    common edge case. This exception denotes a critical internal issue and
+    should thus *never* be raised -- let alone allowed to percolate up the call
+    stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilCallableWrapperException(_BeartypeUtilCallableException):
+    '''
+    **Beartype callable wrapper utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.func.utilfuncwrap` subpackage. This exception denotes a
+    critical internal issue and should thus *never* be raised -- let alone
+    allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : object              }..................
+class _BeartypeUtilObjectException(_BeartypeUtilException):
+    '''
+    Abstract base class of all **beartype object utility exceptions.**
+
+    Instances of subclasses of this exception are raised by private functions
+    defined by the private :mod:`beartype._util.utilobject` submodule. These
+    exceptions denote critical internal issues and should thus *never* be raised
+    -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilObjectNameException(_BeartypeUtilObjectException):
+    '''
+    **Beartype object name exception.**
+
+    This exception is raised by the
+    :func:`beartype._util.utilobject.get_object_basename_scoped` getter when
+    the passed object is **unnamed** (i.e., fails to declare either the
+    ``__name__`` or ``__qualname__`` dunder attributes). This exception denotes
+    a critical internal issue and should thus *never* be raised -- let alone
+    allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : python              }..................
+class _BeartypeUtilPythonException(_BeartypeUtilException):
+    '''
+    Abstract base class of all beartype **Python utility exceptions.**
+
+    Instances of subclasses of this exception are raised by private submodules
+    of the private :mod:`beartype._util.py` subpackage. These exceptions
+    denote critical internal issues and should thus *never* be raised -- let
+    alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilPythonInterpreterException(_BeartypeUtilPythonException):
+    '''
+    Beartype **Python interpreter utility exception.**
+
+    This exception is raised by private functions of the private
+    :mod:`beartype._util.py.utilpyinterpreter` submodule on fatal edge cases.
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilPythonWeakrefException(_BeartypeUtilPythonException):
+    '''
+    Beartype **Python weak reference utility exception.**
+
+    This exception is raised by private functions of the private
+    :mod:`beartype._util.py.utilpyweakref` submodule on fatal edge cases. This
+    exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : text                }..................
+class _BeartypeUtilTextException(_BeartypeUtilException):
+    '''
+    Beartype **text utility exception.**
+
+    This exception is raised by various functions of the private
+    :mod:`beartype._util.text` subpackage.
+
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilTextIdentifierException(_BeartypeUtilTextException):
+    '''
+    Beartype **Python identifier utility exception.**
+
+    This exception is raised by private functions of the private
+    :mod:`beartype._util.text.utiltextidentifier` submodule on fatal edge cases.
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+
+class _BeartypeUtilTextVersionException(_BeartypeUtilTextException):
+    '''
+    Beartype **Python version utility exception.**
+
+    This exception is raised by private functions of the private
+    :mod:`beartype._util.text.utiltextversion` submodule on fatal edge cases.
+    This exception denotes a critical internal issue and should thus *never* be
+    raised -- let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/roar/_roarwarn.py
@@ -0,0 +1,435 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **warning hierarchy** (i.e., public and private warning subclasses
+emitted at decoration, call, and usage time by :mod:`beartype`).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from abc import ABCMeta as _ABCMeta
+
+# ....................{ SUPERCLASS                         }....................
+class BeartypeWarning(UserWarning, metaclass=_ABCMeta):
+    '''
+    Abstract base class of all **beartype warnings.**
+
+    Instances of subclasses of this warning are emitted either:
+
+    * At decoration time from the :func:`beartype.beartype` decorator.
+    * At call time from the new callable generated by the
+      :func:`beartype.beartype` decorator to wrap the original callable.
+    * At Sphinx-based documentation building time from Python code invoked by
+      the ``doc/Makefile`` file.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, message: str) -> None:
+        '''
+        Initialize this exception.
+
+        This constructor (in order):
+
+        #. Passes all passed arguments as is to the superclass constructor.
+        #. Sanitizes the fully-qualified module name of this
+           exception from the private ``"beartype.roar._roarwarn"`` submodule
+           to the public ``"beartype.roar"`` subpackage to both improve the
+           readability of exception messages and discourage end users from
+           accessing this private submodule.
+        '''
+
+        # Defer to the superclass constructor.
+        super().__init__(message)
+
+        # Sanitize the fully-qualified module name of the class of this
+        # warning. See the docstring for justification.
+        self.__class__.__module__ = 'beartype.roar'
+
+# ....................{ CLAW                               }....................
+class BeartypeClawWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype import hook warnings.**
+
+    Instances of subclasses of this warning are emitted at module importation
+    time from the import hooks registered by the :func:`beartype.claw`
+    subpackage, typically due to the :func:`beartype.beartype` decorator failing
+    to decorate callables or classes in modules imported by those hooks.
+    '''
+
+    pass
+
+
+class BeartypeClawDecorWarning(BeartypeClawWarning):
+    '''
+    **Beartype import hook decoration warning.**
+
+    This warning is emitted at module importation time from the import hooks
+    registered by the :func:`beartype.claw` subpackage when the
+    :func:`beartype.beartype` decorator fails to decorate a callable or class
+    declared in a module imported by those hooks.
+    '''
+
+    pass
+
+# ....................{ CONF                               }....................
+class BeartypeConfWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype configuration warnings.**
+
+    Instances of subclasses of this warning are emitted by the
+    :class:`beartype.BeartypeConf` class to inform the user of various non-fatal
+    edge cases concerning beartype configuration.
+    '''
+
+    pass
+
+
+class BeartypeConfShellVarWarning(BeartypeConfWarning):
+    '''
+    **Beartype configuration shell environment variable warning.**
+
+    Instances of this warning are emitted at instantiation time of the
+    :class:`beartype.BeartypeConf` class when the caller erroneously sets a
+    shell environment variable recognized by that class (e.g.,
+    ``${BEARTYPE_IS_COLOR}``) to an valid value conflicting with that of a
+    corresponding parameter also passed to that class (e.g., ``is_color``).
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint                   }....................
+class BeartypeDecorHintWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype decorator type hint warnings.**
+
+    Instances of subclasses of this warning are emitted at decoration time from
+    the :func:`beartype.beartype` decorator on receiving a callable annotated
+    by a suspicious (but *not* necessarily erroneous) type hint warranting
+    non-fatal warnings *without* raising fatal exceptions.
+    '''
+
+    pass
+
+
+
+class BeartypeDecorHintParamDefaultForwardRefWarning(BeartypeDecorHintWarning):
+    '''
+    **Beartyped decorator optional parameter default value type-checking
+    forward reference warning.**
+
+    This exception is raised at decoration time by the :func:`beartype.beartype`
+    decorator when the default value of an optional parameter of a decorated
+    callable is *not* type-checkable against the type hint annotating that
+    parameter, due to that type hint containing a forward reference to a
+    user-defined object that is undefined at that decoration time.
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint : pep             }....................
+class BeartypeDecorHintPepWarning(BeartypeDecorHintWarning):
+    '''
+    Abstract base class of all **beartype decorator PEP-compliant type hint
+    warnings.**
+
+    Instances of subclasses of this warning are emitted at decoration time from
+    the :func:`beartype.beartype` decorator on receiving a callable annotated
+    by a suspicious (but *not* necessarily erroneous) PEP-compliant type hint
+    warranting non-fatal warnings *without* raising fatal exceptions.
+    '''
+
+    pass
+
+
+#FIXME: Consider removal.
+# class BeartypeDecorHintPepIgnorableDeepWarning(BeartypeDecorHintPepWarning):
+#     '''
+#     **Beartype decorator deeply ignorable PEP-compliant type hint warning.**
+#
+#     This warning is emitted at decoration time from the
+#     :func:`beartype.beartype` decorator on receiving a callable annotated by
+#     one or more **deeply ignorable PEP-compliant type hints** (i.e., instances or classes declared
+#     by the stdlib :mod:`typing` module) currently unsupported by this
+#     decorator.
+#     '''
+#
+#     pass
+
+
+#FIXME: Consider removal.
+# class BeartypeDecorHintPepUnsupportedWarning(BeartypeWarning):
+#     '''
+#     **Beartype decorator unsupported PEP-compliant type hint warning.**
+#
+#     This warning is emitted at decoration time from the
+#     :func:`beartype.beartype` decorator on receiving a callable annotated with
+#     one or more PEP-compliant type hints (e.g., instances or classes declared
+#     by the stdlib :mod:`typing` module) currently unsupported by this
+#     decorator.
+#     '''
+#
+#     pass
+
+# ....................{ DECORATOR ~ hint : pep : deprecate }....................
+class BeartypeDecorHintPepDeprecationWarning(
+    BeartypeDecorHintPepWarning, DeprecationWarning):
+    '''
+    **Beartype decorator PEP-compliant type hint deprecation warning.**
+
+    This warning is emitted at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by one
+    or more **deprecated PEP-compliant type hints** (i.e., type hints compliant
+    with outdated PEPs that have since been obsoleted by recent PEPs),
+    including:
+
+    * If the active Python interpreter targets at least Python >= 3.9 and thus
+      supports :pep:`585`, outdated :pep:`484`-compliant type hints (e.g.,
+      ``typing.List[int]``) that have since been obsoleted by the equivalent
+      :pep:`585`-compliant type hints (e.g., ``list[int]``).
+    '''
+
+    pass
+
+
+#FIXME: This should *REALLY* have been called
+#"BeartypeDecorHintPep484DeprecationWarning". Oh well. Let's preserve backward
+#compatibility by just accepting this as is. This goes away in 2026, anyway.
+class BeartypeDecorHintPep585DeprecationWarning(
+    BeartypeDecorHintPepDeprecationWarning):
+    '''
+    **Beartype decorator** :pep:`585`-mandated **deprecation of**
+    :pep:`484`-compliant **type hint warning.**
+
+    This warning is emitted at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by
+    one or more outdated :pep:`484`-compliant type hints (e.g.,
+    ``typing.List[int]``) that have since been obsoleted by the equivalent
+    :pep:`585`-compliant type hints (e.g., ``list[int]``) if the active Python
+    interpreter targets at least Python >= 3.9 and thus supports :pep:`585`.
+
+    See Also
+    --------
+    https://github.com/beartype/beartype#pep-585-deprecations
+        Further discussion
+    '''
+
+    pass
+
+
+class BeartypeDecorHintPep613DeprecationWarning(
+    BeartypeDecorHintPepDeprecationWarning):
+    '''
+    **Beartype decorator** :pep:`613`-compliant **type hint warning.**
+
+    This warning is emitted at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by
+    one or more outdated :pep:`613`-compliant **type aliases** (i.e.,
+    :obj:`typing.TypeAlias` type hint singletons) that have since been obsoleted
+    by the equivalent :pep:`695`-compliant type aliases (e.g., ``type alias =
+    list[int]``) if the active Python interpreter targets at least Python >=
+    3.10 and thus supports :pep:`613`.
+    '''
+
+    pass
+
+# ....................{ DECORATOR ~ hint : non-pep         }....................
+class BeartypeDecorHintNonpepWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype decorator PEP-noncompliant type hint
+    warnings.**
+
+    Instances of subclasses of this warning are emitted at decoration time from
+    the :func:`beartype.beartype` decorator on receiving a callable annotated
+    by a suspicious (but *not* necessarily erroneous) PEP-noncompliant type
+    hint warranting non-fatal warnings *without* raising fatal exceptions.
+    '''
+
+    pass
+
+
+class BeartypeDecorHintNonpepNumpyWarning(BeartypeDecorHintNonpepWarning):
+    '''
+    **Beartype decorator PEP-noncompliant NumPy type hint warning.**
+
+    This exception is raised at decoration time from the
+    :func:`beartype.beartype` decorator on receiving a callable annotated by an
+    suspicious NumPy type hint, including:
+
+    * **Typed NumPy arrays** (i.e., ``numpy.typed.NDArray[...]`` type hints)
+      under Python < 3.8, which this decorator currently reduces to
+      **untyped NumPy arrays** (i.e., :class:`numpy.ndarray`).
+    '''
+
+    pass
+
+# ....................{ MODULE                             }....................
+class BeartypeModuleWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype module warnings.**
+
+    Instances of subclasses of this warning are emitted at various times
+    (including at decoration time from the :func:`beartype.beartype` decorator)
+    on failing to import optional third-party modules, packages, or C
+    extensions warranting non-fatal warnings *without* raising fatal
+    exceptions.
+    '''
+
+    pass
+
+
+class BeartypeModuleNotFoundWarning(BeartypeModuleWarning):
+    '''
+    **Beartype missing optional dependency warning.**
+
+    This warning is emitted at various times to inform the user of a **missing
+    recommended optional dependency** (i.e., third-party Python package *not*
+    installed under the active Python interpreter whose installation is
+    technically optional but recommended).
+    '''
+
+    pass
+
+
+class BeartypeModuleAttributeNotFoundWarning(BeartypeModuleWarning):
+    '''
+    **Beartype missing optional dependency attribute warning.**
+
+    This warning is emitted at various times to inform the user of a **missing
+    recommended optional dependency attribute** (i.e., attribute *not* defined
+    by a third-party Python package installed under the active Python
+    interpreter whose installation is technically optional but recommended,
+    typically due to the currently installed version of that package being
+    unexpectedly old and thus failing to define an attribute defined by modern
+    versions of that package).
+    '''
+
+    pass
+
+
+class BeartypeModuleUnimportableWarning(BeartypeModuleWarning):
+    '''
+    **Beartype unimportable optional dependency warning.**
+
+    This warning is emitted at various times to inform the user of an
+    **unimportable optional dependency** (i.e., third-party Python package
+    installed under the active Python interpreter but which raises unexpected
+    exceptions from module scope when imported).
+    '''
+
+    pass
+
+# ....................{ SPHINX                             }....................
+#FIXME: Consider removal.
+# class BeartypeSphinxWarning(BeartypeWarning, metaclass=_ABCMeta):
+#     '''
+#     Abstract base class of all **beartype Sphinx warnings.**
+#
+#     Instances of subclasses of this warning are emitted at Sphinx-based
+#     documentation building time from the ``doc/Makefile`` file in various edge
+#     cases warranting non-fatal warnings *without* raising fatal exceptions.
+#     '''
+#
+#     pass
+
+# ....................{ VALE                               }....................
+class BeartypeValeWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype data validation warnings.**
+
+    Instances of subclasses of this warning are emitted at usage (e.g.,
+    instantiation, method call) time from the class hierarchy published by the
+    :func:`beartype.vale` subpackage by suspicious (but *not* necessarily
+    erroneous) PEP-compliant type hints warranting non-fatal warnings *without*
+    raising fatal exceptions.
+    '''
+
+    pass
+
+
+class BeartypeValeLambdaWarning(BeartypeValeWarning):
+    '''
+    **Beartype data validation lambda function warning.**
+
+    This warning is emitted on passing the :func:`repr` builtin an instance of
+    the :class:`beartype.vale.Is` class subscripted by a lambda function whose
+    definition is *not* parsable from the script or module file defining that
+    lambda.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ conf                     }....................
+class _BeartypeConfReduceDecoratorExceptionToWarningDefault(
+    BeartypeConfWarning):
+    '''
+    Beartype
+    :attr:`beartype.BeartypeConf.warning_cls_on_decorator_exception`
+    **fake warning default.**
+
+    This warning is *not* actually emitted at all anywhere but instead
+    constitutes intentional design abuse of this submodule. Specifically, this
+    warning is used as the default value for the public
+    :attr:`beartype.BeartypeConf.warning_cls_on_decorator_exception`
+    configuration parameter, enabling private functionality elsewhere to
+    distinguish between the following two common cases:
+
+    * A user does explicitly sets that parameter to :data:`None`, instructing
+      the :func:`beartype.beartype` decorator to raise exceptions rather than
+      emit warnings on decoration-time errors.
+    * A user does *not* explicitly set that parameter, which then defaults to
+      this fake warning category. Private functionality elsewhere then detects
+      this default and conditionally sets that parameter to a meaningful default
+      depending on the current context. As example, when *not* explicitly set by
+      the user:
+
+      * The :mod:`beartype.claw` API defaults that parameter to the public
+        :class:`.BeartypeClawDecorWarning` warning category.
+      * The :func:`beartype.beartype` decorator defaults that parameter to
+        :data:`None`.
+
+    This warning is doing the wrong things, but for the right reasons. Again,
+    this warning is a placeholder that should *never* be emitted to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util                     }....................
+class _BeartypeUtilWarning(BeartypeWarning):
+    '''
+    Abstract base class of all **beartype private utility warnings.**
+
+    Instances of subclasses of this warning are emitted by *most* (but *not*
+    all) private submodules of the private :mod:`beartype._util` subpackage.
+    These warnings denote non-critical internal issues and should thus *never*
+    be emitted, let alone allowed to percolate up the call stack to end users.
+    '''
+
+    pass
+
+# ....................{ PRIVATE ~ util : call              }....................
+class _BeartypeUtilCallableWarning(_BeartypeUtilWarning):
+    '''
+    Beartype **decorator memoization decorator keyword argument** warning.
+
+    This warning is emitted from callables memoized by the
+    :func:`beartype._util.cache.utilcachecall.callable_cached` decorator on
+    calls receiving one or more keyword arguments. Memoizing keyword arguments
+    is substantially more space- and time-intensive than memoizing the
+    equivalent positional arguments, partially defeating the purpose of
+    memoization in the first place.
+
+    This warning denotes a critical internal issue and should thus *never* be
+    emitted to end users.
+    '''
+
+    pass
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/typing/__init__.py
@@ -0,0 +1,393 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype** :mod:`typing` **compatibility layer.**
+
+This submodule declares the exact same set of **public typing attributes**
+(i.e., module-scoped attributes listed by the :attr:`typing.__all__` global) as
+declared by the :mod:`typing` module for your current Python version. Although
+the attributes declared by this submodule *mostly* share the same values as
+the attributes declared by :mod:`typing`, notable differences include:
+
+* :pep:`585`-deprecated typing attributes. :pep:`585` deprecated **38 public
+  typing attributes** to "...be removed from the typing module in the first
+  Python version released 5 years after the release of Python 3.9.0." This
+  submodule preserves those attributes under their original names for the
+  Python 3.8-specific version of the :mod:`typing` module, thus preserving
+  forward compatibility with future Python versions. These include:
+
+  * :attr:`typing.AbstractSet`.
+  * :attr:`typing.AsyncContextManager`.
+  * :attr:`typing.AsyncGenerator`.
+  * :attr:`typing.AsyncIterable`.
+  * :attr:`typing.AsyncIterator`.
+  * :attr:`typing.Awaitable`.
+  * :attr:`typing.ByteString`.
+  * :attr:`typing.Callable`.
+  * :attr:`typing.ChainMap`.
+  * :attr:`typing.Collection`.
+  * :attr:`typing.Container`.
+  * :attr:`typing.ContextManager`.
+  * :attr:`typing.Coroutine`.
+  * :attr:`typing.Counter`.
+  * :attr:`typing.DefaultDict`.
+  * :attr:`typing.Deque`.
+  * :attr:`typing.Dict`.
+  * :attr:`typing.FrozenSet`.
+  * :attr:`typing.Generator`.
+  * :attr:`typing.ItemsView`.
+  * :attr:`typing.Iterable`.
+  * :attr:`typing.Iterator`.
+  * :attr:`typing.KeysView`.
+  * :attr:`typing.List`.
+  * :attr:`typing.Mapping`.
+  * :attr:`typing.MappingView`.
+  * :attr:`typing.Match`.
+  * :attr:`typing.MutableMapping`.
+  * :attr:`typing.MutableSequence`.
+  * :attr:`typing.MutableSet`.
+  * :attr:`typing.OrderedDict`.
+  * :attr:`typing.Pattern`.
+  * :attr:`typing.Reversible`.
+  * :attr:`typing.Set`.
+  * :attr:`typing.Tuple`.
+  * :attr:`typing.Type`.
+  * :attr:`typing.Sequence`.
+  * :attr:`typing.ValuesView`.
+
+Usage
+----------
+:mod:`beartype` users are strongly encouraged to import typing attributes from
+this submodule rather than from :mod:`typing` directly: e.g.,
+
+.. code-block:: python
+
+   # Instead of this...
+   from typing import Tuple, List, Dict, Set, FrozenSet, Type
+
+   # ...always do this.
+   from beartype.typing import Tuple, List, Dict, Set, FrozenSet, Type
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: Fundamentally generalize this submodule to optionally backport
+#attributes from "typing_extensions" where available, resolving issue #237 at:
+#    https://github.com/beartype/beartype/issues/237
+#
+#To do so, we'll basically want to discard the entire current implementation of
+#this submodule in favour of a fundamentally superior approach resembling:
+#    # In "beartype.typing.__init__": the future of typing backports begins today.
+#    from typing import TYPE_CHECKING
+#
+#    # If @beartype is currently being statically type-checked (e.g.,
+#    # by mypy or pyright), just defer to the third-party
+#    # "typing_extensions" package.
+#    #
+#    # Note that this does *NOT* mean that @beartype now unconditionally
+#    # requires "typing_extensions" at either runtime or static
+#    # type-checking time. Any code in an "if TYPE_CHECKING:" is (basically)
+#    # just a convincing semantic lie that everything syntactically ignores.
+#    if TYPE_CHECKING:
+#        from typing_extensions import *  # <-- heh
+#    # Else, @beartype is currently being imported from at runtime. This is
+#    # the common case. This is also the non-trivial case, because @beartype
+#    # does *NOT* require "typing_extensions" as a mandatory runtime
+#    # dependency, because @beartype requires *NOTHING* as a runtime
+#    # dependency. This is the only rule in @beartype's Rule of Law.
+#    else:
+#        #FIXME: Unfortunately, to avoid circular import dependencies, these
+#        #imports will need to be copy-and-pasted into equivalent condensed
+#        #submodules of a new "beartype.typing._util" subpackage.
+#        # Import the requisite machinery that will make the magic happen.
+#        from beartype._util.hint.utilhintfactory import TypeHintTypeFactory
+#        from beartype._util.api.utilapityping import (
+#            import_typing_attr_or_fallback as _import_typing_attr_or_fallback)
+#
+#        # Dynamically define the "Self" type hint as follows:
+#        # * If the active Python interpreter targets Python >= 3.11, just
+#        #   defer to the canonical "typing.Self" type hint.
+#        # * Else if "typing_extensions" is importable *AND* of a sufficiently
+#        #   recent version to define the backported "typing_extensions.Self"
+#        #   type hint, fallback to that hint.
+#        # * Else, synthesize a placeholder type hint that @beartype internally
+#        #   recognizes as semantically equivalent to "typing.Self".
+#        Self = _import_typing_attr_or_fallback('Self', object)
+#        LiteralString = _import_typing_attr_or_fallback('Self', str)
+#        TypeGuard = _import_typing_attr_or_fallback('Self', bool)
+#        Annotated = _import_typing_attr_or_fallback('Annotated', bool)
+#
+#        #FIXME: Repeat the above logic for *ALL* existing "typing" attributes.
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# *NOT* intended for public importation should be locally imported at module
+# scope *ONLY* under alternate private names (e.g., "import re as _re" rather
+# than merely "from re").
+# WARNING: To preserve PEP 561 compliance with static type checkers (e.g.,
+# mypy), external attributes *MUST* be explicitly imported with standard static
+# import machinery rather than non-standard dynamic import shenanigans (e.g.,
+# "from typing import Annotated" rather than
+# "import_typing_attr_or_none('Annotated')").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype._util.py.utilpyversion import (
+    IS_PYTHON_AT_LEAST_3_12 as _IS_PYTHON_AT_LEAST_3_12,
+    IS_PYTHON_AT_LEAST_3_11 as _IS_PYTHON_AT_LEAST_3_11,
+    IS_PYTHON_AT_LEAST_3_10 as _IS_PYTHON_AT_LEAST_3_10,
+    IS_PYTHON_AT_LEAST_3_9  as _IS_PYTHON_AT_LEAST_3_9,
+)
+
+# ....................{ IMPORTS ~ all                      }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To prevent "mypy --no-implicit-reexport" from raising literally
+# hundreds of errors at static analysis time, *ALL* public attributes *MUST* be
+# explicitly reimported under the same names with "{exception_name} as
+# {exception_name}" syntax rather than merely "{exception_name}". Yes, this is
+# ludicrous. Yes, this is mypy. For posterity, these failures resemble:
+#     beartype/_cave/_cavefast.py:47: error: Module "beartype.roar" does not
+#     explicitly export attribute "BeartypeCallUnavailableTypeException";
+#     implicit reexport disabled  [attr-defined]
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+# Import all public attributes of the "typing" module both available under all
+# supported Python versions and *NOT* deprecated by a subsequent Python version
+# under their original names.
+from typing import (
+    TYPE_CHECKING as TYPE_CHECKING,
+    Any as Any,
+    AnyStr as AnyStr,
+    BinaryIO as BinaryIO,
+    ClassVar as ClassVar,
+    Final as Final,  # pyright: ignore
+    ForwardRef as ForwardRef,
+    Generic as Generic,
+    Hashable as Hashable,
+    IO as IO,
+    Literal as Literal,  # pyright: ignore
+    NewType as NewType,
+    NamedTuple as NamedTuple,
+    NoReturn as NoReturn,
+    Optional as Optional,
+    Reversible as Reversible,  # pyright: ignore
+    Sized as Sized,
+    SupportsIndex as SupportsIndex,  # pyright: ignore
+    TypedDict as TypedDict,  # pyright: ignore
+    Text as Text,
+    TextIO as TextIO,
+    TypeVar as TypeVar,
+    Union as Union,
+    cast as cast,
+    final as final,  # pyright: ignore
+    get_args as get_args,  # pyright: ignore
+    get_origin as get_origin,  # pyright: ignore
+    get_type_hints as get_type_hints,
+    no_type_check as no_type_check,
+    no_type_check_decorator as no_type_check_decorator,
+    overload as overload,
+)
+
+# ....................{ IMPORTS ~ version                  }....................
+# Import all public attributes of the "typing" module both available under a
+# subset of supported Python versions and *NOT* deprecated by a subsequent
+# Python version under their original names.
+
+#FIXME: mypy is now emitting non-fatal warnings about our failing to import from
+#"typing_extensions", which is both an overly strongly opinionated position for
+#mypy to stake out *AND* a bad opinion at that, because "typing_extensions"
+#fails to comply with the runtime API of the "typing" module and is thus mostly
+#unusable at runtime. These warnings resemble:
+#    beartype/typing/__init__.py:145: note: Use `from typing_extensions import Final` instead
+#    beartype/typing/__init__.py:145: note: See https://mypy.readthedocs.io/en/stable/runtime_troubles.html#using-new-additions-to-the-typing-module
+#    beartype/typing/__init__.py:145: note: Use `from typing_extensions import Literal` instead
+#
+#That's not the worst, however. mypy is erroneously ignoring our intentional
+#"# type: ignore[attr-defined]" pragmas here. It's likely that the ultimate
+#culprit is our use of beartype-specific "IS_PYTHON_AT_LEAST_*" boolean globals.
+#Instead, mypy appears to only support hard-coded tests against the
+#"sys.version_info" tuple: e.g.,
+#    if sys.version_info >= (3, 8):
+#
+#To resolve this, we should consider:
+#* Abandoning our usage of beartype-specific "IS_PYTHON_AT_LEAST_*" boolean
+#  globals for hard-coded tests against the "sys.version_info" tuple (above).
+#* Submitting an upstream issue requesting that mypy respect the
+#  "# type: ignore[attr-defined]" pragma rather than emitting warnings here.
+
+# If the active Python interpreter targets Python >= 3.10...
+if _IS_PYTHON_AT_LEAST_3_10:
+    from typing import (  # type: ignore[attr-defined]
+        Concatenate as Concatenate,  # pyright: ignore
+        ParamSpec as ParamSpec,  # pyright: ignore
+        ParamSpecArgs as ParamSpecArgs,  # pyright: ignore
+        ParamSpecKwargs as ParamSpecKwargs,  # pyright: ignore
+        TypeAlias as TypeAlias,  # pyright: ignore
+        TypeGuard as TypeGuard,  # pyright: ignore
+        is_typeddict as is_typeddict,  # pyright: ignore
+    )
+
+    # If the active Python interpreter targets Python >= 3.11...
+    if _IS_PYTHON_AT_LEAST_3_11:
+        from typing import (  # type: ignore[attr-defined]
+               LiteralString as LiteralString,  # pyright: ignore
+               Never as Never,  # pyright: ignore
+               NotRequired as NotRequired,  # pyright: ignore
+               Required as Required,  # pyright: ignore
+               Self as Self,  # pyright: ignore
+               TypeVarTuple as TypeVarTuple,  # pyright: ignore
+               Unpack as Unpack,  # pyright: ignore
+               assert_never as assert_never,  # pyright: ignore
+               assert_type as assert_type,  # pyright: ignore
+               clear_overloads as clear_overloads,  # pyright: ignore
+               dataclass_transform as dataclass_transform,  # pyright: ignore
+               reveal_type as reveal_type,  # pyright: ignore
+               get_overloads as get_overloads,  # pyright: ignore
+               reveal_type as reveal_type,  # pyright: ignore
+        )
+
+        # If the active Python interpreter targets Python >= 3.12...
+        if _IS_PYTHON_AT_LEAST_3_12:
+            from typing import (  # type: ignore[attr-defined]
+                TypeAliasType as TypeAliasType,  # pyright: ignore
+                override as override,  # pyright: ignore
+            )
+
+# ....................{ PEP ~ 544                          }....................
+# If this interpreter is performing static type-checking (e.g., via mypy), defer
+# to the standard library versions of the family of "Supports*" protocols
+# available under Python < 3.8.
+if TYPE_CHECKING:
+    from typing import (  # type: ignore[attr-defined]
+        Protocol as Protocol,  # pyright: ignore
+        SupportsAbs as SupportsAbs,
+        SupportsBytes as SupportsBytes,
+        SupportsComplex as SupportsComplex,
+        SupportsFloat as SupportsFloat,
+        SupportsIndex as SupportsIndex,  # pyright: ignore
+        SupportsInt as SupportsInt,
+        SupportsRound as SupportsRound,
+        runtime_checkable as runtime_checkable,  # pyright: ignore
+    )
+# Else, this interpreter is *NOT* performing static type-checking. In this
+# case, prefer our optimized PEP 544 attributes.
+else:
+    from beartype.typing._typingpep544 import (
+        Protocol as Protocol,
+        SupportsAbs as SupportsAbs,
+        SupportsBytes as SupportsBytes,
+        SupportsComplex as SupportsComplex,
+        SupportsFloat as SupportsFloat,
+        SupportsIndex as SupportsIndex,
+        SupportsInt as SupportsInt,
+        SupportsRound as SupportsRound,
+        runtime_checkable as runtime_checkable,
+    )
+
+# ....................{ PEP ~ 585                          }....................
+# If this interpreter is either performing static type-checking (e.g., via mypy)
+# *OR* targets Python < 3.9 and thus fails to support PEP 585, import *ALL*
+# public attributes of the "typing" module deprecated by PEP 585 as their
+# original values.
+#
+# This is intentionally performed *BEFORE* the corresponding "else:" branch
+# below handling the Python >= 3.9 case. Why? Because mypy. If the order of
+# these two branches is reversed, mypy emits errors under Python < 3.9 when
+# attempting to subscript any of the builtin types (e.g., "Tuple"): e.g.,
+#     error: "tuple" is not subscriptable  [misc]
+if TYPE_CHECKING or not _IS_PYTHON_AT_LEAST_3_9:
+    from typing import (
+        AbstractSet as AbstractSet,
+        AsyncContextManager as AsyncContextManager,
+        AsyncGenerator as AsyncGenerator,
+        AsyncIterable as AsyncIterable,
+        AsyncIterator as AsyncIterator,
+        Awaitable as Awaitable,
+        ByteString as ByteString,
+        Callable as Callable,
+        ChainMap as ChainMap,
+        Collection as Collection,
+        Container as Container,
+        ContextManager as ContextManager,
+        Coroutine as Coroutine,
+        Counter as Counter,
+        DefaultDict as DefaultDict,
+        Deque as Deque,
+        Dict as Dict,
+        FrozenSet as FrozenSet,
+        Generator as Generator,
+        ItemsView as ItemsView,
+        Iterable as Iterable,
+        Iterator as Iterator,
+        KeysView as KeysView,
+        List as List,
+        Mapping as Mapping,
+        Match as Match,
+        MappingView as MappingView,
+        MutableMapping as MutableMapping,
+        MutableSequence as MutableSequence,
+        MutableSet as MutableSet,
+        OrderedDict as OrderedDict,
+        Pattern as Pattern,
+        Reversible as Reversible,
+        Set as Set,
+        Tuple as Tuple,
+        Type as Type,
+        Sequence as Sequence,
+        ValuesView as ValuesView,
+    )
+# If the active Python interpreter targets Python >= 3.9 and thus supports PEP
+# 585, alias *ALL* public attributes of the "typing" module deprecated by PEP
+# 585 to their equivalent values elsewhere in the standard library.
+else:
+    from collections import (
+        ChainMap as ChainMap,
+        Counter as Counter,
+        OrderedDict as OrderedDict,
+        defaultdict as DefaultDict,
+        deque as Deque,
+    )
+    from collections.abc import (
+        AsyncIterable as AsyncIterable,
+        AsyncIterator as AsyncIterator,
+        AsyncGenerator as AsyncGenerator,
+        Awaitable as Awaitable,
+        ByteString as ByteString,
+        Callable as Callable,
+        Collection as Collection,
+        Container as Container,
+        Coroutine as Coroutine,
+        Generator as Generator,
+        ItemsView as ItemsView,
+        Iterable as Iterable,
+        Iterator as Iterator,
+        KeysView as KeysView,
+        Mapping as Mapping,
+        MappingView as MappingView,
+        MutableMapping as MutableMapping,
+        MutableSequence as MutableSequence,
+        MutableSet as MutableSet,
+        Reversible as Reversible,
+        Sequence as Sequence,
+        ValuesView as ValuesView,
+        Set as AbstractSet,
+    )
+    from contextlib import (
+        AbstractContextManager as ContextManager,
+        AbstractAsyncContextManager as AsyncContextManager,
+    )
+    from re import (
+        Match as Match,
+        Pattern as Pattern,
+    )
+    from typing import (  # type: ignore[attr-defined]
+        Annotated,
+    )
+
+    Dict = dict  # type: ignore[misc]
+    FrozenSet = frozenset  # type: ignore[misc]
+    List = list  # type: ignore[misc]
+    Set = set  # type: ignore[misc]
+    Tuple = tuple  # type: ignore[assignment]
+    Type = type  # type: ignore[assignment]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/typing/_typingcache.py
@@ -0,0 +1,174 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype typing callable caching** (i.e., general-purpose memoization of
+function and method calls intended to be called *only* from submodules of this
+subpackage) utilities.
+
+This private submodule implements only a minimal subset of the caching
+functionality implemented by the general-purpose
+:mod:`beartype._util.cache.utilcachecall` submodule, from which this submodule
+was originally derived. Since the latter transitively imports from the
+:mod:`beartype.typing` subpackage at module scope, submodules of the
+:mod:`beartype.typing` subpackage *cannot* safely import from the
+:mod:`beartype._util.cache.utilcachecall` submodule at module scope. Ergo, the
+existence of this submodule.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._util.py.utilpyversion import IS_PYTHON_AT_LEAST_3_9
+from functools import wraps
+from typing import TYPE_CHECKING
+
+# If either a pure-static type-checker is currently statically type-checking
+# @beartype *OR* the active Python interpreter targets Python >= 3.9, PEP 585 is
+# supported. In this case, embrace non-deprecated PEP 585-compliant type hints.
+if TYPE_CHECKING or IS_PYTHON_AT_LEAST_3_9:
+    from collections.abc import Callable
+    Dict = dict
+# Else, the active Python interpreter targets Python < 3.9 and thus fails to
+# support PEP 585. Note that we intentionally avoid importing these type hint
+# factories from "beartype.typing", as that would induce a circular import
+# dependency. Instead, we manually import the relevant type hint factories
+# conditionally depending on the version of the active Python interpreter.
+else:
+    from typing import Callable, Dict
+
+# ....................{ CONSTANTS                          }....................
+_SENTINEL = object()
+'''
+Sentinel object of arbitrary value.
+'''
+
+# ....................{ DECORATORS                         }....................
+def callable_cached_minimal(func: Callable) -> Callable:
+    '''
+    **Memoize** (i.e., efficiently cache and return all previously returned
+    values of the passed callable as well as all previously raised exceptions
+    of that callable previously rather than inefficiently recalling that
+    callable) the passed callable.
+
+    Parameters
+    ----------
+    func : Callable
+        Callable to be memoized.
+
+    Returns
+    ----------
+    Callable
+        Closure wrapping this callable with memoization.
+
+    See Also
+    ----------
+    :func:`beartype._util.cache.utilcachecall.callable_cached`
+        Further details.
+    '''
+    assert callable(func), f'{repr(func)} not callable.'
+
+    # Dictionary mapping a tuple of all flattened parameters passed to each
+    # prior call of the decorated callable with the value returned by that
+    # call if any (i.e., if that call did *NOT* raise an exception).
+    params_flat_to_return_value: Dict[tuple, object] = {}
+
+    # get() method of this dictionary, localized for efficiency.
+    params_flat_to_return_value_get = params_flat_to_return_value.get
+
+    # Dictionary mapping a tuple of all flattened parameters passed to each
+    # prior call of the decorated callable with the exception raised by that
+    # call if any (i.e., if that call raised an exception).
+    params_flat_to_exception: Dict[tuple, Exception] = {}
+
+    # get() method of this dictionary, localized for efficiency.
+    params_flat_to_exception_get = params_flat_to_exception.get
+
+    @wraps(func)
+    def _callable_cached(*args):
+        f'''
+        Memoized variant of the {func.__name__}() callable.
+
+        See Also
+        ----------
+        :func:`callable_cached`
+            Further details.
+        '''
+
+        # If passed only one positional argument, minimize space consumption by
+        # flattening this tuple of only that argument into that argument. Since
+        # tuple items are necessarily hashable, this argument is necessarily
+        # hashable as well and thus permissible as a dictionary key below.
+        if len(args) == 1:
+            params_flat = args[0]
+        # Else, one or more positional arguments are passed. In this case,
+        # reuse this tuple as is.
+        else:
+            params_flat = args
+
+        # Attempt to...
+        try:
+            #FIXME: Optimize the params_flat_to_exception_get() case, please.
+            #Since "None" is *NOT* a valid exception, we shouldn't need a
+            #sentinel for safety here. Instead, this should suffice:
+            #    exception = params_flat_to_exception_get(params_flat)
+
+            #    # If this callable previously raised an exception when called with
+            #    # these parameters, re-raise the same exception.
+            #    if exception:
+            #        raise exception
+
+            # Exception raised by a prior call to the decorated callable when
+            # passed these parameters *OR* the sentinel placeholder otherwise
+            # (i.e., if this callable either has yet to be called with these
+            # parameters *OR* has but failed to raise an exception).
+            #
+            # Note that this call raises a "TypeError" exception if any item of
+            # this flattened tuple is unhashable.
+            exception = params_flat_to_exception_get(params_flat, _SENTINEL)
+
+            # If this callable previously raised an exception when called with
+            # these parameters, re-raise the same exception.
+            if exception is not _SENTINEL:
+                raise exception  # pyright: ignore[reportGeneralTypeIssues]
+            # Else, this callable either has yet to be called with these
+            # parameters *OR* has but failed to raise an exception.
+
+            # Value returned by a prior call to the decorated callable when
+            # passed these parameters *OR* a sentinel placeholder otherwise
+            # (i.e., if this callable has yet to be passed these parameters).
+            return_value = params_flat_to_return_value_get(
+                params_flat, _SENTINEL)
+
+            # If this callable has already been called with these parameters,
+            # return the value returned by that prior call.
+            if return_value is not _SENTINEL:
+                return return_value
+            # Else, this callable has yet to be called with these parameters.
+
+            # Attempt to...
+            try:
+                # Call this parameter with these parameters and cache the value
+                # returned by this call to these parameters.
+                return_value = params_flat_to_return_value[params_flat] = func(
+                    *args)
+            # If this call raises an exception...
+            except Exception as exception:
+                # Cache this exception to these parameters.
+                params_flat_to_exception[params_flat] = exception
+
+                # Re-raise this exception.
+                raise exception
+        # If one or more objects either passed to *OR* returned from this call
+        # are unhashable, perform this call as is *WITHOUT* memoization. While
+        # non-ideal, stability is better than raising a fatal exception.
+        except TypeError:
+            return func(*args)
+
+        # Return this value.
+        return return_value
+
+    # Return this wrapper.
+    return _callable_cached
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/typing/_typingpep544.py
@@ -0,0 +1,629 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype** :pep:`544` **optimization layer.**
+
+This private submodule implements a :func:`beartype.beartype``-compatible
+(i.e., decorated by the :func:`typing.runtime_checkable` decorator) drop-in
+replacement for :class:`typing.Protocol` that can lead to significant
+performance improvements.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: *YIKES.* Our "beartype.typing.Protocol" implementation is broken yet
+#again -- but this time for @classmethod-decorated callables. Consider this:
+#    from beartype.typing import Protocol
+#    class BrokenProtocol(Protocol):
+#        @classmethod
+#        def broken_classmethod(cls) -> object:
+#            pass
+#
+#Now define an arbitrary class violating that protocol:
+#    class BrokenClass(object): pass
+#
+#Now attempt to demonstrate that this class violates that protocol:
+#    >>> isinstance(BrokenClass, BrokenProtocol)
+#    True  # <----- WAAAAAAAAAT
+#
+#This issue is almost certainly related to classmethods. We clearly never tested
+#that. Classmethods clearly require explicit handling and caching. *sigh*
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing._typingcache import callable_cached_minimal
+from beartype._util.py.utilpyversion import (
+    IS_PYTHON_AT_LEAST_3_12,
+    IS_PYTHON_AT_LEAST_3_9,
+)
+from typing import (  # type: ignore[attr-defined]
+    EXCLUDED_ATTRIBUTES,  # pyright: ignore
+    TYPE_CHECKING,
+    Any,
+    Generic,
+    Protocol as _ProtocolSlow,
+    SupportsAbs as _SupportsAbsSlow,
+    SupportsBytes as _SupportsBytesSlow,
+    SupportsComplex as _SupportsComplexSlow,
+    SupportsFloat as _SupportsFloatSlow,
+    SupportsIndex as _SupportsIndexSlow,  # pyright: ignore
+    SupportsInt as _SupportsIntSlow,
+    SupportsRound as _SupportsRoundSlow,
+    TypeVar,
+    runtime_checkable,
+)
+
+# If either *NO* pure-static type-checker is currently statically type-checking
+# @beartype *OR* the active Python interpreter targets Python < 3.9, the active
+# Python interpreter targets Python < 3.9 and thus fails to support PEP 585. In
+# this case, embrace non-deprecated PEP 585-compliant type hints.
+if not (TYPE_CHECKING or IS_PYTHON_AT_LEAST_3_9):
+    from typing import Dict, Tuple, Type
+# Else, the active Python interpreter targets Python < 3.9 and thus fails to
+# support PEP 585.
+#
+# Note that we intentionally:
+# * Avoid importing these type hint factories from "beartype.typing", as that
+#   would induce a circular import dependency. Instead, we manually import the
+#   relevant type hint factories conditionally depending on the version of the
+#   active Python interpreter. *sigh*
+# * Test the negation of this condition first. Why? Because mypy quietly
+#   defecates all over itself if the order of these two branches is reversed.
+#   Yeah. It's as bad as it sounds.
+else:
+    Dict = dict
+    Tuple = tuple
+    Type = type
+
+# If the active Python interpreter was invoked by a static type checker (e.g.,
+# mypy), violate privacy encapsulation. Doing so invites breakage under newer
+# Python releases. Confining any potential breakage to this technically optional
+# static type-checking phase minimizes the fallout by ensuring that this API
+# continues to behave as expected at runtime.
+#
+# See also this deep typing voodoo:
+#     https://github.com/python/mypy/issues/11614
+if TYPE_CHECKING:
+    from abc import ABCMeta as _ProtocolMeta
+# Else, this interpreter was *NOT* invoked by a static type checker and is thus
+# subject to looser runtime constraints. In this case, access the same metaclass
+# *WITHOUT* violating privacy encapsulation.
+else:
+    _ProtocolMeta = type(_ProtocolSlow)
+
+# ....................{ PRIVATE ~ constants                }....................
+_PROTOCOL_ATTR_NAMES_IGNORABLE = frozenset(EXCLUDED_ATTRIBUTES)
+'''
+Frozen set of the names all **ignorable non-protocol attributes** (i.e.,
+attributes *not* considered part of the protocol of a
+:class:`beartype.typing.Protocol` subclass when passing that protocol to
+the :func:`isinstance` builtin in structural subtyping checks).
+'''
+
+
+_T_co = TypeVar("_T_co", covariant=True)
+'''
+Arbitrary covariant type variable.
+'''
+
+
+_TT = TypeVar("_TT", bound="_CachingProtocolMeta")
+'''
+Arbitrary type variable bound (i.e., confined) to classes.
+'''
+
+# ....................{ PRIVATE ~ metaclasses              }....................
+class _CachingProtocolMeta(_ProtocolMeta):
+    '''
+    **Caching protocol metaclass** (i.e., drop-in replacement for the
+    private metaclass of the public :class:`typing.Protocol` superclass
+    that additionally caches :meth:`class.__instancecheck__` results).
+
+    This metaclass amortizes the `non-trivial time complexity of protocol
+    validation <protocol cost_>`__ to a trivial constant-time lookup.
+
+    .. _protocol cost:
+       https://github.com/python/mypy/issues/3186#issuecomment-885718629
+
+    Caveats
+    ----------
+    **This metaclass will yield unpredictable results for any object with
+    one or more methods not declared by the class of that object,**
+    including objects whose methods are dynamically assembled at runtime.
+    This metaclass is ill-suited for such "types."
+
+    Motivation
+    ----------
+    By default, :class:`typing.Protocol` subclasses are constrained to only
+    be checkable by static type checkers (e.g., :mod:`mypy`). Checking a
+    protocol with a runtime type checker (e.g., :mod:`beartype`) requires
+    explicitly decorating that protocol with the
+    :func:`typing.runtime_checkable` decorator. Why? We have no idea.
+
+    For unknown (but probably indefensible) reasons, :pep:`544` authors
+    enforced this constraint with a trivial private
+    :class:`typing.Protocol` boolean instance variable imposing *no* space
+    or time burden set only by the optional
+    :func:`typing.runtime_checkable` decorator. Since that's demonstrably
+    insane, we pretend :pep:`544` authors chose wisely by unconditionally
+    decorating *all* :class:`beartype.typing.Protocol` subclasses by that
+    decorator.
+
+    Technically, any non-caching :class:`typing.Protocol` subclass can be
+    effectively coerced into a caching :class:`beartype.typing.Protocol`
+    protocol through inheritance: e.g.,
+
+    .. code-block:: python
+
+      >>> from abc import abstractmethod
+      >>> from typing import Protocol
+      >>> from beartype.typing import _CachingProtocolMeta, runtime_checkable
+      >>> @runtime_checkable
+      ... class _MyProtocol(Protocol):  # plain vanilla protocol
+      ...     @abstractmethod
+      ...     def myfunc(self, arg: int) -> str:
+      ...         pass
+      >>> @runtime_checkable  # redundant, but useful for documentation
+      ... class MyProtocol(
+      ...     _MyProtocol,
+      ...     Protocol,
+      ...     metaclass=_CachingProtocolMeta,  # caching version
+      ... ):
+      ...     pass
+      >>> class MyImplementation:
+      ...     def myfunc(self, arg: int) -> str:
+      ...         return str(arg * -2 + 5)
+      >>> my_thing: MyProtocol = MyImplementation()
+      >>> isinstance(my_thing, MyProtocol)
+      True
+
+    Pragmatically, :class:`beartype.typing.Protocol` trivially eliminates
+    *all* of the above fragile boilerplate: e.g.,
+
+    .. code-block:: python
+
+      >>> from beartype.typing import Protocol
+      >>> class MyBearProtocol(Protocol):
+      ...     @abstractmethod
+      ...     def myfunc(self, arg: int) -> str:
+      ...         pass
+      >>> my_thing: MyBearProtocol = MyImplementation()
+      >>> isinstance(my_thing, MyBearProtocol)
+      True
+    '''
+
+    # ................{ CLASS VARIABLES                        }................
+    _abc_inst_check_cache: Dict[type, bool]  # pyright: ignore
+    '''
+    :func:`isinstance` **cache** (i.e., dictionary mapping from each type of any
+    object previously passed as the first parameter to the :func:`isinstance`
+    builtin whose second parameter was this protocol onto each boolean returned
+    by that call to that builtin).
+    '''
+
+    # ................{ DUNDERS                                }................
+    def __new__(
+        mcls: Type[_TT],  # pyright: ignore
+        name: str,
+        bases: Tuple[type, ...],  # pyright: ignore
+        namespace: Dict[str, Any],  # pyright: ignore
+        **kw: Any,
+    ) -> _TT:
+
+        # See <https://github.com/python/mypy/issues/9282>
+        cls = super().__new__(mcls, name, bases, namespace, **kw)  # pyright: ignore
+
+        # If this class is *NOT* the abstract "beartype.typing.Protocol"
+        # superclass defined below...
+        if name != 'Protocol':
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # CAUTION: Synchronize this "if" conditional against the standard
+            # "typing" module, which defines the exact same logic in the
+            # Protocol.__init_subclass__() class method.
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # If it is unknown whether this class is an abstract protocol
+            # directly subclassing the "Protocol" superclass *OR* a concrete
+            # subclass of an abstract protocol, decide which applies now. Why?
+            # Because upstream performs the same logic. Since this logic tests
+            # the non-transitive dunder tuple "__bases__" of all *DIRECT*
+            # superclasses of this class rather than the transitive dunder tuple
+            # "__mro__" of all direct and indirect superclasses of this class,
+            # upstream logic erroneously detects abstract fast @beartype
+            # protocols as concrete by unconditionally reducing to:
+            #     cls._is_protocol = False
+            #
+            # Why? Because "beartype.typing.Protocol" subclasses
+            # "typing.Protocol", subclasses of "beartype.typing.Protocol" list
+            # "beartype.typing.Protocol" rather than "typing.Protocol" in their
+            # "__bases__" dunder tuple. Disaster, thy name is "typing"!
+            if not cls.__dict__.get('_is_protocol'):
+                # print(f'Protocol {cls} bases: {cls.__bases__}')
+                cls._is_protocol = any(b is Protocol for b in cls.__bases__)  # type: ignore[attr-defined]
+
+            # If this protocol is concrete rather than abstract, monkey-patch
+            # this concrete protocol to be implicitly type-checkable at runtime.
+            # By default, protocols are *NOT* type-checkable at runtime unless
+            # explicitly decorated by this nonsensical decorator.
+            #
+            # Note that the abstract "beartype.typing.Protocol" superclass
+            # *MUST* be explicitly excluded from consideration. Why? For unknown
+            # reasons, monkey-patching that superclass as implicitly
+            # type-checkable at runtime has extreme consequences throughout the
+            # typing ecosystem. In particular, doing so causes *ALL*
+            # non-protocol classes to be subsequently erroneously detected as
+            # being PEP 544-compliant protocols: e.g.,
+            #     # If we monkey-patched the "Protocol" superclass as well, then
+            #     # the following snippet would insanely hold true... wat!?!?!?!
+            #     >>> from typing import Protocol
+            #     >>> class OhBoy(object): pass
+            #     >>> issubclass(OhBoy, Protocol)
+            #     True  # <-- we have now destroyed the world, folks.
+            if cls._is_protocol:  # type: ignore[attr-defined]
+                # print(f'Protocol {cls} mro: {cls.__mro__}')
+                runtime_checkable(cls)  # pyright: ignore
+        # Else, this class is the abstract "beartype.typing.Protocol"
+        # superclass defined below. In this case, avoid dangerously
+        # monkey-patching this superclass.
+
+        # Prefixing this class member with "_abc_" is necessary to prevent
+        # it from being considered part of the Protocol. See also:
+        #     https://github.com/python/cpython/blob/main/Lib/typing.py
+        cls._abc_inst_check_cache = {}
+
+        # Return this caching protocol.
+        return cls
+
+
+    def __instancecheck__(cls, inst: Any) -> bool:
+        '''
+        :data:`True` only if the passed object is a **structural subtype**
+        (i.e., satisfies the protocol defined by) the passed protocol.
+
+        Parameters
+        ----------
+        cls : type
+            :pep:`544`-compliant protocol to check this object against.
+        inst : Any
+            Arbitrary object to check against this protocol.
+
+        Returns
+        ----------
+        bool
+            :data:`True` only if this object satisfies this protocol.
+        '''
+
+        # Attempt to...
+        try:
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # CAUTION: This *MUST* remain *SUPER* tight!! Even adding a
+            # mere assertion here can add ~50% to our best-case runtime.
+            #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # Return a pre-cached boolean indicating whether an object of
+            # the same arbitrary type as the object passed to this call
+            # satisfied the same protocol in a prior call of this method.
+            return cls._abc_inst_check_cache[type(inst)]
+        # If this method has yet to be passed the same protocol *AND* an
+        # object of the same type as the object passed to this call...
+        except KeyError:
+            # If you're going to do *anything*, do it here. Try not to
+            # expand the rest of this method if you can avoid it.
+            inst_t = type(inst)
+            bases_pass_muster = True
+
+            for base in cls.__bases__:
+                #FIXME: This branch probably erroneously matches unrelated
+                #user-defined types whose names just happen to be "Generic"
+                #or "Protocol". Ideally, we should tighten that up to only
+                #match the actual "{beartype,}.typing.{Generic,Protocol}"
+                #superclasses. Of course, note that
+                #"beartype.typing.Protocol" is *NOT* "typing.Protocol', so
+                #we'll want to explicitly test against both.
+                if base is cls or base.__name__ in (
+                    'Protocol',
+                    'Generic',
+                    'object',
+                ):
+                    continue
+                if not isinstance(inst, base):
+                    bases_pass_muster = False
+                    break
+
+            cls._abc_inst_check_cache[inst_t] = bases_pass_muster and (
+                _check_only_my_attrs(cls, inst))
+
+            return cls._abc_inst_check_cache[inst_t]
+
+# ....................{ PRIVATE ~ functions                }....................
+#FIXME: Docstring us up, please.
+#FIXME: Comment us up, please.
+def _check_only_my_attrs(cls, inst: Any, _EMPTY_DICT = {}) -> bool:
+
+    cls_attr_name_to_value = cls.__dict__
+    cls_attr_name_to_hint = cls_attr_name_to_value.get(
+        '__annotations__', _EMPTY_DICT)
+    cls_attr_names = (
+        cls_attr_name_to_value | cls_attr_name_to_hint
+        if IS_PYTHON_AT_LEAST_3_9 else
+        dict(cls_attr_name_to_value, **cls_attr_name_to_hint)
+    )
+
+    # For the name of each attribute declared by this protocol class...
+    for cls_attr_name in cls_attr_names:
+        # If...
+        if (
+            # This name implies this attribute to be unignorable *AND*...
+            #
+            # Specifically, if this name is neither...
+            not (
+                # A private attribute defined by dark machinery in the
+                # "ABCMeta" metaclass for abstract base classes *OR*...
+                cls_attr_name.startswith('_abc_') or
+                # That of an ignorable non-protocol attribute...
+                cls_attr_name in _PROTOCOL_ATTR_NAMES_IGNORABLE
+            # This attribute is either...
+            ) and (
+                # Undefined by the passed object *OR*...
+                not hasattr(inst, cls_attr_name) or
+                # Defined by the passed object as a "blocked" (i.e., omitted
+                # from being type-checked as part of this protocol) method.
+                # For unknown and indefensible reasons, PEP 544 explicitly
+                # supports this fragile, unreadable, and error-prone idiom
+                # enabling objects to leave methods "undefined." What this!?
+                (
+                    #FIXME: Unit test this up, please.
+                    # A callable *AND*...
+                    callable(getattr(cls, cls_attr_name, None)) and
+                    # The passed object nullified this method. *facepalm*
+                    getattr(inst, cls_attr_name) is None
+                )
+            )
+        ):
+            # Then the passed object violates this protocol. In this case,
+            # return false.
+            return False
+
+    # Else, the passed object satisfies this protocol. In this case, return
+    # true.
+    return True
+
+# ....................{ CLASSES                            }....................
+# @runtime_checkable
+class Protocol(
+    _ProtocolSlow,
+    # Force protocols to be generics. Although the standard
+    # "typing.Protocol" superclass already implicitly subclasses from the
+    # "typing.Generic" superclass, the non-standard
+    # "typing_extensions.Protocol" superclass does *NOT*. Ergo, we force
+    # this to be the case.
+    Generic,  # pyright: ignore
+    metaclass=_CachingProtocolMeta,
+):
+    '''
+    :func:`beartype.beartype`-compatible (i.e., decorated by
+    :func:`typing.runtime_checkable`) drop-in replacement for
+    :class:`typing.Protocol` that can lead to significant performance
+    improvements.
+
+    Uses :class:`_CachingProtocolMeta` to cache :func:`isinstance` check
+    results.
+
+    Examples
+    ----------
+    .. code-block:: python
+
+       >>> from abc import abstractmethod
+       >>> from beartype import beartype
+       >>> from beartype.typing import Protocol
+
+       >>> class MyBearProtocol(Protocol):  # <-- runtime-checkable through inheritance
+       ...   @abstractmethod
+       ...   def myfunc(self, arg: int) -> str:
+       ...     pass
+
+       >>> my_thing: MyBearProtocol = MyImplementation()
+       >>> isinstance(my_thing, MyBearProtocol)
+       True
+
+       >>> @beartype
+       ... def do_somthing(thing: MyBearProtocol) -> None:
+       ...   thing.myfunc(0)
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    __slots__: Any = ()
+
+    # ..................{ DUNDERS                            }..................
+    @callable_cached_minimal
+    def __class_getitem__(cls, item):
+
+        # We have to redefine this method because typing.Protocol's version
+        # is very persnickety about only working for typing.Generic and
+        # typing.Protocol. That's an exclusive club, and we ain't in it.
+        # (RIP, GC.) Let's see if we can sneak in, shall we?
+
+        # FIXME: Once <https://bugs.python.org/issue46581> is addressed,
+        # consider replacing the madness below with something like:
+        #   cached_gen_alias = _ProtocolSlow.__class_getitem__(_ProtocolSlow, params)
+        #   our_gen_alias = cached_gen_alias.copy_with(params)
+        #   our_gen_alias.__origin__ = cls
+        #   return our_gen_alias
+
+        # Superclass __class_getitem__() dunder method, localized for
+        # brevity, efficiency, and (most importantly) to squelch false
+        # positive "errors" from pyright with a single pragma comment.
+        super_class_getitem = super().__class_getitem__  # pyright: ignore
+
+        # If the superclass typing.Protocol.__class_getitem__() dunder
+        # method has been wrapped as expected with caching by the private
+        # (and thus *NOT* guaranteed to exist) @typing._tp_cache decorator,
+        # call that unwrapped method directly to obtain the expected
+        # generic alias.
+        #
+        # Note that:
+        # * We intentionally call the unwrapped method rather than the
+        #   decorated closure wrapping that method with memoization. Why?
+        #   Because subsequent logic monkey-patches this generic alias to
+        #   refer to this class rather than the standard "typing.Protocol".
+        #   However, doing so violates internal expectations of the
+        #   @typing._tp_cache decorator performing this memoization.
+        # * This method is already memoized by our own @callable_cached
+        #   decorator. Calling the decorated closure wrapping that
+        #   unwrapped method with memoization would needlessly consume
+        #   excess space and time for *NO* additional benefit.
+        if hasattr(super_class_getitem, '__wrapped__'):
+            # Protocol class to be passed as the "cls" parameter to the
+            # unwrapped superclass typing.Protocol.__class_getitem__()
+            # dunder method. There exist two unique cases corresponding to
+            # two unique branches of an "if" conditional in that method,
+            # depending on whether either this "Protocol" superclass or a
+            # user-defined subclass of this superclass is being
+            # subscripted. Specifically, this class is...
+            protocol_cls = (
+                # If this "Protocol" superclass is being directly
+                # subclassed by one or more type variables (e.g.,
+                # "Protocol[S, T]"), the non-caching "typing.Protocol"
+                # superclass underlying this caching protocol superclass.
+                # Since the aforementioned "if" conditional performs an
+                # explicit object identity test for the "typing.Protocol"
+                # superclass, we *MUST* pass that rather than this
+                # superclass to trigger that conditional appropriately.
+                _ProtocolSlow
+                if cls is Protocol else
+                # Else, a user-defined subclass of this "Protocol"
+                # superclass is being subclassed by one or more type
+                # variables *OR* types satisfying the type variables
+                # subscripting the superclass (e.g.,
+                # "UserDefinedProtocol[str]" for a user-defined subclass
+                # class UserDefinedProtocol(Protocol[AnyStr]). In this
+                # case, this subclass as is.
+                cls
+            )
+
+            gen_alias = super_class_getitem.__wrapped__(protocol_cls, item)
+        # We shouldn't ever be here, but if we are, we're making the
+        # assumption that typing.Protocol.__class_getitem__() no longer
+        # caches. Heaven help us if that ever uses some proprietary
+        # memoization implementation we can't see anymore because it's not
+        # based on the standard @functools.wraps decorator.
+        else:
+            gen_alias = super_class_getitem(item)
+
+        # Switch the origin of this generic alias from its default of
+        # "typing.Protocol" to this caching protocol class. If *NOT* done,
+        # CPython incorrectly sets the metaclass of subclasses to the
+        # non-caching "type(typing.Protocol)" metaclass rather than our
+        # caching "_CachingProtocolMeta" metaclass.
+        #
+        # Luddite alert: we don't fully understand the mechanics here. We
+        # suspect no one does.
+        gen_alias.__origin__ = cls
+
+        # We're done! Time for a honey brewskie break. We earned it.
+        return gen_alias
+
+#FIXME: Ensure that the main @beartype codebase handles protocols whose
+#repr() starts with "beartype.typing" as well, please.
+
+# Replace the unexpected (and thus non-compliant) fully-qualified name of
+# the module declaring this caching protocol superclass (e.g.,
+# "beartype.typing._typingpep544") with the expected (and thus compliant)
+# fully-qualified name of the standard "typing" module declaring the
+# non-caching "typing.Protocol" superclass.
+#
+# If this is *NOT* done, then the machine-readable representation of this
+# caching protocol superclass when subscripted by one or more type
+# variables (e.g., "beartype.typing.Protocol[S, T]") will be differ
+# significantly from that of the non-caching "typing.Protocol" superclass
+# (e.g., beartype.typing._typingpep544.Protocol[S, T]"). Because
+# @beartype (and possibly other third-party packages) expect the two
+# representations to comply, this awkward monkey-patch preserves sanity.
+Protocol.__module__ = 'beartype.typing'
+
+# ....................{ PROTOCOLS                          }....................
+class SupportsAbs(_SupportsAbsSlow[_T_co], Protocol, Generic[_T_co]):
+    '''
+    Caching variant of :class:`typing.SupportsAbs`.
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+
+class SupportsBytes(_SupportsBytesSlow, Protocol):
+    '''
+    Caching variant of :class:`typing.SupportsBytes`.
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+
+class SupportsComplex(_SupportsComplexSlow, Protocol):
+    '''
+    Caching variant of :class:`typing.SupportsComplex`.
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+
+class SupportsFloat(_SupportsFloatSlow, Protocol):
+    '''
+    Caching variant of :class:`typing.SupportsFloat`."
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+
+class SupportsInt(_SupportsIntSlow, Protocol):
+    '''
+    Caching variant of :class:`typing.SupportsInt`.
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+
+class SupportsIndex(_SupportsIndexSlow, Protocol):
+    '''
+    Caching variant of :class:`typing.SupportsIndex`.
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+
+class SupportsRound(_SupportsRoundSlow[_T_co], Protocol, Generic[_T_co]):
+    '''
+    Caching variant of :class:`typing.SupportsRound`.
+    '''
+    __module__: str = 'beartype.typing'
+    __slots__: Any = ()
+
+# ....................{ MONKEY-PATCHES                     }....................
+# If the active Python interpreter targets Python >= 3.12, monkey-patch the
+# standard "typing" module to support our "Protocol" superclass.
+if IS_PYTHON_AT_LEAST_3_12:
+    import typing
+    from typing import _generic_class_getitem as _generic_class_getitem_old  # type: ignore[attr-defined]
+
+    def _generic_class_getitem_new(cls, params):
+        '''
+        Beartype-specific wrapper for the private
+        :func:`typing._generic_class_getitem` utility function, enabling that
+        function to transparently support our beartype-specific
+        :class:`beartype.typing.Protocol` superclass equivalent to the standard
+        :class:`typing.Protocol` superclass.
+        '''
+
+        # If the passed class is our "beartype.typing.Protocol" superclass,
+        # silently replace that with "typing.Protocol" *BEFORE* calling the
+        # standard typing._generic_class_getitem() utility function -- which
+        # explicitly only supports the latter.
+        if cls is Protocol:
+            cls = _ProtocolSlow
+        # Else, the passed class is *NOT* our "beartype.typing.Protocol"
+        # superclass. In this case, preserve that class as is.
+
+        # Defer to the standard typing._generic_class_getitem() implementation.
+        return _generic_class_getitem_old(cls, params)
+
+    # Replace the standard typing._generic_class_getitem() implementation with
+    # the wrapper defined above. *gulp*
+    typing._generic_class_getitem = _generic_class_getitem_new  # type: ignore[attr-defined]
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/__init__.py
@@ -0,0 +1,162 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype validator API.**
+
+This submodule publishes a PEP-compliant hierarchy of subscriptable (indexable)
+classes enabling callers to validate the internal structure of arbitrarily
+complex scalars, data structures, and third-party objects. Like annotation
+objects defined by the :mod:`typing` module (e.g., :attr:`typing.Union`), these
+classes dynamically generate PEP-compliant type hints when subscripted
+(indexed) and are thus intended to annotate callables and variables. Unlike
+annotation objects defined by the :mod:`typing` module, these classes are *not*
+explicitly covered by existing PEPs and thus *not* directly usable as
+annotations.
+
+Instead, callers are expected to (in order):
+
+#. Annotate callable parameters and returns to be validated with
+   :pep:`593`-compliant :attr:`typing.Annotated` type hints.
+#. Subscript those hints with (in order):
+
+   #. The type of those parameters and returns.
+   #. One or more subscriptions of classes declared by this submodule.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: [FEATURE] Add a new "beartype.vale.IsInline" validator factory,
+#elegantly resolving issue #82 and presumably other future issues, too. The
+#core idea here is that "beartype.vale.IsInline" will enable callers to
+#directly embed arbitrary test code substrings in the bodies of wrapper
+#functions dynamically generated by @beartype. The signature resembles:
+#    beartype.vale.IsInline[code: str, arg_1: object, ..., arg_N: object]
+#...where:
+#* "arg_1" through "arg_N" are optional arbitrary objects to be made available
+#  through the corresponding format variables "{arg_1}" through "{arg_N}" in
+#  the "code" substring. These arguments are the *ONLY* safe means of exposing
+#  non-builtin objects to the "code" substring.
+#* "code" is a mandatory arbitrary test code substring. This substring *MUST*
+#  contain at least this mandatory format variable:
+#  * "{obj}", expanding to the current object being validated. Should this
+#    perhaps be "{pith}" instead for disambiguity? *shrug*
+#  Additionally, for each optional "arg_{index}" object subscripting this
+#  "IsInline" factory, this "code" substring *MUST* contain at least one
+#  corresponding format variable "{arg_{index}}". For example:
+#      # This is valid.
+#      IsInline['len({obj}) == len({arg_1})', ['muh', 'list',]]
+#
+#      # This is invalid, because the "['muh', 'list',]" list argument is
+#      # *NEVER* referenced via "{arg_1}" in this code snippet.
+#      IsInline['len({obj}) == 2', ['muh', 'list',]]
+#  Lastly, this substring may additionally contain these optional format
+#  variables:
+#  * "{indent}", expanding to the current indentation level. Specifically:
+#    * Any "code" substring beginning with a newline *MUST* contain one or more
+#      "{indent}" variables.
+#    * Any "code" substring *NOT* beginning with a newline must *NOT* contain
+#      any "{indent}" variables.
+
+#FIXME: As intelligently requested by @Saphyel at #32, add support for
+#additional classes support constraints resembling:
+#
+#* String constraints:
+#  * Email.
+#  * Uuid.
+#  * Choice.
+#  * Language.
+#  * Locale.
+#  * Country.
+#  * Currency.
+#* Comparison constraints
+#  * IdenticalTo.
+#  * NotIdenticalTo.
+#  * LessThan.
+#  * GreaterThan.
+#  * Range.
+#  * DivisibleBy.
+
+#FIXME: Add a new BeartypeValidator.find_cause() method with the same
+#signature and docstring as the existing ViolationCause.find_cause()
+#method. This new BeartypeValidator.find_cause() method should then be
+#called by the "_peperrorannotated" submodule to generate human-readable
+#exception messages. Note that this implies that:
+#* The BeartypeValidator.__init__() method will need to additionally accept a new
+#  mandatory "find_cause: Callable[[], Optional[str]]" parameter, which
+#  that method should then localize to "self.find_cause".
+#* Each __class_getitem__() dunder method of each "_BeartypeValidatorFactoryABC" subclass will need
+#  to additionally define and pass that callable when creating and returning
+#  its "BeartypeValidator" instance.
+
+#FIXME: *BRILLIANT IDEA.* Holyshitballstime. The idea here is that we can
+#leverage all of our existing "beartype.is" infrastructure to dynamically
+#synthesize PEP-compliant type hints that would then be implicitly supported by
+#any runtime type checker. At present, subscriptions of "Is" (e.g.,
+#"Annotated[str, Is[lambda text: bool(text)]]") are only supported by beartype
+#itself. Of course, does anyone care? I mean, if you're using a runtime type
+#checker, you're probably *ONLY* using beartype. Right? That said, this would
+#technically improve portability by allowing users to switch between different
+#checkers... except not really, since they'd still have to import beartype
+#infrastructure to do so. So, this is probably actually useless.
+#
+#Nonetheless, the idea itself is trivial. We declare a new
+#"beartype.is.Portable" singleton accessed in the same way: e.g.,
+#    from beartype import beartype
+#    from beartype.is import Portable
+#    NonEmptyStringTest = Is[lambda text: bool(text)]
+#    NonEmptyString = Portable[str, NonEmptyStringTest]
+#    @beartype
+#    def munge_it(text: NonEmptyString) -> str: ...
+#
+#So what's the difference between "typing.Annotated" and "beartype.is.Portable"
+#then? Simple. The latter dynamically generates one new PEP 3119-compliant
+#metaclass and associated class whenever subscripted. Clearly, this gets
+#expensive in both space and time consumption fast -- which is why this won't
+#be the default approach. For safety, this new class does *NOT* subclass the
+#first subscripted class. Instead:
+#* This new metaclass of this new class simply defines an __isinstancecheck__()
+#  dunder method. For the above example, this would be:
+#    class NonEmptyStringMetaclass(object):
+#        def __isinstancecheck__(cls, obj) -> bool:
+#            return isinstance(obj, str) and NonEmptyStringTest(obj)
+#* This new class would then be entirely empty. For the above example, this
+#  would be:
+#    class NonEmptyStringClass(object, metaclass=NonEmptyStringMetaclass):
+#        pass
+#
+#Well, so much for brilliant. It's slow and big, so it seems doubtful anyone
+#would actually do that. Nonetheless, that's food for thought for you.
+
+# ....................{ IMPORTS                            }....................
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+# WARNING: To avoid polluting the public module namespace, external attributes
+# should be locally imported at module scope *ONLY* under alternate private
+# names (e.g., "from argparse import ArgumentParser as _ArgumentParser" rather
+# than merely "from argparse import ArgumentParser").
+#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+from beartype.vale._is._valeis import _IsFactory
+from beartype.vale._is._valeistype import (
+    _IsInstanceFactory,
+    _IsSubclassFactory,
+)
+from beartype.vale._is._valeisobj import _IsAttrFactory
+from beartype.vale._is._valeisoper import _IsEqualFactory
+
+# ....................{ SINGLETONS                         }....................
+# Public factory singletons instantiating these private factory classes.
+Is = _IsFactory(basename='Is')
+IsAttr = _IsAttrFactory(basename='IsAttr')
+IsEqual = _IsEqualFactory(basename='IsEqual')
+IsInstance = _IsInstanceFactory(basename='IsInstance')
+IsSubclass = _IsSubclassFactory(basename='IsSubclass')
+
+# Delete all private factory classes imported above for safety.
+del (
+    _IsFactory,
+    _IsAttrFactory,
+    _IsEqualFactory,
+    _IsInstanceFactory,
+    _IsSubclassFactory,
+)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_core/_valecore.py
@@ -0,0 +1,549 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Core beartype validator.**
+
+This private submodule defines the core private :class:`BeartypeValidator`
+class instantiated by public **beartype validator factories** (i.e., instances
+of concrete subclasses of the private
+:class:`beartype._vale._factory._valeisabc._BeartypeValidatorFactoryABC`
+abstract base class (ABC)).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.vale._util._valeutilfunc import die_unless_validator_tester
+from beartype.vale._util._valeutiltext import format_diagnosis_line
+from beartype.vale._util._valeutiltyping import (
+    BeartypeValidatorTester,
+    BeartypeValidatorRepresenter,
+)
+from beartype._data.hint.datahinttyping import LexicalScope
+from beartype._util.func.arg.utilfuncargtest import is_func_argless
+from beartype._util.text.utiltextrepr import represent_object
+
+# ....................{ CLASSES                            }....................
+class BeartypeValidator(object):
+    '''
+    **Beartype validator** (i.e., object encapsulating a caller-defined
+    validation callable returning ``True`` when an arbitrary object passed to
+    that callable satisfies an arbitrary constraint, suitable for subscripting
+    (indexing) :pep:`593`-compliant :attr:`typing.Annotated` type hints
+    enforcing that validation on :mod:`beartype`-decorated callable parameters
+    and returns annotated by those hints).
+
+    Caveats
+    ----------
+    **This private class is not intended to be externally instantiated** (e.g.,
+    by calling the :meth:`__init__` constructor). This class is *only* intended
+    to be internally instantiated by subscripting (indexing) various public
+    type hint factories (e.g., :class:`beartype.vale.Is`).
+
+    Attributes
+    ----------
+    _get_repr : BeartypeValidatorRepresenter
+        **Representer** (i.e., either a string *or* caller-defined callable
+        accepting no arguments returning a machine-readable representation of
+        this validator). See the :data:`BeartypeValidatorRepresenter` type hint
+        for further details.
+    _is_valid : BeartypeValidatorTester
+        **Validator tester** (i.e., caller-defined callable accepting a single
+        arbitrary object and returning either ``True`` if that object satisfies
+        an arbitrary constraint *or* ``False`` otherwise).
+    _is_valid_code : str
+        **Validator code** (i.e., Python code snippet validating the
+        previously localized parameter or return value against the same
+        validation performed by the :meth:`is_valid` function). For efficiency,
+        callers validating data through dynamically generated code (e.g., the
+        :func:`beartype.beartype` decorator) rather than standard function
+        calls (e.g., the private :mod:`beartype._decor._hint._pep._error`
+        subpackage) should prefer :attr:`is_valid_code` to :meth:`is_valid`.
+        Despite performing the same validation as the :meth:`is_valid`
+        callable, this code avoids the additional stack frame imposed by
+        calling that callable and thus constitutes an optimization.
+    _is_valid_code_locals : LexicalScope
+        **Validator code local scope** (i.e., dictionary mapping from the name
+        to value of each local attribute referenced in :attr:`code`) required
+        to dynamically compile this validator code into byte code at runtime.
+
+    See Also
+    ----------
+    :class:`Is`
+        Class docstring for further details.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats the purpose.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Slot all instance variables defined on this object to reduce the costs of
+    # both reading and writing these variables by approximately ~10%.
+    __slots__ = (
+        '_get_repr',
+        '_is_valid',
+        '_is_valid_code',
+        '_is_valid_code_locals',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+        *,
+
+        # Mandatory keyword-only parameters.
+        is_valid: BeartypeValidatorTester,
+        is_valid_code: str,
+        is_valid_code_locals: LexicalScope,
+        get_repr: BeartypeValidatorRepresenter,
+    ) -> None:
+        '''
+        Initialize this validator from the passed metadata.
+
+        Parameters
+        ----------
+        is_valid : BeartypeValidatorTester
+            **Validator tester** (i.e., caller-defined callable accepting a
+            single arbitrary object and returning either ``True`` if that object
+            satisfies an arbitrary constraint *or* ``False`` otherwise).
+        is_valid_code : str
+            **Validator code** (i.e., Python code snippet validating the
+            previously localized parameter or return value against the same
+            validation performed by the :func:`is_valid` function). This code:
+
+            * *Must* contain one or more ``"{obj}"`` substrings, which external
+              code generators (e.g., the :func:`beartype.beartype` decorator)
+              will globally replace at evaluation time with the actual test
+              subject object to be validated by this code.
+            * *May* contain one or more ``"{indent}"`` substrings, which such
+              code generators will globally replace at evaluation time with the
+              line-oriented indentation required to generate a
+              valid Python statement embedding this code. For consistency with
+              :pep:`8`-compliant and well-established Python style guides, any
+              additional indentation hard-coded into this code should be
+              aligned to **four-space indentation.**
+        is_valid_code_locals : LexicalScope
+            **Validator code local scope** (i.e., dictionary mapping from the
+            name to value of each local attribute referenced in
+            :attr:`is_valid_code` code) required to dynamically compile this
+            validator code into byte code at runtime.
+        get_repr : BeartypeValidatorRepresenter
+            **Representer** (i.e., either a string *or* caller-defined callable
+            accepting no arguments returning a machine-readable representation
+            of this validator). See the :data:`BeartypeValidatorRepresenter`
+            type hint for further details.
+
+        Raises
+        ----------
+        beartype.roar.BeartypeValeSubscriptionException
+            If either:
+
+            * ``is_valid`` is either:
+
+              * *Not* callable.
+              * A C-based rather than pure-Python callable.
+              * A pure-Python callable accepting two or more arguments.
+
+            * ``is_valid_code`` is either:
+
+              * *Not* a string.
+              * A string either:
+
+                * Empty.
+                * Non-empty but **invalid** (i.e., *not* containing the test
+                  subject substring ``{obj}``).
+
+            * ``is_valid_locals`` is *not* a dictionary.
+            * ``get_repr`` is either:
+
+              * *Not* callable.
+              * A C-based rather than pure-Python callable.
+              * A pure-Python callable accepting one or more arguments.
+              * The empty string.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype.vale._is._valeisabc import _BeartypeValidatorFactoryABC
+
+        # If that callable is *NOT* a validator tester, raise an exception.
+        die_unless_validator_tester(is_valid)
+        # Else, that callable is a validator tester.
+
+        # If this code is *NOT* a string, raise an exception.
+        if not isinstance(is_valid_code, str):
+            raise BeartypeValeSubscriptionException(
+                f'Validator code not string:\n'
+                f'{represent_object(is_valid_code)}'
+            )
+        # Else, this code is a string.
+        #
+        # If this code is the empty string, raise an exception.
+        elif not is_valid_code:
+            raise BeartypeValeSubscriptionException('Validator code empty.')
+        # Else, this code is a non-empty string.
+        #
+        # If this code does *NOT* contain the test subject substring
+        # "{obj}" and is invalid, raise an exception.
+        elif '{obj}' not in is_valid_code:
+            raise BeartypeValeSubscriptionException(
+                f'Validator code invalid '
+                f'(i.e., test subject substring "{{obj}}" not found):\n'
+                f'{is_valid_code}'
+            )
+        # Else, this code is hopefully valid.
+        #
+        # If this code is *NOT* explicitly prefixed by "(" and suffixed by
+        # ")", do so to ensure this code remains safely evaluable when
+        # embedded in parent expressions.
+        elif not (
+            is_valid_code[ 0] == '(' and
+            is_valid_code[-1] == ')'
+        ):
+            is_valid_code = f'({is_valid_code})'
+        # Else, this code is explicitly prefixed by "(" and suffixed by ")".
+
+        # If this dictionary of code locals is *NOT* a dictionary, raise an
+        # exception.
+        if not isinstance(is_valid_code_locals, dict):
+            raise BeartypeValeSubscriptionException(
+                f'Validator locals '
+                f'{represent_object(is_valid_code_locals)} not dictionary.'
+            )
+        # Else, this dictionary of code locals is a dictionary.
+
+        # Classify this validator, effectively binding this callable to this
+        # object as an object-specific static method.
+        self._is_valid = is_valid
+
+        # Classify this representer via a writeable property internally
+        # validating this representer. (Embrace the magical, people.)
+        self.get_repr = get_repr
+
+        # Classify all remaining parameters.
+        self._is_valid_code = is_valid_code
+        self._is_valid_code_locals = is_valid_code_locals
+
+    # ..................{ PROPERTIES ~ read-only             }..................
+    # Properties with no corresponding setter and thus read-only.
+
+    @property
+    def is_valid(self) -> BeartypeValidatorTester:
+        '''
+        **Validator callable** (i.e., caller-defined callable accepting a
+        single arbitrary object and returning either ``True`` if that object
+        satisfies an arbitrary constraint *or* ``False`` otherwise).
+        '''
+
+        return self._is_valid
+
+    # ..................{ PROPERTIES ~ writeable             }..................
+    # Properties with a corresponding setter and thus writeable.
+
+    @property
+    def get_repr(self) -> BeartypeValidatorRepresenter:
+        '''
+        **Representer** (i.e., either a string *or* caller-defined callable
+        accepting no arguments returning a machine-readable representation of
+        this validator). See the :data:`BeartypeValidatorRepresenter` type hint
+        for further details.
+        '''
+
+        return self._get_repr
+
+
+    @get_repr.setter
+    def get_repr(self, get_repr: BeartypeValidatorRepresenter) -> None:
+        '''
+        Override the initial representer for this validator.
+
+        Parameters
+        ----------
+        get_repr : BeartypeValidatorRepresenter
+            **Representer** (i.e., either a string *or* caller-defined callable
+            accepting no arguments returning a machine-readable representation
+            of this validator). See the :data:`BeartypeValidatorRepresenter`
+            type hint for further details.
+
+        Raises
+        ----------
+        :exc:`BeartypeValeSubscriptionException`
+            This representer is either:
+
+            * *Not* callable.
+            * A C-based rather than pure-Python callable.
+            * A pure-Python callable accepting one or more arguments.
+        '''
+
+        # If this representer is a string...
+        if isinstance(get_repr, str):
+            # If this string is empty, raise an exception.
+            if not get_repr:
+                raise BeartypeValeSubscriptionException(
+                    'Representer string empty.')
+        # Else, this representer is *NOT* a string.
+        #
+        # If this representer is *NOT* a pure-Python callable accepting one
+        # argument, raise an exception.
+        elif not is_func_argless(
+            func=get_repr, exception_cls=BeartypeValeSubscriptionException):
+            raise BeartypeValeSubscriptionException(
+                f'Representer {repr(get_repr)} neither string nor '
+                f'argumentless pure-Python callable.'
+            )
+        # Else, this representer is an argumentless pure-Python callable.
+
+        # Set this representer.
+        self._get_repr = get_repr
+
+    # ..................{ DUNDERS ~ str                      }..................
+    def __repr__(self) -> str:
+        '''
+        Machine-readable representation of this validator.
+
+        This function is memoized for efficiency.
+
+        Warns
+        ----------
+        BeartypeValeLambdaWarning
+            If this validator is implemented as a pure-Python lambda function
+            whose definition is *not* parsable from the script or module
+            defining that lambda.
+        '''
+
+        # If the instance variable underlying this dunder method is a callable,
+        # reduce this variable to the string returned by this callable.
+        if callable(self._get_repr):
+            self._get_repr = self._get_repr()
+
+        # In either case, this variable is now a string. Guarantee this.
+        assert isinstance(self._get_repr, str), f'{self._get_repr} not string.'
+
+        # Return this string as is.
+        return self._get_repr
+
+    # ..................{ GETTERS                            }..................
+    def get_diagnosis(
+        self,
+        *,
+
+        # Mandatory keyword-only parameters.
+        obj: object,
+        indent_level_outer: str,
+        indent_level_inner: str,
+
+        # Optional keyword-only parameters.
+        is_shortcircuited: bool = False,
+    ) -> str:
+        '''
+        Human-readable **validation failure diagnosis** (i.e., substring
+        describing how the passed object either satisfies *or* violates this
+        validator).
+
+        This method is typically called by high-level error-handling logic to
+        unambiguously describe the failure of an arbitrary object to satisfy an
+        arbitrary validator. Since this validator may be synthesized from one
+        or more lower-level validators (e.g., via the :meth:`__and__`,
+        :meth:`__or__`, and :meth:`__invert__` dunder methods), the simple
+        machine-readable representation of this validator does *not* adequately
+        describe how exactly the passed object satisfies or fails to satisfy
+        this validator. Only an exhaustive description suffices.
+
+        Parameters
+        ----------
+        obj : object
+            Arbitrary object to be diagnosed against this validator.
+        indent_level_outer : str
+            **Outermost indentation level** (i.e., zero or more adjacent spaces
+            prefixing each line of the returned substring).
+        indent_level_inner : str
+            **Innermost indentation level** (i.e., zero or more adjacent spaces
+            delimiting the human-readable representation of the tri-state
+            boolean and validator representation in the returned substring).
+        is_shortcircuited : bool, optional
+            ``True`` only if this validator has been **short-circuited** (i.e.,
+            *not* required to be tested against) by a previously tested sibling
+            validator, in which case this method will silently catch and reduce
+            exceptions raised by the :meth:`is_valid` method to ``False``.
+
+            Short-circuiting typically arises from binary validators (e.g.,
+            :class:`beartype.vale._core._valecore.BeartypeValidatorConjunction`)
+            in which a low-level sibling validator, previously tested against by
+            the higher-level binary validator encapsulating both this validator
+            and that sibling validator, has already either fully satisfied *or*
+            failed to satisfy that binary validator; a binary validator
+            explicitly sets this parameter to ``True`` for *all* children
+            validators except the first child validator when the first child
+            validator either fully satisfies *or* fails to satisfy that binary
+            validator.
+
+            This is *not* merely an optimization; this is a design requirement.
+            External users often chain validators together with set operators
+            (e.g., ``&``, ``|``) under the standard expectation of
+            short-circuiting, in which later validators are *not* tested when
+            earlier validators already satisfy requirements. Violating this
+            expectation causes later validators to trivially raise exceptions.
+
+            Without short-circuiting, the otherwise valid following example
+            raises a non-human-readable exception. The short-circuited
+            ``IsArrayMatrix`` validator expects to be tested *only* when the
+            preceding non-short-circuited ``IsArray2D`` validator fails:
+
+            .. code-block:: python
+
+               >>> import numpy as np
+               >>> from beartype.vale import Is
+               >>> IsArray2D = Is[lambda arr: arr.ndim == 2]
+               >>> IsArrayMatrix = Is[lambda arr: arr.shape[0] == arr.shape[1]]
+               >>> IsArray2DMatrix = IsArray2D & IsArrayMatrix
+               >>> IsArray2DMatrix.get_diagnosis(
+               ...     obj=np.zeros((4,)),
+               ...     indent_level_outer='',
+               ...     indent_level_inner='    ',
+               ... )
+               Traceback (most recent call last):
+                 File "/home/leycec/tmp/mopy.py", line 10, in <module>
+                   print(IsArray2DMatrix.get_diagnosis(
+                 File "/home/leycec/py/beartype/beartype/vale/_core/_valecorebinary.py", line 149, in get_diagnosis
+                   line_inner_operand_2 = self._validator_operand_2.get_diagnosis(
+                 File "/home/leycec/py/beartype/beartype/vale/_core/_valecore.py", line 480, in get_diagnosis
+                   is_obj_valid = self.is_valid(obj)
+                 File "/home/leycec/tmp/mopy.py", line 7, in <lambda>
+                   IsArrayMatrix = Is[lambda arr: arr.shape[0] == arr.shape[1]]
+               IndexError: tuple index out of range
+
+            Defaults to ``False``.
+
+        Returns
+        ----------
+        str
+            Substring diagnosing this object against this validator.
+        '''
+        assert isinstance(is_shortcircuited, bool), (
+            f'{repr(is_shortcircuited)} not boolean.')
+
+        # True only if the passed object satisfies this validator.
+        is_obj_valid = None
+
+        # If this validator has been short-circuited by a prior sibling...
+        if is_shortcircuited:
+            # Attempt to decide whether that object satisfies this validator.
+            try:
+                is_obj_valid = self.is_valid(obj)
+            # If doing so raises an exception, this short-circuited validator
+            # was *NOT* intended to be called under short-circuiting. In this
+            # case, silently ignore this exception. See the above discussion.
+            except:
+                pass
+        # Else, this validator is *NOT* short-circuited. In this case, this
+        # validator is *NOT* expected to raise exceptions. Nonetheless, if this
+        # validator does so, ensure that exception is propagated up the call
+        # stack by *NOT* silently ignoring that exception (as above).
+        else:
+            is_obj_valid = self.is_valid(obj)
+
+        # Format the validity of this object against this validator for the
+        # typical case of a lowest-level beartype validator *NOT* wrapping one
+        # or more other even lower-level beartype validators (e.g., via a set
+        # theoretic operator).
+        return format_diagnosis_line(
+            validator_repr=repr(self),
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner,
+            is_obj_valid=is_obj_valid,
+        )
+
+    # ..................{ DUNDERS ~ operator                 }..................
+    # Define a domain-specific language (DSL) enabling callers to dynamically
+    # synthesize higher-level validators from lower-level validators via
+    # overloaded set theoretic operators.
+
+    def __and__(self, other: 'BeartypeValidator') -> 'BeartypeValidator':
+        '''
+        **Conjunction** (i.e., ``self & other``), synthesizing a new
+        :class:`BeartypeValidator` object whose validator returns :data:`True`
+        only when the validators of both this *and* the passed
+        :class:`BeartypeValidator` objects all return :data:`True`.
+
+        Parameters
+        ----------
+        other : BeartypeValidator
+            Object to conjunctively synthesize with this object.
+
+        Returns
+        ----------
+        BeartypeValidator
+            New object conjunctively synthesized with this object.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If the passed object is *not* also an instance of the same class.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype.vale._core._valecorebinary import (
+            BeartypeValidatorConjunction)
+
+        # Closures for great justice.
+        return BeartypeValidatorConjunction(
+            validator_operand_1=self,
+            validator_operand_2=other,
+        )
+
+
+    def __or__(self, other: 'BeartypeValidator') -> 'BeartypeValidator':
+        '''
+        **Disjunction** (i.e., ``self | other``), synthesizing a new
+        :class:`BeartypeValidator` object whose validator returns :data:`True`
+        only when the validators of either this *or* the passed
+        :class:`BeartypeValidator` objects return :data:`True`.
+
+        Parameters
+        ----------
+        other : BeartypeValidator
+            Object to disjunctively synthesize with this object.
+
+        Returns
+        ----------
+        BeartypeValidator
+            New object disjunctively synthesized with this object.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype.vale._core._valecorebinary import (
+            BeartypeValidatorDisjunction)
+
+        # Closures for great justice.
+        return BeartypeValidatorDisjunction(
+            validator_operand_1=self,
+            validator_operand_2=other,
+        )
+
+
+    #FIXME: Fun optimization: if inverting something that's already been
+    #inverted, return the original "BeartypeValidator" object sans inversion.
+    def __invert__(self) -> 'BeartypeValidator':
+        '''
+        **Negation** (i.e., ``~self``), synthesizing a new
+        :class:`BeartypeValidator` object whose validator returns :data:`True`
+        only when the validators of this :class:`BeartypeValidator` object
+        returns :data:`False`.
+
+        Returns
+        ----------
+        BeartypeValidator
+            New object negating this object.
+        '''
+
+        # Avoid circular import dependencies.
+        from beartype.vale._core._valecoreunary import (
+            BeartypeValidatorNegation)
+
+        # Closures for profound lore.
+        return BeartypeValidatorNegation(validator_operand=self)
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_core/_valecorebinary.py
@@ -0,0 +1,395 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Core unary beartype validators** (i.e., :class:`BeartypeValidator` subclasses
+implementing binary operations on pairs of lower-level beartype validators).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from abc import ABCMeta, abstractmethod
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype.vale._util._valeutiltext import format_diagnosis_line
+from beartype._util.kind.map.utilmapset import merge_mappings_two
+from beartype._data.code.datacodeindent import CODE_INDENT_1
+from beartype._util.text.utiltextrepr import represent_object
+
+# ....................{ SUPERCLASSES                       }....................
+class BeartypeValidatorBinaryABC(BeartypeValidator, metaclass=ABCMeta):
+    '''
+    Abstract base class of all **beartype binary validator** (i.e., validator
+    modifying the boolean truthiness returned by the validation performed by a
+    pair of lower-level beartype validators) subclasses.
+
+    Attributes
+    ----------
+    _validator_operand_1 : BeartypeValidator
+        First lower-level validator operated upon by this higher-level
+        validator.
+    _validator_operand_2 : BeartypeValidator
+        Second lower-level validator operated upon by this higher-level
+        validator.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats our purposes.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_validator_operand_1',
+        '_validator_operand_2',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+        validator_operand_1: BeartypeValidator,
+        validator_operand_2: BeartypeValidator,
+        **kwargs
+    ) -> None:
+        '''
+        Initialize this higher-level validator from the passed validators.
+
+        Parameters
+        ----------
+        validator_operand_1 : BeartypeValidator
+            First validator operated upon by this higher-level validator.
+        validator_operand_2 : BeartypeValidator
+            Second validator operated upon by this higher-level validator.
+
+        All remaining parameters are passed as is to the superclass
+        :meth:`BeartypeValidator.__init__` method.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If either of these operands are *not* beartype validators.
+        '''
+
+        # Locals safely merging the locals required by the code provided by
+        # both validators.
+        is_valid_code_locals = merge_mappings_two(
+            validator_operand_1._is_valid_code_locals,
+            validator_operand_2._is_valid_code_locals,
+        )
+
+        # Callable accepting no arguments returning a machine-readable
+        # representation of this binary validator.
+        get_repr = lambda: (
+            f'{repr(validator_operand_1)} {self._operator_symbol} '
+            f'{repr(validator_operand_2)}'
+        )
+
+        # Initialize our superclass with all remaining parameters.
+        super().__init__(
+            is_valid_code_locals=is_valid_code_locals,  # type: ignore[arg-type]
+            get_repr=get_repr,
+            **kwargs
+        )
+
+        # Classify all remaining parameters.
+        self._validator_operand_1 = validator_operand_1
+        self._validator_operand_2 = validator_operand_2
+
+    # ..................{ GETTERS                            }..................
+    #FIXME: Unit test us up, please.
+    #FIXME: Overly verbose for conjunctions involving three or more
+    #beartype validators. Contemplate compaction schemes, please. Specifically,
+    #we need to detect this condition here and then compact based on that:
+    #    # If either of these validators are themselves conjunctions...
+    #    if isinstance(self._validator_operand_1, BeartypeValidatorConjunction):
+    #       ...
+    #    if isinstance(self._validator_operand_2, BeartypeValidatorConjunction):
+    #       ...
+    def get_diagnosis(
+        self,
+        *,
+
+        # Mandatory keyword-only parameters.
+        obj: object,
+        indent_level_outer: str,
+        indent_level_inner: str,
+
+        # Optional keyword-only parameters.
+        is_shortcircuited: bool = False,
+    ) -> str:
+
+        # Innermost indentation level indented one level deeper than the passed
+        # innermost indentation level.
+        indent_level_inner_nested = indent_level_inner + CODE_INDENT_1
+
+        # Line diagnosing this object against this parent conjunction.
+        line_outer_prefix = format_diagnosis_line(
+            validator_repr='(',
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner,
+            is_obj_valid=self.is_valid(obj),
+        )
+
+        # Line diagnosing this object against this first child validator, with
+        # an increased indentation level for readability.
+        line_inner_operand_1 = self._validator_operand_1.get_diagnosis(
+            obj=obj,
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner_nested,
+            is_shortcircuited=is_shortcircuited,
+        )
+
+        # If this binary validator has *NOT* already been short-circuited,
+        # decide whether this first child validator short-circuits this second
+        # child validator with respect to the passed object.
+        if not is_shortcircuited:
+            is_shortcircuited = self._is_shortcircuited(obj)
+        # Else, this binary validator has already been short-circuited (e.g.,
+        # due to being embedded in a higher-level parent validator that was
+        # short-circuited with respect to the passed object). In this case,
+        # preserve this short-circuiting as is.
+
+        # Line diagnosing this object against this second child validator, with
+        # an increased indentation level for readability.
+        line_inner_operand_2 = self._validator_operand_2.get_diagnosis(
+            obj=obj,
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner_nested,
+            is_shortcircuited=is_shortcircuited,
+        )
+
+        # Line providing the suffixing ")" delimiter for readability.
+        line_outer_suffix = format_diagnosis_line(
+            validator_repr=')',
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner,
+        )
+
+        # Return these lines concatenated.
+        return (
+            f'{line_outer_prefix}\n'
+            f'{line_inner_operand_1} {self._operator_symbol}\n'
+            f'{line_inner_operand_2}\n'
+            f'{line_outer_suffix}'
+        )
+
+    # ..................{ ABSTRACT                           }..................
+    # Abstract methods required to be concretely implemented by subclasses.
+
+    @property
+    @abstractmethod
+    def _operator_symbol(self) -> str:
+        '''
+        Human-readable string embodying the operation performed by this binary
+        validator - typically the single-character mathematical sign
+        symbolizing this operation.
+        '''
+
+        pass
+
+
+    @abstractmethod
+    def _is_shortcircuited(self, obj: object) -> bool:
+        '''
+        ``True`` only if the first child validator short-circuits the second
+        child validator underlying this parent validator with respect to the
+        passed object.
+
+        In this context, "short-circuits" is in the boolean evaluation sense.
+        Specifically, short-circuiting:
+
+        * Occurs when the first child validator either fully satisfies or
+          violates this parent validator with respect to the passed object.
+        * Implies the second child validator to be safely ignorable with
+          respect to the passed object.
+
+        Parameters
+        ----------
+        obj : object
+            Arbitrary object to be diagnosed against this validator.
+
+        Returns
+        ----------
+        bool
+            ``True`` only if this the passed object short-circuits the second
+            child operand validator underlying this parent binary validator.
+        '''
+
+        pass
+
+# ....................{ SUBCLASSES ~ &                     }....................
+class BeartypeValidatorConjunction(BeartypeValidatorBinaryABC):
+    '''
+    **Beartype conjunction validator** (i.e., validator conjunctively
+    evaluating the boolean truthiness returned by the validation performed by a
+    pair of lower-level beartype validators, typically instantiated and
+    returned by the :meth:`BeartypeValidator.__and__` dunder method of the
+    first validator passed the second).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+        validator_operand_1: BeartypeValidator,
+        validator_operand_2: BeartypeValidator,
+    ) -> None:
+        '''
+        Initialize this higher-level validator from the passed validators.
+
+        Parameters
+        ----------
+        validator_operand_1 : BeartypeValidator
+            First validator operated upon by this higher-level validator.
+        validator_operand_2 : BeartypeValidator
+            Second validator operated upon by this higher-level validator.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If either of these operands are *not* beartype validators.
+        '''
+
+        # Validate the passed operands as sane.
+        _validate_operands(self, validator_operand_1, validator_operand_2)
+
+        # Initialize our superclass with all remaining parameters.
+        super().__init__(
+            validator_operand_1=validator_operand_1,
+            validator_operand_2=validator_operand_2,
+            # Lambda function conjunctively performing both validations.
+            is_valid=lambda obj: (
+                validator_operand_1.is_valid(obj) and
+                validator_operand_2.is_valid(obj)
+            ),
+            # Code expression conjunctively performing both validations.
+            is_valid_code=(
+                f'({validator_operand_1._is_valid_code} and '
+                f'{validator_operand_2._is_valid_code})'
+            ),
+        )
+
+    # ..................{ PROPERTIES                         }..................
+    @property
+    def _operator_symbol(self) -> str:
+        return '&'
+
+
+    def _is_shortcircuited(self, obj: object) -> bool:
+
+        # Return true only if the passed object violates this first child
+        # validator. Why? Because if this first child validator is violated,
+        # then this parent validator as a whole is violated; no further
+        # validation of this second child validator is required.
+        return not self._validator_operand_1.is_valid(obj)
+
+# ....................{ SUBCLASSES ~ |                     }....................
+class BeartypeValidatorDisjunction(BeartypeValidatorBinaryABC):
+    '''
+    **Beartype disjunction validator** (i.e., validator disjunctively
+    evaluating the boolean truthiness returned by the validation performed by a
+    pair of lower-level beartype validators, typically instantiated and
+    returned by the :meth:`BeartypeValidator.__and__` dunder method of the
+    first validator passed the second).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+        validator_operand_1: BeartypeValidator,
+        validator_operand_2: BeartypeValidator,
+    ) -> None:
+        '''
+        Initialize this higher-level validator from the passed validators.
+
+        Parameters
+        ----------
+        validator_operand_1 : BeartypeValidator
+            First validator operated upon by this higher-level validator.
+        validator_operand_2 : BeartypeValidator
+            Second validator operated upon by this higher-level validator.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If either of these operands are *not* beartype validators.
+        '''
+
+        # Validate the passed operands as sane.
+        _validate_operands(self, validator_operand_1, validator_operand_2)
+
+        # Initialize our superclass with all remaining parameters.
+        super().__init__(
+            validator_operand_1=validator_operand_1,
+            validator_operand_2=validator_operand_2,
+            # Lambda function disjunctively performing both validations.
+            is_valid=lambda obj: (
+                validator_operand_1.is_valid(obj) or
+                validator_operand_2.is_valid(obj)
+            ),
+            # Code expression disjunctively performing both validations.
+            is_valid_code=(
+                f'({validator_operand_1._is_valid_code} or '
+                f'{validator_operand_2._is_valid_code})'
+            ),
+        )
+
+    # ..................{ PROPERTIES                         }..................
+    @property
+    def _operator_symbol(self) -> str:
+        return '|'
+
+
+    def _is_shortcircuited(self, obj: object) -> bool:
+
+        # Return true only if the passed object satisfies this first child
+        # validator. Why? Because if this first child validator is satisfied,
+        # then this parent validator as a whole is satisfied; no further
+        # validation of this second child validator is required.
+        return self._validator_operand_1.is_valid(obj)
+
+# ....................{ PRIVATE ~ validators               }....................
+def _validate_operands(
+    self: BeartypeValidatorBinaryABC,
+    validator_operand_1: BeartypeValidator,
+    validator_operand_2: BeartypeValidator,
+) -> None:
+    '''
+    Validate the passed validator operands as sane.
+
+    Parameters
+    ----------
+    self : BeartypeValidatorBinaryABC
+        Beartype binary validator operating upon these operands.
+    validator_operand_1 : BeartypeValidator
+        First validator operated upon by this higher-level validator.
+    validator_operand_2 : BeartypeValidator
+        Second validator operated upon by this higher-level validator.
+
+    Raises
+    ----------
+    BeartypeValeSubscriptionException
+        If either of these operands are *not* beartype validators.
+    '''
+
+    # If either of these operands are *NOT* beartype validators, raise an
+    # exception.
+    if not isinstance(validator_operand_1, BeartypeValidator):
+        raise BeartypeValeSubscriptionException(
+            f'Beartype "{self._operator_symbol}" validator first operand '
+            f'{represent_object(validator_operand_1)} not beartype '
+            f'validator (i.e., "beartype.vale.Is*[...]" object).'
+        )
+    elif not isinstance(validator_operand_2, BeartypeValidator):
+        raise BeartypeValeSubscriptionException(
+            f'Beartype "{self._operator_symbol}" validator second operand '
+            f'{represent_object(validator_operand_2)} not beartype '
+            f'validator (i.e., "beartype.vale.Is*[...]" object).'
+        )
+    # Else, both of these operands are beartype validators.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_core/_valecoreunary.py
@@ -0,0 +1,213 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Core unary beartype validators** (i.e., :class:`BeartypeValidator` subclasses
+implementing unary operations on a single lower-level beartype validator).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from abc import (
+    ABCMeta,
+    abstractmethod,
+)
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype.vale._util._valeutiltext import format_diagnosis_line
+from beartype._data.code.datacodeindent import CODE_INDENT_1
+from beartype._util.text.utiltextrepr import represent_object
+
+# ....................{ SUPERCLASSES                       }....................
+class BeartypeValidatorUnaryABC(BeartypeValidator, metaclass=ABCMeta):
+    '''
+    Abstract base class of all **beartype binary validator** (i.e., validator
+    modifying the boolean truthiness returned by the validation performed by a
+    single lower-level beartype validator) subclasses.
+
+    Attributes
+    ----------
+    _validator_operand : BeartypeValidator
+        Lower-level validator operated upon by this higher-level validator.
+    '''
+
+    # ..................{ CLASS VARIABLES                    }..................
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # CAUTION: Subclasses declaring uniquely subclass-specific instance
+    # variables *MUST* additionally slot those variables. Subclasses violating
+    # this constraint will be usable but unslotted, which defeats our purposes.
+    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # Slot all instance variables defined on this object to minimize the time
+    # complexity of both reading and writing variables across frequently called
+    # cache dunder methods. Slotting has been shown to reduce read and write
+    # costs by approximately ~10%, which is non-trivial.
+    __slots__ = (
+        '_validator_operand',
+    )
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(
+        self,
+        validator_operand: BeartypeValidator,
+        **kwargs
+    ) -> None:
+        '''
+        Initialize this validator from the passed metadata.
+
+        Parameters
+        ----------
+        validator_operand : BeartypeValidator
+            Lower-level validator operated upon by this higher-level validator.
+
+        Raises
+        ------
+        BeartypeValeSubscriptionException
+            If this operand is *not* itself a beartype validator.
+        '''
+
+        # Callable accepting no arguments returning a machine-readable
+        # representation of this binary validator.
+        get_repr = lambda: (
+            f'{self._operator_symbol}{repr(validator_operand)}')
+
+        # Initialize our superclass with all remaining parameters.
+        super().__init__(
+            is_valid_code_locals=validator_operand._is_valid_code_locals,
+            get_repr=get_repr,
+            **kwargs
+        )
+
+        # Classify all remaining passed parameters.
+        self._validator_operand = validator_operand
+
+    # ..................{ GETTERS                            }..................
+    #FIXME: Unit test us up, please.
+    def get_diagnosis(
+        self,
+        *,
+
+        # Mandatory keyword-only parameters.
+        obj: object,
+        indent_level_outer: str,
+        indent_level_inner: str,
+        **kwargs
+    ) -> str:
+
+        # Line diagnosing this object against this negated parent validator.
+        line_outer_prefix = format_diagnosis_line(
+            validator_repr='(',
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner,
+            is_obj_valid=self.is_valid(obj),
+        )
+
+        # Line diagnosing this object against this non-negated child validator
+        # with an increased indentation level for readability.
+        line_inner_operand = self._validator_operand.get_diagnosis(
+            obj=obj,
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner + CODE_INDENT_1,
+            **kwargs
+        )
+
+        # Line providing the suffixing ")" delimiter for readability.
+        line_outer_suffix = format_diagnosis_line(
+            validator_repr=')',
+            indent_level_outer=indent_level_outer,
+            indent_level_inner=indent_level_inner,
+        )
+
+        # Return these lines concatenated.
+        return (
+            f'{self._operator_symbol}{line_outer_prefix}\n'
+            f'{line_inner_operand}\n'
+            f'{line_outer_suffix}'
+        )
+
+    # ..................{ ABSTRACT                           }..................
+    # Abstract methods required to be concretely implemented by subclasses.
+
+    @property
+    @abstractmethod
+    def _operator_symbol(self) -> str:
+        '''
+        Human-readable string embodying the operation performed by this unary
+        validator - typically the single-character mathematical sign
+        symbolizing this operation.
+        '''
+
+        pass
+
+# ....................{ SUBCLASSES                         }....................
+class BeartypeValidatorNegation(BeartypeValidatorUnaryABC):
+    '''
+    **Negation beartype validator** (i.e., validator negating the boolean
+    truthiness returned by the validation performed by a lower-level beartype
+    validator, typically instantiated and returned by the
+    :meth:`BeartypeValidator.__invert__` dunder method of that validator).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, validator_operand: BeartypeValidator) -> None:
+        '''
+        Initialize this higher-level validator from the passed validator.
+
+        Parameters
+        ----------
+        validator_operand : BeartypeValidator
+            Validator operated upon by this higher-level validator.
+
+        Raises
+        ------
+        BeartypeValeSubscriptionException
+            If this operand is *not* a beartype validator.
+        '''
+
+        # Validate the passed operand as sane.
+        _validate_operand(self, validator_operand)
+
+        # Initialize our superclass with all remaining parameters.
+        super().__init__(
+            validator_operand=validator_operand,
+            is_valid=lambda obj: not validator_operand.is_valid(obj),
+            is_valid_code=f'(not {validator_operand._is_valid_code})',
+        )
+
+    # ..................{ PROPERTIES                         }..................
+    @property
+    def _operator_symbol(self) -> str:
+        return '~'
+
+# ....................{ PRIVATE ~ validators               }....................
+def _validate_operand(
+    self: BeartypeValidatorUnaryABC,
+    validator_operand: BeartypeValidator,
+) -> None:
+    '''
+    Validate the passed validator operand as sane.
+
+    Parameters
+    ----------
+    self : BeartypeValidatorUnaryABC
+        Beartype unary validator operating upon this operand.
+    validator_operand : BeartypeValidator
+        Validator operated upon by this higher-level validator.
+
+    Raises
+    ------
+    BeartypeValeSubscriptionException
+        If this operand is *not* a beartype validator.
+    '''
+
+    #FIXME: Unit test us up, please.
+    # If this operand is *NOT* a beartype validator, raise an exception.
+    if not isinstance(validator_operand, BeartypeValidator):
+        raise BeartypeValeSubscriptionException(
+            f'Beartype "{self._operator_symbol}" validator operand '
+            f'{represent_object(validator_operand)} not beartype '
+            f'validator (i.e., "beartype.vale.Is*[...]" object).'
+        )
+    # Else, this operand is a beartype validator.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_is/_valeis.py
@@ -0,0 +1,571 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **functional validation classes** (i.e., :mod:`beartype`-specific
+classes enabling callers to define PEP-compliant validators from arbitrary
+caller-defined callables *not* efficiently generating stack-free code).
+
+This private submodule defines the core low-level class hierarchy driving the
+entire :mod:`beartype` validation ecosystem.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import (
+    BeartypeValeLambdaWarning,
+    BeartypeValeValidationException,
+)
+from beartype.typing import Protocol
+from beartype.vale._is._valeisabc import _BeartypeValidatorFactoryABC
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype.vale._util._valeutilfunc import die_unless_validator_tester
+from beartype.vale._util._valeutiltyping import BeartypeValidatorTester
+from beartype._data.hint.datahinttyping import LexicalScope
+from beartype._util.func.utilfuncscope import add_func_scope_attr
+from beartype._util.text.utiltextrepr import (
+    represent_func,
+    represent_object,
+)
+
+# ....................{ PRIVATE ~ protocols                }....................
+class _SupportsBool(Protocol):
+    '''
+    Fast caching protocol matching any object whose class defines the
+    :meth:`__bool__` dunder method.
+    '''
+
+    def __bool__(self) -> bool: ...
+
+
+class _SupportsLen(Protocol):
+    '''
+    Fast caching protocol matching any object whose class defines the
+    :meth:`__len__` dunder method.
+    '''
+
+    def __len__(self) -> bool: ...
+
+
+_BoolLike = (_SupportsBool, _SupportsLen)
+'''
+:func:`isinstance`-able tuple of fast caching protocols matching any
+**bool-like** (i.e., object whose class defines at least one of the
+:meth:`__bool__` and/or :meth:`__len__` dunder methods).
+'''
+
+# ....................{ PRIVATE ~ subclasses               }....................
+class _IsFactory(_BeartypeValidatorFactoryABC):
+    '''
+    **Beartype callable validator factory** (i.e., class that, when subscripted
+    (indexed) by an arbitrary callable returning :data:`True` when the object
+    passed to that callable satisfies a caller-defined constraint, creates a
+    new :class:`.BeartypeValidator` object encapsulating that callable suitable
+    for subscripting (indexing) :obj:`typing.Annotated` type hints, enforcing
+    that constraint on :mod:`beartype`-decorated callable parameters and
+    returns annotated by those hints).
+
+    This class validates that callable parameters and returns satisfy the
+    arbitrary **callable validator** (i.e., callable whose signature satisfies
+    ``collections.abc.Callable[[typing.Any], bool]``) subscripting (indexing)
+    this class. Callable validators are caller-defined and may thus validate
+    the internal integrity, consistency, and structure of arbitrary objects
+    ranging from simple builtin scalars like integers and strings to complex
+    data structures defined by third-party packages like NumPy arrays and
+    Pandas DataFrames.
+
+    This class creates one new :class:`.BeartypeValidator` object for each
+    callable validator subscripting (indexing) this class. These objects:
+
+    * Are **PEP-compliant** and thus guaranteed to *never* violate existing or
+      future standards.
+    * Are **Safely ignorable** by *all* static and runtime type checkers other
+      than :mod:`beartype` itself.
+    * **Less efficient** than :class:`BeartypeValidator` objects created by
+      subscripting every other :mod:`beartype.vale` class. Specifically:
+
+      * Every :class:`.BeartypeValidator` object created by subscripting this
+        class necessarily calls a callable validator and thus incurs at least
+        one additional call stack frame per :mod:`beartype`-decorated callable
+        call.
+      * Every :class:`.BeartypeValidator` object created by subscripting every
+        other :mod:`beartype.vale` class directly calls *no* callable and thus
+        incurs additional call stack frames only when the active Python
+        interpreter internally calls dunder methods (e.g., ``__eq__()``) to
+        satisfy their validation constraint.
+
+    Usage
+    -----
+    Any :mod:`beartype`-decorated callable parameter or return annotated by a
+    :obj:`typing.Annotated` type hint subscripted (indexed) by this class
+    subscripted (indexed) by a callable validator (e.g.,
+    ``typing.Annotated[{cls}, beartype.vale.Is[lambda obj: {expr}]]`` for any
+    class ``{cls}``  and Python expression ``{expr}`` evaluating to a boolean)
+    validates that parameter or return value to be an instance of that class
+    satisfying that callable validator.
+
+    Specifically, callers are expected to (in order):
+
+    #. Annotate a callable parameter or return to be validated with a
+       :pep:`593`-compliant :obj:`typing.Annotated` type hint.
+    #. Subscript that hint with (in order):
+
+       #. The type expected by that parameter or return.
+       #. One or more subscriptions (indexations) of this class, each itself
+          subscripted (indexed) by a **callable validator** (i.e., callable
+          accepting a single arbitrary object and returning either :data:`True`
+          if that object satisfies an arbitrary constraint *or* :data:`False`
+          otherwise). If that hint is subscripted by:
+
+          * Only one subscription of this class, that parameter or return
+            satisfies that hint when both:
+
+            * That parameter or return is an instance of the expected type.
+            * That validator returns :data:`True` when passed that parameter or
+              return.
+
+          * Two or more subscriptions of this class, that parameter or return
+            satisfies that hint when both:
+
+            * That parameter or return is an instance of the expected type.
+            * *All* callable validators subscripting *all* subscriptions of
+              this class return :data:`True` when passed that parameter or
+              return.
+
+          Formally, the signature of each callable validator *must* resemble:
+
+          .. code-block:: python
+
+             def is_object_valid(obj) -> bool:
+                 return bool(obj)
+
+          Equivalently, each callable validator *must* satisfy the type hint
+          ``collections.abc.Callable[[typing.Any,], bool]``. If not the case,
+          an exception is raised. Note that:
+
+          * If that parameter or return is *not* an instance of the expected
+            type, **no callable validator is called.** Equivalently, each
+            callable validator is called *only* when that parameter or return
+            is already an instance of the expected type. Callable validators
+            need *not* revalidate that type (e.g., by passing that parameter or
+            return and type to the :func:`isinstance` builtin).
+          * The name of each callable validator is irrelevant. For convenience,
+            most callable validators are defined as nameless lambda functions.
+
+    For example, the following type hint only accepts non-empty strings:
+
+    .. code-block:: python
+
+       Annotated[str, Is[lambda text: bool(text)]]
+
+    :class:`.BeartypeValidator` objects also support an expressive
+    domain-specific language (DSL) enabling callers to trivially synthesize new
+    objects from existing objects with standard Pythonic math operators:
+
+    * **Negation** (i.e., ``not``). Negating an :class:`.BeartypeValidator`
+      object with the ``~`` operator synthesizes a new
+      :class:`.BeartypeValidator` object whose validator returns :data:`True`
+      only when the validator of the original object returns :data:`False`. For
+      example, the following type hint only accepts strings containing *no*
+      periods:
+
+      .. code-block:: python
+
+         Annotated[str, ~Is[lambda text: '.' in text]]
+
+    * **Conjunction** (i.e., ``and``). Conjunctively combining two or more
+      :class:`.BeartypeValidator` objects with the ``&`` operator synthesizes a
+      new :class:`.BeartypeValidator` object whose validator returns
+      :data:`True` only when all data validators of the original objects return
+      :data:`True`. For example, the following type hint only accepts non-empty
+      strings containing *no* periods:
+
+      .. code-block:: python
+
+         Annotated[str, (
+              Is[lambda text: bool(text)] &
+             ~Is[lambda text: '.' in text]
+         )]
+
+    * **Disjunction** (i.e., ``or``). Disjunctively combining two or more
+      :class:`.BeartypeValidator` objects with the ``|`` operator synthesizes a
+      new :class:`.BeartypeValidator` object whose validator returns
+      :data:`True` only when at least one validator of the original objects
+      returns :data:`True`. For example, the following type hint accepts both
+      empty strings *and* non-empty strings containing at least one period:
+
+      .. code-block:: python
+
+         Annotated[str, (
+             ~Is[lambda text: bool(text)] |
+              Is[lambda text: '.' in text]
+         )]
+
+    See also the **Examples** subsection below.
+
+    Caveats
+    -------
+    **This class is currently only supported by the** :func:`beartype.beartype`
+    **decorator.** All other static and runtime type checkers silently ignore
+    subscriptions of this class subscripting :obj:`typing.Annotated` type
+    hints.
+
+    **This class incurs a minor time performance penalty at call time.**
+    Specifically, each type hint of a :mod:`beartype`-decorated callable
+    subscripted by a subscription of this class adds one additional stack frame
+    to each call of that callable. While negligible (in the average case), this
+    cost can become non-negligible when compounded across multiple type hints
+    annotating a frequently called :mod:`beartype`-decorated callable --
+    especially when those type hints are subscripted by multiple subscriptions
+    of this class at different nesting levels.
+
+    **This class prohibits instantiation.** This class is *only* intended to be
+    subscripted. Attempting to instantiate this class into an object will raise
+    an :exc:`.BeartypeValeSubscriptionException` exception.
+
+    Examples
+    --------
+    .. code-block:: python
+
+       # Import the requisite machinery.
+       >>> from beartype import beartype
+       >>> from beartype.vale import Is
+       >>> from typing import Annotated
+
+       # Validator matching only strings with lengths ranging [4, 40].
+       >>> IsRangy = Is[lambda text: 4 <= len(text) <= 40]
+
+       # Validator matching only unquoted strings.
+       >>> IsUnquoted = Is[lambda text:
+       ...     text.count('"') < 2 and text.count("'") < 2]
+
+       # Type hint matching only unquoted strings.
+       >>> UnquotedString = Annotated[str, IsUnquoted]
+
+       # Type hint matching only quoted strings.
+       >>> QuotedString = Annotated[str, ~IsUnquoted]
+
+       # Type hint matching only unquoted strings with lengths ranging [4, 40].
+       >>> UnquotedRangyString = Annotated[str, IsUnquoted & IsRangy]
+
+       # Annotate callables by those type hints.
+       >>> @beartype
+       ... def doublequote_text(text: UnquotedString) -> QuotedString:
+       ...     """
+       ...     Double-quote the passed unquoted string.
+       ...     """
+       ...     return f'"{text}"'  # The best things in life are one-liners.
+       >>> @beartype
+       ... def singlequote_prefix(text: UnquotedRangyString) -> QuotedString:
+       ...     """
+       ...     Single-quote the prefix spanning characters ``[0, 3]`` of the
+       ...     passed unquoted string with length ranging ``[4, 40]``.
+       ...     """
+       ...     return f"'{text[:3]}'"  # "Guaranteed to work," says @beartype.
+
+       # Call those callables with parameters satisfying those validators.
+       >>> doublequote_text("You know anything about nuclear fusion?")
+       "You know anything about nuclear fusion?"
+       >>> singlequote_prefix("Not now, I'm too tired. Maybe later.")
+       'Not'
+
+       # Call those callables with parameters not satisfying those validators.
+       >>> doublequote_text('''"Everybody relax, I'm here."''')
+       beartype.roar._roarexc.BeartypeCallHintParamViolation: @beartyped
+       doublequote_text() parameter text='"Everybody relax, I\'m here."'
+       violates type hint typing.Annotated[str, Is[lambda text: text.count('"')
+       < 2 and text.count("'") < 2]], as value '"Everybody relax, I\'m here."'
+       violates validator Is[lambda text: text.count('"') < 2 and
+       text.count("'") < 2].
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    def __getitem__(  # type: ignore[override]
+        self, is_valid: BeartypeValidatorTester) -> BeartypeValidator:
+        '''
+        Create and return a new beartype validator from the passed **validator
+        callable** (i.e., caller-defined callable accepting a single arbitrary
+        object and returning either :data:`True` if that object satisfies an
+        arbitrary constraint *or* :data:`Falsee` otherwise), suitable for
+        subscripting :pep:`593`-compliant :obj:`typing.Annotated` type hints.
+
+        This method is intentionally *not* memoized, as this method is usually
+        subscripted only by subscription-specific lambda functions uniquely
+        defined for each subscription of this class.
+
+        Parameters
+        ----------
+        is_valid : Callable[[Any,], bool]
+            Validator callable to validate parameters and returns against.
+
+        Returns
+        -------
+        BeartypeValidator
+            New object encapsulating this validator callable.
+
+        Raises
+        ------
+        BeartypeValeSubscriptionException
+            If either:
+
+            * This class was subscripted by two or more arguments.
+            * This class was subscripted by one argument that either:
+
+              * Is *not* callable.
+              * Is a C-based rather than pure-Python callable.
+              * Is a pure-Python callable accepting two or more arguments.
+
+        See Also
+        --------
+        :class:`._IsAttrFactory`
+            Usage instructions.
+        '''
+
+        # ..................{ VALIDATE                       }..................
+        # If this class was subscripted by either no arguments *OR* two or more
+        # arguments, raise an exception.
+        self._die_unless_getitem_args_1(is_valid)
+        # Else, this class was subscripted by exactly one argument.
+
+        # If that callable is *NOT* a validator tester, raise an exception.
+        die_unless_validator_tester(is_valid)
+        # Else, that callable is a validator tester.
+
+        # Lambda function dynamically generating the machine-readable
+        # representation of this validator, deferred due to the computational
+        # expense of accurately retrieving the source code for this validator
+        # (especially when this validator is itself a lambda function).
+        get_repr = lambda: (
+            f'{self._basename}['
+            f'{represent_func(func=is_valid, warning_cls=BeartypeValeLambdaWarning)}'
+            f']'
+        )
+
+        # ..................{ CLOSURE                        }..................
+        #FIXME: Unit test edge cases extensively, please.
+        def _is_valid_bool(obj: object) -> bool:
+            '''
+            :data:`True` only if the passed object satisfies the caller-defined
+            validation callable subscripting this :attr:`beartype.vale.Is`
+            validator factory.
+
+            This closure wraps that possibly unsafe callable with an implicit
+            type cast, guaranteeing that either:
+
+            * If that callable returns a boolean, this closure returns that
+              boolean as is.
+            * If that callable returns a non-boolean object, either:
+
+              * If that non-boolean is implicitly convertible into a boolean
+                (i.e., if passing that non-boolean to the :class:`bool` type
+                succeeds *without* raising an exception), this closure coerces
+                that non-boolean into a boolean and returns that boolean.
+              * Else, this closure raises a human-readable exception.
+
+            This closure is principally intended to massage non-standard
+            validation callables defined by popular third-party packages like
+            NumPy, which commonly return non-boolean objects that are implicitly
+            convertible into boolean objects: e.g.,
+
+            .. code-block::
+
+               >>> import numpy as np
+               >>> matrix = np.array([[2, 1], [1, 2]])
+               >>> is_all = np.all(matrix > 0))
+               >>> type(is_all)
+               <class 'numpy.bool_'>
+               >>> is_all
+               True  # <-- y u lie, numpy
+               >>> bool(is_all)
+               True
+
+            Caveats
+            ----------
+            **This closure is comparatively slower than the passed callable.**
+            This closure should *never* be called directly from code snippets
+            embedded in wrapper functions dynamically generated by the
+            :func:`beartype.beartype` decorator. This closure should *only* be
+            called indirectly by exception-handling functionality performed by
+            those wrapper functions in the event of a type-checking violation,
+            at which time efficiency is no longer a driving force.
+
+            This implies that wrapper functions dynamically generated by the
+            :func:`beartype.beartype` decorator *could* implicitly coerce
+            non-boolean objects returned by the passed callable into the
+            ;data;`True` singleton. Although non-ideal, debugging such concerns
+            is squarely the user's concern; attempting to safeguard users from
+            semantic issues like this would destroy runtime performance for *no*
+            tangible gain in the general case. The best :mod:`beartype` can (and
+            should) do is defer validation until a type-checking violation.
+
+            Parameters
+            ----------
+            obj : object
+                Object to be validated by that validation callable.
+
+            Returns
+            -------
+            bool
+                :data:`True` only if that object satisfies that validation
+                callable.
+
+            Raises
+            ------
+            BeartypeValeValidationException
+                If that validation callable returns a **non-bool-like**, where
+                "non-bool-like" is any object that both:
+
+                * Is *not* a **boolean** (i.e., :class:`bool` instance).
+                * Is *not* **implicitly convertible** into a boolean (i.e., is
+                  an object whose class defines neither the :meth:`__bool__` nor
+                  :meth:`__len__` dunder methods).
+            '''
+
+            # Object returned by validating this object against that callable.
+            is_obj_valid = is_valid(obj)
+
+            # If that object is a boolean, return that object as is.
+            if isinstance(is_obj_valid, bool):
+                return is_obj_valid
+            # Else, that object is *NOT* a boolean.
+
+            # "True" *ONLY* if that object is a bool-like (i.e., object whose
+            # class defines the __bool__() and/or __len__() dunder methods).
+            #
+            # Note that we intentionally avoid the Easier to Ask for Permission
+            # than Forgiveness (EAFP) approach typically favoured by the Python
+            # community for coercing types. Namely, we avoid doing this:
+            #    # Attempt to coerce this boolean into a non-boolean.
+            #    try:
+            #        is_obj_valid_bool = bool(is_obj_valid)
+            #    except Exception as exception:
+            #        raise SomeBeartypeException(...) from exception
+            #
+            # Why? Because the bool() constructor is overly permissive to the
+            # point of being *FRANKLY BROKEN.* Why? Because that constructor
+            # *NEVER* raises an exception (unless the class of that object
+            # defines a __bool__() dunder method raising an exception). Why?
+            # Because that constructor implicitly coerces *ALL* objects whose
+            # classes define *NO* __bool__() dunder method to "True" except for
+            # the following, which the bool() constructor explicitly detects
+            # and hard-codes to be coerced to "False":
+            # * The "None" singleton.
+            # * The "False" singleton.
+            # * Numeric 0 across all numeric types, including:
+            #   * Integer 0.
+            #   * Floating-point 0.0.
+            # * Empty containers across all container types, including:
+            #   * The empty tuple singleton (i.e., "()").
+            #   * The empty string singleton (i.e., "''").
+            #   * Any empty list (e.g., "[]").
+            #
+            # The proof is in the gelatinous spaghetti code:
+            #     >>> class OhMyGods(object): pass
+            #     >>> bool(OhMyGods())
+            #     True  # <-- WHAT THE HECK IS THIS, GUIDO. SRSLY, BRO. SRSLY.
+            #
+            # This is, of course, unbelievable. This is, of course, all true.
+            # What is this, Guido? Visual Basic in my Python? *facepalm*
+            #
+            # Note also that there are several means of testing for booliness.
+            # The obvious approach of calling getattr() is also the slowest,
+            # because getattr() internally performs the EAFP approach and
+            # exception handling in Python is known to be an obvious bottleneck.
+            # Ergo, we intentionally avoid doing this:
+            #     is_obj_valid_bool_method = getattr(is_obj_valid, '__bool__', None)
+            #
+            # Ideally, we would instead defer to a beartype-specific fast
+            # caching protocol that also internally performs a similar getattr()
+            # call wrapped within caching logic that amortizes the cost of that
+            # call across all isinstance() calls passed an object of that same
+            # type. Since there exists *NO* standard "SupportsBool" protocol,
+            # we would then trivially define our own like so:
+            #     from beartype.typing import Protocol
+            #     class SupportsBool(Protocol):
+            #         def __bool__(self) -> bool: ...
+            #
+            # Surprisingly, that fails. Why? Because the bool() constructor
+            # internally coerces objects into booleans like so:
+            # * If the passed object defines the __bool__() dunder method, that
+            #   constructor defers to that method.
+            # * Else if the passed object defines the __len__() dunder method,
+            #   that constructor defers to that method.
+            # * Else if the passed object is one of several hard-coded objects
+            #   evaluating to "False", that constructor returns "False".
+            # * Else, that constructor returns "True".
+            #
+            # To handle the first two cases, we instead:
+            # * Define both our own "SupportsBool" and "SupportsLen" protocols.
+            # * Decide whether that object is bool-like by deferring to those
+            #   protocols.
+            is_obj_valid_boollike = isinstance(is_obj_valid, _BoolLike)  # pyright: ignore
+
+            # If that object is *NOT* bool-like, raise an exception.
+            if not is_obj_valid_boollike:
+                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+                # CAUTION: Synchronize with the exception raised below, please.
+                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+                raise BeartypeValeValidationException(
+                    f'Validator {get_repr()} '
+                    f'return value {repr(is_obj_valid)} not bool-like '
+                    f'(i.e., instance of neither "bool" nor '
+                    f'class defining __bool__() or __len__() dunder methods) '
+                    f'for subject object:\n{represent_object(obj)}'
+                )
+            # Else, that object is bool-like.
+
+            # Boolean coerced from this non-boolean via the __bool__() or
+            # __len__() dunder methods declared by the type of this non-boolean,
+            # initialized to "False" for safety.
+            is_obj_valid_bool = False
+
+            # Attempt to perform this coercion.
+            try:
+                is_obj_valid_bool = bool(is_obj_valid)
+            # If whichever of the __bool__() or __len__() dunder methods is
+            # called by the above bool() constructor raises an exception, wrap
+            # that exception in a higher-level @beartype exception.
+            #
+            # Note that this is *NOT* simply an uncommon edge case. In
+            # particular, the Pandas "DataFrame" type defines a __bool__()
+            # dunder method that unconditionally raises an exception. *facepalm*
+            except Exception as exception:
+                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+                # CAUTION: Synchronize with the exception raised above, please.
+                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+                raise BeartypeValeValidationException(
+                    f'Validator {get_repr()} '
+                    f'return value {repr(is_obj_valid)} erroneously bool-like '
+                    f'(i.e., instance of class defining __bool__() or __len__() '
+                    f'dunder methods raising unexpected exception) '
+                    f'for subject object:\n{represent_object(obj)}'
+                ) from exception
+
+            # Return this boolean.
+            return is_obj_valid_bool
+
+        # ..................{ VALIDATOR                      }..................
+        # Dictionary mapping from the name to value of each local attribute
+        # referenced in the "is_valid_code" snippet defined below.
+        is_valid_code_locals: LexicalScope = {}
+
+        # Name of a new parameter added to the signature of each
+        # @beartype-decorated wrapper function whose value is this validator,
+        # enabling this validator to be called directly in the body of those
+        # functions *WITHOUT* imposing additional stack frames.
+        is_valid_attr_name = add_func_scope_attr(
+            attr=_is_valid_bool, func_scope=is_valid_code_locals)
+
+        # One one-liner to rule them all and in "pdb" bind them.
+        return BeartypeValidator(
+            is_valid=_is_valid_bool,
+            # Python code snippet calling this validator (via this new
+            # parameter), passed an object to be interpolated into this snippet
+            # by downstream logic.
+            is_valid_code=f'{is_valid_attr_name}({{obj}})',
+            is_valid_code_locals=is_valid_code_locals,
+            get_repr=get_repr,
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_is/_valeisabc.py
@@ -0,0 +1,153 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype validation superclasses** (i.e., :mod:`beartype`-specific abstract
+base classes (ABCs) from all concrete beartype validation subclasses derive).
+
+This private submodule defines the core low-level class hierarchy driving the
+entire :mod:`beartype` data validation ecosystem.
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from abc import ABCMeta, abstractmethod
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.typing import Any
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype._util.text.utiltextrepr import represent_object
+
+# ....................{ METACLASSES                        }....................
+class _BeartypeValidatorFactoryABCMeta(ABCMeta):
+    '''
+    Metaclass all **beartype validator factory subclasses** (i.e.,
+    :class:`_BeartypeValidatorFactoryABC` subclasses).
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(cls, classname, superclasses, attr_name_to_value) -> None:
+        super().__init__(classname, superclasses, attr_name_to_value)
+
+        # Sanitize the fully-qualified name of the module declaring this class
+        # from the private name of the module implementing this classes to the
+        # public name of the module exporting this class, improving end user
+        # clarity and usability.
+        cls.__module__ = 'beartype.vale'
+
+# ....................{ SUPERCLASSES                       }....................
+#FIXME: Pyright appears to be extremely confused. It thinks that the
+#"_BeartypeValidatorFactoryABCMeta" metaclass is a "generic" (i.e., subclasses
+#"typing.Generic"), when in fact that metaclass merely subclasses the standard
+#"abc.ABCMeta" metaclass. Consider submitting an upstream pyright issue, please.
+class _BeartypeValidatorFactoryABC(
+    object, metaclass=_BeartypeValidatorFactoryABCMeta):  # pyright: ignore[reportGeneralTypeIssues]
+    '''
+    Abstract base class of all **beartype validator factory subclasses**
+    (i.e., subclasses that, when subscripted (indexed) by subclass-specific
+    objects, create new :class:`BeartypeValidator` objects encapsulating those
+    objects, themselves suitable for subscripting (indexing)
+    :attr:`typing.Annotated` type hints, themselves enforcing subclass-specific
+    validation constraints and contracts on :mod:`beartype`-decorated callable
+    parameters and returns annotated by those hints).
+
+    Attributes
+    ----------
+    _basename : str
+        Machine-readable basename of the public factory singleton
+        instantiating this private factory subclass (e.g., ``"IsAttr"``).
+    _getitem_exception_prefix : str
+        Human-readable substring prefixing exceptions raised by the subclass
+        implementation of the abstract :meth:__getitem__` dunder method.
+    '''
+
+    # ..................{ INITIALIZERS                       }..................
+    def __init__(self, basename: str) -> None:
+        '''
+        Initialize this subclass instance.
+
+        Parameters
+        ----------
+        basename : str
+            Machine-readable basename of the public factory singleton
+            instantiating this private factory subclass (e.g., ``"IsAttr"``).
+        '''
+        assert isinstance(basename, str), f'{repr(basename)} not string.'
+
+        # Classify all passed parameters.
+        self._basename = basename
+
+        # Initialize all remaining instance variables.
+        self._getitem_exception_prefix = (
+            f'Beartype validator factory "{self._basename}" '
+            f'subscripted by '
+        )
+
+    # ..................{ ABSTRACT ~ dunder                  }..................
+    @abstractmethod
+    def __getitem__(self, *args, **kwargs) -> BeartypeValidator:
+        '''
+        Create and return a new beartype validator validating the subclass
+        constraint parametrized by the passed arguments subscripting this
+        beartype validator factory.
+
+        Like standard type hints (e.g., :attr:`typing.Union`), instances of
+        concrete subclasses of this abstract base class (ABC) are *only*
+        intended to be subscripted (indexed).
+
+        Concrete subclasses are required to implement this abstract method.
+        Concrete subclasses are strongly recommended (but *not* required) to
+        memoize their implementations by the
+        :func:`beartype._util.cache.utilcachecall.callable_cached` decorator.
+
+        Returns
+        ----------
+        BeartypeValidator
+            Beartype validator encapsulating this validation.
+        '''
+
+        pass
+
+    # ..................{ PRIVATE ~ validator                }..................
+    #FIXME: Unit test us up, please.
+    def _die_unless_getitem_args_1(self, args: Any) -> None:
+        '''
+        Raise an exception unless this beartype validator factory was
+        subscripted (indexed) by exactly one argument.
+
+        This validator is intended to be called by concrete subclass
+        implementations of the :meth:`__getitem__` dunder method to validate
+        the arguments subscripting this beartype validator factory.
+
+        Parameters
+        ----------
+        args : Any
+            Variadic positional arguments to be inspected.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If the caller dunder method was passed either:
+
+            * No arguments.
+            * Two or more arguments.
+        '''
+
+        # If this object was subscripted by either no arguments or two or more
+        # arguments, raise an exception. Specifically...
+        if isinstance(args, tuple):
+            # If this object was subscripted by two or more arguments, raise a
+            # human-readable exception.
+            if args:
+                raise BeartypeValeSubscriptionException(
+                    f'{self._getitem_exception_prefix}two or more arguments '
+                    f'{represent_object(args)}.'
+                )
+            # Else, this object was subscripted by *NO* arguments. In this case,
+            # raise a human-readable exception.
+            else:
+                raise BeartypeValeSubscriptionException(
+                    f'{self._getitem_exception_prefix}empty tuple.')
+        # Else, this object was subscripted by exactly one argument.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_is/_valeisobj.py
@@ -0,0 +1,374 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+Beartype **declarative object validation classes** (i.e.,
+:mod:`beartype`-specific classes enabling callers to define PEP-compliant
+validators from arbitrary caller-defined objects tested via explicitly
+supported object introspectors efficiently generating stack-free code).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+# All "FIXME:" comments for this submodule reside in this package's "__init__"
+# submodule to improve maintainability and readability here.
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.typing import Any, Tuple
+from beartype.vale._is._valeisabc import _BeartypeValidatorFactoryABC
+from beartype.vale._util._valeutilsnip import (
+    VALE_CODE_CHECK_ISATTR_TEST_format,
+    VALE_CODE_CHECK_ISATTR_VALUE_EXPR_format,
+    VALE_CODE_INDENT_1,
+)
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype._data.hint.datahinttyping import LexicalScope
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.kind.map.utilmapset import update_mapping
+from beartype._util.func.utilfuncscope import add_func_scope_attr
+from beartype._util.text.utiltextrepr import represent_object
+from beartype._util.utilobject import SENTINEL
+
+# ....................{ SUBCLASSES ~ attr                  }....................
+class _IsAttrFactory(_BeartypeValidatorFactoryABC):
+    '''
+    **Beartype object attribute validator factory** (i.e., object creating and
+    returning a new beartype validator when subscripted (indexed) by both the
+    name of any object attribute *and* any **attribute validator** (i.e., other
+    beartype validator created by subscripting any :mod:`beartype.vale` class),
+    validating that :mod:`beartype`-decorated callable parameters and returns
+    annotated by :attr:`typing.Annotated` type hints subscripted by the former
+    validator define an attribute with that name satisfying that attribute
+    validator).
+
+    This class efficiently validates that callable parameters and returns
+    define arbitrary object attributes satisfying arbitrary validators
+    subscripting this factory. Any :mod:`beartype`-decorated callable parameter
+    or return annotated by a :attr:`typing.Annotated` type hint subscripted by
+    this factory subscripted by any object attribute name and validator (e.g.,
+    ``typing.Annotated[{cls}, beartype.vale.IsAttr[{attr_name},
+    {attr_validator}]]`` for any class ``{cls}``, object attribute name
+    ``{attr_name}`, and object attribute validator ``{attr_validator}``)
+    validates that parameter or return value to be an instance of that class
+    defining an attribute with that name satisfying that attribute validator.
+
+    **This factory incurs no time performance penalties at call time.** Whereas
+    the general-purpose :class:`beartype.vale.Is` factory necessarily calls
+    the caller-defined callable subscripting that factory at call time and thus
+    incurs a minor time performance penalty, this factory efficiently reduces
+    to one-line tests in :mod:`beartype`-generated wrapper functions *without*
+    calling any callables and thus incurs *no* time performance penalties.
+
+    Examples
+    ----------
+    .. code-block:: python
+
+       # Import the requisite machinery.
+       >>> from beartype import beartype
+       >>> from beartype.vale import IsAttr, IsEqual
+       >>> from typing import Annotated
+       >>> import numpy as np
+
+       # Type hint matching only two-dimensional NumPy arrays of 64-bit floats,
+       # generating code resembling:
+       #    (isinstance(array, np.ndarray) and
+       #     array.ndim == 2 and
+       #     array.dtype == np.dtype(np.float64))
+       >>> Numpy2dFloat64Array = Annotated[
+       ...     np.ndarray,
+       ...     IsAttr['ndim', IsEqual[2]],
+       ...     IsAttr['dtype', IsEqual[np.dtype(np.float64)]],
+       ... ]
+
+       # Type hint matching only one-dimensional NumPy arrays of 64-bit floats,
+       # generating code resembling:
+       #    (isinstance(array, np.ndarray) and
+       #     array.ndim == 2 and
+       #     array.dtype.type == np.float64)
+       >>> Numpy1dFloat64Array = Annotated[
+       ...     np.ndarray,
+       ...     IsAttr['ndim', IsEqual[2]],
+       ...     # Nested attribute validators test equality against a "."-delimited
+       ...     # attribute lookup (e.g., "dtype.type"), as expected.
+       ...     IsAttr['dtype', IsAttr['type', IsEqual[np.float64]]],
+       ... ]
+
+       # NumPy arrays of well-known real number series.
+       >>> FAREY_2D_FLOAT64_ARRAY = np.array(
+       ...     [[0/1, 1/8,], [1/7, 1/6,], [1/5, 1/4], [2/7, 1/3], [3/8, 2/5]])
+       >>> FAREY_1D_FLOAT64_ARRAY = np.array(
+       ...     [3/7, 1/2, 4/7, 3/5, 5/8, 2/3, 5/7, 3/4, 4/5, 5/6, 6/7, 7/8])
+
+       # Annotate callables by those type hints.
+       >>> @beartype
+       ... def sqrt_sum_2d(
+       ...     array: Numpy2dFloat64Array) -> Numpy1dFloat64Array:
+       ...     """
+       ...     One-dimensional NumPy array of 64-bit floats produced by first
+       ...     summing the passed two-dimensional NumPy array of 64-bit floats
+       ...     along its second dimension and then square-rooting those sums.
+       ...     """
+       ...     return np.sqrt(array.sum(axis=1))
+
+       # Call those callables with parameters satisfying those hints.
+       >>> sqrt_sum_2d(FAREY_2D_FLOAT64_ARRAY)
+       [0.35355339 0.55634864 0.67082039 0.78679579 0.88034084]
+
+       # Call those callables with parameters violating those hints.
+       >>> sqrt_sum_2d(FAREY_1D_FLOAT64_ARRAY)
+       beartype.roar.BeartypeCallHintParamViolation: @beartyped
+       sqrt_sum_2d() parameter array="array([0.42857143, 0.5, 0.57142857, 0.6,
+       0.625, ...])" violates type hint typing.Annotated[numpy.ndarray,
+       IsAttr['ndim', IsEqual[2]], IsAttr['dtype', IsEqual[dtype('float64')]]],
+       as value "array([0.42857143, 0.5, 0.57142857, 0.6, 0.625, ...])"
+       violates validator IsAttr['ndim', IsEqual[2]].
+
+    See Also
+    ----------
+    :class:`beartype.vale.Is`
+        Further commentary.
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    @callable_cached
+    def __getitem__(  # type: ignore[override]
+        self, args: Tuple[str, BeartypeValidator]) -> BeartypeValidator:
+        '''
+        Create and return a new beartype validator validating object attributes
+        with the passed name satisfying the passed validator, suitable for
+        subscripting :pep:`593`-compliant :attr:`typing.Annotated` type hints.
+
+        This method is memoized for efficiency.
+
+        Parameters
+        ----------
+        args : Tuple[str, BeartypeValidator]
+            2-tuple ``(attr_name, attr_validator)``, where:
+
+            * ``attr_name`` is the arbitrary attribute name to validate that
+              parameters and returns define satisfying the passed validator.
+            * ``attr_validator`` is the attribute validator to validate that
+              attributes with the passed name of parameters and returns
+              satisfy.
+
+        Returns
+        ----------
+        BeartypeValidator
+            Beartype validator encapsulating this validation.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If this factory was subscripted by either:
+
+            * *No* arguments.
+            * One argument.
+            * Three or more arguments.
+
+        See Also
+        ----------
+        :class:`_IsAttrFactory`
+            Usage instructions.
+        '''
+
+        # If this class was subscripted by one non-tuple argument, raise an
+        # exception.
+        if not isinstance(args, tuple):
+            raise BeartypeValeSubscriptionException(
+                f'{self._getitem_exception_prefix}non-tuple argument '
+                f'{represent_object(args)}.'
+            )
+        # Else, this class was subscripted by either no *OR* two or more
+        # arguments (contained in this tuple).
+        #
+        # If this class was *NOT* subscripted by two arguments...
+        elif len(args) != 2:
+            # If this class was subscripted by one or more arguments, then by
+            # deduction this class was subscripted by three or more arguments.
+            # In this case, raise a human-readable exception.
+            if args:
+                raise BeartypeValeSubscriptionException(
+                    f'{self._getitem_exception_prefix}three or more arguments '
+                    f'{represent_object(args)}.'
+                )
+            # Else, this class was subscripted by *NO* arguments. In this case,
+            # raise a human-readable exception.
+            else:
+                raise BeartypeValeSubscriptionException(
+                    f'{self._getitem_exception_prefix}empty tuple.')
+        # Else, this class was subscripted by exactly two arguments.
+
+        # Localize these arguments to human-readable local variables.
+        attr_name, attr_validator = args
+
+        # Representer (i.e., callable accepting *NO* arguments returning a
+        # machine-readable representation of this validator), defined *AFTER*
+        # localizing these validator arguments.
+        get_repr = lambda: (
+            f'{self._basename}[{repr(attr_name)}, {repr(attr_validator)}]')
+
+        # If this name is *NOT* a string, raise an exception.
+        if not isinstance(attr_name, str):
+            raise BeartypeValeSubscriptionException(
+                f'{get_repr()} first argument '
+                f'{represent_object(attr_name)} not string.'
+            )
+        # Else, this name is a string.
+        #
+        # If this name is the empty string, raise an exception.
+        elif not attr_name:
+            raise BeartypeValeSubscriptionException(
+                f'{get_repr()} first argument is empty string.')
+        # Else, this name is a non-empty string.
+        #
+        # Note that this name has *NOT* yet been validated to be valid Python
+        # identifier. While we could do so here by calling our existing
+        # is_identifier() tester, doing so would inefficiently repeat
+        # the split on "." characters performed below. Instead, we iteratively
+        # validate each split substring to be a valid Python identifier below.
+
+        # Callable inefficiently validating object attributes with this name
+        # against this validator.
+        # is_valid: BeartypeValidatorTester = None  # type: ignore[assignment]
+
+        # Code snippet efficiently validating object attributes with this name
+        # against this validator.
+        is_valid_code = ''
+
+        # Dictionary mapping from the name to value of each local attribute
+        # referenced in the "is_valid_code" snippet defined below.
+        is_valid_code_locals: LexicalScope = {}
+
+        # If this attribute name is unqualified (i.e., contains no "."
+        # delimiters), prefer an efficient optimization avoiding iteration.
+        if '.' not in attr_name:
+            # If this name is *NOT* a valid Python identifier, raise an
+            # exception.
+            if not attr_name.isidentifier():
+                raise BeartypeValeSubscriptionException(
+                    f'{get_repr()} first argument {repr(attr_name)} not '
+                    f'syntactically valid Python identifier.'
+                )
+            # Else, this name is a valid Python identifier.
+
+            def is_valid(pith: Any) -> bool:
+                f'''
+                ``True`` only if the passed object defines an attribute named
+                "{attr_name}" whose value satisfies the validator
+                {repr(attr_validator)}.
+                '''
+
+                # Attribute of this object with this name if this object
+                # defines such an attribute *OR* a sentinel placeholder
+                # otherwise (i.e., if this object defines *NO* such attribute).
+                pith_attr = getattr(pith, attr_name, SENTINEL)
+
+                # Return true only if...
+                return (
+                    # This object defines an attribute with this name *AND*...
+                    pith_attr is not SENTINEL and
+                    # This attribute satisfies this validator.
+                    attr_validator.is_valid(pith_attr)
+                )
+
+            # Names of new parameters added to the signature of wrapper
+            # functions enabling this validator to be tested in those functions
+            # *WITHOUT* additional stack frames whose values are:
+            # * The sentinel placeholder.
+            #
+            # Add these parameters *BEFORE* generating locals.
+            local_name_sentinel = add_func_scope_attr(
+                attr=SENTINEL, func_scope=is_valid_code_locals)
+
+            # Generate locals safely merging the locals required by both the
+            # code generated below *AND* the externally provided code
+            # validating this attribute.
+            update_mapping(
+                mapping_trg=is_valid_code_locals,
+                mapping_src=attr_validator._is_valid_code_locals,
+            )
+
+            #FIXME: Unfortunately, "local_name_attr_value" still isn't a
+            #sufficiently unique name below, because "IsAttr['name',
+            #IsAttr['name', IsEqual[True]]]" is a trivial counter-example where
+            #the current approach breaks down. For true uniquification here,
+            #we're going to need to instead:
+            #* Define a global private counter:
+            #  _local_name_obj_attr_value_counter = Counter(0)
+            #* Replace the assignment below with:
+            #  local_name_obj_attr_value = (
+            #      f'{{obj}}_isattr_'
+            #      f'{next(_local_name_obj_attr_value_counter)}'
+            #  )
+            #Of course, this assumes "Counter" objects are thread-safe. If
+            #they're not, we'll need to further obfuscate all this behind a
+            #[R]Lock of some sort. *sigh*
+            #FIXME: Oh, right. We mixed up "collections.Counter" with
+            #"itertools.count". The former is orthogonal to our interests here;
+            #the latter is of interest but *NOT* thread-safe. The solution is
+            #for us to implement a new "FastWriteCounter" class resembling that
+            #published in this extremely clever (and thus awesome) article:
+            #    https://julien.danjou.info/atomic-lock-free-counters-in-python
+
+            # Name of a local variable in this code whose:
+            # * Name is sufficiently obfuscated as to be hopefully unique to
+            #   the code generated by this validator.
+            # * Value is the value of this attribute of the arbitrary object
+            #   being validated by this code.
+            local_name_attr_value = f'{{obj}}_isattr_{attr_name}'
+
+            # Python expression expanding to the value of this attribute,
+            # efficiently optimized under Python >= 3.8 with an assignment
+            # expression to avoid inefficient access of this value.
+            attr_value_expr = VALE_CODE_CHECK_ISATTR_VALUE_EXPR_format(
+                attr_name_expr=repr(attr_name),
+                local_name_attr_value=local_name_attr_value,
+                local_name_sentinel=local_name_sentinel,
+            )
+
+            # Python expression validating the value of this attribute,
+            # formatted so as to be safely embeddable in the larger code
+            # expression defined below.
+            attr_value_is_valid_expr = (
+                attr_validator._is_valid_code.format(
+                    # Replace the placeholder substring "{obj}" in this code
+                    # with the expression expanding to this attribute's value,
+                    # defined as the name of the local variable previously
+                    # assigned the value of this attribute by the
+                    # "VALE_CODE_CHECK_ISATTR_VALUE_EXPR" code snippet
+                    # subsequently embedded in the
+                    # "VALE_CODE_CHECK_ISATTR_VALUE_TEST" code snippet.
+                    obj=local_name_attr_value,
+                    # Replace the placeholder substring "{indent}" in this code
+                    # with an indentation increased by one level.
+                    indent=VALE_CODE_INDENT_1,
+                ))
+
+            # Code snippet efficiently validating against this object.
+            is_valid_code = VALE_CODE_CHECK_ISATTR_TEST_format(
+                attr_value_expr=attr_value_expr,
+                attr_value_is_valid_expr=attr_value_is_valid_expr,
+                local_name_sentinel=local_name_sentinel,
+            )
+        # Else, this attribute name is qualified (i.e., contains one or more
+        # "." delimiters), fallback to a general solution performing iteration.
+        else:
+            #FIXME: Implement us up when we find the time, please. We currently
+            #raise an exception simply because we ran out of time for this. :{
+            raise BeartypeValeSubscriptionException(
+                f'{get_repr()} first argument '
+                f'{repr(attr_name)} not unqualified Python identifier '
+                f'(i.e., contains one or more "." characters).'
+            )
+
+        # Create and return this subscription.
+        return BeartypeValidator(
+            is_valid=is_valid,
+            is_valid_code=is_valid_code,
+            is_valid_code_locals=is_valid_code_locals,
+            get_repr=get_repr,
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_is/_valeisoper.py
@@ -0,0 +1,254 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype declarative operator validation classes** (i.e.,
+:mod:`beartype`-specific classes enabling callers to define PEP-compliant
+validators from arbitrary caller-defined objects tested via explicitly
+supported operators efficiently generating stack-free code).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ TODO                               }....................
+#FIXME: *Useful optimization.* For "_IsEqualFactory", we can (and should)
+#directly embed the values of builtins when comparing against builtins (e.g.,
+#integers, strings). Specifically, we should only conditionally perform this
+#line below:
+#       param_name_obj_value = add_func_scope_attr(
+#           attr=obj, func_scope=is_valid_code_locals)
+#...when we absolutely must. So when mustn't we? We see two simple approaches
+#to detecting builtin objects:
+#* Detect the types of those objects. While obvious, this presents several
+#  subtleties:
+#  * Fake builtin objects, which would naturally need to be excluded.
+#  * Subclasses of builtin objects, which would *ALSO* need to be excluded.
+#  In short, "isinstance(param_name_obj_value, TUPLE_OF_TRUE_BUILTIN_TYPES)"
+#  fails to suffice -- although something more brute-force like
+#  "type(param_name_obj_value) in SET_OF_TRUE_BUILTIN_TYPES" might suffice.
+#* Detect the first character of their repr() strings as belonging to the set:
+#      BUILTIN_OBJ_REPR_CHARS_FIRST = {
+#          "'", '"', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9}
+#      repr(param_name_obj_value) in BUILTIN_OBJ_REPR_CHARS_FIRST
+#We like the latter quite a bit more, as it has *NO* obvious edge cases,
+#requires *NO* hard-coding of types, and appears to scale gracefully. The only
+#downside is that it assumes third-party repr() strings to be sane, but... if
+#that *ISN'T* the case, that is a bug in those third-parties. *shrug*
+
+#FIXME: Generalize to support arbitrary binary operators by:
+#* Define a new "_IsOperatorBinaryABC(_BeartypeValidatorFactoryABC, metaclass=ABCMeta)" superclass.
+#* In that superclass:
+#  * Define a stock __class_getitem__() method whose implementation is
+#    sufficiently generic so as to be applicable to all subclasses. To do so,
+#    this method should access class variables defined by those subclasses.
+#  * Note that there is absolutely no reason or point to define abstract class
+#    methods forcing subclasses to define various metadata, for the unfortunate
+#    reason that abstract class methods do *NOT* actually enforce subclasses
+#    that aren't instantiable anyway to implement those methods. *sigh*
+#* Refactor "_IsEqualFactory" to:
+#  * Subclass that superclass.
+#  * Define the following class variables, which the superclass
+#    __class_getitem__() method will internally access to implement itself:
+#    from operator import __eq__
+#
+#    class _IsEqualFactory(_IsOperatorBinaryABC):
+#        _operator = __eq__
+#        _operator_code = '=='
+#
+#Ridiculously sweet, eh? We know.
+
+# ....................{ IMPORTS                           }....................
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.typing import Any
+from beartype.vale._is._valeisabc import _BeartypeValidatorFactoryABC
+from beartype.vale._util._valeutilsnip import (
+    VALE_CODE_CHECK_ISEQUAL_TEST_format)
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype._data.hint.datahinttyping import LexicalScope
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.func.utilfuncscope import add_func_scope_attr
+
+# ....................{ SUBCLASSES ~ equal                 }....................
+class _IsEqualFactory(_BeartypeValidatorFactoryABC):
+    '''
+    **Beartype object equality validator factory** (i.e., object creating and
+    returning a new beartype validator when subscripted (indexed) by any
+    object, validating that :mod:`beartype`-decorated callable parameters and
+    returns annotated by :attr:`typing.Annotated` type hints subscripted by
+    that validator equal that object).
+
+    This class efficiently validates that callable parameters and returns are
+    equal to the arbitrary object subscripting this factory. Any
+    :mod:`beartype`-decorated callable parameter or return annotated by a
+    :attr:`typing.Annotated` type hint subscripted by this factory subscripted
+    by any object (e.g., ``typing.Annotated[{cls},
+    beartype.vale.IsEqual[{obj}]]`` for any class ``{cls}``  and object
+    ``{obj}`) validates that parameter or return value to equal that object
+    under the standard ``==`` equality comparison.
+
+    This factory is a generalization of the :pep:`586`-compliant
+    :attr:`typing.Literal` type hint factory, because this factory does
+    everything that factory does and substantially more. Superficially,
+    :attr:`typing.Literal` type hints also validate that callable parameters
+    and returns are equal to (i.e., ``==``) the literal object subscripting
+    those hints. The similarity ends there, however. :attr:`typing.Literal` is
+    only subscriptable by literal :class:`bool`, :class:`bytes`, :class:`int`,
+    :class:`str`, :class:`Enum`, and ``type(None)`` objects; meanwhile, this
+    factory is subscriptable by *any* object.
+
+    **This factory incurs no time performance penalties at call time.** Whereas
+    the general-purpose :class:`beartype.vale.Is` factory necessarily calls
+    the caller-defined callable subscripting that factory at call time and thus
+    incurs a minor time performance penalty, this factory efficiently reduces
+    to one-line tests in :mod:`beartype`-generated wrapper functions *without*
+    calling any callables and thus incurs *no* time performance penalties.
+
+    Caveats
+    ----------
+    **This class is intentionally subscriptable by only a single object.** Why?
+    Disambiguity. When subscripted by variadic positional (i.e., one or more)
+    objects, this class internally treats those objects as items of a tuple to
+    validate equality against rather than as independent objects to iteratively
+    validate equality against. Since this is non-intuitive, callers should avoid
+    subscripting this class by multiple objects. Although non-intuitive, this is
+    also unavoidable. The ``__class_getitem__()`` dunder method obeys the same
+    semantics as the ``__getitem__()`` dunder method, which is unable to
+    differentiate between being subscripted two or more objects and being
+    subscripted by a tuple of two or more objects. Since being able to validate
+    equality against tuples of two or more objects is essential and since this
+    class being subscripted by two or more objects would trivially reduce to
+    shorthand for the existing ``|`` set operator already supported by this
+    class, this class preserves support for tuples of two or more objects at a
+    cost of non-intuitive results when subscripted by multiple objects.
+
+    Don't blame us. We didn't vote for :pep:`560`.
+
+    Examples
+    ----------
+    .. code-block:: python
+
+       # Import the requisite machinery.
+       >>> from beartype import beartype
+       >>> from beartype.vale import IsEqual
+       >>> from typing import Annotated
+
+       # Lists of the first ten items of well-known simple whole number series.
+       >>> WHOLE_NUMBERS      = [0, 1, 2, 3, 4,  5,  6,  7,  8,  9]
+       >>> WHOLE_NUMBERS_EVEN = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
+       >>> WHOLE_NUMBERS_ODD  = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]
+
+       # Type hint matching only lists of integers equal to one of these lists.
+       >>> SimpleWholeNumberSeries = Annotated[
+       ...     list[int],
+       ...     IsEqual[WHOLE_NUMBERS] |
+       ...     IsEqual[WHOLE_NUMBERS_EVEN] |
+       ...     IsEqual[WHOLE_NUMBERS_ODD]
+       ... ]
+
+       # Annotate callables by those type hints.
+       >>> @beartype
+       ... def guess_next(series: SimpleWholeNumberSeries) -> int:
+       ...     """
+       ...     Guess the next whole number in the passed whole number series.
+       ...     """
+       ...     if series == WHOLE_NUMBERS: return WHOLE_NUMBERS[-1] + 1
+       ...     else:                       return        series[-1] + 2
+
+       # Call those callables with parameters equal to one of those objects.
+       >>> guess_next(list(range(10)))
+       10
+       >>> guess_next([number*2 for number in range(10)])
+       20
+
+       # Call those callables with parameters unequal to one of those objects.
+       >>> guess_next([1, 2, 3, 6, 7, 14, 21, 42,])
+       beartype.roar.BeartypeCallHintParamViolation: @beartyped guess_next()
+       parameter series=[1, 2, 3, 6, 7, 14, 21, 42] violates type hint
+       typing.Annotated[list[int], IsEqual[[0, 1, 2, 3, 4, 5, 6, 7, 8,
+       9]] | IsEqual[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]] | IsEqual[[1, 3, 5,
+       7, 9, 11, 13, 15, 17, 19]]], as value [1, 2, 3, 6, 7, 14, 21, 42]
+       violates validator IsEqual[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]] |
+       IsEqual[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]] | IsEqual[[1, 3, 5, 7, 9,
+       11, 13, 15, 17, 19]].
+
+    See Also
+    ----------
+    :class:`beartype.vale.Is`
+        Further commentary.
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    @callable_cached
+    def __getitem__(self, obj: Any) -> BeartypeValidator:  # type: ignore[override]
+        '''
+        Create and return a new beartype validator validating equality against
+        the passed object, suitable for subscripting :pep:`593`-compliant
+        :attr:`typing.Annotated` type hints.
+
+        This method is memoized for efficiency.
+
+        Parameters
+        ----------
+        obj : Any
+            Arbitrary object to validate equality against.
+
+        Returns
+        ----------
+        BeartypeValidator
+            Beartype validator encapsulating this validation.
+
+        Raises
+        ----------
+        BeartypeValeSubscriptionException
+            If this factory was subscripted by either:
+
+            * *No* arguments.
+            * Two or more arguments.
+
+        See Also
+        ----------
+        :class:`_IsEqualFactory`
+            Usage instructions.
+        '''
+
+        # If...
+        if (
+            # This factory was subscripted by either no arguments *OR* two or
+            # more arguments *AND*...
+            isinstance(obj, tuple) and
+            # This factory was subscripted by no arguments...
+            not obj
+        # Then raise an exception.
+        ):
+            raise BeartypeValeSubscriptionException(
+                f'{self._getitem_exception_prefix}empty tuple.')
+        # Else, this factory was subscripted by one or more arguments. In any
+        # case, accept this object as is. See the class docstring for details.
+        # print(f'_IsEqualFactory[{repr(obj)}]')
+
+        # Callable inefficiently validating against this object.
+        is_valid = lambda pith: pith == obj
+
+        # Dictionary mapping from the name to value of each local attribute
+        # referenced in the "is_valid_code" snippet defined below.
+        is_valid_code_locals: LexicalScope = {}
+
+        # Name of a new parameter added to the signature of wrapper functions
+        # whose value is this object, enabling this object to be tested in
+        # those functions *WITHOUT* additional stack frames.
+        param_name_obj_value = add_func_scope_attr(
+            attr=obj, func_scope=is_valid_code_locals)
+
+        # Code snippet efficiently validating against this object.
+        is_valid_code = VALE_CODE_CHECK_ISEQUAL_TEST_format(
+            param_name_obj_value=param_name_obj_value)
+
+        # Create and return this subscription.
+        return BeartypeValidator(
+            is_valid=is_valid,
+            is_valid_code=is_valid_code,
+            is_valid_code_locals=is_valid_code_locals,
+            get_repr=lambda: f'{self._basename}[{repr(obj)}]',
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_is/_valeistype.py
@@ -0,0 +1,430 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype declarative type validation classes** (i.e.,
+:mod:`beartype`-specific classes enabling callers to define PEP-compliant
+validators from arbitrary caller-defined classes tested via explicitly
+supported object introspectors efficiently generating stack-free code).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.vale._is._valeisabc import _BeartypeValidatorFactoryABC
+from beartype.vale._util._valeutilsnip import (
+    VALE_CODE_CHECK_ISINSTANCE_TEST_format,
+    VALE_CODE_CHECK_ISSUBCLASS_TEST_format,
+)
+from beartype.vale._core._valecore import BeartypeValidator
+from beartype._data.hint.datahinttyping import (
+    LexicalScope,
+    TypeOrTupleTypes,
+)
+from beartype._util.cache.utilcachecall import callable_cached
+from beartype._util.cls.utilclstest import is_type_subclass
+from beartype._util.cls.pep.utilpep3119 import (
+    die_unless_type_isinstanceable,
+    die_unless_object_isinstanceable,
+    die_unless_type_issubclassable,
+    die_unless_object_issubclassable,
+)
+from beartype._util.func.utilfuncscope import add_func_scope_attr
+from beartype._util.utilobject import get_object_name
+
+# ....................{ SUBCLASSES ~ instance              }....................
+class _IsInstanceFactory(_BeartypeValidatorFactoryABC):
+    '''
+    **Beartype type instance validator factory** (i.e., object creating and
+    returning a new beartype validator when subscripted (indexed) by any class,
+    validating that :mod:`beartype`-decorated callable parameters and returns
+    annotated by :attr:`typing.Annotated` type hints subscripted by that
+    validator are objects whose classes subclass that class).
+
+    This class efficiently validates that callable parameters and returns are
+    instances of the arbitrary class subscripting (indexing) this factory. Any
+    :mod:`beartype`-decorated callable parameter or return annotated by a
+    :attr:`typing.Annotated` type hint subscripted by this factory subscripted
+    by any class (e.g., ``typing.Annotated[type,
+    beartype.vale.IsInstance[{cls}]]`` for any class ``{cls}``)
+    validates that parameter or return value to be a subclass of that class.
+
+    This factory generalizes :pep:`484`-compliant **isinstanceable types**
+    (i.e., normal pure-Python and C-based classes that may be passed as the
+    second parameter to the :func:`isinstance` builtin), because this factory
+    does everything those types do and considerably more. Superficially,
+    isinstanceable types also validate that callable parameters and returns are
+    instances of those types. The similarity ends there, however.
+    Isinstanceable types only narrowly apply to callable parameters and
+    returns; meanwhile, this factory produces beartype validators universally
+    applicable to both:
+
+    * Callable parameters and returns.
+    * **Attributes** of callable parameters and returns via the
+      :class:`beartype.vale.IsAttr` factory.
+
+    **This factory incurs no time performance penalties at call time.** Whereas
+    the general-purpose :class:`beartype.vale.Is` factory necessarily calls
+    the caller-defined callable subscripting that factory at call time and thus
+    incurs a minor time performance penalty, this factory efficiently reduces
+    to one-line tests in :mod:`beartype`-generated wrapper functions *without*
+    calling any callables and thus incurs *no* time performance penalties.
+
+    Examples
+    --------
+    .. code-block:: python
+
+       # Import the requisite machinery.
+       >>> from beartype import beartype
+       >>> from beartype.vale import IsInstance
+       >>> from math import factorial as loose_factorial
+       >>> from typing import Annotated
+
+       # Type hint matching any non-boolean integer, generating code like:
+       #    (isinstance(number, int) and not isinstance(number, bool)))
+       # Surprisingly, booleans are literally integers in Python (e.g.,
+       # ``issubclass(bool, int) is True``). Callable parameters and returns
+       # annotated as accepting only integers thus implicitly accept booleans
+       # as well by default. This type hint explicitly prevents that ambiguity.
+       >>> IntNonbool = Annotated[int, ~IsInstance[bool]]
+
+       # Annotate callables by those type hints.
+       >>> @beartype
+       ... def strict_factorial(integer: IntNonbool) -> IntNonbool:
+       ...     """
+       ...     Factorial of the passed integer, explicitly prohibiting booleans
+       ...     masquerading as integers.
+       ...     """
+       ...     return loose_factorial(integer)
+
+       # Call those callables with parameters satisfying those hints.
+       >>> strict_factorial(42)
+       1405006117752879898543142606244511569936384000000000
+
+       # Call those callables with parameters violating those hints.
+       >>> strict_factorial(True)
+       beartype.roar.BeartypeCallHintParamViolation: @beartyped
+       strict_factorial() parameter integer=True violates type hint
+       typing.Annotated[int, ~IsInstance[builtins.bool]], as True violates
+       validator ~IsInstance[builtins.bool]:
+
+    See Also
+    --------
+    :class:`beartype.vale.Is`
+        Further commentary.
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    @callable_cached
+    def __getitem__(self, types: TypeOrTupleTypes) -> BeartypeValidator:  # type: ignore[override]
+        '''
+        Create and return a new beartype validator validating type instancing
+        against at least one of the passed classes, suitable for subscripting
+        :pep:`593`-compliant :attr:`typing.Annotated` type hints.
+
+        This method is memoized for efficiency.
+
+        Parameters
+        ----------
+        types : TypeOrTupleTypes
+            One or more arbitrary classes to validate type instancing against.
+
+        Returns
+        -------
+        BeartypeValidator
+            Beartype validator encapsulating this validation.
+
+        Raises
+        ------
+        BeartypeValeSubscriptionException
+            If this factory was subscripted by either:
+
+            * *No* arguments.
+            * One or more arguments that are *not* **isinstanceable types**
+              (i.e., classes passable as the second argument to the :func:
+              `isinstance` builtin).
+
+        See Also
+        --------
+        :class:`_IsAttrFactory`
+            Usage instructions.
+        '''
+
+        # Machine-readable string representing this type or tuple of types.
+        types_repr = ''
+
+        # If this factory was subscripted by either no arguments *OR* two or
+        # more arguments...
+        if isinstance(types, tuple):
+            # If this factory was subscripted by *NO* arguments, raise an
+            # exception.
+            if not types:
+                raise BeartypeValeSubscriptionException(
+                    f'{self._getitem_exception_prefix}empty tuple.')
+            # Else, this factory was subscripted by two or more arguments.
+
+            # If any such argument is *NOT* an isinstanceable type, raise an
+            # exception.
+            die_unless_object_isinstanceable(
+                obj=types,
+                exception_cls=BeartypeValeSubscriptionException,
+                exception_prefix=self._getitem_exception_prefix,
+            )
+            # Else, all such arguments are isinstanceable types.
+
+            # Append the fully-qualified name of each such type to this string.
+            for cls in types:
+                types_repr += f'{get_object_name(cls)}, '
+
+            # Strip the suffixing ", " from this string for readability.
+            types_repr = types_repr[:-2]
+        # Else, this factory was subscripted by one argument. In this case...
+        else:
+            # If this argument is *NOT* an isinstanceable type, raise an
+            # exception.
+            die_unless_type_isinstanceable(
+                cls=types,
+                exception_cls=BeartypeValeSubscriptionException,
+                exception_prefix=self._getitem_exception_prefix,
+            )
+            # Else, this argument is an isinstanceable type.
+
+            # Fully-qualified name of this type.
+            types_repr = get_object_name(types)
+
+        # Callable inefficiently validating against this type.
+        is_valid = lambda pith: isinstance(pith, types)
+
+        # Dictionary mapping from the name to value of each local attribute
+        # referenced in the "is_valid_code" snippet defined below.
+        is_valid_code_locals: LexicalScope = {}
+
+        # Name of a new parameter added to the signature of wrapper functions
+        # whose value is this type or tuple of types, enabling this type or
+        # tuple of types to be tested in those functions *WITHOUT* additional
+        # stack frames.
+        param_name_types = add_func_scope_attr(
+            attr=types, func_scope=is_valid_code_locals)
+
+        # Code snippet efficiently validating against this type.
+        is_valid_code = VALE_CODE_CHECK_ISINSTANCE_TEST_format(
+            param_name_types=param_name_types)
+
+        # Create and return this subscription.
+        return BeartypeValidator(
+            is_valid=is_valid,
+            is_valid_code=is_valid_code,
+            is_valid_code_locals=is_valid_code_locals,
+
+            # Intentionally pass this subscription's machine-readable
+            # representation as a string rather than lambda function returning
+            # a string, as this string is safely, immediately, and efficiently
+            # constructable from these arguments' representation.
+            get_repr=f'{self._basename}[{types_repr}]',
+        )
+
+# ....................{ SUBCLASSES ~ subclass              }....................
+class _IsSubclassFactory(_BeartypeValidatorFactoryABC):
+    '''
+    **Beartype type inheritance validator factory** (i.e., object creating and
+    returning a new beartype validator when subscripted (indexed) by any class,
+    validating that :mod:`beartype`-decorated callable parameters and returns
+    annotated by :attr:`typing.Annotated` type hints subscripted by that
+    validator subclass that class).
+
+    This class efficiently validates that callable parameters and returns are
+    subclasses of the arbitrary class subscripting (indexing) this factory. Any
+    :mod:`beartype`-decorated callable parameter or return annotated by a
+    :attr:`typing.Annotated` type hint subscripted by this factory subscripted
+    by any class (e.g., ``typing.Annotated[type,
+    beartype.vale.IsSubclass[{cls}]]`` for any class ``{cls}``)
+    validates that parameter or return value to be a subclass of that class.
+
+    This factory generalizes the :pep:`484`-compliant :attr:`typing.Type` and :
+    pep:`585`-compliant :class:`type` type hint factories, because this factory
+    does everything those factories do and substantially more. Superficially, :
+    attr:`typing.Type` and :class:`type` type hints also validate that callable
+    parameters and returns are subclasses of the classes subscripting those
+    hints. The similarity ends there, however. Those hints only narrowly apply
+    to callable parameters and returns; meanwhile, this factory produces
+    beartype validators universally applicable to both:
+
+    * Callable parameters and returns.
+    * **Attributes** of callable parameters and returns via the
+      :class:`beartype.vale.IsAttr` factory.
+
+    **This factory incurs no time performance penalties at call time.** Whereas
+    the general-purpose :class:`beartype.vale.Is` factory necessarily calls
+    the caller-defined callable subscripting that factory at call time and thus
+    incurs a minor time performance penalty, this factory efficiently reduces
+    to one-line tests in :mod:`beartype`-generated wrapper functions *without*
+    calling any callables and thus incurs *no* time performance penalties.
+
+    Examples
+    --------
+    .. code-block:: python
+
+       # Import the requisite machinery.
+       >>> from beartype import beartype
+       >>> from beartype.vale import IsAttr, IsSubclass
+       >>> from typing import Annotated
+       >>> import numpy as np
+
+       # Type hint matching only NumPy arrays of floats of arbitrary precision,
+       # generating code resembling:
+       #    (isinstance(array, np.ndarray) and
+       #     np.issubdtype(array.dtype, np.floating))
+       >>> NumpyFloatArray = Annotated[
+       ...     np.ndarray, IsAttr['dtype', IsAttr['type', IsSubclass[np.floating]]]]
+
+       # Type hint matching only NumPy arrays of integers of arbitrary
+       # precision, generating code resembling:
+       #    (isinstance(array, np.ndarray) and
+       #     np.issubdtype(array.dtype, np.integer))
+       >>> NumpyIntArray = Annotated[
+       ...     np.ndarray, IsAttr['dtype', IsAttr['type', IsSubclass[np.integer]]]]
+
+       # NumPy arrays of well-known real number series.
+       >>> E_APPROXIMATIONS = np.array(
+       ...     [1+1, 1+1+1/2, 1+1+1/2+1/6, 1+1+1/2+1/6+1/24,])
+       >>> FACTORIALS = np.array([1, 2, 6, 24, 120, 720, 5040, 40320, 362880,])
+
+       # Annotate callables by those type hints.
+       >>> @beartype
+       ... def round_int(array: NumpyFloatArray) -> NumpyIntArray:
+       ...     """
+       ...     NumPy array of integers rounded from the passed NumPy array of
+       ...     floating-point numbers to the nearest 64-bit integer.
+       ...     """
+       ...     return np.around(array).astype(np.int64)
+
+       # Call those callables with parameters satisfying those hints.
+       >>> round_int(E_APPROXIMATIONS)
+       [2, 3, 3, 3]
+
+       # Call those callables with parameters violating those hints.
+       >>> round_int(FACTORIALS)
+       beartype.roar.BeartypeCallHintParamViolation: @beartyped round_int()
+       parameter array="array([ 1, 2, 6, 24, 120, 720, 5040, 40320, ...])"
+       violates type hint typing.Annotated[numpy.ndarray, IsAttr['dtype',
+       IsAttr['type', IsSubclass[numpy.floating]]]], as "array([ 1, 2, 6, 24,
+       120, 720, 5040, 40320, ...])" violates validator IsAttr['dtype',
+       IsAttr['type', IsSubclass[numpy.floating]]]
+
+    See Also
+    ----------
+    :class:`beartype.vale.Is`
+        Further commentary.
+    '''
+
+    # ..................{ DUNDERS                            }..................
+    @callable_cached
+    def __getitem__(self, types: TypeOrTupleTypes) -> BeartypeValidator:  # type: ignore[override]
+        '''
+        Create and return a new beartype validator validating type inheritance
+        against at least one of the passed classes, suitable for subscripting
+        :pep:`593`-compliant :attr:`typing.Annotated` type hints.
+
+        This method is memoized for efficiency.
+
+        Parameters
+        ----------
+        types : TypeOrTupleTypes
+            One or more arbitrary classes to validate type inheritance against.
+
+        Returns
+        -------
+        BeartypeValidator
+            Beartype validator encapsulating this validation.
+
+        Raises
+        ------
+        BeartypeValeSubscriptionException
+            If this factory was subscripted by either:
+
+            * *No* arguments.
+            * One or more arguments that are *not* **issubclassable types**
+              (i.e., classes passable as the second argument to the :func:
+              `issubclass` builtin).
+
+        See Also
+        --------
+        :class:`_IsAttrFactory`
+            Usage instructions.
+        '''
+
+        # Machine-readable string representing this type or tuple of types.
+        types_repr = ''
+
+        # If this factory was subscripted by either no arguments *OR* two or
+        # more arguments...
+        if isinstance(types, tuple):
+            # If this factory was subscripted by *NO* arguments, raise an
+            # exception.
+            if not types:
+                raise BeartypeValeSubscriptionException(
+                    f'{self._getitem_exception_prefix}empty tuple.')
+            # Else, this factory was subscripted by two or more arguments.
+
+            # If any such argument is *NOT* an issubclassable type, raise an
+            # exception.
+            die_unless_object_issubclassable(
+                obj=types,
+                exception_cls=BeartypeValeSubscriptionException,
+                exception_prefix=self._getitem_exception_prefix,
+            )
+            # Else, all such arguments are issubclassable types.
+
+            # Append the fully-qualified name of each such type to this string.
+            for cls in types:
+                types_repr += f'{get_object_name(cls)}, '
+
+            # Strip the suffixing ", " from this string for readability.
+            types_repr = types_repr[:-2]
+        # Else, this factory was subscripted by one argument. In this case...
+        else:
+            # If this argument is *NOT* an issubclassable type, raise an
+            # exception.
+            die_unless_type_issubclassable(
+                cls=types,
+                exception_cls=BeartypeValeSubscriptionException,
+                exception_prefix=self._getitem_exception_prefix,
+            )
+            # Else, this argument is an issubclassable type.
+
+            # Fully-qualified name of this type.
+            types_repr = get_object_name(types)
+
+        # Callable inefficiently validating against this type.
+        is_valid = lambda pith: is_type_subclass(pith, types)
+
+        # Dictionary mapping from the name to value of each local attribute
+        # referenced in the "is_valid_code" snippet defined below.
+        is_valid_code_locals: LexicalScope = {}
+
+        # Name of a new parameter added to the signature of wrapper functions
+        # whose value is this type or tuple of types, enabling this type or
+        # tuple of types to be tested in those functions *WITHOUT* additional
+        # stack frames.
+        param_name_types = add_func_scope_attr(
+            attr=types, func_scope=is_valid_code_locals)
+
+        # Code snippet efficiently validating against this type.
+        is_valid_code = VALE_CODE_CHECK_ISSUBCLASS_TEST_format(
+            param_name_types=param_name_types)
+
+        # Create and return this subscription.
+        return BeartypeValidator(
+            is_valid=is_valid,
+            is_valid_code=is_valid_code,
+            is_valid_code_locals=is_valid_code_locals,
+
+            # Intentionally pass this subscription's machine-readable
+            # representation as a string rather than lambda function returning
+            # a string, as this string is safely, immediately, and efficiently
+            # constructable from these arguments' representation.
+            get_repr=f'{self._basename}[{types_repr}]',
+        )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_util/_valeutilfunc.py
@@ -0,0 +1,58 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype validator callable utilities** (i.e., callables performing low-level
+callable-centric operations on behalf of higher-level beartype validators).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar import BeartypeValeSubscriptionException
+from beartype.vale._util._valeutiltyping import BeartypeValidatorTester
+from beartype._util.func.arg.utilfuncargtest import (
+    die_unless_func_args_len_flexible_equal)
+
+# ....................{ FORMATTERS                         }....................
+def die_unless_validator_tester(
+    validator_tester: BeartypeValidatorTester) -> None:
+    '''
+    Raise an exception unless the passed object is a **validator tester** (i.e.,
+    caller-defined callable accepting a single arbitrary object and returning
+    either :data:`True` if that object satisfies an arbitrary constraint *or*
+    :data:`False` otherwise).
+
+    Parameters
+    ----------
+    validator_tester : BeartypeValidatorTester
+        Object to be validated.
+
+    Raises
+    ------
+    beartype.roar.BeartypeValeSubscriptionException
+        If that object is either:
+
+        * *Not* callable.
+        * A C-based rather than pure-Python callable.
+        * A pure-Python callable accepting two or more arguments.
+    '''
+
+    # If this validator is either uncallable, a C-based callable, *OR* a
+    # pure-Python callable accepting more or less than one parameter, raise
+    # an exception.
+    die_unless_func_args_len_flexible_equal(
+        func=validator_tester,
+        func_args_len_flexible=1,
+        exception_cls=BeartypeValeSubscriptionException,
+    )
+    # Else, this validator is a pure-Python callable accepting exactly one
+    # parameter. Since no further validation can be performed on this
+    # callable without unsafely calling that callable, we accept this
+    # callable as is for now.
+    #
+    # Note that we *COULD* technically inspect annotations if defined on
+    # this callable as well. Since this callable is typically defined as a
+    # lambda, annotations are typically *NOT* defined on this callable.
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_util/_valeutilsnip.py
@@ -0,0 +1,96 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype validator code snippets** (i.e., triple-quoted pure-Python code
+constants formatted and concatenated together into wrapper functions
+type-checking decorated callables annotated by one or more beartype
+validators).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype._data.code.datacodeindent import CODE_INDENT_1
+
+# ....................{ INDENTATION                        }....................
+VALE_CODE_INDENT_1 = f'{{indent}}{CODE_INDENT_1}'
+'''
+Code snippet prefixed by the placeholder substring ``"{indent}"`` (which the
+:func:`beartype._check.code.codemake.make_func_pith_code` replaces with
+the indentation level required by the current beartype validator) followed by a
+single level of indentation.
+'''
+
+# ....................{ CHECK ~ factory                    }....................
+VALE_CODE_CHECK_ISEQUAL_TEST = '''
+{{indent}}# True only if this pith equals this object.
+{{indent}}{{obj}} == {param_name_obj_value}'''
+'''
+:attr:`beartype.vale.IsEqual`-specific code snippet validating an arbitrary
+object to be equal to another arbitrary object.
+'''
+
+
+VALE_CODE_CHECK_ISINSTANCE_TEST = '''
+{{indent}}# True only if this pith is of this type.
+{{indent}}isinstance({{obj}}, {param_name_types})'''
+'''
+:attr:`beartype.vale.IsInstance`-specific code snippet validating an arbitrary
+object to instance an arbitrary type.
+'''
+
+
+VALE_CODE_CHECK_ISSUBCLASS_TEST = '''
+{{indent}}# True only if this pith is a class subclassing this superclass.
+{{indent}}(isinstance({{obj}}, type) and issubclass({{obj}}, {param_name_types}))'''
+'''
+:attr:`beartype.vale.IsSubclass`-specific code snippet validating an arbitrary
+type to subclass another arbitrary type.
+'''
+
+# ....................{ CHECK ~ factory : isattr           }....................
+VALE_CODE_CHECK_ISATTR_TEST = '''(
+{{indent}}    # True only if this pith defines an attribute with this name.
+{{indent}}    {attr_value_expr}
+{{indent}}    is not {local_name_sentinel} and {attr_value_is_valid_expr}
+{{indent}})'''
+'''
+:attr:`beartype.vale.IsAttr`-specific code snippet validating an arbitrary
+object to define an attribute with an arbitrary name satisfying an arbitrary
+expression evaluating to a boolean.
+'''
+
+
+_VALE_CODE_CHECK_ISATTR_VALUE_EXPR_RAW = (
+    'getattr({{obj}}, {attr_name_expr}, {local_name_sentinel})')
+'''
+:attr:`beartype.vale.IsAttr`-specific Python expression inefficiently yielding
+the value of the attribute with an arbitrary name of an arbitrary object to be
+validated.
+'''
+
+
+VALE_CODE_CHECK_ISATTR_VALUE_EXPR = (
+    f'({{local_name_attr_value}} := {_VALE_CODE_CHECK_ISATTR_VALUE_EXPR_RAW})')
+'''
+:attr:`beartype.vale.IsAttr`-specific Python expression efficiently yielding
+the value of the attribute with an arbitrary name of an arbitrary object to be
+validated.
+
+For efficiency, this expression is optimized to localize this value to a local
+variable whose name *must* be uniquified and formatted by the caller into the
+``local_name_attr_value`` format variable.
+'''
+
+# ....................{ METHODS                            }....................
+# Format methods of the code snippets declared above as a microoptimization.
+
+VALE_CODE_CHECK_ISATTR_TEST_format = VALE_CODE_CHECK_ISATTR_TEST.format
+VALE_CODE_CHECK_ISATTR_VALUE_EXPR_format = (
+    VALE_CODE_CHECK_ISATTR_VALUE_EXPR.format)
+VALE_CODE_CHECK_ISEQUAL_TEST_format = VALE_CODE_CHECK_ISEQUAL_TEST.format
+VALE_CODE_CHECK_ISINSTANCE_TEST_format = VALE_CODE_CHECK_ISINSTANCE_TEST.format
+VALE_CODE_CHECK_ISSUBCLASS_TEST_format = VALE_CODE_CHECK_ISSUBCLASS_TEST.format
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_util/_valeutiltext.py
@@ -0,0 +1,111 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype validator text utilities** (i.e., callables performing low-level
+string-centric operations on behalf of higher-level beartype validators).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.roar._roarexc import _BeartypeValeUtilException
+from beartype.typing import Optional
+from beartype._cave._cavemap import NoneTypeOr
+
+# ....................{ FORMATTERS                         }....................
+def format_diagnosis_line(
+    # Mandatory parameters.
+    validator_repr: str,
+    indent_level_outer: str,
+    indent_level_inner: str,
+
+    # Optional parameters.
+    is_obj_valid: Optional[bool] = None,
+) -> str:
+    '''
+    Single line of a larger human-readable **validation failure diagnosis**
+    (i.e., substring describing how an arbitrary object either satisfies *or*
+    violates an arbitrary validator), formatted with the passed indentation
+    level and boolean value.
+
+    Parameters
+    ----------
+    validator_repr : str
+        **Validator representation** (i.e., unformatted single line of a larger
+        diagnosis report to be formatted by this function).
+    indent_level_outer : str
+        **Outermost indentation level** (i.e., zero or more adjacent spaces
+        prefixing each line of the returned substring).
+    indent_level_inner : str
+        **Innermost indentation level** (i.e., zero or more adjacent spaces
+        delimiting the human-readable representation of the tri-state boolean
+        and validator representation in the returned substring).
+    is_obj_valid : Optional[bool]
+        Tri-state boolean such that:
+
+        * If ``True``, that arbitrary object satisfies the beartype validator
+          described by this specific line.
+        * If ``False``, that arbitrary object violates the beartype validator
+          described by this specific line.
+        * If ``None``, this specific line is entirely syntactic (e.g., a
+          suffixing ")" delimiter) isolated to its own discrete line for
+          readability. In this case, this line does *not* describe how an
+          arbitrary object either satisfies *or* violates an arbitrary
+          validator.
+
+        Defaults to ``None``.
+
+    Returns
+    ----------
+    str
+        This diagnosis line formatted with this indentation level.
+
+    Raises
+    ----------
+    _BeartypeValeUtilException
+        If ``is_obj_valid`` is *not* a **tri-state boolean** (i.e., either
+        ``True``, ``False``, or ``None``).
+    '''
+    assert isinstance(validator_repr, str), (
+        f'{repr(validator_repr)} not string.')
+    assert isinstance(indent_level_outer, str), (
+        f'{repr(indent_level_outer)} not string.')
+    assert isinstance(indent_level_inner, str), (
+        f'{repr(indent_level_inner)} not string.')
+
+    # If "is_obj_valid" is *NOT* a tri-state boolean, raise an exception.
+    #
+    # Note that this condition is intentionally validated with full-blown
+    # exception handling rather than a simple "assert" statement. This condition
+    # was previously implemented via a simple "assert" statement, which then
+    # raised a non-human-readable assertion in an end user issue. *OH, GODS!*
+    if not isinstance(is_obj_valid, NoneTypeOr[bool]):
+        raise _BeartypeValeUtilException(
+            f'beartype.vale._valeutiltext.format_diagnosis_line() parameter '
+            f'"is_obj_valid" value {repr(is_obj_valid)} '
+            f'not tri-state boolean for '
+            f'validator representation: {validator_repr}'
+        )
+    # Else, "is_obj_valid" is a tri-state boolean.
+
+    # String representing this boolean value, padded with spaces on the left as
+    # needed to produce a column-aligned line diagnosis resembling:
+    #     False == (
+    #      True ==     Is[lambda foo: foo.x + foo.y >= 0] &
+    #     False ==     Is[lambda foo: foo.x + foo.y <= 10]
+    #              )
+    is_obj_valid_str = ''
+    if   is_obj_valid is True:  is_obj_valid_str = ' True == '
+    elif is_obj_valid is False: is_obj_valid_str = 'False == '
+    else:                       is_obj_valid_str = '         '
+
+    # Do one thing and do it well.
+    return (
+        f'{indent_level_outer}'
+        f'{is_obj_valid_str}'
+        f'{indent_level_inner}'
+        f'{validator_repr}'
+    )
--- /dev/null
+++ aptc-1.0/src/spdx/lib/beartype/vale/_util/_valeutiltyping.py
@@ -0,0 +1,55 @@
+#!/usr/bin/env python3
+# --------------------( LICENSE                            )--------------------
+# Copyright (c) 2014-2024 Beartype authors.
+# See "LICENSE" for further details.
+
+'''
+**Beartype validator PEP-compliant type hints** (i.e., hints annotating callables
+declared throughout the :mod:`beartype.vale` subpackage, either for compliance
+with :pep:`561` or simply for documentation purposes).
+
+This private submodule is *not* intended for importation by downstream callers.
+'''
+
+# ....................{ IMPORTS                            }....................
+from beartype.typing import (
+    Callable,
+    Union,
+)
+
+# ....................{ HINTS                              }....................
+BeartypeValidatorRepresenter = Union[str, Callable[[], str]]
+'''
+PEP-compliant type hint matching a **beartype validator representer** (i.e.,
+either a string *or* caller-defined callable accepting no arguments returning a
+machine-readable representation of a beartype validator).
+
+Technically, this representation *could* be passed by the caller rather than
+this callable dynamically generating that representation. Pragmatically,
+generating this representation is sufficiently slow for numerous types of
+validators that deferring their generation until required by a call to the
+:meth:`__repr__` dunder method externally called by a call to the :func:`repr`
+builtin` on this validator is effectively mandatory. Validators whose
+representations are particularly slow to generate include:
+
+* The :class:`beartype.vale.Is` class subscripted by a lambda rather than
+  non-lambda function. Generating the representation of that class subscripted
+  by a non-lambda function only requires introspecting the name of that function
+  and is thus trivially fast. However, lambda functions have no names and are
+  thus *only* distinguishable by their source code; generating the
+  representation of that class subscripted by a lambda function requires parsing
+  the source code of the file declaring that lambda for the exact substring of
+  that code declaring that lambda.
+'''
+
+
+BeartypeValidatorTester = Callable[[object], bool]
+'''
+PEP-compliant type hint matching a **beartype validator tester** (i.e.,
+caller-defined callable accepting a single arbitrary object and returning
+either :data:`True` if that object satisfies an arbitrary constraint *or*
+:data:`True` otherwise).
+
+Beartype validator testers are suitable for subscripting functional beartype
+validator factories (e.g., :attr:`beartype.vale.Is`).
+'''
